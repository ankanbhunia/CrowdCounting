INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:10.2249022484, MAE: 101.2080616, MSE: 101.208062004
INFO:root:(Meta-testing) test MAE: 101.541422653, MSE: 101.541423512
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.92773497105, MAE: 3.70236587524, MSE: 3.70236584572
INFO:root:(Meta-training) post train loss: 2.13366699219, MAE: 37.6027603149, MSE: 37.6027595968
INFO:root:(Meta-training) pre-training test MAE: 6.88640213013, MSE: 6.88640217694
INFO:root:(Meta-training) post-training test MAE: 40.4782524109, MSE: 40.4782520818
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-43.9210, device='cuda:0'), 'backend.0.bias': tensor(0.0013, device='cuda:0'), 'backend.10.weight': tensor(-2.8210, device='cuda:0'), 'backend.8.bias': tensor(-0.1662, device='cuda:0'), 'backend.6.weight': tensor(-52.1225, device='cuda:0'), 'backend.2.bias': tensor(-0.0119, device='cuda:0'), 'backend.10.bias': tensor(0.1539, device='cuda:0'), 'output_layer.bias': tensor(-30.3483, device='cuda:0'), 'backend.2.weight': tensor(-93.3561, device='cuda:0'), 'backend.6.bias': tensor(-0.0265, device='cuda:0'), 'backend.0.weight': tensor(-21.5634, device='cuda:0'), 'output_layer.weight': tensor(-5.2881, device='cuda:0'), 'backend.4.weight': tensor(-96.7639, device='cuda:0'), 'backend.4.bias': tensor(-0.0339, device='cuda:0')}
INFO:root:==> Training scene: 2
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.4576377869, MAE: 14.0155792236, MSE: 14.0155792746
INFO:root:(Meta-training) post train loss: 28.2439670563, MAE: 246.063415527, MSE: 246.063412813
INFO:root:(Meta-training) pre-training test MAE: 8.87585067749, MSE: 8.875850583
INFO:root:(Meta-training) post-training test MAE: 235.911209106, MSE: 235.911207144
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-1020.3315, device='cuda:0'), 'backend.0.bias': tensor(-0.1067, device='cuda:0'), 'backend.10.weight': tensor(-2049.0601, device='cuda:0'), 'backend.8.bias': tensor(-5.0614, device='cuda:0'), 'backend.6.weight': tensor(-1269.1802, device='cuda:0'), 'backend.2.bias': tensor(-0.5702, device='cuda:0'), 'backend.10.bias': tensor(-49.0951, device='cuda:0'), 'output_layer.bias': tensor(-201.3320, device='cuda:0'), 'backend.2.weight': tensor(-2259.5662, device='cuda:0'), 'backend.6.bias': tensor(-1.0513, device='cuda:0'), 'backend.0.weight': tensor(-684.9735, device='cuda:0'), 'output_layer.weight': tensor(-48.6112, device='cuda:0'), 'backend.4.weight': tensor(-2496.1777, device='cuda:0'), 'backend.4.bias': tensor(-1.3279, device='cuda:0')}
INFO:root:==> Training scene: 3
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.215716362, MAE: 12.3267059326, MSE: 12.3267058703
INFO:root:(Meta-training) post train loss: 13.1575832367, MAE: 155.954437256, MSE: 155.95443921
INFO:root:(Meta-training) pre-training test MAE: 17.9829978943, MSE: 17.9829979178
INFO:root:(Meta-training) post-training test MAE: 149.803665161, MSE: 149.803667084
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-411.3130, device='cuda:0'), 'backend.0.bias': tensor(-0.1084, device='cuda:0'), 'backend.10.weight': tensor(-577.3652, device='cuda:0'), 'backend.8.bias': tensor(-1.6774, device='cuda:0'), 'backend.6.weight': tensor(-752.4664, device='cuda:0'), 'backend.2.bias': tensor(-0.3534, device='cuda:0'), 'backend.10.bias': tensor(-13.2628, device='cuda:0'), 'output_layer.bias': tensor(-113.9395, device='cuda:0'), 'backend.2.weight': tensor(-1495.3204, device='cuda:0'), 'backend.6.bias': tensor(-0.6486, device='cuda:0'), 'backend.0.weight': tensor(-532.8894, device='cuda:0'), 'output_layer.weight': tensor(-24.8956, device='cuda:0'), 'backend.4.weight': tensor(-1443.4893, device='cuda:0'), 'backend.4.bias': tensor(-0.7667, device='cuda:0')}
INFO:root:==> Training scene: 4
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.40858054161, MAE: 3.46781778336, MSE: 3.46781785142
INFO:root:(Meta-training) post train loss: 1.24631130695, MAE: 40.1663703918, MSE: 40.1663700161
INFO:root:(Meta-training) pre-training test MAE: 5.10420227051, MSE: 5.1042023119
INFO:root:(Meta-training) post-training test MAE: 38.2077407837, MSE: 38.207740327
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-22.4932, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(-6.9668, device='cuda:0'), 'backend.8.bias': tensor(-0.0887, device='cuda:0'), 'backend.6.weight': tensor(1.9747, device='cuda:0'), 'backend.2.bias': tensor(-0.0034, device='cuda:0'), 'backend.10.bias': tensor(-0.2023, device='cuda:0'), 'output_layer.bias': tensor(-28.7350, device='cuda:0'), 'backend.2.weight': tensor(-43.8065, device='cuda:0'), 'backend.6.bias': tensor(0.0327, device='cuda:0'), 'backend.0.weight': tensor(-7.9347, device='cuda:0'), 'output_layer.weight': tensor(-4.6944, device='cuda:0'), 'backend.4.weight': tensor(-74.9707, device='cuda:0'), 'backend.4.bias': tensor(-0.0318, device='cuda:0')}
INFO:root:==> Training scene: 5
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.464849472, MAE: 11.5086917877, MSE: 11.5086915716
INFO:root:(Meta-training) post train loss: 12.0098371506, MAE: 157.504074097, MSE: 157.504073608
INFO:root:(Meta-training) pre-training test MAE: 6.65334415436, MSE: 6.65334403491
INFO:root:(Meta-training) post-training test MAE: 148.859954834, MSE: 148.859958046
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-168.4951, device='cuda:0'), 'backend.0.bias': tensor(-0.0335, device='cuda:0'), 'backend.10.weight': tensor(-512.0421, device='cuda:0'), 'backend.8.bias': tensor(-0.8689, device='cuda:0'), 'backend.6.weight': tensor(-290.6689, device='cuda:0'), 'backend.2.bias': tensor(-0.2067, device='cuda:0'), 'backend.10.bias': tensor(-12.1426, device='cuda:0'), 'output_layer.bias': tensor(-113.5457, device='cuda:0'), 'backend.2.weight': tensor(-810.5502, device='cuda:0'), 'backend.6.bias': tensor(-0.2528, device='cuda:0'), 'backend.0.weight': tensor(-189.6143, device='cuda:0'), 'output_layer.weight': tensor(-21.5855, device='cuda:0'), 'backend.4.weight': tensor(-870.6675, device='cuda:0'), 'backend.4.bias': tensor(-0.5180, device='cuda:0')}
INFO:root:==> Training scene: 6
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.31700372696, MAE: 4.50811004639, MSE: 4.50810994402
INFO:root:(Meta-training) post train loss: 2.54581308365, MAE: 56.9175300598, MSE: 56.9175300291
INFO:root:(Meta-training) pre-training test MAE: 3.33308029175, MSE: 3.33308034573
INFO:root:(Meta-training) post-training test MAE: 57.6218566895, MSE: 57.6218562727
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-37.6213, device='cuda:0'), 'backend.0.bias': tensor(0.0053, device='cuda:0'), 'backend.10.weight': tensor(-48.7510, device='cuda:0'), 'backend.8.bias': tensor(-0.1999, device='cuda:0'), 'backend.6.weight': tensor(-3.2662, device='cuda:0'), 'backend.2.bias': tensor(-0.0192, device='cuda:0'), 'backend.10.bias': tensor(-1.0821, device='cuda:0'), 'output_layer.bias': tensor(-43.8108, device='cuda:0'), 'backend.2.weight': tensor(-99.3718, device='cuda:0'), 'backend.6.bias': tensor(0.0174, device='cuda:0'), 'backend.0.weight': tensor(-8.4586, device='cuda:0'), 'output_layer.weight': tensor(-7.1186, device='cuda:0'), 'backend.4.weight': tensor(-117.8177, device='cuda:0'), 'backend.4.bias': tensor(-0.0676, device='cuda:0')}
INFO:root:==> Training scene: 7
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.56835842133, MAE: 9.11410331726, MSE: 9.11410331697
INFO:root:(Meta-training) post train loss: 8.68908500671, MAE: 118.70375061, MSE: 118.703749217
INFO:root:(Meta-training) pre-training test MAE: 7.59414863586, MSE: 7.59414860186
INFO:root:(Meta-training) post-training test MAE: 119.183746338, MSE: 119.183747319
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-183.1739, device='cuda:0'), 'backend.0.bias': tensor(-0.0085, device='cuda:0'), 'backend.10.weight': tensor(-210.6387, device='cuda:0'), 'backend.8.bias': tensor(-0.9138, device='cuda:0'), 'backend.6.weight': tensor(-301.4147, device='cuda:0'), 'backend.2.bias': tensor(-0.1017, device='cuda:0'), 'backend.10.bias': tensor(-4.8148, device='cuda:0'), 'output_layer.bias': tensor(-90.9324, device='cuda:0'), 'backend.2.weight': tensor(-551.6276, device='cuda:0'), 'backend.6.bias': tensor(-0.2307, device='cuda:0'), 'backend.0.weight': tensor(-168.9219, device='cuda:0'), 'output_layer.weight': tensor(-16.1698, device='cuda:0'), 'backend.4.weight': tensor(-548.3022, device='cuda:0'), 'backend.4.bias': tensor(-0.2530, device='cuda:0')}
INFO:root:==> Training scene: 8
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.70169210434, MAE: 4.29832458496, MSE: 4.29832450693
INFO:root:(Meta-training) post train loss: 3.9628610611, MAE: 41.1326179504, MSE: 41.1326173725
INFO:root:(Meta-training) pre-training test MAE: 0.344522476196, MSE: 0.34452247522
INFO:root:(Meta-training) post-training test MAE: 45.7303619385, MSE: 45.730363144
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-90.5592, device='cuda:0'), 'backend.0.bias': tensor(-0.0234, device='cuda:0'), 'backend.10.weight': tensor(-131.2070, device='cuda:0'), 'backend.8.bias': tensor(-0.3804, device='cuda:0'), 'backend.6.weight': tensor(-169.8558, device='cuda:0'), 'backend.2.bias': tensor(-0.0816, device='cuda:0'), 'backend.10.bias': tensor(-2.6672, device='cuda:0'), 'output_layer.bias': tensor(-34.8099, device='cuda:0'), 'backend.2.weight': tensor(-365.8163, device='cuda:0'), 'backend.6.bias': tensor(-0.1439, device='cuda:0'), 'backend.0.weight': tensor(-121.5345, device='cuda:0'), 'output_layer.weight': tensor(-7.2147, device='cuda:0'), 'backend.4.weight': tensor(-379.3094, device='cuda:0'), 'backend.4.bias': tensor(-0.1953, device='cuda:0')}
INFO:root:==> Training scene: 9
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.31722784042, MAE: 1.57554912567, MSE: 1.57554914801
INFO:root:(Meta-training) post train loss: 4.04796648026, MAE: 13.7908353806, MSE: 13.7908351375
INFO:root:(Meta-training) pre-training test MAE: 5.13178634644, MSE: 5.13178641226
INFO:root:(Meta-training) post-training test MAE: 10.5187931061, MSE: 10.5187932721
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(12.7442, device='cuda:0'), 'backend.0.bias': tensor(0.0095, device='cuda:0'), 'backend.10.weight': tensor(-5.2698, device='cuda:0'), 'backend.8.bias': tensor(0.0464, device='cuda:0'), 'backend.6.weight': tensor(44.8917, device='cuda:0'), 'backend.2.bias': tensor(0.0177, device='cuda:0'), 'backend.10.bias': tensor(-0.2285, device='cuda:0'), 'output_layer.bias': tensor(-7.7328, device='cuda:0'), 'backend.2.weight': tensor(82.0613, device='cuda:0'), 'backend.6.bias': tensor(0.0495, device='cuda:0'), 'backend.0.weight': tensor(42.8594, device='cuda:0'), 'output_layer.weight': tensor(-1.1357, device='cuda:0'), 'backend.4.weight': tensor(46.6689, device='cuda:0'), 'backend.4.bias': tensor(0.0206, device='cuda:0')}
INFO:root:==> Training scene: 10
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 2.62649679184, MAE: 0.140889167786, MSE: 0.14088916471
INFO:root:(Meta-training) post train loss: 1.72036874294, MAE: 8.40645599365, MSE: 8.40645601949
INFO:root:(Meta-training) pre-training test MAE: 2.28190612793, MSE: 2.28190613808
INFO:root:(Meta-training) post-training test MAE: 9.2960319519, MSE: 9.29603175338
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(29.3622, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(14.4824, device='cuda:0'), 'backend.8.bias': tensor(0.1243, device='cuda:0'), 'backend.6.weight': tensor(20.2014, device='cuda:0'), 'backend.2.bias': tensor(0.0180, device='cuda:0'), 'backend.10.bias': tensor(0.5394, device='cuda:0'), 'output_layer.bias': tensor(7.4570, device='cuda:0'), 'backend.2.weight': tensor(65.5934, device='cuda:0'), 'backend.6.bias': tensor(0.0065, device='cuda:0'), 'backend.0.weight': tensor(18.4875, device='cuda:0'), 'output_layer.weight': tensor(1.3642, device='cuda:0'), 'backend.4.weight': tensor(55.7639, device='cuda:0'), 'backend.4.bias': tensor(0.0333, device='cuda:0')}
INFO:root:==> Training scene: 11
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 20.0581626892, MAE: 3.79273986816, MSE: 3.79273981411
INFO:root:(Meta-training) post train loss: 15.4374341965, MAE: 60.0539627075, MSE: 60.0539633632
INFO:root:(Meta-training) pre-training test MAE: 1.65007305145, MSE: 1.65007306717
INFO:root:(Meta-training) post-training test MAE: 46.8975715637, MSE: 46.8975726901
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-285.1150, device='cuda:0'), 'backend.0.bias': tensor(-0.0562, device='cuda:0'), 'backend.10.weight': tensor(-397.6520, device='cuda:0'), 'backend.8.bias': tensor(-1.2813, device='cuda:0'), 'backend.6.weight': tensor(-501.0734, device='cuda:0'), 'backend.2.bias': tensor(-0.1695, device='cuda:0'), 'backend.10.bias': tensor(-8.2408, device='cuda:0'), 'output_layer.bias': tensor(-36.3815, device='cuda:0'), 'backend.2.weight': tensor(-722.0707, device='cuda:0'), 'backend.6.bias': tensor(-0.4861, device='cuda:0'), 'backend.0.weight': tensor(-277.7591, device='cuda:0'), 'output_layer.weight': tensor(-10.3747, device='cuda:0'), 'backend.4.weight': tensor(-798.2838, device='cuda:0'), 'backend.4.bias': tensor(-0.4068, device='cuda:0')}
INFO:root:==> Training scene: 12
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.26931238174, MAE: 9.15769100189, MSE: 9.15769098289
INFO:root:(Meta-training) post train loss: 5.25304222107, MAE: 128.482192993, MSE: 128.48219265
INFO:root:(Meta-training) pre-training test MAE: 4.61597824097, MSE: 4.61597820524
INFO:root:(Meta-training) post-training test MAE: 141.958709717, MSE: 141.958710161
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(260.6506, device='cuda:0'), 'backend.0.bias': tensor(0.0241, device='cuda:0'), 'backend.10.weight': tensor(468.7807, device='cuda:0'), 'backend.8.bias': tensor(1.2948, device='cuda:0'), 'backend.6.weight': tensor(381.9536, device='cuda:0'), 'backend.2.bias': tensor(0.2002, device='cuda:0'), 'backend.10.bias': tensor(12.5315, device='cuda:0'), 'output_layer.bias': tensor(110.0442, device='cuda:0'), 'backend.2.weight': tensor(951.6746, device='cuda:0'), 'backend.6.bias': tensor(0.2520, device='cuda:0'), 'backend.0.weight': tensor(256.8109, device='cuda:0'), 'output_layer.weight': tensor(24.2919, device='cuda:0'), 'backend.4.weight': tensor(1108.7393, device='cuda:0'), 'backend.4.bias': tensor(0.5716, device='cuda:0')}
INFO:root:==> Training scene: 13
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.15585327148, MAE: 0.122278213501, MSE: 0.122278211939
INFO:root:(Meta-training) post train loss: 6.03297472, MAE: 16.0758628845, MSE: 16.0758632778
INFO:root:(Meta-training) pre-training test MAE: 6.88552856445, MSE: 6.88552854815
INFO:root:(Meta-training) post-training test MAE: 24.3776416779, MSE: 24.3776415836
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(63.4808, device='cuda:0'), 'backend.0.bias': tensor(0.0233, device='cuda:0'), 'backend.10.weight': tensor(82.2610, device='cuda:0'), 'backend.8.bias': tensor(0.2575, device='cuda:0'), 'backend.6.weight': tensor(116.4730, device='cuda:0'), 'backend.2.bias': tensor(0.0472, device='cuda:0'), 'backend.10.bias': tensor(1.7025, device='cuda:0'), 'output_layer.bias': tensor(19.4742, device='cuda:0'), 'backend.2.weight': tensor(230.1301, device='cuda:0'), 'backend.6.bias': tensor(0.0803, device='cuda:0'), 'backend.0.weight': tensor(113.1909, device='cuda:0'), 'output_layer.weight': tensor(4.3418, device='cuda:0'), 'backend.4.weight': tensor(236.4320, device='cuda:0'), 'backend.4.bias': tensor(0.1142, device='cuda:0')}
INFO:root:==> Training scene: 14
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.2247161865, MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post train loss: 11.210111618, MAE: 134.058197021, MSE: 134.058194861
INFO:root:(Meta-training) pre-training test MAE: 9.19702339172, MSE: 9.19702319208
INFO:root:(Meta-training) post-training test MAE: 132.986633301, MSE: 132.986635842
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-412.4717, device='cuda:0'), 'backend.0.bias': tensor(-0.0713, device='cuda:0'), 'backend.10.weight': tensor(-431.9966, device='cuda:0'), 'backend.8.bias': tensor(-1.9927, device='cuda:0'), 'backend.6.weight': tensor(-607.5501, device='cuda:0'), 'backend.2.bias': tensor(-0.2443, device='cuda:0'), 'backend.10.bias': tensor(-9.6424, device='cuda:0'), 'output_layer.bias': tensor(-102.2852, device='cuda:0'), 'backend.2.weight': tensor(-871.2704, device='cuda:0'), 'backend.6.bias': tensor(-0.6839, device='cuda:0'), 'backend.0.weight': tensor(-302.5320, device='cuda:0'), 'output_layer.weight': tensor(-20.8222, device='cuda:0'), 'backend.4.weight': tensor(-984.5856, device='cuda:0'), 'backend.4.bias': tensor(-0.5933, device='cuda:0')}
INFO:root:==> Training scene: 15
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.0185213089, MAE: 6.06261253357, MSE: 6.06261263084
INFO:root:(Meta-training) post train loss: 5.02552652359, MAE: 89.3602752686, MSE: 89.3602752293
INFO:root:(Meta-training) pre-training test MAE: 2.2882976532, MSE: 2.28829766213
INFO:root:(Meta-training) post-training test MAE: 88.706703186, MSE: 88.7067043381
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(73.9416, device='cuda:0'), 'backend.0.bias': tensor(-0.0452, device='cuda:0'), 'backend.10.weight': tensor(228.9542, device='cuda:0'), 'backend.8.bias': tensor(0.1953, device='cuda:0'), 'backend.6.weight': tensor(-42.0229, device='cuda:0'), 'backend.2.bias': tensor(-0.0187, device='cuda:0'), 'backend.10.bias': tensor(7.8502, device='cuda:0'), 'output_layer.bias': tensor(67.6426, device='cuda:0'), 'backend.2.weight': tensor(47.4639, device='cuda:0'), 'backend.6.bias': tensor(-0.2108, device='cuda:0'), 'backend.0.weight': tensor(-75.9561, device='cuda:0'), 'output_layer.weight': tensor(11.4994, device='cuda:0'), 'backend.4.weight': tensor(242.4803, device='cuda:0'), 'backend.4.bias': tensor(0.1128, device='cuda:0')}
INFO:root:==> Training scene: 16
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.7963008881, MAE: 16.1687660217, MSE: 16.1687657413
INFO:root:(Meta-training) post train loss: 22.4242420197, MAE: 229.407485962, MSE: 229.407482373
INFO:root:(Meta-training) pre-training test MAE: 6.00388336182, MSE: 6.00388337666
INFO:root:(Meta-training) post-training test MAE: 239.257141113, MSE: 239.257142984
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-988.6004, device='cuda:0'), 'backend.0.bias': tensor(-0.2824, device='cuda:0'), 'backend.10.weight': tensor(-1988.3594, device='cuda:0'), 'backend.8.bias': tensor(-5.0329, device='cuda:0'), 'backend.6.weight': tensor(-2082.1543, device='cuda:0'), 'backend.2.bias': tensor(-1.0028, device='cuda:0'), 'backend.10.bias': tensor(-44.8206, device='cuda:0'), 'output_layer.bias': tensor(-201.1472, device='cuda:0'), 'backend.2.weight': tensor(-3871.7910, device='cuda:0'), 'backend.6.bias': tensor(-2.2654, device='cuda:0'), 'backend.0.weight': tensor(-1286.4836, device='cuda:0'), 'output_layer.weight': tensor(-56.6222, device='cuda:0'), 'backend.4.weight': tensor(-4343.2554, device='cuda:0'), 'backend.4.bias': tensor(-2.4096, device='cuda:0')}
INFO:root:==> Training scene: 17
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 32.0257339478, MAE: 15.1991195679, MSE: 15.1991193617
INFO:root:(Meta-training) post train loss: 48.2651138306, MAE: 335.650817871, MSE: 335.650813719
INFO:root:(Meta-training) pre-training test MAE: 11.0977325439, MSE: 11.0977325598
INFO:root:(Meta-training) post-training test MAE: 336.292419434, MSE: 336.292422974
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-7079.0317, device='cuda:0'), 'backend.0.bias': tensor(-1.0678, device='cuda:0'), 'backend.10.weight': tensor(-9176.1621, device='cuda:0'), 'backend.8.bias': tensor(-32.7449, device='cuda:0'), 'backend.6.weight': tensor(-9999.3828, device='cuda:0'), 'backend.2.bias': tensor(-3.5476, device='cuda:0'), 'backend.10.bias': tensor(-201.9896, device='cuda:0'), 'output_layer.bias': tensor(-380.1562, device='cuda:0'), 'backend.2.weight': tensor(-13915.4082, device='cuda:0'), 'backend.6.bias': tensor(-10.0968, device='cuda:0'), 'backend.0.weight': tensor(-4359.9946, device='cuda:0'), 'output_layer.weight': tensor(-154.6839, device='cuda:0'), 'backend.4.weight': tensor(-14321.7207, device='cuda:0'), 'backend.4.bias': tensor(-7.5350, device='cuda:0')}
INFO:root:==> Training scene: 18
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.19173002243, MAE: 9.96483707428, MSE: 9.96483724213
INFO:root:(Meta-training) post train loss: 8.31142997742, MAE: 108.922950745, MSE: 108.92294976
INFO:root:(Meta-training) pre-training test MAE: 26.310459137, MSE: 26.31045865
INFO:root:(Meta-training) post-training test MAE: 94.4987640381, MSE: 94.4987650796
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-88.2468, device='cuda:0'), 'backend.0.bias': tensor(0.0020, device='cuda:0'), 'backend.10.weight': tensor(-150.8420, device='cuda:0'), 'backend.8.bias': tensor(-0.5698, device='cuda:0'), 'backend.6.weight': tensor(-90.5707, device='cuda:0'), 'backend.2.bias': tensor(-0.0589, device='cuda:0'), 'backend.10.bias': tensor(-4.4716, device='cuda:0'), 'output_layer.bias': tensor(-71.4431, device='cuda:0'), 'backend.2.weight': tensor(-212.6841, device='cuda:0'), 'backend.6.bias': tensor(-0.1036, device='cuda:0'), 'backend.0.weight': tensor(-35.0566, device='cuda:0'), 'output_layer.weight': tensor(-12.1312, device='cuda:0'), 'backend.4.weight': tensor(-304.2381, device='cuda:0'), 'backend.4.bias': tensor(-0.2161, device='cuda:0')}
INFO:root:==> Training scene: 19
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.85736942291, MAE: 15.1381454468, MSE: 15.1381455981
INFO:root:(Meta-training) post train loss: 11.7894163132, MAE: 200.715942383, MSE: 200.715945119
INFO:root:(Meta-training) pre-training test MAE: 19.7869281769, MSE: 19.786928058
INFO:root:(Meta-training) post-training test MAE: 196.792785645, MSE: 196.792790375
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-82.1093, device='cuda:0'), 'backend.0.bias': tensor(0.0720, device='cuda:0'), 'backend.10.weight': tensor(-106.0497, device='cuda:0'), 'backend.8.bias': tensor(-0.6434, device='cuda:0'), 'backend.6.weight': tensor(60.6098, device='cuda:0'), 'backend.2.bias': tensor(0.0389, device='cuda:0'), 'backend.10.bias': tensor(-4.0570, device='cuda:0'), 'output_layer.bias': tensor(-149.3103, device='cuda:0'), 'backend.2.weight': tensor(-19.7756, device='cuda:0'), 'backend.6.bias': tensor(0.1884, device='cuda:0'), 'backend.0.weight': tensor(94.8992, device='cuda:0'), 'output_layer.weight': tensor(-21.7000, device='cuda:0'), 'backend.4.weight': tensor(-218.3605, device='cuda:0'), 'backend.4.bias': tensor(-0.1340, device='cuda:0')}
INFO:root:==> Training scene: 20
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.6179828644, MAE: 19.8658561707, MSE: 19.8658564426
INFO:root:(Meta-training) post train loss: 23.238319397, MAE: 305.630065918, MSE: 305.630061308
INFO:root:(Meta-training) pre-training test MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post-training test MAE: 309.446746826, MSE: 309.446746731
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(58.7686, device='cuda:0'), 'backend.0.bias': tensor(0.1086, device='cuda:0'), 'backend.10.weight': tensor(-648.2241, device='cuda:0'), 'backend.8.bias': tensor(0.4562, device='cuda:0'), 'backend.6.weight': tensor(345.6557, device='cuda:0'), 'backend.2.bias': tensor(-0.1202, device='cuda:0'), 'backend.10.bias': tensor(-15.2989, device='cuda:0'), 'output_layer.bias': tensor(-243.9008, device='cuda:0'), 'backend.2.weight': tensor(-578.7978, device='cuda:0'), 'backend.6.bias': tensor(0.6730, device='cuda:0'), 'backend.0.weight': tensor(372.4923, device='cuda:0'), 'output_layer.weight': tensor(-42.9096, device='cuda:0'), 'backend.4.weight': tensor(-832.2754, device='cuda:0'), 'backend.4.bias': tensor(-0.4173, device='cuda:0')}
INFO:root:==> Training scene: 21
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.92966938019, MAE: 7.99254989624, MSE: 7.99255000362
INFO:root:(Meta-training) post train loss: 7.9303984642, MAE: 103.157707214, MSE: 103.157707881
INFO:root:(Meta-training) pre-training test MAE: 17.2073936462, MSE: 17.2073934943
INFO:root:(Meta-training) post-training test MAE: 94.2486724854, MSE: 94.2486737307
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-110.2387, device='cuda:0'), 'backend.0.bias': tensor(-0.0146, device='cuda:0'), 'backend.10.weight': tensor(-230.1305, device='cuda:0'), 'backend.8.bias': tensor(-0.4253, device='cuda:0'), 'backend.6.weight': tensor(-117.1572, device='cuda:0'), 'backend.2.bias': tensor(-0.0757, device='cuda:0'), 'backend.10.bias': tensor(-5.3008, device='cuda:0'), 'output_layer.bias': tensor(-71.6464, device='cuda:0'), 'backend.2.weight': tensor(-347.9861, device='cuda:0'), 'backend.6.bias': tensor(-0.0327, device='cuda:0'), 'backend.0.weight': tensor(-114.7507, device='cuda:0'), 'output_layer.weight': tensor(-14.5011, device='cuda:0'), 'backend.4.weight': tensor(-442.1409, device='cuda:0'), 'backend.4.bias': tensor(-0.2187, device='cuda:0')}
INFO:root:==> Training scene: 22
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.6123580933, MAE: 10.1582298279, MSE: 10.1582299753
INFO:root:(Meta-training) post train loss: 13.2736635208, MAE: 153.450256348, MSE: 153.450254052
INFO:root:(Meta-training) pre-training test MAE: 16.6812591553, MSE: 16.6812590741
INFO:root:(Meta-training) post-training test MAE: 142.571716309, MSE: 142.571713041
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-348.8337, device='cuda:0'), 'backend.0.bias': tensor(-0.1027, device='cuda:0'), 'backend.10.weight': tensor(-844.5209, device='cuda:0'), 'backend.8.bias': tensor(-1.7194, device='cuda:0'), 'backend.6.weight': tensor(-814.8105, device='cuda:0'), 'backend.2.bias': tensor(-0.4311, device='cuda:0'), 'backend.10.bias': tensor(-20.1072, device='cuda:0'), 'output_layer.bias': tensor(-113.4044, device='cuda:0'), 'backend.2.weight': tensor(-1628.4746, device='cuda:0'), 'backend.6.bias': tensor(-0.7616, device='cuda:0'), 'backend.0.weight': tensor(-452.7469, device='cuda:0'), 'output_layer.weight': tensor(-25.8738, device='cuda:0'), 'backend.4.weight': tensor(-1727.8400, device='cuda:0'), 'backend.4.bias': tensor(-1.0229, device='cuda:0')}
INFO:root:==> Training scene: 23
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 21.1111278534, MAE: 0.63020324707, MSE: 0.630203236541
INFO:root:(Meta-training) post train loss: 22.0809364319, MAE: 13.3690032959, MSE: 13.3690035203
INFO:root:(Meta-training) pre-training test MAE: 6.70138835907, MSE: 6.70138847426
INFO:root:(Meta-training) post-training test MAE: 37.1159133911, MSE: 37.1159138976
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(16.0166, device='cuda:0'), 'backend.0.bias': tensor(0.0425, device='cuda:0'), 'backend.10.weight': tensor(-114.7200, device='cuda:0'), 'backend.8.bias': tensor(-0.0449, device='cuda:0'), 'backend.6.weight': tensor(201.0809, device='cuda:0'), 'backend.2.bias': tensor(0.0558, device='cuda:0'), 'backend.10.bias': tensor(-2.8130, device='cuda:0'), 'output_layer.bias': tensor(-25.3122, device='cuda:0'), 'backend.2.weight': tensor(294.5784, device='cuda:0'), 'backend.6.bias': tensor(0.1817, device='cuda:0'), 'backend.0.weight': tensor(233.2811, device='cuda:0'), 'output_layer.weight': tensor(-4.9482, device='cuda:0'), 'backend.4.weight': tensor(177.3403, device='cuda:0'), 'backend.4.bias': tensor(0.0573, device='cuda:0')}
INFO:root:==> Training scene: 24
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.3689892292, MAE: 3.61751317978, MSE: 3.61751322588
INFO:root:(Meta-training) post train loss: 1.41690564156, MAE: 57.1678237915, MSE: 57.1678244841
INFO:root:(Meta-training) pre-training test MAE: 3.67163085938, MSE: 3.67163085126
INFO:root:(Meta-training) post-training test MAE: 62.9182167053, MSE: 62.9182159974
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(67.4449, device='cuda:0'), 'backend.0.bias': tensor(-0.0376, device='cuda:0'), 'backend.10.weight': tensor(95.9710, device='cuda:0'), 'backend.8.bias': tensor(0.2977, device='cuda:0'), 'backend.6.weight': tensor(-43.1883, device='cuda:0'), 'backend.2.bias': tensor(-0.0293, device='cuda:0'), 'backend.10.bias': tensor(3.6065, device='cuda:0'), 'output_layer.bias': tensor(48.0856, device='cuda:0'), 'backend.2.weight': tensor(-23.3053, device='cuda:0'), 'backend.6.bias': tensor(-0.1360, device='cuda:0'), 'backend.0.weight': tensor(-73.2256, device='cuda:0'), 'output_layer.weight': tensor(7.2894, device='cuda:0'), 'backend.4.weight': tensor(94.5628, device='cuda:0'), 'backend.4.bias': tensor(0.0419, device='cuda:0')}
INFO:root:==> Training scene: 25
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.78185081482, MAE: 3.64704179764, MSE: 3.647041789
INFO:root:(Meta-training) post train loss: 1.53377187252, MAE: 41.5643920898, MSE: 41.5643914043
INFO:root:(Meta-training) pre-training test MAE: 7.03860282898, MSE: 7.03860292617
INFO:root:(Meta-training) post-training test MAE: 38.4184913635, MSE: 38.4184912347
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(6.1834, device='cuda:0'), 'backend.0.bias': tensor(0.0124, device='cuda:0'), 'backend.10.weight': tensor(-7.2555, device='cuda:0'), 'backend.8.bias': tensor(0.0298, device='cuda:0'), 'backend.6.weight': tensor(31.5153, device='cuda:0'), 'backend.2.bias': tensor(0.0100, device='cuda:0'), 'backend.10.bias': tensor(-0.1930, device='cuda:0'), 'output_layer.bias': tensor(-28.9806, device='cuda:0'), 'backend.2.weight': tensor(31.5567, device='cuda:0'), 'backend.6.bias': tensor(0.0482, device='cuda:0'), 'backend.0.weight': tensor(44.4503, device='cuda:0'), 'output_layer.weight': tensor(-4.4127, device='cuda:0'), 'backend.4.weight': tensor(9.8322, device='cuda:0'), 'backend.4.bias': tensor(0.0038, device='cuda:0')}
INFO:root:==> Training scene: 26
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.51275110245, MAE: 4.93081665039, MSE: 4.93081656946
INFO:root:(Meta-training) post train loss: 6.66961336136, MAE: 63.5387802124, MSE: 63.5387796048
INFO:root:(Meta-training) pre-training test MAE: 1.70257949829, MSE: 1.70257951593
INFO:root:(Meta-training) post-training test MAE: 74.05909729, MSE: 74.0590980231
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-64.9164, device='cuda:0'), 'backend.0.bias': tensor(0.0207, device='cuda:0'), 'backend.10.weight': tensor(-215.7396, device='cuda:0'), 'backend.8.bias': tensor(-0.2159, device='cuda:0'), 'backend.6.weight': tensor(-53.6763, device='cuda:0'), 'backend.2.bias': tensor(0.0031, device='cuda:0'), 'backend.10.bias': tensor(-5.1249, device='cuda:0'), 'output_layer.bias': tensor(-58.9641, device='cuda:0'), 'backend.2.weight': tensor(-154.8734, device='cuda:0'), 'backend.6.bias': tensor(0.1189, device='cuda:0'), 'backend.0.weight': tensor(-51.5997, device='cuda:0'), 'output_layer.weight': tensor(-9.6605, device='cuda:0'), 'backend.4.weight': tensor(-269.6787, device='cuda:0'), 'backend.4.bias': tensor(-0.1026, device='cuda:0')}
INFO:root:==> Training scene: 27
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.81052994728, MAE: 3.4300737381, MSE: 3.43007370984
INFO:root:(Meta-training) post train loss: 1.85474944115, MAE: 49.2230949402, MSE: 49.2230950463
INFO:root:(Meta-training) pre-training test MAE: 0.405708312988, MSE: 0.405708318655
INFO:root:(Meta-training) post-training test MAE: 53.5645370483, MSE: 53.5645374102
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(21.7239, device='cuda:0'), 'backend.0.bias': tensor(-0.0415, device='cuda:0'), 'backend.10.weight': tensor(88.3675, device='cuda:0'), 'backend.8.bias': tensor(0.0254, device='cuda:0'), 'backend.6.weight': tensor(-91.4464, device='cuda:0'), 'backend.2.bias': tensor(-0.0413, device='cuda:0'), 'backend.10.bias': tensor(3.2484, device='cuda:0'), 'output_layer.bias': tensor(40.5884, device='cuda:0'), 'backend.2.weight': tensor(-47.4420, device='cuda:0'), 'backend.6.bias': tensor(-0.2370, device='cuda:0'), 'backend.0.weight': tensor(-68.5267, device='cuda:0'), 'output_layer.weight': tensor(6.0570, device='cuda:0'), 'backend.4.weight': tensor(54.8532, device='cuda:0'), 'backend.4.bias': tensor(-0.0010, device='cuda:0')}
INFO:root:==> Training scene: 28
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.91805839539, MAE: 16.495388031, MSE: 16.4953884269
INFO:root:(Meta-training) post train loss: 16.5992279053, MAE: 248.975204468, MSE: 248.975204275
INFO:root:(Meta-training) pre-training test MAE: 5.10612487793, MSE: 5.10612491749
INFO:root:(Meta-training) post-training test MAE: 254.839996338, MSE: 254.839992691
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-218.2436, device='cuda:0'), 'backend.0.bias': tensor(0.0600, device='cuda:0'), 'backend.10.weight': tensor(-483.3945, device='cuda:0'), 'backend.8.bias': tensor(-0.9689, device='cuda:0'), 'backend.6.weight': tensor(58.4666, device='cuda:0'), 'backend.2.bias': tensor(-0.1581, device='cuda:0'), 'backend.10.bias': tensor(-8.8787, device='cuda:0'), 'output_layer.bias': tensor(-200.1620, device='cuda:0'), 'backend.2.weight': tensor(-680.3275, device='cuda:0'), 'backend.6.bias': tensor(0.2169, device='cuda:0'), 'backend.0.weight': tensor(194.6782, device='cuda:0'), 'output_layer.weight': tensor(-33.2362, device='cuda:0'), 'backend.4.weight': tensor(-900.4709, device='cuda:0'), 'backend.4.bias': tensor(-0.4924, device='cuda:0')}
INFO:root:==> Training scene: 29
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.79754734039, MAE: 17.5090179443, MSE: 17.5090178007
INFO:root:(Meta-training) post train loss: 19.8869838715, MAE: 259.828735352, MSE: 259.828729647
INFO:root:(Meta-training) pre-training test MAE: 19.3920478821, MSE: 19.3920476916
INFO:root:(Meta-training) post-training test MAE: 262.822540283, MSE: 262.822539939
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-562.1874, device='cuda:0'), 'backend.0.bias': tensor(-0.0445, device='cuda:0'), 'backend.10.weight': tensor(-752.2290, device='cuda:0'), 'backend.8.bias': tensor(-2.6582, device='cuda:0'), 'backend.6.weight': tensor(-1082.9220, device='cuda:0'), 'backend.2.bias': tensor(-0.3633, device='cuda:0'), 'backend.10.bias': tensor(-19.6488, device='cuda:0'), 'output_layer.bias': tensor(-208.3302, device='cuda:0'), 'backend.2.weight': tensor(-1791.1677, device='cuda:0'), 'backend.6.bias': tensor(-0.9017, device='cuda:0'), 'backend.0.weight': tensor(-419.6158, device='cuda:0'), 'output_layer.weight': tensor(-41.2734, device='cuda:0'), 'backend.4.weight': tensor(-1991.5450, device='cuda:0'), 'backend.4.bias': tensor(-0.9737, device='cuda:0')}
INFO:root:==> Training scene: 30
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.79670476913, MAE: 2.56892776489, MSE: 2.56892779772
INFO:root:(Meta-training) post train loss: 5.1647310257, MAE: 24.4140777588, MSE: 24.4140775
INFO:root:(Meta-training) pre-training test MAE: 1.84230804443, MSE: 1.84230806249
INFO:root:(Meta-training) post-training test MAE: 22.7580795288, MSE: 22.7580793518
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-46.0849, device='cuda:0'), 'backend.0.bias': tensor(-0.0036, device='cuda:0'), 'backend.10.weight': tensor(-73.4196, device='cuda:0'), 'backend.8.bias': tensor(-0.1900, device='cuda:0'), 'backend.6.weight': tensor(-62.4307, device='cuda:0'), 'backend.2.bias': tensor(-0.0266, device='cuda:0'), 'backend.10.bias': tensor(-1.6552, device='cuda:0'), 'output_layer.bias': tensor(-17.0427, device='cuda:0'), 'backend.2.weight': tensor(-127.3669, device='cuda:0'), 'backend.6.bias': tensor(-0.0366, device='cuda:0'), 'backend.0.weight': tensor(-25.0341, device='cuda:0'), 'output_layer.weight': tensor(-3.4376, device='cuda:0'), 'backend.4.weight': tensor(-128.4538, device='cuda:0'), 'backend.4.bias': tensor(-0.0640, device='cuda:0')}
INFO:root:==> Training scene: 31
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.92816901207, MAE: 6.54268741608, MSE: 6.54268743565
INFO:root:(Meta-training) post train loss: 3.94747591019, MAE: 79.0179595947, MSE: 79.0179592917
INFO:root:(Meta-training) pre-training test MAE: 2.77071666718, MSE: 2.77071666233
INFO:root:(Meta-training) post-training test MAE: 81.9200592041, MSE: 81.9200585699
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-42.4968, device='cuda:0'), 'backend.0.bias': tensor(0.0191, device='cuda:0'), 'backend.10.weight': tensor(-89.6895, device='cuda:0'), 'backend.8.bias': tensor(-0.1760, device='cuda:0'), 'backend.6.weight': tensor(25.6620, device='cuda:0'), 'backend.2.bias': tensor(-0.0125, device='cuda:0'), 'backend.10.bias': tensor(-2.3425, device='cuda:0'), 'output_layer.bias': tensor(-62.3058, device='cuda:0'), 'backend.2.weight': tensor(-101.7161, device='cuda:0'), 'backend.6.bias': tensor(0.0798, device='cuda:0'), 'backend.0.weight': tensor(28.3380, device='cuda:0'), 'output_layer.weight': tensor(-10.7214, device='cuda:0'), 'backend.4.weight': tensor(-192.2546, device='cuda:0'), 'backend.4.bias': tensor(-0.0999, device='cuda:0')}
INFO:root:==> Training scene: 32
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.5723743439, MAE: 3.49564743042, MSE: 3.49564744882
INFO:root:(Meta-training) post train loss: 8.17095565796, MAE: 36.8633918762, MSE: 36.8633919759
INFO:root:(Meta-training) pre-training test MAE: 3.27803039551, MSE: 3.27803041451
INFO:root:(Meta-training) post-training test MAE: 33.7333984375, MSE: 33.733397971
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-57.7676, device='cuda:0'), 'backend.0.bias': tensor(-0.0101, device='cuda:0'), 'backend.10.weight': tensor(-168.3620, device='cuda:0'), 'backend.8.bias': tensor(-0.3028, device='cuda:0'), 'backend.6.weight': tensor(-124.5957, device='cuda:0'), 'backend.2.bias': tensor(-0.0514, device='cuda:0'), 'backend.10.bias': tensor(-3.7852, device='cuda:0'), 'output_layer.bias': tensor(-26.0408, device='cuda:0'), 'backend.2.weight': tensor(-202.6724, device='cuda:0'), 'backend.6.bias': tensor(-0.1367, device='cuda:0'), 'backend.0.weight': tensor(-33.2300, device='cuda:0'), 'output_layer.weight': tensor(-5.5099, device='cuda:0'), 'backend.4.weight': tensor(-261.8801, device='cuda:0'), 'backend.4.bias': tensor(-0.1489, device='cuda:0')}
INFO:root:===> Updating meta network
INFO:root:===> Gradients updated: {'backend.8.weight': tensor([[[[ 7.7916e-01,  8.5606e-01,  7.9228e-01],
          [ 9.0868e-01,  7.7736e-01,  6.4876e-01],
          [ 9.0064e-01,  9.4987e-01,  7.5752e-01]],

         [[ 1.1307e-01,  1.0704e-01,  9.0648e-02],
          [ 1.2796e-01,  1.0473e-01,  1.2942e-01],
          [ 1.3047e-01,  1.6048e-01,  1.4018e-01]],

         [[ 7.5768e-01,  7.1184e-01,  8.0713e-01],
          [ 7.5325e-01,  7.6828e-01,  8.4883e-01],
          [ 6.4983e-01,  8.1942e-01,  6.6784e-01]],

         ...,

         [[ 4.8735e-03,  5.3942e-03,  5.6950e-03],
          [ 4.0224e-03,  5.7926e-03,  2.3920e-03],
          [ 5.1352e-03,  6.9414e-03,  1.8357e-03]],

         [[ 2.1338e-02,  1.4164e-02,  1.3132e-02],
          [ 1.4678e-02,  1.8111e-02,  1.2113e-02],
          [ 1.1622e-02,  1.0919e-02,  8.9136e-03]],

         [[ 8.8305e-01,  8.2144e-01,  7.5310e-01],
          [ 8.2313e-01,  8.4059e-01,  7.4162e-01],
          [ 8.5086e-01,  7.3575e-01,  7.3748e-01]]],


        [[[-4.9812e-01, -5.0378e-01, -5.1191e-01],
          [-4.0563e-01, -2.9149e-01, -3.7377e-01],
          [-2.8067e-01, -3.3813e-01, -3.9142e-01]],

         [[-3.6184e-02, -4.4534e-02, -3.7252e-02],
          [-3.7536e-02, -2.0504e-02, -3.5803e-02],
          [-3.6210e-02, -6.8325e-02, -4.4340e-02]],

         [[-3.7382e-01, -3.9211e-01, -4.3686e-01],
          [-4.6847e-01, -4.9453e-01, -5.1677e-01],
          [-5.1365e-01, -5.5016e-01, -3.8768e-01]],

         ...,

         [[-5.0242e-03, -1.1525e-03, -2.1685e-03],
          [-3.8029e-03, -3.3366e-03, -1.4325e-03],
          [-3.0780e-03, -4.2159e-03, -4.6185e-03]],

         [[-5.8556e-03, -1.7622e-02, -2.0925e-02],
          [-2.2585e-02, -2.9422e-02, -2.1775e-02],
          [-1.7520e-02, -1.5502e-02, -9.9940e-03]],

         [[-3.5619e-01, -4.2216e-01, -4.5200e-01],
          [-4.1187e-01, -5.1697e-01, -4.8196e-01],
          [-2.5478e-01, -2.9194e-01, -3.7740e-01]]],


        [[[-5.0192e-01, -1.6550e-01, -3.0480e-01],
          [-4.3924e-01, -2.2387e-01, -4.2957e-01],
          [-2.3618e-01, -4.3159e-01, -5.8229e-01]],

         [[-1.4858e-02, -4.3006e-02, -5.9082e-02],
          [-6.6482e-03, -6.0454e-02, -7.7891e-02],
          [-2.2637e-02, -5.3769e-02, -7.4317e-02]],

         [[ 8.3277e-02,  2.6160e-02, -2.1678e-01],
          [-1.3345e-01, -2.8881e-01, -1.2474e-01],
          [-3.7338e-01, -2.9140e-01, -1.1983e-01]],

         ...,

         [[-8.1383e-03, -4.9585e-03, -2.1029e-03],
          [-4.4008e-03, -1.6208e-03,  3.1504e-03],
          [-6.1087e-04,  1.2553e-03, -5.3142e-03]],

         [[ 1.1792e-02, -2.7062e-03, -3.8844e-03],
          [-1.7545e-03, -1.5361e-02, -9.7135e-03],
          [-3.5432e-03, -5.4996e-03, -2.7222e-03]],

         [[-7.8808e-03, -2.6094e-01, -2.7988e-01],
          [-1.4145e-01, -1.4226e-01, -3.1542e-01],
          [ 2.1230e-02, -2.0337e-01, -2.4090e-01]]],


        ...,


        [[[-2.9929e-01, -3.0268e-01, -2.6287e-01],
          [-2.9783e-01, -3.2070e-01, -2.3949e-01],
          [-3.1233e-01, -3.2161e-01, -2.6809e-01]],

         [[-3.4950e-02, -4.1251e-02, -3.6930e-02],
          [-3.8473e-02, -3.4362e-02, -3.8018e-02],
          [-3.6614e-02, -3.9380e-02, -3.5096e-02]],

         [[-1.7141e-01, -1.5779e-01, -1.4476e-01],
          [-1.7421e-01, -1.4054e-01, -1.5374e-01],
          [-1.1284e-01, -1.3553e-01, -1.4858e-01]],

         ...,

         [[-3.5639e-03, -2.7828e-03, -2.7395e-03],
          [-3.8445e-03, -3.7023e-03, -1.9841e-03],
          [-5.2669e-03, -4.6121e-03, -2.3858e-03]],

         [[-4.0673e-03, -2.9856e-03, -2.4181e-03],
          [-3.0785e-03, -2.0582e-03, -2.0236e-03],
          [-1.1365e-03, -2.0668e-03, -1.9190e-03]],

         [[-2.2178e-01, -2.4374e-01, -2.2302e-01],
          [-2.0329e-01, -2.1494e-01, -2.0253e-01],
          [-2.2834e-01, -2.2162e-01, -2.1170e-01]]],


        [[[-1.9047e-01, -5.0808e-01, -6.5154e-01],
          [-5.2507e-01, -5.0222e-01, -7.7457e-01],
          [-2.1515e-01,  8.5308e-02, -3.5444e-01]],

         [[ 3.1732e-02, -1.1143e-01,  1.3257e-02],
          [-6.2911e-02,  5.6852e-02, -3.5362e-02],
          [-4.4691e-02, -6.0706e-02, -1.5646e-02]],

         [[-2.1752e-01, -4.0753e-01,  1.6298e-01],
          [-2.4689e-01,  2.1465e-01, -1.9746e-01],
          [-3.6736e-01, -3.6167e-01, -3.7535e-01]],

         ...,

         [[-1.1183e-02, -9.8650e-03, -4.9529e-03],
          [-1.2928e-02, -9.7737e-03, -1.4051e-02],
          [-9.3565e-03, -6.5622e-03, -3.3314e-03]],

         [[ 8.0945e-03,  1.3654e-02,  8.0037e-03],
          [-5.6982e-03,  1.6571e-03, -4.8263e-03],
          [-4.1136e-03,  1.1965e-03,  4.5940e-03]],

         [[ 1.2224e-01,  3.1816e-01, -1.0589e-02],
          [-2.2472e-02, -3.1922e-01, -2.2589e-01],
          [ 2.7710e-03,  5.2608e-03,  1.2988e-02]]],


        [[[-4.9065e-01, -5.2073e-01, -5.2141e-01],
          [-6.1824e-01, -4.1892e-01, -5.3042e-01],
          [-7.6838e-01, -4.8344e-01, -6.1932e-01]],

         [[-1.0348e-01, -5.7851e-02, -8.9388e-02],
          [-8.2592e-02, -8.9406e-02, -8.5119e-02],
          [-9.8153e-02, -1.1333e-01, -1.1591e-01]],

         [[-5.3413e-01, -5.2772e-01, -4.8901e-01],
          [-3.7988e-01, -3.6942e-01, -5.1767e-01],
          [-4.2634e-01, -3.9946e-01, -4.8190e-01]],

         ...,

         [[-1.6936e-03, -4.2674e-03, -6.6556e-03],
          [-3.8204e-03, -4.7556e-03, -4.0910e-03],
          [-4.4072e-03, -1.1244e-03, -1.3581e-03]],

         [[-1.8637e-02, -5.6246e-03, -1.0103e-02],
          [-2.4521e-04, -1.3707e-03, -3.9373e-03],
          [-5.8170e-03, -9.9685e-03, -7.9207e-03]],

         [[-6.9425e-01, -5.7233e-01, -5.7277e-01],
          [-5.3208e-01, -6.1464e-01, -5.7705e-01],
          [-6.7009e-01, -4.8128e-01, -5.7393e-01]]]], device='cuda:0'), 'backend.0.bias': tensor([ 3.7435e-02,  8.6876e-03,  2.9687e-02,  9.5616e-02, -7.9372e-03,
        -2.2906e-01,  2.1799e-02,  1.2915e-01, -1.1742e-01,  5.3095e-02,
         6.5154e-02, -3.3857e-02, -1.8881e-01,  6.5475e-02,  1.1124e-01,
        -1.6869e-02, -9.0779e-02, -5.9172e-02, -1.5687e-02, -6.3608e-03,
        -1.0433e-01,  1.4869e-02,  2.4667e-01,  3.6992e-02, -5.4465e-02,
         1.1375e-02, -1.7108e-01, -2.9399e-02, -1.2781e-01, -2.2294e-02,
         5.0198e-02, -4.6588e-02, -4.9303e-02, -6.8110e-02, -1.1202e-01,
         1.1110e-01,  4.5686e-02,  1.5133e-01,  3.5387e-02, -2.8245e-02,
         4.8509e-02, -1.7623e-01,  1.0986e-01, -1.7990e-01,  3.6819e-02,
         6.6091e-03,  8.1264e-03,  1.3467e-01,  2.1311e-02, -2.2371e-02,
        -3.5823e-02,  1.0288e-01, -2.3761e-01,  1.0828e-01, -1.2286e-01,
         4.3771e-02,  9.0975e-02,  5.4302e-03,  6.3598e-03,  6.7666e-02,
        -8.3071e-03,  2.5766e-02,  1.2529e-01,  9.5696e-02, -3.2556e-02,
         1.1474e-03,  4.7837e-02, -1.0141e-01, -5.9006e-02,  1.1059e-01,
         1.9460e-03,  3.8479e-02,  1.3206e-02, -2.1734e-02, -5.8065e-03,
         5.6676e-02,  6.5931e-02,  2.8955e-02,  1.0560e-01,  8.2581e-03,
        -4.4968e-02,  1.1842e-03, -1.6334e-01,  3.3130e-02,  1.4979e-02,
        -5.1272e-02,  1.3311e-02, -1.1537e-01,  1.1990e-01, -2.9759e-03,
         2.5823e-02, -1.2387e-01,  3.3274e-02,  1.4201e-01, -1.8099e-02,
        -8.3501e-02, -1.2276e-01, -1.7765e-01, -1.7965e-01,  1.4993e-01,
        -2.8382e-04, -9.3293e-03,  1.3635e-01,  3.1087e-03,  3.3438e-02,
        -1.6648e-02, -3.7137e-02,  1.8646e-02, -1.6222e-02, -1.3726e-01,
        -2.6878e-02,  1.3328e-01, -2.0468e-02, -1.7347e-02,  1.0685e-01,
        -9.4509e-03, -3.3733e-02,  5.2323e-02, -6.5747e-02,  5.0566e-02,
         6.0394e-02, -2.3553e-02, -1.8967e-01,  6.2572e-03,  7.2336e-02,
        -1.7123e-02, -2.7193e-03, -9.6274e-02,  4.6956e-04, -2.2710e-01,
         6.5825e-03,  3.1451e-02, -7.9215e-03, -1.7999e-01,  1.5686e-01,
        -1.3606e-02, -3.6707e-02, -1.8343e-01,  1.3468e-01,  1.1925e-02,
        -1.4942e-02, -9.2967e-03,  3.1526e-02, -3.5561e-02,  8.4170e-03,
        -7.3547e-02,  6.9648e-02,  1.4172e-01, -5.6148e-02,  8.2015e-02,
         5.3280e-02,  9.1901e-02,  2.8384e-03, -1.3483e-02,  7.4776e-02,
         6.9650e-03, -2.7512e-02, -3.0703e-02, -2.0543e-01,  1.8875e-01,
         6.9804e-02,  3.3833e-02, -2.7313e-02, -2.0109e-01, -5.1882e-02,
         2.3691e-03,  1.0829e-01, -3.6844e-02, -8.6511e-02, -2.1700e-01,
        -7.0293e-02,  6.8957e-02,  3.1386e-02,  1.3123e-02, -3.2300e-02,
        -1.0123e-01,  8.2451e-02, -1.8404e-02,  2.7770e-02, -1.5899e-01,
         4.5792e-03,  1.1975e-02,  7.1419e-03,  4.3326e-03, -1.7068e-01,
        -3.9195e-02,  4.2245e-02,  8.9102e-02, -5.1279e-03, -5.4138e-02,
         1.3988e-03, -8.0117e-02, -5.2302e-02,  8.1205e-03,  1.2798e-01,
         8.6178e-02,  5.2950e-02,  7.4545e-02, -3.3941e-03,  1.7204e-01,
        -1.1362e-01,  1.4206e-01,  2.1858e-01,  9.2226e-02, -1.9899e-01,
         3.6389e-02, -1.1806e-01, -8.2608e-02,  9.6324e-02,  3.8894e-02,
        -4.3605e-03, -1.4082e-01,  8.5449e-02,  7.8835e-02,  4.1850e-02,
         1.1329e-02,  7.4670e-02,  6.7291e-02, -7.1616e-02, -1.5780e-01,
        -9.5883e-03, -2.2307e-02, -6.0844e-02,  9.7203e-02, -1.1720e-01,
         1.0030e-01, -1.0907e-02, -3.6493e-02, -2.5842e-04, -7.7157e-02,
        -1.7274e-01,  2.3191e-02, -1.9712e-02,  3.5280e-02, -1.4302e-01,
         1.2824e-02,  4.7918e-02, -1.6809e-01,  5.6044e-02,  7.4026e-02,
         2.2772e-02, -1.4494e-01, -4.2030e-02, -6.3802e-02,  1.2182e-02,
         4.3356e-02,  5.3708e-02,  4.2697e-02, -2.8499e-02,  1.4108e-01,
        -5.5321e-03,  9.1691e-02,  6.3696e-02, -3.4249e-02, -2.8303e-02,
        -5.3446e-02,  2.9556e-03, -5.0376e-02,  1.6559e-02,  1.2318e-01,
        -4.0798e-04, -9.3539e-02, -6.3955e-02, -1.3603e-02, -5.2657e-02,
         3.6484e-02, -9.6793e-02, -8.6375e-02,  4.8670e-04,  8.6016e-03,
        -1.0094e-01, -5.5460e-02, -6.2287e-03,  2.4522e-02,  1.6359e-01,
        -3.3313e-02,  4.5279e-02,  5.1331e-02, -1.2520e-01,  9.1646e-02,
        -5.9487e-02, -1.1458e-01, -6.1017e-02, -2.1344e-01,  2.6369e-02,
         1.8461e-02, -8.5298e-04,  3.9910e-01,  2.6680e-02, -1.6055e-01,
        -6.4645e-02, -5.6140e-02,  1.0158e-02, -1.4173e-02,  7.4239e-02,
         3.7757e-02, -7.6091e-02, -5.3069e-02,  4.9687e-02, -2.6026e-01,
        -1.8112e-01,  1.3090e-01,  2.7321e-02,  2.0811e-02,  3.8818e-02,
         4.0496e-02, -4.4816e-02, -3.4690e-02, -6.9139e-02,  1.2729e-01,
        -1.7978e-01,  3.2795e-02, -4.3860e-02,  9.0157e-02,  3.4749e-02,
        -5.8771e-02, -2.9962e-02, -2.5499e-03, -2.6117e-03, -3.0464e-02,
         4.8108e-02, -1.5034e-01,  4.0939e-02, -8.9531e-02, -2.2503e-02,
         2.5584e-02,  9.0479e-02,  6.8585e-02,  1.1664e-01, -1.2779e-02,
         1.4530e-02,  2.3291e-02, -8.2612e-02,  7.2054e-02,  6.5950e-03,
         5.9477e-02,  2.1410e-02, -1.0625e-01, -1.0625e-01, -8.5957e-02,
         8.7441e-02,  6.5847e-02,  1.9994e-02, -2.2160e-02, -7.1827e-02,
        -1.4756e-03, -2.1725e-02,  4.5513e-02,  4.6463e-02, -5.6595e-02,
         7.0407e-02, -7.1066e-02,  8.3108e-02,  7.8467e-02,  9.3380e-02,
         6.4081e-04,  4.0035e-02, -3.3871e-03,  4.2069e-02, -1.4598e-01,
         7.9622e-02,  1.4402e-01, -4.1291e-02,  4.3087e-02, -1.2321e-01,
        -1.4229e-01, -1.5477e-02, -1.5638e-01,  7.6901e-02, -1.8435e-02,
        -3.0861e-02, -7.7829e-02,  4.6241e-02,  1.0649e-01,  6.2955e-02,
         3.3868e-02,  5.2016e-02,  7.5417e-02, -1.0650e-01, -8.4428e-04,
        -1.1416e-01,  5.3098e-02,  1.0518e-01,  1.0734e-01, -8.4018e-02,
         1.3562e-01, -1.2334e-01, -4.9150e-02,  1.2403e-01, -8.0860e-02,
         1.4998e-01, -2.3119e-02,  1.0668e-01, -5.9597e-02, -1.0735e-02,
         4.4334e-02,  2.6920e-02, -5.7334e-02,  1.0288e-01,  2.2908e-01,
        -6.2294e-02,  4.3519e-02,  3.5141e-02, -3.7513e-02, -1.5320e-01,
        -1.7330e-01, -1.7242e-01,  1.1273e-01,  8.8120e-02,  1.7925e-02,
         1.5912e-01, -8.8506e-03,  3.6223e-03, -1.5002e-02, -9.1840e-02,
         2.3672e-02,  2.8329e-02,  2.2835e-02,  4.4367e-02, -6.7740e-02,
        -5.3699e-02, -3.3514e-03, -1.7343e-02, -9.4081e-03,  5.4577e-02,
        -5.9959e-02, -4.1871e-03, -5.1598e-02, -1.4495e-02, -7.0580e-02,
        -1.0849e-01,  1.7600e-01, -9.0256e-02,  1.1788e-01, -3.2405e-03,
         5.9323e-02, -6.7924e-02, -6.7785e-02,  3.3781e-02,  3.1116e-02,
        -1.1967e-01,  1.1624e-01, -6.5047e-02,  6.9481e-02,  3.6161e-02,
         1.8170e-02, -1.1415e-02, -2.2333e-02, -5.7601e-02,  4.2443e-02,
         1.4755e-02,  2.9848e-02,  9.0881e-02, -1.8336e-02, -1.7758e-01,
         6.6599e-02, -4.1333e-02, -5.6229e-02, -2.5875e-02, -1.4190e-01,
         2.3747e-03,  1.5122e-02,  8.3819e-03,  1.7196e-02,  4.8925e-02,
        -1.8419e-01,  1.6592e-04, -5.9003e-03, -2.3125e-01, -1.4528e-01,
         2.8598e-02,  4.2600e-02, -3.7204e-02,  1.2312e-02,  1.3099e-01,
        -3.3446e-02, -1.1550e-01, -3.2146e-02, -5.2977e-02,  3.4270e-02,
        -1.4025e-02, -7.2394e-03,  5.4485e-03, -2.1932e-02, -1.5543e-02,
         5.1916e-02,  6.7210e-03, -2.1290e-01,  8.3986e-02,  9.0954e-02,
        -1.9859e-02,  5.5643e-02,  7.0866e-02, -6.5067e-02, -1.8819e-02,
        -2.6500e-03, -1.0378e-02, -2.6327e-02,  1.3805e-01,  7.2932e-03,
         6.3785e-02, -1.9617e-02,  5.1562e-03, -6.8185e-02,  2.9798e-02,
         9.7752e-02,  1.3504e-01, -1.2660e-01,  6.2450e-04,  6.9422e-02,
         2.6582e-02,  5.3618e-02], device='cuda:0'), 'backend.10.weight': tensor([[[[-2.1959e-01, -3.3617e-01, -3.1556e-01],
          [-4.1270e-01, -3.4179e-01, -3.8507e-01],
          [-5.4396e-01, -5.1189e-01, -5.2420e-01]],

         [[-1.8068e-01, -1.1518e-01, -9.5161e-02],
          [-5.3012e-02, -3.9710e-02, -3.9326e-02],
          [-1.9610e-02, -1.2149e-02, -1.1782e-02]],

         [[-5.8630e-01, -4.5302e-01, -3.9153e-01],
          [-5.4708e-01, -2.9469e-01, -3.2340e-01],
          [-3.8501e-01, -3.9806e-01, -5.7451e-01]],

         ...,

         [[-9.7576e-02, -7.3513e-02, -7.1505e-02],
          [-5.3139e-02, -8.2464e-02, -6.4261e-02],
          [-5.2220e-02, -5.2127e-02, -5.7822e-02]],

         [[-7.6080e-01, -6.6570e-01, -8.5296e-01],
          [-6.0264e-01, -6.6787e-01, -6.7291e-01],
          [-1.1411e+00, -6.8185e-01, -6.6706e-01]],

         [[-1.8829e-01, -1.7583e-01, -2.0558e-01],
          [-1.6771e-01, -2.0710e-01, -3.6578e-01],
          [-1.1624e-01, -1.1664e-01, -1.4306e-01]]],


        [[[-2.3476e+00, -2.6140e+00, -2.5955e+00],
          [-3.0088e+00, -2.9354e+00, -2.9637e+00],
          [-3.3367e+00, -3.2346e+00, -3.2560e+00]],

         [[-3.5227e-01, -3.1430e-01, -2.8929e-01],
          [-3.8315e-01, -3.6267e-01, -3.4866e-01],
          [-1.9386e-01, -1.8508e-01, -1.6998e-01]],

         [[-2.3411e+00, -2.0769e+00, -1.9700e+00],
          [-2.4370e+00, -2.0338e+00, -2.0448e+00],
          [-1.9506e+00, -1.8898e+00, -2.0975e+00]],

         ...,

         [[-7.2566e-01, -7.4311e-01, -7.0555e-01],
          [-6.7706e-01, -7.6847e-01, -7.2329e-01],
          [-6.1617e-01, -6.6311e-01, -6.7481e-01]],

         [[-4.6668e+00, -4.4965e+00, -4.7603e+00],
          [-4.8601e+00, -4.4961e+00, -4.5276e+00],
          [-5.5612e+00, -4.5514e+00, -4.3601e+00]],

         [[-5.4382e-01, -5.9397e-01, -6.5607e-01],
          [-5.7638e-01, -6.7748e-01, -8.0152e-01],
          [-4.7273e-01, -5.1591e-01, -6.0473e-01]]],


        [[[ 5.0461e-01,  5.0912e-01,  5.1985e-01],
          [ 5.1670e-01,  5.3388e-01,  5.4456e-01],
          [ 5.2959e-01,  5.4138e-01,  5.4454e-01]],

         [[ 8.5475e-03,  1.2207e-02,  1.2803e-02],
          [ 2.4507e-02,  2.6864e-02,  2.6616e-02],
          [ 2.4521e-02,  2.6697e-02,  2.7364e-02]],

         [[ 1.6012e-01,  1.9595e-01,  1.9410e-01],
          [ 1.9142e-01,  2.1182e-01,  1.9630e-01],
          [ 1.9157e-01,  2.1010e-01,  2.0856e-01]],

         ...,

         [[ 1.0573e-01,  1.0355e-01,  1.0533e-01],
          [ 1.1294e-01,  1.1248e-01,  1.1330e-01],
          [ 1.1578e-01,  1.1593e-01,  1.1540e-01]],

         [[ 5.8945e-01,  6.1057e-01,  6.0976e-01],
          [ 5.8720e-01,  6.4044e-01,  6.4838e-01],
          [ 6.2204e-01,  6.5195e-01,  6.4490e-01]],

         [[ 3.2154e-02,  3.4026e-02,  2.0880e-02],
          [ 3.2994e-02,  4.0004e-02,  2.7592e-02],
          [ 3.6006e-02,  4.3411e-02,  3.7158e-02]]],


        ...,


        [[[ 1.8190e-01,  1.7046e-01,  1.6139e-01],
          [ 1.8184e-01,  1.8455e-01,  1.6810e-01],
          [ 1.5529e-01,  1.4892e-01,  1.3226e-01]],

         [[ 6.4872e-03,  1.1624e-02,  1.2358e-02],
          [ 5.4277e-02,  5.7847e-02,  5.7604e-02],
          [ 2.9974e-02,  3.2117e-02,  3.0282e-02]],

         [[ 7.2629e-02,  8.3997e-02,  7.7993e-02],
          [ 1.4803e-01,  1.6411e-01,  1.4653e-01],
          [ 1.2448e-01,  1.1466e-01,  9.5875e-02]],

         ...,

         [[ 2.1644e-02,  2.1378e-02,  2.0795e-02],
          [ 2.4206e-02,  2.2717e-02,  2.0400e-02],
          [ 1.9733e-02,  1.8385e-02,  1.5471e-02]],

         [[ 2.3900e-01,  2.4282e-01,  2.2168e-01],
          [ 2.5852e-01,  2.4316e-01,  2.4233e-01],
          [ 1.6480e-01,  1.7964e-01,  1.5443e-01]],

         [[ 1.5493e-02,  1.5617e-02,  2.1987e-02],
          [ 3.8231e-02,  3.1676e-02,  3.4201e-02],
          [ 3.2447e-02,  4.2885e-02,  4.5704e-02]]],


        [[[-1.1759e+00, -1.6960e+00, -1.5655e+00],
          [-2.0424e+00, -1.9111e+00, -1.9262e+00],
          [-2.5530e+00, -2.4313e+00, -2.4598e+00]],

         [[-5.2375e-01, -3.9010e-01, -3.5612e-01],
          [-1.7797e-01, -1.4278e-01, -1.5335e-01],
          [-5.4149e-02, -3.4321e-02, -4.5134e-02]],

         [[-2.4280e+00, -2.0517e+00, -1.8042e+00],
          [-2.3026e+00, -1.3931e+00, -1.5063e+00],
          [-1.5431e+00, -1.5189e+00, -2.2005e+00]],

         ...,

         [[-3.9746e-01, -3.2304e-01, -2.6708e-01],
          [-2.9420e-01, -3.7322e-01, -3.1304e-01],
          [-2.4681e-01, -2.3345e-01, -2.4592e-01]],

         [[-3.1743e+00, -3.0652e+00, -3.6059e+00],
          [-2.6640e+00, -2.7461e+00, -2.8847e+00],
          [-4.6844e+00, -3.0260e+00, -2.9310e+00]],

         [[-6.6746e-01, -6.5959e-01, -6.4882e-01],
          [-5.9409e-01, -7.4414e-01, -1.1450e+00],
          [-3.8093e-01, -3.7266e-01, -4.6022e-01]]],


        [[[-2.0956e-02, -2.0874e-02, -1.9518e-02],
          [-2.7313e-02, -2.4516e-02, -2.2938e-02],
          [-3.3471e-02, -3.3802e-02, -3.1649e-02]],

         [[-7.0705e-03, -8.3364e-03, -8.0706e-03],
          [-1.5045e-03, -2.1105e-03, -1.4246e-03],
          [-2.9152e-04, -2.5144e-04, -2.7530e-04]],

         [[-2.9277e-02, -2.6434e-02, -2.3441e-02],
          [-2.4026e-02, -2.1748e-02, -2.1338e-02],
          [-1.7061e-02, -2.5575e-02, -2.2425e-02]],

         ...,

         [[-3.2052e-03, -2.6869e-03, -1.9415e-03],
          [-1.3244e-03, -1.4512e-03, -1.2490e-03],
          [-1.7377e-03, -2.1666e-03, -1.5999e-03]],

         [[-3.7680e-02, -3.7452e-02, -3.5263e-02],
          [-3.3036e-02, -3.4708e-02, -2.4630e-02],
          [-4.1510e-02, -3.3301e-02, -3.4321e-02]],

         [[-1.6050e-02, -1.3616e-02, -1.1221e-02],
          [-9.7572e-03, -1.1921e-02, -1.2731e-02],
          [-5.4952e-03, -6.2393e-03, -4.1736e-03]]]], device='cuda:0'), 'backend.8.bias': tensor([ 4.9737e+00, -3.2972e+00, -1.2807e+00,  7.2608e-01, -1.5039e+00,
         1.6829e-01,  4.9959e-01, -2.1996e+00, -8.1899e-01, -1.3866e+00,
        -2.9949e-01, -4.3840e+00,  3.9718e-01, -3.1363e+00, -3.8491e+00,
        -2.6649e+00, -4.2858e-03, -5.9884e-01,  2.8110e+00, -2.2734e+00,
        -3.7313e-01,  7.8966e+00, -2.7427e-01, -4.5185e+00, -4.7506e-01,
         6.7307e+00,  2.4345e+00,  7.2646e+00, -3.2969e+00, -2.1476e+00,
        -1.9279e+00, -1.8337e+00, -1.6325e+00, -6.2015e-01, -9.9722e-01,
        -4.8325e+00,  2.9649e+00, -1.7396e+00, -1.6582e+00, -2.2803e+00,
         8.5869e-01,  3.3221e+00, -1.2001e+00,  9.5225e-02, -6.5972e-01,
         2.6132e+00, -3.0081e+00,  2.7432e+00, -2.9369e+00, -5.7038e-01,
        -4.1127e+00, -5.6515e+00, -3.8666e-01, -3.7298e+00,  7.6422e-01,
        -2.0456e+00, -2.0734e+00,  2.8771e-01, -2.2529e+00,  3.3025e+00,
         3.9578e+00, -2.1992e+00, -7.6606e-01, -1.0977e+00,  1.1326e-01,
        -3.4376e+00, -6.3099e-01, -7.0960e+00,  2.1510e+00,  1.8661e+00,
         2.0419e-01, -8.1414e-01,  4.6508e+00, -2.5497e+00, -4.1237e-01,
        -3.9497e+00,  2.1542e+00, -1.6452e+00, -1.1187e+00,  2.3748e+00,
        -5.8479e+00,  1.0999e+00,  9.7701e-02,  1.6046e+01, -1.4923e-01,
         3.7003e+00,  8.8302e-01, -4.3128e+00, -3.0774e+00,  5.0141e+00,
        -3.2504e+00,  2.5759e+00,  8.8290e-01, -1.0728e-01, -4.5347e-01,
        -2.7930e+00, -5.8308e+00, -1.6652e+00, -3.4447e-01, -4.6627e+00,
        -3.4878e+00, -2.0511e+00, -6.1619e-03,  5.6120e+00, -1.7160e-01,
        -5.2394e-01, -4.4822e-01,  1.6986e+00, -1.6533e+00, -2.3031e+00,
         2.8576e+00, -3.0469e+00, -5.3538e+00, -1.7170e+00,  8.7231e-01,
        -6.4554e+00, -1.1156e+00, -1.7038e+00,  9.7583e+00,  4.5828e-02,
         6.5802e+00, -2.2104e+00,  1.9929e+00, -5.2730e-02, -1.6266e+00,
        -1.3862e+00, -1.2762e+00, -3.9050e+00], device='cuda:0'), 'backend.6.weight': tensor([[[[ 1.7659e-02, -2.6832e-02,  1.1385e-02],
          [-9.5987e-03, -6.9888e-02, -7.4893e-02],
          [-5.2249e-02, -5.5227e-02, -7.9817e-02]],

         [[ 3.0971e-02,  5.7662e-02, -3.3493e-03],
          [-1.8451e-02, -1.3400e-02, -2.8494e-02],
          [-3.6402e-02, -7.0431e-02, -3.7302e-02]],

         [[-8.8065e-02, -1.2215e-01, -9.8337e-02],
          [-8.9381e-02, -4.0194e-02, -8.8762e-02],
          [-6.7900e-02, -6.4821e-02, -2.2597e-02]],

         ...,

         [[ 7.3210e-02, -2.9444e-02,  3.3526e-02],
          [ 1.1094e-02, -1.5081e-02, -2.0852e-02],
          [-5.2141e-02, -7.4994e-02, -8.7375e-02]],

         [[ 6.4951e-02,  5.9654e-02, -4.4956e-03],
          [-3.5679e-02,  6.1586e-02, -3.2397e-02],
          [-2.3371e-02, -6.1786e-02, -2.3975e-02]],

         [[-4.3150e-02, -2.9796e-02, -3.8646e-03],
          [-2.6559e-02, -1.7022e-02,  2.6667e-02],
          [ 4.5345e-02,  5.3840e-02,  8.0433e-02]]],


        [[[-1.8931e-02, -1.3767e-02, -2.2328e-02],
          [-1.7999e-02, -1.7059e-02, -1.7738e-02],
          [-1.7195e-03,  2.6559e-03, -3.2753e-03]],

         [[-4.8772e-03, -9.9158e-03, -1.8203e-02],
          [-9.3297e-03, -3.3824e-03, -1.0877e-02],
          [ 3.6881e-03, -3.0340e-03,  1.1091e-03]],

         [[-1.9346e-02, -1.9373e-02, -7.3065e-03],
          [ 1.2832e-02,  5.7143e-05, -5.6077e-03],
          [-1.6917e-02, -1.6682e-02, -2.7383e-02]],

         ...,

         [[-3.2147e-02, -5.1278e-02, -5.4454e-02],
          [-2.2433e-02, -6.8819e-03, -2.5639e-02],
          [-2.3895e-02, -3.1763e-02, -3.6114e-02]],

         [[-2.0606e-02, -3.0017e-02, -4.2409e-02],
          [-3.8846e-02, -2.1024e-02, -2.3158e-02],
          [-1.8858e-02, -2.0132e-02, -2.1347e-02]],

         [[ 3.0966e-02,  2.2453e-02,  2.1628e-02],
          [-1.4633e-02,  3.5285e-03,  8.0392e-04],
          [ 3.7985e-03, -2.6813e-03,  6.2536e-03]]],


        [[[ 1.6406e-01,  1.0967e-01,  1.5278e-01],
          [ 1.9659e-01,  1.5155e-01,  1.5199e-01],
          [ 1.1946e-01,  1.4954e-01,  1.1909e-01]],

         [[ 6.7720e-02,  1.4779e-01,  1.6977e-01],
          [ 1.0759e-01,  1.5109e-01,  1.3400e-01],
          [ 1.4679e-01,  1.1283e-01,  7.9238e-02]],

         [[ 4.3010e-01,  4.1349e-01,  3.3435e-01],
          [ 3.3524e-01,  3.7894e-01,  3.6660e-01],
          [ 3.4610e-01,  3.0348e-01,  3.2541e-01]],

         ...,

         [[ 1.7422e-01,  1.2320e-01,  1.7807e-01],
          [ 1.3168e-01,  1.4664e-01,  7.5703e-02],
          [ 8.7482e-02,  1.2710e-01,  1.0617e-01]],

         [[ 2.8918e-01,  2.1335e-01,  3.0835e-01],
          [ 2.9417e-01,  2.6610e-01,  3.8148e-01],
          [ 3.5822e-01,  1.8312e-01,  2.4299e-01]],

         [[ 6.2543e-01,  6.9266e-01,  6.6342e-01],
          [ 6.4601e-01,  6.5722e-01,  6.6194e-01],
          [ 7.1699e-01,  7.2908e-01,  6.5544e-01]]],


        ...,


        [[[-3.0835e-03, -5.4563e-03, -4.0023e-03],
          [-4.0692e-03, -5.8401e-03, -5.1373e-03],
          [-3.0648e-03, -2.8590e-03, -4.6756e-03]],

         [[-3.8953e-03, -4.8944e-03, -5.4123e-03],
          [-1.1260e-02, -8.1187e-03, -8.4610e-03],
          [-7.5158e-03, -1.0222e-02, -8.0836e-03]],

         [[-1.4891e-02, -1.4623e-02, -2.0754e-02],
          [-2.3570e-02, -1.8869e-02, -2.5201e-02],
          [-2.3054e-02, -2.1368e-02, -1.9387e-02]],

         ...,

         [[-7.3069e-03, -1.0875e-02, -7.4364e-03],
          [-6.0824e-03, -5.9057e-03, -9.7994e-03],
          [-5.6780e-03, -4.5554e-03, -5.1283e-03]],

         [[-6.7615e-03, -8.6668e-03, -1.2406e-02],
          [-1.7809e-02, -1.6932e-02, -1.4824e-02],
          [-1.3919e-02, -1.8692e-02, -1.7843e-02]],

         [[-1.1690e-02, -1.2990e-02, -9.4363e-03],
          [-3.4773e-02, -3.4121e-02, -3.0164e-02],
          [-3.9312e-02, -4.2817e-02, -4.0379e-02]]],


        [[[-1.1916e-02, -8.5963e-03, -1.0027e-02],
          [-9.8618e-03, -1.3041e-02, -9.8268e-03],
          [-1.3514e-02, -1.5581e-02, -1.3258e-02]],

         [[-4.4533e-03, -6.6127e-03, -5.6979e-03],
          [-4.0485e-03, -4.0086e-03, -5.0110e-03],
          [-4.2606e-03, -4.7118e-03, -7.7490e-03]],

         [[-2.5375e-02, -2.8867e-02, -3.2323e-02],
          [-1.9552e-02, -2.3627e-02, -2.7003e-02],
          [-1.9886e-02, -1.9896e-02, -2.6292e-02]],

         ...,

         [[-8.8458e-03, -8.3308e-03, -7.5918e-03],
          [-1.1403e-02, -1.1842e-02, -1.1067e-02],
          [-1.5496e-02, -1.6875e-02, -1.5704e-02]],

         [[-1.7235e-02, -2.2533e-02, -1.8845e-02],
          [-1.8398e-02, -1.8702e-02, -1.9821e-02],
          [-2.2294e-02, -1.8882e-02, -2.1458e-02]],

         [[-2.3913e-02, -3.0530e-02, -3.6398e-02],
          [-2.0194e-02, -2.3742e-02, -3.0163e-02],
          [-1.7456e-02, -1.2982e-02, -2.0532e-02]]],


        [[[-3.1058e-02,  1.6961e-02, -5.0719e-02],
          [-2.3574e-02,  2.1135e-02, -5.6128e-04],
          [-7.0931e-02, -4.7651e-02, -1.5537e-02]],

         [[ 4.7571e-02, -7.3378e-03,  3.1953e-02],
          [ 1.1158e-01,  5.7628e-02, -1.6503e-04],
          [ 1.5484e-03, -5.2596e-03, -5.0018e-03]],

         [[ 5.3416e-02,  2.0064e-01,  1.3220e-01],
          [-1.2124e-01, -1.6742e-01, -8.4608e-02],
          [-2.1417e-01, -2.5808e-01, -3.0919e-01]],

         ...,

         [[ 2.0335e-02,  1.1659e-01, -2.2834e-02],
          [ 1.9424e-01,  2.3623e-01,  1.9429e-01],
          [ 8.7268e-03,  4.6950e-02,  3.9764e-02]],

         [[-2.1545e-02,  4.8327e-02,  2.2329e-02],
          [ 1.4284e-01,  4.5181e-02, -4.6277e-02],
          [ 1.0123e-01,  2.4752e-01,  1.2154e-01]],

         [[-3.1303e-01, -2.8268e-01, -2.1845e-01],
          [-1.3687e-01, -1.7780e-01, -2.2222e-01],
          [-6.3102e-03,  3.5331e-02,  1.3386e-01]]]], device='cuda:0'), 'backend.2.bias': tensor([-9.5446e-02,  1.2119e-01, -7.2412e-03, -1.1388e-01, -1.4564e-01,
        -1.3560e-02,  3.4906e-03,  7.2917e-02,  7.2378e-02, -8.7557e-02,
        -2.1073e-01, -4.4164e-02, -1.4528e-04, -2.8609e-02, -7.1420e-02,
        -1.7638e-01,  7.6593e-02, -9.6580e-02, -3.9318e-02,  1.0934e-02,
        -9.4718e-03, -5.9569e-03, -1.8186e-01,  6.3051e-02, -9.9818e-02,
         6.5248e-02, -1.8788e-01, -2.5883e-02, -7.8021e-02, -1.6218e-01,
         2.9943e-02,  2.5168e-02, -1.4130e-01, -1.0984e-02,  1.9060e-01,
        -6.5445e-02,  2.4095e-01,  2.0355e-01,  5.0608e-02,  3.8263e-01,
         8.4446e-02,  5.4898e-04,  5.1958e-03, -5.1448e-03, -1.3075e-01,
        -9.0038e-02, -1.0445e-01, -7.5575e-02, -4.8597e-02, -1.1293e-01,
         1.2865e-02, -6.1109e-02,  3.9256e-02,  2.2155e-02, -1.2546e-01,
         5.5564e-02, -8.7547e-02, -4.8290e-01,  2.3835e-02,  2.4570e-04,
         1.9773e-02,  3.4710e-02, -1.0664e-01, -8.6276e-03, -3.3260e-02,
        -2.8562e-02,  1.6659e-02, -3.4660e-02, -2.5922e-01,  1.1552e-01,
         1.8186e-02, -1.5381e-01, -5.6099e-02, -5.9995e-02, -2.5072e-01,
        -1.1116e-01,  1.4272e-01, -2.8126e-02,  2.4978e-01,  1.3899e-01,
        -2.2722e-01,  1.6405e-02,  1.9516e-02, -1.4806e-02,  2.3787e-02,
        -2.5481e-02, -9.9124e-02,  5.5211e-03,  9.6772e-03,  9.0138e-04,
         1.0361e-01, -8.6638e-02,  8.5512e-02,  8.5153e-02,  4.3013e-01,
        -1.7292e-01,  2.5248e-01, -2.4306e-02, -1.4437e-01, -9.8617e-02,
        -2.0636e-02, -2.6137e-02, -3.1094e-01,  2.7443e-01,  1.5304e-02,
        -5.0385e-02, -7.4304e-02,  6.4035e-02,  1.5670e-02,  1.0776e-01,
         5.7238e-02, -6.2665e-02, -6.3629e-02, -1.7401e-01, -1.7384e-01,
        -2.9029e-02, -3.5188e-02, -1.0351e-01,  5.5872e-02, -3.7030e-02,
        -9.5963e-02, -8.1389e-02, -1.5220e-01,  1.9719e-01, -1.1948e-01,
        -1.6690e-01, -9.5103e-02,  1.5895e-01, -4.6990e-02,  8.7202e-03,
        -4.3617e-02,  1.1448e-01, -2.8033e-02,  1.1368e-01, -6.3127e-02,
         2.6896e-03,  2.8196e-02, -7.3617e-02, -1.2489e-01, -6.4794e-04,
         3.3711e-01, -2.7532e-02, -1.2788e-01, -1.1739e-01, -1.4322e-01,
        -6.4527e-02,  4.3953e-02,  4.8670e-02,  1.0128e-01, -5.3158e-02,
         1.9053e-02,  5.7650e-03, -2.0636e-01,  4.9395e-02,  1.0601e-01,
         2.6320e-01,  9.8343e-03, -4.2334e-02,  4.7640e-02,  4.1247e-02,
        -4.3124e-02,  4.6511e-02, -1.8741e-02, -1.7739e-01,  1.6252e-01,
         5.0900e-02,  5.9271e-02, -7.1250e-02, -1.3990e-01, -1.2607e-02,
         1.3636e-01, -1.9154e-02,  9.9166e-02,  9.7900e-03, -7.9714e-03,
         9.6062e-02, -1.1978e-02, -2.6987e-02,  5.5692e-02, -2.0706e-02,
        -7.5234e-03,  9.6910e-02, -2.6948e-02,  1.9295e-02, -1.2362e-01,
        -2.1191e-01,  2.5301e-02, -4.3554e-02,  5.8502e-02,  2.8271e-03,
         3.3452e-03, -2.0438e-01, -1.5362e-01, -7.2068e-02, -1.3362e-01,
        -6.9234e-02,  7.7536e-03, -2.2435e-01, -5.0224e-02, -6.3791e-02,
         1.4208e-01, -1.0317e-01, -4.3360e-02,  2.3452e-01, -1.0269e-02,
        -2.0785e-01, -1.0588e-01, -1.0867e-01,  7.9160e-02,  2.6167e-02,
        -3.6232e-02,  2.0472e-01, -4.7377e-02, -2.2673e-01,  8.8925e-02,
        -1.1418e-01, -3.3483e-02,  1.1014e-01,  5.6064e-02, -5.1882e-03,
         5.2240e-02,  4.1363e-01,  1.6679e-01, -2.8168e-02, -1.5872e-01,
         1.9175e-01, -2.0996e-03,  2.7883e-01,  1.0203e-01, -3.1543e-03,
        -1.3493e-01,  2.3953e-02,  6.8328e-03, -2.6365e-02, -1.9148e-03,
        -2.4797e-02, -9.5862e-02,  3.1373e-01,  1.0827e-01, -3.9025e-01,
         1.2352e-02,  1.6870e-01, -1.3239e-02,  9.2258e-02, -1.0212e-01,
        -2.7446e-01, -1.4298e-01,  4.5009e-03,  9.2050e-02, -9.7839e-03,
        -1.4301e-01, -5.0959e-02,  1.0820e-01,  7.1856e-02, -1.1097e-01,
        -2.3027e-02, -1.9032e-01, -3.1622e-01, -1.0966e-01,  2.0769e-02,
        -1.2985e-01,  7.2919e-02, -6.8903e-03,  2.2240e-02,  4.5560e-02,
         4.6644e-02,  1.0875e-01,  1.8415e-01,  2.5828e-02, -3.4738e-03,
        -3.4905e-02, -1.1111e-01, -7.4145e-05, -5.3387e-02, -2.1667e-01,
         2.3660e-01,  8.3035e-02,  1.6275e-01, -6.9704e-02, -2.4587e-03,
         3.3348e-01, -5.4761e-02,  2.8825e-02, -5.8684e-02,  3.8901e-02,
        -2.1663e-01,  2.5281e-03,  1.5021e-01, -1.5284e-02,  5.2181e-03,
         3.5758e-02,  9.5709e-02,  2.2947e-01, -8.4515e-03,  1.3986e-01,
         3.1625e-02,  2.7621e-01,  1.1267e-01,  7.1197e-03,  6.4725e-02,
         5.0483e-02, -1.1644e-01, -1.0756e-01,  7.3277e-02,  2.8579e-01,
        -1.7353e-01,  2.0274e-01, -5.0729e-01, -2.1406e-01, -1.3283e-01,
        -1.5440e-02, -9.0185e-02,  1.2485e-01,  7.0721e-03,  5.6439e-02,
        -2.2061e-02, -3.1489e-01,  7.7755e-02, -2.7833e-02, -3.0608e-02,
         6.8865e-02, -7.9893e-02, -2.6295e-02,  1.7898e-02,  1.6963e-01,
         8.7090e-02,  1.7398e-02, -2.1467e-01,  2.5737e-02,  1.3856e-02,
         8.3725e-03, -2.8858e-01,  1.6860e-03,  5.3388e-02,  9.3108e-02,
         6.1977e-03, -5.2588e-02,  1.9725e-01, -3.6482e-01, -1.1734e-01,
         2.1406e-01, -1.0736e-02, -3.6181e-01,  5.7253e-01, -5.5066e-02,
         3.8286e-02, -5.8543e-01,  2.0143e-01,  5.1481e-03,  1.5529e-01,
        -5.8389e-02,  9.6528e-02,  3.9118e-03,  1.5408e-01, -6.9548e-04,
         3.3011e-01,  8.9386e-02,  1.8885e-01, -1.6547e-02,  1.7787e-03,
        -6.3063e-02, -2.0380e-02, -7.3930e-02,  5.7186e-02, -2.2169e-01,
        -1.7594e-01,  7.2579e-02,  8.9697e-02,  1.4016e-01,  1.4531e-01,
        -4.8201e-02, -7.4430e-02, -1.2660e-01,  2.2440e-02, -1.7195e-01,
         5.1155e-02, -1.6276e-02, -8.0200e-02,  1.0578e-01, -3.3091e-02,
         1.2326e-01,  1.1280e-01,  1.3937e-02, -2.6170e-01, -4.8325e-02,
         1.8080e-01, -8.4014e-02,  4.3011e-02, -2.0495e-01, -4.6509e-02,
         2.2161e-01,  2.0268e-02, -2.6133e-01, -6.8646e-02,  1.0454e-02,
        -1.6853e-02, -4.4688e-01, -2.6738e-01, -5.5871e-02, -7.4339e-02,
        -4.4163e-01, -6.0499e-02, -4.2863e-02,  2.1001e-01, -3.5374e-02,
         1.9708e-01,  8.2746e-03, -6.6388e-03,  9.9983e-03, -1.5928e-01,
        -9.6030e-02, -8.3696e-02, -2.3543e-01, -3.2171e-02,  2.4577e-02,
        -4.3335e-01, -1.3247e-01,  3.6886e-02, -1.4186e-01,  5.9451e-03,
        -9.1732e-02, -1.2927e-01,  8.5177e-02, -1.1440e-03,  4.2597e-02,
         5.3823e-02, -1.4818e-01, -7.7131e-02, -2.5510e-02,  2.2265e-01,
        -6.6039e-02, -1.0947e-01, -4.1537e-01, -2.4051e-02,  2.0213e-01,
        -1.0381e-01,  3.8250e-02, -2.7224e-02, -4.7804e-02, -1.2561e-02,
        -1.4074e-02, -1.2187e-01,  1.6062e-01, -1.7874e-01, -1.2773e-03,
         1.0068e-01,  3.8112e-02, -1.4348e-01,  1.2197e-01,  1.4000e-03,
        -1.0440e-02,  6.5084e-02,  1.1841e-02, -7.3006e-02, -2.5583e-01,
         2.6120e-03,  1.5690e-01,  1.7598e-01,  6.9525e-02, -6.1460e-02,
        -9.7276e-02,  3.5660e-02,  4.7911e-02,  8.2741e-02,  1.4097e-02,
         4.9413e-02,  4.2053e-02,  1.4344e-01, -6.2792e-02,  4.0253e-04,
         1.5250e-01, -1.7522e-01, -5.9424e-02, -1.0787e-01, -2.6703e-03,
         4.5778e-02, -1.4195e-01,  3.6366e-01,  1.7674e-01,  3.2443e-01,
        -2.4558e-01,  1.8080e-02, -3.6560e-01,  2.6439e-03,  9.1668e-02,
         7.1583e-03, -9.6865e-02, -6.1576e-02, -3.0196e-01, -1.1254e-01,
        -5.5087e-02, -5.7571e-02,  1.0761e-01, -2.8562e-02, -4.1266e-01,
         4.0287e-02,  3.0001e-02, -6.0385e-02,  3.4556e-02, -2.6565e-01,
        -3.9133e-02, -5.7808e-02,  1.2102e-01,  5.8582e-02, -1.1471e-02,
         4.9078e-02, -1.0090e-01, -8.9324e-02, -9.7825e-02,  7.6051e-02,
        -2.5764e-01,  1.2565e-02], device='cuda:0'), 'backend.10.bias': tensor([-5.8029e+00, -5.3878e+01,  1.0696e+01,  2.2877e+01, -1.1115e+01,
         2.1028e-01, -3.5056e+00, -4.7255e+00, -1.8161e+00,  5.6120e-01,
        -4.5989e+00, -1.4484e+01, -2.5311e+01, -2.5464e-01, -1.0811e+01,
        -1.0108e+01,  2.4036e+00,  7.8466e-01, -1.4855e+01, -3.5416e+01,
         3.4983e+00, -1.6306e+01, -2.6800e-01, -1.6920e-02,  1.0981e+00,
         2.8397e+01,  8.6920e-01, -1.3417e+00, -4.1239e-01, -3.3987e+01,
        -1.3303e+01, -3.8404e+00, -7.8278e-01,  4.7887e-02, -2.9392e-01,
        -4.3888e+01,  3.2917e-01, -5.0268e+01, -4.0567e-01,  8.4493e-01,
         5.0142e+00, -5.7116e+01,  7.1828e-02,  1.0728e+00,  4.6707e-01,
        -3.4152e+01, -7.9422e+00,  4.3289e-01,  1.0090e+01, -6.5736e-01,
        -2.2008e+01,  1.0102e+00, -2.4218e-01, -1.8479e+01, -2.5554e-02,
         7.1699e+00,  1.1377e+00,  1.8071e+00,  4.5674e+00,  8.1736e+00,
         1.3086e+00,  2.5759e+00, -2.7065e+01, -2.6927e-01], device='cuda:0'), 'output_layer.bias': tensor([-2368.7078], device='cuda:0'), 'backend.2.weight': tensor([[[[-2.6742e-02, -3.9614e-02, -8.0124e-03],
          [-1.7410e-02, -5.3060e-02, -2.6566e-02],
          [-3.5897e-02, -4.0332e-02, -1.3289e-02]],

         [[-8.8579e-03, -7.8054e-03, -8.0913e-03],
          [-1.2177e-02, -8.5550e-03, -4.6021e-03],
          [-1.0736e-02, -2.2352e-03, -2.1005e-03]],

         [[-5.4202e-02, -2.8205e-02, -6.6149e-02],
          [-9.3613e-02, -8.7685e-02, -1.0216e-01],
          [-8.6319e-02, -6.5353e-02, -6.5386e-02]],

         ...,

         [[-6.8698e-02, -1.2343e-01, -6.7855e-02],
          [-5.2472e-02, -1.2091e-01, -9.2997e-02],
          [-1.5116e-01, -1.8670e-01, -1.7145e-01]],

         [[-3.5145e-02, -2.8826e-02, -2.5547e-02],
          [-4.4440e-02, -3.8224e-02, -3.8731e-02],
          [-2.2133e-02, -2.8051e-02, -2.6024e-02]],

         [[-2.7208e-02, -1.4604e-02, -2.6460e-02],
          [-1.3161e-02, -1.7328e-02, -2.3120e-02],
          [-3.2824e-02, -1.9330e-02, -3.9086e-02]]],


        [[[ 7.7713e-02,  3.7037e-02,  5.9200e-02],
          [ 6.9623e-02,  3.8971e-02,  3.4251e-02],
          [ 5.2237e-02,  4.0354e-02,  4.5527e-02]],

         [[ 8.7291e-03,  1.0783e-02,  1.1893e-02],
          [ 7.5939e-03,  7.7002e-03,  8.8362e-03],
          [ 1.1768e-02,  6.2632e-03,  1.1725e-02]],

         [[ 7.2416e-02,  8.9041e-02,  8.2412e-02],
          [ 8.0393e-02,  7.5214e-02,  6.3760e-02],
          [ 7.1171e-02,  1.0386e-01,  9.9017e-02]],

         ...,

         [[ 1.4388e-01,  1.0236e-01,  1.3851e-01],
          [ 1.2052e-01,  1.1337e-01,  1.7002e-01],
          [ 1.5285e-01,  1.2835e-01,  1.4204e-01]],

         [[ 6.6291e-02,  5.3916e-02,  5.6078e-02],
          [ 4.6757e-02,  4.0122e-02,  2.8891e-02],
          [ 3.1188e-02,  4.4872e-02,  4.0961e-02]],

         [[ 2.8077e-02,  3.7204e-02,  3.6338e-02],
          [ 1.5339e-02,  4.2387e-02,  3.7634e-02],
          [ 1.9189e-02,  3.1697e-02,  4.1698e-02]]],


        [[[-9.8626e-03, -5.9452e-04, -1.5902e-03],
          [-1.4517e-03,  7.3027e-03, -3.8607e-03],
          [-8.3058e-03, -4.2330e-05, -1.1306e-02]],

         [[-6.2690e-04, -3.3444e-04,  7.6351e-05],
          [ 4.1101e-03,  6.4975e-04, -1.6113e-03],
          [ 1.8854e-03,  1.6981e-03, -2.0548e-03]],

         [[-1.1348e-02, -4.0557e-03, -9.0507e-03],
          [-2.9622e-03, -7.6354e-03, -1.2746e-02],
          [-1.6145e-02, -2.2904e-02, -9.9353e-03]],

         ...,

         [[-1.6466e-02, -2.5884e-02, -7.2912e-03],
          [-3.2712e-02,  8.7710e-03, -2.2341e-02],
          [-3.5268e-03,  5.4275e-03, -9.8836e-03]],

         [[ 5.0233e-03, -4.1960e-03,  3.6693e-03],
          [ 7.6088e-03, -2.2836e-03,  6.1414e-03],
          [-9.2006e-03, -6.9912e-03, -5.7219e-03]],

         [[-4.1632e-03, -5.1102e-03,  1.0462e-03],
          [-7.3523e-03, -3.9126e-03,  8.5422e-03],
          [-5.4494e-03, -4.1674e-03, -1.1901e-02]]],


        ...,


        [[[-8.8313e-03,  4.3763e-03,  6.6472e-02],
          [-8.1419e-03,  2.4335e-02,  4.2202e-02],
          [-1.7273e-02,  3.1402e-02,  6.8160e-02]],

         [[-4.0413e-03,  5.5689e-03,  1.0041e-02],
          [ 2.1228e-03,  7.6126e-03,  1.1747e-03],
          [ 6.4545e-04,  9.1158e-03,  6.0498e-03]],

         [[-2.5101e-02,  1.5325e-02, -1.1125e-03],
          [ 1.4317e-03,  2.7357e-02, -5.7320e-03],
          [-1.0063e-02,  1.4975e-03, -1.9937e-03]],

         ...,

         [[ 2.0681e-01,  1.0092e-01,  1.4817e-01],
          [ 6.5343e-02,  1.9605e-01,  2.1522e-01],
          [ 1.7583e-01,  1.0937e-01,  1.1586e-01]],

         [[-1.5121e-02, -9.0398e-03,  1.3653e-03],
          [-2.0700e-02, -1.1765e-02, -4.5479e-03],
          [-1.5400e-02, -1.9582e-02, -1.5347e-02]],

         [[ 8.9630e-03,  4.3920e-02,  3.4446e-02],
          [ 3.6677e-02,  5.0558e-02,  1.8873e-02],
          [ 3.5363e-02,  5.3386e-02,  2.4552e-02]]],


        [[[-6.4076e-02, -7.1425e-02, -1.3557e-01],
          [-1.0440e-01, -1.0575e-01, -1.1695e-01],
          [-1.1025e-01, -1.1215e-01, -1.0477e-01]],

         [[-1.5107e-02, -2.1763e-02, -2.7487e-02],
          [-2.0305e-02, -1.2359e-02, -2.1814e-02],
          [-2.3953e-02, -1.2941e-02, -1.2730e-02]],

         [[-1.3945e-01, -1.1373e-01, -1.1284e-01],
          [-1.5474e-01, -1.2212e-01, -1.1001e-01],
          [-1.8234e-01, -1.5628e-01, -1.4352e-01]],

         ...,

         [[-4.4711e-01, -4.0075e-01, -4.7918e-01],
          [-3.8267e-01, -4.4923e-01, -4.4081e-01],
          [-4.6188e-01, -4.5301e-01, -4.6997e-01]],

         [[-2.4722e-02, -3.4569e-02, -2.5147e-02],
          [-3.2768e-02, -3.5458e-02, -3.5849e-02],
          [-2.8946e-02, -3.0527e-02, -3.7151e-02]],

         [[-6.7310e-02, -7.3471e-02, -8.8189e-02],
          [-9.3798e-02, -9.4707e-02, -9.7847e-02],
          [-9.2636e-02, -8.5534e-02, -7.9306e-02]]],


        [[[-3.6616e-02, -1.3962e-02, -1.0299e-02],
          [-8.8737e-02, -4.4200e-02, -1.8938e-02],
          [-7.0728e-02, -3.1265e-02,  2.7326e-02]],

         [[-9.3137e-03,  8.7382e-04, -9.4224e-03],
          [-5.9765e-03, -2.6666e-03, -8.2774e-03],
          [ 3.5150e-03,  4.4633e-03, -7.3995e-04]],

         [[ 7.3820e-02,  4.9794e-02,  1.5395e-02],
          [ 1.2660e-01,  1.1229e-01,  9.8425e-02],
          [ 4.8687e-02,  5.5703e-02,  1.0727e-01]],

         ...,

         [[-8.3058e-02, -1.9621e-02,  9.4110e-02],
          [-1.6082e-02,  5.3198e-02,  5.2266e-02],
          [ 5.3615e-02,  5.5289e-02,  4.2036e-02]],

         [[-3.1701e-02, -4.6874e-02, -5.6747e-02],
          [-1.4007e-02, -1.7434e-02,  8.5385e-03],
          [-3.1724e-03, -1.3170e-02, -6.2194e-03]],

         [[-1.9242e-03,  1.0771e-02,  9.0749e-03],
          [-1.2533e-02, -1.8963e-04, -3.9584e-03],
          [-4.5665e-03, -1.1592e-02,  7.9200e-03]]]], device='cuda:0'), 'backend.6.bias': tensor([-8.3898e-02, -1.6171e-02,  1.1420e+00, -5.7551e-02,  5.3863e-01,
        -8.3389e-01,  1.1408e-01,  3.1573e-02, -1.6201e-01, -2.2798e-01,
        -1.0613e+00,  1.7285e-02, -1.9214e+00, -1.1184e-01, -6.8129e-01,
         2.2950e-02, -1.4048e+00, -2.4419e-01,  9.4105e-01,  2.4619e-01,
         3.1539e-01, -3.4581e-01,  4.3028e-01,  2.8217e-03, -6.5242e-01,
         1.2156e+00, -1.1701e+00,  9.7104e-02,  1.8541e-01, -8.4765e-01,
        -8.2549e-02,  8.8012e-01,  1.3529e+00,  1.4453e-01, -1.8760e-01,
         2.3450e-01, -5.5987e-02,  4.2681e-01, -3.5006e-01,  5.4508e-01,
        -8.3722e-01,  6.0963e-02,  8.9376e-03, -6.9761e-03,  2.5819e-01,
        -8.1418e-01, -1.1959e+00,  7.2166e-01, -1.3467e-01, -9.9605e-01,
         2.0732e+00,  7.9013e-01,  1.2127e+00, -1.5427e-01,  2.0352e-01,
        -5.0857e-01, -2.5497e-01, -2.5927e-01, -5.9106e-03, -1.0637e-01,
        -7.7560e-01, -3.9563e-01, -5.0864e-01, -4.2363e-01, -1.1203e-01,
         1.5607e+00,  1.1222e+00, -2.8460e-01, -5.2958e-01,  4.4043e-01,
        -2.0771e+00,  1.1595e+00,  5.9845e-01,  6.1729e-02,  3.3175e-02,
        -4.1539e-01,  5.6374e-01, -1.5174e+00, -9.2519e-01, -7.4753e-01,
         2.4033e-03, -7.1819e-02, -3.7930e-01, -1.2810e+00,  1.7283e+00,
        -1.5668e-02, -1.0817e-01,  4.1597e-01, -5.1974e-01, -2.8065e-01,
         4.1466e-01, -2.6418e-01, -9.3957e-01,  1.0207e+00,  2.1993e-01,
         7.7892e-01, -1.2826e-02, -9.0745e-01,  5.0318e-01, -1.2849e+00,
        -1.3128e+00,  1.6148e-02,  1.0761e-01,  1.2552e-02, -7.9037e-01,
        -4.6911e-01, -1.1417e+00, -7.8196e-02,  2.5987e-03,  1.5219e-02,
         5.2964e-02, -5.6886e-01,  2.0896e-01, -2.1517e-02,  4.7351e-01,
        -1.4713e+00, -3.6948e-01,  2.1909e-02,  1.2982e+00,  1.3832e+00,
        -4.6231e-01, -2.0406e-02,  2.7874e-02, -1.9149e+00,  1.5788e+00,
        -8.4886e-01,  1.3790e+00,  3.3353e+00, -1.1661e+00, -4.0027e-01,
         1.9986e-01,  1.0772e+00,  9.1899e-01, -6.6467e-01,  4.5549e-01,
         1.8903e+00, -7.6614e-01,  2.3348e-02, -1.0125e+00, -2.0532e+00,
        -8.9911e-01,  1.2650e+00, -1.0543e+00,  8.2443e-01, -8.1073e-01,
        -4.6521e-02, -4.7348e-04, -3.0504e-01, -9.6905e-03, -5.8532e-01,
        -5.4517e-01, -6.6429e-01, -2.3238e-02,  2.0377e+00,  1.8188e+00,
        -7.2864e-01, -2.5927e-02,  4.8815e-02, -2.2779e-04, -5.5808e-01,
        -3.7023e-01, -1.1683e-01, -1.0920e+00, -8.0475e-03,  8.5100e-02,
         1.4044e+00, -1.8894e-02, -1.2077e-01, -2.6243e-01, -4.0546e-01,
         2.1496e-02,  9.4085e-02, -6.4142e-01, -1.6538e+00, -8.9192e-01,
        -4.8410e-01,  1.4859e-02,  5.2869e-01,  1.6901e-01, -2.0868e-01,
         1.7791e-02,  4.9152e-01,  4.9781e-01, -7.0547e-01,  1.7543e-01,
        -7.4892e-01, -5.0041e-01, -6.2179e-02,  3.3094e-02,  1.9181e+00,
         4.4188e-01,  2.4910e-01, -3.7713e-01,  1.5005e+00,  3.7024e-01,
        -1.5421e-01, -2.9336e-01, -2.8169e-01, -1.0113e-01, -1.9074e+00,
        -6.8935e-01, -6.8837e-01,  1.9108e-01, -6.8252e-01, -6.3966e-01,
         1.6775e-01,  8.4237e-01, -4.1269e-01,  1.0999e+00,  1.0861e+00,
         5.0100e-01,  2.0691e-02, -7.4591e-01, -4.0649e-01,  3.1674e-01,
         4.7350e-02, -1.3425e-02,  4.4528e-01, -1.0489e+00, -1.3415e+00,
         3.2184e-01,  8.5183e-01, -3.3267e-01, -2.9079e-01, -4.9677e-01,
        -1.3985e-01,  4.5514e-02,  6.9376e-01, -1.9076e+00,  1.0485e+00,
        -5.9901e-01,  1.0391e+00, -3.5584e-01, -1.5562e-01, -7.4192e-01,
         1.9428e+00, -1.1659e+00, -4.8475e-02, -9.1319e-02, -1.1107e+00,
        -7.8743e-01, -1.0142e+00,  1.9766e-02,  6.6773e-02, -1.4531e-01,
        -2.2162e-01,  3.6885e-01, -3.8783e-01,  3.8288e-01, -7.1044e-01,
        -2.3415e-01, -3.7066e-01,  5.3615e-01, -6.6176e-02, -6.9477e-02,
         9.0248e-04], device='cuda:0'), 'backend.0.weight': tensor([[[[-1.0966e-02, -1.7621e-02, -1.1160e-02],
          [-3.1523e-03, -5.4632e-03, -6.9490e-03],
          [ 4.9180e-03,  6.9476e-03,  1.3822e-03]],

         [[-9.4742e-02, -8.2674e-02, -6.6369e-02],
          [ 5.5786e-03, -1.3236e-02, -4.1413e-02],
          [ 9.9205e-02,  7.3026e-02, -2.9830e-03]],

         [[ 5.2258e-02,  5.8760e-02,  5.5728e-02],
          [ 6.1536e-02,  8.4549e-02,  3.7031e-02],
          [ 1.0334e-01,  9.4033e-02,  6.6053e-02]],

         ...,

         [[ 4.8511e-04,  4.6800e-04,  3.1705e-03],
          [ 1.0351e-04, -2.0711e-03, -2.6303e-03],
          [ 7.7475e-04, -3.3156e-03, -2.7112e-03]],

         [[ 2.9965e-03, -6.2072e-03,  2.7158e-02],
          [-5.4857e-03, -1.4380e-02,  8.3963e-04],
          [-1.3332e-03,  7.5225e-03, -1.0117e-02]],

         [[ 7.4051e-02,  9.7492e-02,  1.3282e-01],
          [ 8.5057e-02,  8.1246e-02,  8.0772e-02],
          [ 7.5952e-02,  9.3830e-02,  8.4564e-02]]],


        [[[ 3.3558e-03,  5.4447e-03,  3.4575e-03],
          [ 7.2749e-03,  8.1879e-03,  2.1702e-03],
          [ 5.1317e-04,  5.7351e-03,  8.8267e-03]],

         [[ 1.1157e-01,  1.0452e-01,  8.9038e-02],
          [ 9.8320e-02,  1.2030e-01,  8.4504e-02],
          [ 8.3781e-02,  8.3956e-02,  6.3719e-02]],

         [[ 1.8970e-02,  2.2374e-02,  1.1431e-02],
          [ 1.7493e-02,  1.1410e-02,  1.2681e-02],
          [ 4.9744e-04, -3.6672e-03, -6.4817e-03]],

         ...,

         [[ 4.9068e-03,  4.3096e-03,  2.7914e-04],
          [ 3.1393e-03,  2.7693e-03,  4.3248e-03],
          [-1.0944e-03,  2.5520e-03,  2.1073e-03]],

         [[ 1.2171e-02,  1.2222e-02,  7.5670e-03],
          [ 1.7481e-02,  2.1930e-02,  1.4792e-02],
          [ 1.9990e-02,  2.3994e-02,  2.8636e-02]],

         [[ 9.6598e-03, -4.9524e-03,  1.7027e-02],
          [ 5.5919e-03, -9.2168e-03,  2.0792e-02],
          [-8.4701e-03, -1.2579e-04,  8.8652e-03]]],


        [[[ 1.0118e-02,  1.2773e-02,  7.2149e-03],
          [ 1.0303e-02,  1.2340e-02,  4.9372e-03],
          [ 1.7318e-02,  2.1504e-02,  1.9950e-03]],

         [[ 2.1414e-01,  1.4136e-01,  1.1734e-01],
          [ 2.9938e-01,  2.4249e-01,  1.0766e-01],
          [ 2.0077e-01,  2.0029e-01,  4.3078e-02]],

         [[ 4.6795e-02,  5.1594e-02,  4.4769e-02],
          [ 3.4120e-02,  5.9093e-02,  4.1478e-02],
          [ 7.0839e-02,  7.7759e-02,  7.5428e-02]],

         ...,

         [[-6.3567e-04, -4.8425e-04, -4.7804e-03],
          [ 1.0010e-02,  5.5797e-03,  5.0050e-03],
          [ 8.7088e-03,  4.7925e-03,  6.8315e-03]],

         [[ 5.1333e-02,  2.5492e-02,  5.5947e-03],
          [ 4.4769e-02,  3.4322e-02,  7.7108e-03],
          [ 3.5574e-02,  4.2392e-02,  2.2568e-02]],

         [[ 5.0627e-02,  2.1954e-02,  8.0029e-02],
          [-2.6765e-02,  7.8560e-03,  5.7526e-02],
          [ 7.2560e-02,  8.3125e-02,  7.9695e-02]]],


        ...,


        [[[ 2.0045e-02,  6.3759e-03,  5.0314e-04],
          [ 2.1294e-02,  8.4863e-03, -6.0189e-03],
          [ 1.8922e-02,  1.4830e-02,  8.0024e-03]],

         [[ 2.1408e-01,  1.7944e-01,  2.6119e-02],
          [ 2.9567e-01,  2.6751e-01,  9.5505e-02],
          [ 2.9139e-01,  2.5383e-01,  8.2906e-02]],

         [[ 1.7747e-01,  1.9658e-01,  1.8618e-01],
          [ 7.2047e-02,  4.3121e-02,  1.0900e-01],
          [ 1.5234e-01,  1.9394e-01,  1.6790e-01]],

         ...,

         [[ 3.3875e-03, -5.1793e-04,  1.4072e-03],
          [ 3.2953e-03,  6.6849e-04, -3.8083e-03],
          [ 9.4261e-03,  8.2753e-03,  4.3094e-03]],

         [[ 6.2547e-02,  3.2149e-02, -9.1812e-03],
          [ 6.9780e-02,  1.9209e-02, -1.8665e-02],
          [ 7.1130e-02,  4.4202e-02,  1.8727e-03]],

         [[ 2.4898e-01,  2.3220e-01,  3.5021e-01],
          [ 3.2867e-02,  3.7559e-02,  1.8472e-01],
          [ 1.1136e-01,  1.3888e-01,  1.8594e-01]]],


        [[[ 4.4694e-02,  4.3510e-02,  3.1191e-02],
          [ 4.5765e-02,  4.5041e-02,  4.3092e-02],
          [ 5.0477e-02,  5.0648e-02,  4.6611e-02]],

         [[ 4.8131e-01,  4.9008e-01,  4.3751e-01],
          [ 4.3487e-01,  4.5149e-01,  4.4866e-01],
          [ 3.1297e-01,  3.5288e-01,  3.5300e-01]],

         [[ 4.8868e-02,  5.6780e-02,  6.4834e-02],
          [ 3.0821e-02,  3.8098e-02,  4.7188e-02],
          [ 6.1475e-02,  5.3463e-02,  4.0251e-02]],

         ...,

         [[ 1.1525e-02,  1.3004e-02,  1.0198e-02],
          [ 5.2148e-03,  1.3582e-03,  8.1858e-03],
          [ 6.3621e-03,  2.3229e-03,  4.0533e-03]],

         [[ 6.6031e-02,  5.6164e-02,  2.7975e-02],
          [ 5.5590e-02,  5.5610e-02,  3.7570e-02],
          [ 2.7232e-02,  1.7299e-02, -1.6124e-03]],

         [[ 4.3124e-02,  2.8378e-02,  3.5879e-02],
          [ 1.2765e-02,  2.6671e-02,  2.7429e-02],
          [ 5.3278e-02,  7.6972e-02,  1.1788e-02]]],


        [[[ 9.0564e-03,  9.5045e-03,  1.0586e-02],
          [ 1.3180e-02,  1.0426e-02,  1.5775e-02],
          [ 1.5142e-02,  1.6775e-02,  1.7506e-02]],

         [[ 1.0941e-01,  1.0080e-01,  1.7831e-01],
          [ 1.3935e-01,  1.4261e-01,  2.3914e-01],
          [ 1.8721e-01,  1.9382e-01,  2.4268e-01]],

         [[ 5.9846e-02,  6.3959e-02,  5.8495e-02],
          [ 9.4832e-02,  1.2498e-01,  1.2457e-01],
          [ 9.6726e-02,  1.0555e-01,  9.4717e-02]],

         ...,

         [[ 4.8436e-04,  2.5726e-03,  1.3078e-03],
          [ 3.2865e-03,  2.4151e-03,  3.0783e-03],
          [ 3.2824e-03,  2.0314e-03,  1.3949e-03]],

         [[ 1.3699e-02,  7.8330e-03,  2.1782e-02],
          [ 1.6425e-02,  1.2317e-02,  2.7761e-02],
          [ 1.4945e-02,  1.5759e-02,  1.8320e-02]],

         [[ 8.6318e-02,  1.5244e-01,  1.0609e-01],
          [ 1.5536e-01,  1.3366e-01,  1.5492e-01],
          [ 1.0859e-01,  8.9653e-02,  6.4164e-02]]]], device='cuda:0'), 'output_layer.weight': tensor([[[[-1.6358e+00]],

         [[-2.5940e+01]],

         [[-2.2885e+01]],

         [[-4.2481e+01]],

         [[-8.9195e+00]],

         [[-4.3450e-01]],

         [[-4.4648e+00]],

         [[-8.7988e+00]],

         [[-9.7922e+00]],

         [[-6.4884e+00]],

         [[-1.6077e+00]],

         [[-9.1065e+00]],

         [[-9.2577e+00]],

         [[-8.4950e+00]],

         [[-3.1119e+00]],

         [[-4.4014e+00]],

         [[-1.1049e+00]],

         [[-9.0646e+00]],

         [[-1.0693e+01]],

         [[-1.3028e+01]],

         [[-1.9226e+01]],

         [[-5.4063e+00]],

         [[-1.7429e+00]],

         [[-4.2664e-01]],

         [[-1.4460e+00]],

         [[-6.2714e+01]],

         [[-1.6194e+00]],

         [[-1.6695e+00]],

         [[-1.2076e+00]],

         [[-1.8779e+01]],

         [[-4.6703e+00]],

         [[-1.2733e+01]],

         [[-1.3408e+00]],

         [[ 4.5206e-02]],

         [[-4.8045e+00]],

         [[-1.6932e+01]],

         [[-6.8475e-01]],

         [[-2.4269e+01]],

         [[-4.6628e-01]],

         [[-6.4551e+00]],

         [[-3.5551e+00]],

         [[-2.7895e+01]],

         [[-2.5402e-01]],

         [[-4.7532e-01]],

         [[-1.3100e-01]],

         [[-1.7155e+01]],

         [[-2.8089e+00]],

         [[-2.4248e-01]],

         [[-1.8241e+01]],

         [[-4.4686e-01]],

         [[-5.6391e+00]],

         [[-2.1812e+00]],

         [[-1.2111e-01]],

         [[-4.8903e+00]],

         [[-4.5772e-03]],

         [[-2.9828e+01]],

         [[-1.2588e+00]],

         [[-2.7432e+00]],

         [[-3.9311e+00]],

         [[-2.8007e+01]],

         [[-3.5534e+00]],

         [[-2.1570e+00]],

         [[-1.0613e+01]],

         [[-2.9811e-01]]]], device='cuda:0'), 'backend.4.weight': tensor([[[[-1.2050e-02, -6.0804e-02, -5.4469e-02],
          [-8.9147e-03, -8.2509e-02, -6.2419e-02],
          [-1.1261e-02, -5.8706e-02, -4.9875e-04]],

         [[-3.8530e-02, -2.3249e-02,  2.3059e-02],
          [-6.0005e-02,  3.9833e-02,  4.6436e-02],
          [-1.0442e-01, -3.2644e-02, -1.4268e-04]],

         [[-1.3504e-02, -2.6101e-02, -1.9275e-02],
          [-1.5314e-02, -2.7579e-02, -7.4564e-03],
          [-3.1707e-02, -1.0188e-02, -1.2930e-02]],

         ...,

         [[ 4.6737e-03, -5.3109e-02, -8.8508e-02],
          [ 4.9761e-02, -9.0174e-02, -3.2585e-02],
          [-4.8894e-02,  1.3480e-02,  3.9002e-02]],

         [[-5.9419e-02, -1.0137e-01, -1.1546e-01],
          [-7.5364e-02, -4.8470e-02, -2.4964e-02],
          [-4.4913e-02, -1.8799e-02, -1.4600e-02]],

         [[-8.9495e-02, -3.5858e-02, -1.2369e-02],
          [-2.1258e-02, -2.2860e-02, -6.7886e-02],
          [-1.1565e-01, -7.2963e-02, -5.9712e-02]]],


        [[[-6.1421e-02, -7.4410e-02, -5.5029e-02],
          [-8.4431e-02, -5.0344e-02, -1.7650e-02],
          [-4.9211e-02, -2.8632e-02, -3.9525e-02]],

         [[-1.1809e-01, -1.2985e-01, -1.3566e-01],
          [-1.5668e-01, -1.1772e-01, -1.3297e-01],
          [-1.5706e-01, -1.5218e-01, -1.7541e-01]],

         [[-3.7271e-02, -3.6367e-02, -3.9533e-02],
          [-3.3907e-02, -2.5396e-02, -3.3014e-02],
          [-2.8684e-02, -1.9192e-02, -1.9852e-02]],

         ...,

         [[-1.4428e-01, -1.3440e-01, -4.8936e-02],
          [-8.5696e-02, -9.6214e-02, -5.4567e-02],
          [-1.2662e-01, -7.0622e-02, -9.3472e-02]],

         [[-1.1058e-01, -7.2285e-02, -7.5916e-02],
          [-9.1712e-02, -5.9537e-02, -8.4218e-02],
          [-6.3677e-02, -6.2910e-02, -1.0002e-01]],

         [[-2.0823e-01, -2.0906e-01, -2.1805e-01],
          [-1.7231e-01, -2.0222e-01, -2.3789e-01],
          [-2.6540e-01, -2.6746e-01, -2.9672e-01]]],


        [[[ 2.7762e-03,  2.2977e-03, -5.3764e-02],
          [-2.6936e-02,  4.3401e-02, -7.2007e-02],
          [ 1.5599e-03,  1.1804e-02, -7.6262e-02]],

         [[-1.1999e-02,  1.6804e-02,  6.0267e-02],
          [ 7.1735e-02, -4.5565e-03,  5.1573e-02],
          [ 8.9457e-02,  8.7166e-02,  1.6582e-01]],

         [[-3.9874e-03,  9.4175e-03,  2.3182e-02],
          [ 3.4039e-02, -1.6632e-03,  2.0193e-02],
          [ 1.2939e-02, -1.6656e-03,  1.1720e-02]],

         ...,

         [[-5.3544e-02,  1.3020e-01, -1.4320e-01],
          [-8.9344e-02,  8.4099e-02, -1.5566e-01],
          [ 6.7424e-02, -2.3242e-02, -2.0595e-01]],

         [[ 3.7304e-02, -9.8509e-03,  4.2857e-02],
          [ 6.3233e-02, -4.5391e-02, -6.4480e-02],
          [ 6.6969e-03, -1.4844e-01, -1.3270e-02]],

         [[ 6.5939e-02,  8.0869e-04,  5.4285e-02],
          [ 7.0899e-03, -9.7527e-02,  9.8899e-02],
          [ 1.2406e-01,  7.0386e-02,  1.2213e-01]]],


        ...,


        [[[-9.2287e-02, -3.1212e-02, -7.2765e-02],
          [-9.2672e-02, -9.8747e-02, -1.3587e-01],
          [-1.0899e-01, -1.5502e-01, -7.5263e-02]],

         [[-1.1606e-01, -1.4396e-01, -5.8015e-02],
          [-3.7693e-02, -6.5499e-02, -8.3958e-02],
          [-6.8771e-02, -8.4258e-02, -5.5587e-02]],

         [[-3.3651e-02, -2.5016e-02, -3.0571e-02],
          [-2.4607e-02, -3.8932e-02, -3.2553e-02],
          [-2.4548e-02, -2.5012e-02, -2.2982e-02]],

         ...,

         [[-1.4991e-01, -1.0191e-01, -1.7541e-01],
          [-2.3860e-01, -2.6577e-01, -1.5842e-01],
          [-1.5260e-01, -1.9920e-01, -1.9439e-01]],

         [[-2.2625e-01, -2.1584e-01, -1.7163e-01],
          [-1.7381e-01, -1.5323e-01, -1.7070e-01],
          [-1.4792e-01, -1.9673e-01, -1.1020e-01]],

         [[-1.4642e-01, -8.4644e-02, -1.1511e-01],
          [-2.1537e-01, -2.6934e-01, -2.4112e-01],
          [-1.4448e-01, -8.2778e-02, -1.1832e-01]]],


        [[[-1.5638e-01, -1.4835e-01, -1.9036e-01],
          [-1.7547e-01, -8.7567e-02, -1.1183e-01],
          [-8.2419e-02,  2.9825e-02,  2.9445e-02]],

         [[-3.5347e-03,  7.8472e-02,  3.5790e-02],
          [ 2.8735e-02, -8.3442e-02, -3.0317e-02],
          [-1.1561e-01, -1.6252e-01, -1.9590e-01]],

         [[-5.9862e-02, -6.6110e-02, -3.8213e-02],
          [-5.4670e-02, -3.5383e-02, -2.5554e-02],
          [ 9.8645e-03, -6.5176e-03, -9.3019e-03]],

         ...,

         [[-3.2161e-01, -2.8489e-01, -2.5918e-01],
          [-3.2716e-01, -4.6101e-02, -1.2386e-01],
          [-6.2740e-02, -1.9311e-01, -9.9466e-02]],

         [[-2.3160e-01, -2.2290e-01, -1.7311e-01],
          [-1.2878e-01, -1.0607e-01, -1.8933e-01],
          [-1.3857e-01, -1.7023e-01, -8.4567e-02]],

         [[-9.7380e-02, -1.5025e-01, -2.1385e-01],
          [-1.5372e-01, -1.2470e-01, -9.2417e-02],
          [-1.2050e-01, -2.0160e-01, -1.7870e-01]]],


        [[[ 1.4705e-01,  2.1214e-01,  1.3026e-01],
          [ 1.5705e-01,  2.3031e-01,  1.4932e-01],
          [ 2.4698e-01,  3.2268e-01,  2.5551e-01]],

         [[ 4.3678e-01,  4.6324e-01,  4.4894e-01],
          [ 4.4244e-01,  3.3968e-01,  4.9461e-01],
          [ 3.9638e-01,  3.2134e-01,  2.9273e-01]],

         [[ 8.4497e-02,  7.1967e-02,  5.6404e-02],
          [ 5.4277e-02,  3.5380e-02,  4.2072e-02],
          [ 1.0959e-01,  7.9676e-02,  6.8024e-02]],

         ...,

         [[ 2.5636e-01,  3.1694e-01,  2.9748e-01],
          [ 3.4446e-01,  5.3525e-01,  3.9326e-01],
          [ 4.9409e-01,  4.1774e-01,  5.3854e-01]],

         [[ 4.0206e-01,  3.6071e-01,  3.3972e-01],
          [ 4.3792e-01,  3.8572e-01,  3.7576e-01],
          [ 4.6685e-01,  4.0983e-01,  4.3655e-01]],

         [[ 5.7194e-01,  5.3079e-01,  4.8957e-01],
          [ 6.5429e-01,  7.0739e-01,  6.6911e-01],
          [ 6.2929e-01,  4.8608e-01,  4.9187e-01]]]], device='cuda:0'), 'backend.4.bias': tensor([-1.0812e-01, -3.6618e-01,  1.2842e-01, -4.9061e-02, -2.9246e-01,
        -3.0940e-02, -2.1621e-01,  5.0669e-02,  7.6933e-02, -3.7847e-01,
         3.8316e-01,  6.9392e-02,  3.7674e-01,  3.4863e-02, -2.4371e-01,
        -6.7994e-02, -1.8840e-01,  9.8037e-02,  2.0498e-02,  1.9599e-03,
        -1.7969e-01,  3.6393e-01, -1.7573e-01, -4.2377e-01, -7.6807e-02,
        -5.1208e-01,  1.6247e-01,  1.3582e-01, -1.0089e-01, -6.3033e-01,
         2.1797e-01, -3.1502e-02,  2.5708e-02, -1.9572e-01,  4.0423e-02,
        -1.9214e-01, -1.6726e-01,  7.8278e-03,  1.1864e-01, -1.0252e-02,
        -5.1317e-05,  1.6473e-01,  4.8820e-02, -2.7859e-01, -2.8268e-01,
        -2.4050e-02, -1.5400e-03,  5.9487e-02, -3.5743e-01,  8.5502e-02,
        -3.2695e-01, -2.1991e-01, -4.9916e-01, -4.0061e-02, -2.6690e-02,
         3.2183e-01, -3.9357e-01, -1.2466e-02, -5.5511e-01, -3.7874e-01,
        -1.0882e-01, -8.0761e-03, -4.0334e-02, -2.3989e-01,  4.2835e-01,
         1.1270e-01,  5.2403e-03, -4.4079e-02, -1.1977e-01, -5.8302e-01,
        -4.5836e-01, -3.2118e-02, -4.3981e-01, -1.7271e-01, -1.0471e-01,
        -9.2244e-02, -2.5923e-01, -4.8508e-02, -1.3433e-01,  4.9865e-01,
         4.0562e-03,  4.7469e-01,  1.2650e-01,  2.1825e-01,  4.0002e-01,
         5.3301e-02, -4.8195e-02, -7.7327e-03,  3.1429e-02, -2.9858e-01,
         9.6680e-02,  5.9243e-03, -3.5871e-01, -1.8527e-01, -2.1074e-01,
        -2.4775e-02, -4.3049e-03, -4.8010e-01, -2.3097e-02, -4.8733e-01,
        -2.3378e-01,  1.2449e-02,  1.9692e-01,  6.4458e-01, -3.0372e-02,
        -7.6164e-02, -1.2317e-01,  1.7330e-01, -1.0179e-01,  4.4206e-02,
        -1.2982e-01, -1.8453e-01,  2.1300e-01, -5.0385e-02, -2.0801e-01,
         2.6361e-02, -5.6353e-01,  5.0608e-01,  1.8496e-01,  8.3392e-03,
        -3.2192e-02,  5.1195e-01, -1.3434e-02, -5.2054e-02,  1.4464e-01,
         3.7586e-02,  3.4293e-01,  6.9668e-03,  2.2647e-01,  5.1073e-01,
         3.4326e-02, -7.9606e-03,  3.3117e-01, -1.0774e-01, -4.2534e-02,
         3.0071e-02,  6.7357e-03, -7.9038e-01,  4.9791e-02, -4.3896e-01,
        -3.2473e-01, -2.9875e-01, -3.1349e-03, -4.8676e-03,  4.0755e-02,
        -7.9778e-03,  2.4404e-01, -5.4110e-02, -1.1398e-01,  1.1373e-03,
         3.8763e-02,  9.8145e-03, -3.7268e-01, -1.4726e-02,  5.2646e-01,
        -4.4866e-01,  2.7330e-01, -1.6093e-01, -1.5819e-01, -2.0994e-01,
         1.9685e-02, -2.4198e-02, -8.2346e-02, -3.9722e-01, -1.6619e-02,
         4.0966e-02,  3.9075e-01, -5.4413e-01, -1.2593e-01, -1.4784e-01,
        -3.4171e-01, -6.1623e-03, -2.4370e-01, -2.2418e-01,  3.0572e-04,
        -2.3542e-01, -6.4282e-02,  1.3203e-02, -1.1394e-01, -4.1008e-02,
        -8.9198e-02, -5.1334e-02, -3.2771e-01,  5.0280e-03,  2.6738e-01,
         6.9735e-02,  6.9241e-01,  4.3881e-01, -2.2326e-01,  2.3691e-02,
        -3.1278e-01, -9.1258e-02, -2.7652e-01,  1.0137e-01,  1.0067e+00,
        -3.0610e-02, -3.0768e-02, -1.6984e-01,  6.5684e-01,  8.3777e-02,
         4.4153e-01,  2.3669e-01, -1.1397e-01,  3.7615e-03, -2.0286e-02,
        -2.9738e-01,  5.2123e-02, -1.5838e-01, -1.8250e-01,  8.7092e-02,
        -9.9924e-03, -4.6142e-02, -4.2110e-01, -9.8056e-02, -1.8507e-01,
        -6.2266e-03,  1.6868e-02, -1.9718e-01, -2.3422e-01, -3.4677e-01,
         1.6644e-01,  1.2507e-01,  3.9420e-01,  7.4627e-02, -3.1263e-02,
        -3.1774e-01,  8.2828e-02,  1.5916e-02,  9.8656e-02,  1.1932e-02,
        -3.0593e-01, -3.5126e-02,  2.9627e-01,  2.0167e-01,  1.0441e-01,
        -1.0012e-01,  5.5526e-01, -1.0112e-01,  1.1197e-01, -5.4778e-02,
         5.3432e-01,  1.8932e-01,  1.2888e-01, -9.9682e-01, -3.9092e-02,
        -1.6113e-01,  1.7402e-02,  1.7735e-02,  1.6028e-01, -3.4078e-01,
         3.0156e-01,  7.4538e-02, -2.5540e-01, -3.4748e-01,  2.8851e-01,
        -2.7768e-01, -7.4830e-02,  1.7404e-01, -6.9480e-02, -2.7810e-01,
        -1.2865e-01,  2.2681e-01, -2.0875e-01, -4.3857e-01, -1.3635e-01,
        -3.7374e-01, -6.9311e-04,  2.8005e-01,  1.3252e-04, -1.2098e-01,
        -3.6943e-01, -1.2100e-01,  3.8067e-02, -3.8953e-01, -3.6714e-01,
        -4.5713e-02, -3.1230e-02, -1.0634e-01,  1.4169e-01,  2.3006e-01,
        -1.8546e-01, -2.0267e-01, -6.4679e-02, -2.3959e-01,  3.1085e-01,
         3.6061e-01,  1.6338e-02, -2.4542e-01, -8.0525e-02, -2.3345e-01,
        -1.0109e-02, -2.5682e-02,  9.0185e-01,  2.6805e-01,  3.4583e-01,
        -1.8348e-02, -1.3388e-01, -2.4006e-01,  1.4226e-02, -4.0938e-02,
        -1.7018e-01, -1.4158e-01, -2.0831e-01, -1.6937e-01, -8.4635e-02,
        -3.2971e-01, -2.7501e-01,  1.6289e-02, -4.0976e-02, -1.1737e-01,
         1.2761e-02, -1.3447e-01, -1.0033e-01, -1.4785e-01,  1.6940e-01,
        -6.3067e-02, -1.2878e-01,  6.4633e-01, -5.3337e-01,  1.4793e-02,
        -9.2401e-02, -4.7321e-01,  4.4709e-02, -3.0021e-01,  1.7768e-01,
        -4.5306e-01, -1.2879e-01, -3.4056e-02, -1.7092e-01, -3.2663e-01,
        -4.7845e-02, -3.4171e-01,  3.4814e-01, -1.8827e-01, -1.6557e-01,
        -5.7711e-01, -1.1870e-01,  2.7405e-01,  2.3554e-01, -2.6390e-01,
         2.1475e-01, -3.4904e-01,  1.3482e-01, -1.8987e-01, -2.4476e-02,
        -3.1930e-01,  9.0381e-02,  6.3579e-01, -1.4431e-01, -2.4493e-01,
         2.1646e-01,  4.9190e-01,  1.1630e-02,  7.9975e-02,  2.4348e-01,
         1.2596e-02, -1.4821e-01, -7.4587e-02,  1.5592e-01,  1.3076e-01,
         3.0585e-01, -3.6773e-01,  1.8266e-02,  9.1949e-02,  3.1869e-01,
        -2.1595e-01,  3.7490e-01, -2.6143e-02, -3.6379e-01,  8.8123e-03,
         2.6170e-02,  2.5107e-02,  2.6420e-02, -9.9201e-02,  3.0538e-01,
        -1.0716e-02, -1.9231e-01, -2.7256e-01,  1.1161e+00,  1.0307e-02,
        -9.5665e-02, -7.0739e-04, -3.1032e-01, -7.5437e-02,  2.4541e-01,
        -9.1378e-02, -5.9279e-01,  3.0527e-03,  1.4868e-02, -4.7875e-01,
         6.7284e-02, -1.8228e-01,  4.9474e-02,  3.0890e-02,  1.5924e-01,
         1.5409e-02,  3.8060e-02, -2.0830e-01, -1.9951e-01, -4.6217e-02,
        -5.7944e-01, -4.0634e-02,  1.8277e-01, -1.0762e-01, -5.3346e-01,
        -9.1331e-03, -3.6206e-01, -5.0548e-02,  2.9751e-01, -2.0689e-02,
         6.0334e-01,  2.5752e-01,  9.7460e-03,  6.7221e-03, -1.2128e-01,
        -8.0106e-02, -4.5753e-02,  6.7042e-02, -1.8903e-02, -2.1782e-01,
        -3.6457e-01, -2.6535e-02,  6.3350e-01, -3.4595e-01, -3.7134e-02,
        -9.5446e-02, -3.0462e-01, -3.0521e-01, -6.8316e-02, -5.2827e-01,
         1.4542e-01, -1.9183e-01,  1.9116e-03, -5.3528e-03, -1.5697e-01,
         2.8601e-02,  2.2384e-01, -4.2826e-02,  3.7193e-01, -1.0106e-01,
        -7.1846e-02, -1.7502e-01,  3.7556e-02, -6.9689e-01, -3.6151e-01,
        -3.2395e-02, -2.4084e-02, -3.1030e-01,  9.2290e-02, -4.0313e-01,
        -1.1534e-01,  1.2941e-01,  3.9190e-01,  6.1184e-02, -1.3612e-01,
        -2.1757e-02,  9.9646e-02,  2.4690e-01, -1.4986e-03,  1.3126e-01,
        -4.5444e-01,  3.8564e-01, -4.4021e-01,  4.3855e-01, -1.5638e-01,
         2.3229e-01,  4.4087e-02, -5.8861e-02, -1.5707e-03, -1.2277e-01,
        -8.8028e-02, -1.9164e-01, -6.1247e-02,  4.0479e-01, -3.7728e-01,
        -1.1528e-01,  1.1578e-01,  7.6795e-01, -7.4226e-02,  2.1551e-01,
         1.1526e-01, -2.0986e-03,  1.7941e-01, -7.2154e-01,  3.0800e-01,
        -3.7802e-02, -1.0173e-01,  2.5063e-01, -9.7411e-03, -1.2966e-01,
        -9.2898e-03,  5.0408e-02, -1.3581e-01,  2.7527e-01, -1.5139e-01,
         3.9172e-02,  5.3646e-02,  7.7754e-02,  2.6265e-02,  3.7059e-02,
         4.2296e-01, -4.2494e-02, -4.7809e-01, -2.3012e-01,  1.5902e-01,
         1.3807e-01, -1.8588e-01, -2.5382e-01,  1.1852e-02, -2.7152e-01,
        -2.3342e-01,  9.9333e-01], device='cuda:0')}
INFO:root:Summary name (meta-train): train loss is illegal; using _meta-train___train_loss instead.
INFO:root:Summary name (meta-train): train MAE is illegal; using _meta-train___train_MAE instead.
INFO:root:Summary name (meta-train): train MSE is illegal; using _meta-train___train_MSE instead.
INFO:root:Summary name (meta-train): test MAE is illegal; using _meta-train___test_MAE instead.
INFO:root:Summary name (meta-train): test MSE is illegal; using _meta-train___test_MSE instead.
INFO:root:Summary name (meta-test) train loss is illegal; using _meta-test__train_loss instead.
INFO:root:Summary name (meta-test) train MAE is illegal; using _meta-test__train_MAE instead.
INFO:root:Summary name (meta-test) train MSE is illegal; using _meta-test__train_MSE instead.
INFO:root:Summary name (meta-test) test MAE is illegal; using _meta-test__test_MAE instead.
INFO:root:Summary name (meta-test) test MSE is illegal; using _meta-test__test_MSE instead.
INFO:root:===> Training epoch: 2/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:489.379760265, MAE: 1208.2483532, MSE: 1208.2483646
INFO:root:(Meta-testing) test MAE: 1191.54629898, MSE: 1191.54629835
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.88615751266, MAE: 5.2863612175, MSE: 5.28636129757
INFO:root:(Meta-training) post train loss: 2.55021047592, MAE: 3.69257235527, MSE: 3.69257238628
INFO:root:(Meta-training) pre-training test MAE: 2.81819248199, MSE: 2.8181924645
INFO:root:(Meta-training) post-training test MAE: 14.8131504059, MSE: 14.8131505123
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-72.3521, device='cuda:0'), 'backend.0.bias': tensor(-0.0175, device='cuda:0'), 'backend.10.weight': tensor(-146.6169, device='cuda:0'), 'backend.8.bias': tensor(-0.0953, device='cuda:0'), 'backend.6.weight': tensor(-101.1415, device='cuda:0'), 'backend.2.bias': tensor(-0.0419, device='cuda:0'), 'backend.10.bias': tensor(-0.2738, device='cuda:0'), 'output_layer.bias': tensor(13.7381, device='cuda:0'), 'backend.2.weight': tensor(-87.7103, device='cuda:0'), 'backend.6.bias': tensor(-0.0673, device='cuda:0'), 'backend.0.weight': tensor(-45.9372, device='cuda:0'), 'output_layer.weight': tensor(17.7768, device='cuda:0'), 'backend.4.weight': tensor(-38.0084, device='cuda:0'), 'backend.4.bias': tensor(-0.0194, device='cuda:0')}
INFO:root:==> Training scene: 2
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.1483201981, MAE: 12.8588237762, MSE: 12.8588238177
INFO:root:(Meta-training) post train loss: 24.7598114014, MAE: 319.908599854, MSE: 319.908605112
INFO:root:(Meta-training) pre-training test MAE: 16.1991920471, MSE: 16.1991919045
INFO:root:(Meta-training) post-training test MAE: 321.064086914, MSE: 321.064087742
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(3071.7417, device='cuda:0'), 'backend.0.bias': tensor(1.0439, device='cuda:0'), 'backend.10.weight': tensor(5227.1123, device='cuda:0'), 'backend.8.bias': tensor(3.4101, device='cuda:0'), 'backend.6.weight': tensor(4269.0293, device='cuda:0'), 'backend.2.bias': tensor(1.3926, device='cuda:0'), 'backend.10.bias': tensor(21.2512, device='cuda:0'), 'output_layer.bias': tensor(-352.2825, device='cuda:0'), 'backend.2.weight': tensor(3795.6118, device='cuda:0'), 'backend.6.bias': tensor(2.2225, device='cuda:0'), 'backend.0.weight': tensor(2667.0874, device='cuda:0'), 'output_layer.weight': tensor(-433.9282, device='cuda:0'), 'backend.4.weight': tensor(2385.2065, device='cuda:0'), 'backend.4.bias': tensor(1.0120, device='cuda:0')}
INFO:root:==> Training scene: 3
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 23.8228435516, MAE: 48.7415733337, MSE: 48.7415732901
INFO:root:(Meta-training) post train loss: 354.426269531, MAE: 1437.98828125, MSE: 1437.9882649
INFO:root:(Meta-training) pre-training test MAE: 16.4611339569, MSE: 16.4611340164
INFO:root:(Meta-training) post-training test MAE: 1262.35473633, MSE: 1262.35474412
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(37343.1836, device='cuda:0'), 'backend.0.bias': tensor(14.3120, device='cuda:0'), 'backend.10.weight': tensor(40709.3398, device='cuda:0'), 'backend.8.bias': tensor(26.6775, device='cuda:0'), 'backend.6.weight': tensor(51948.6562, device='cuda:0'), 'backend.2.bias': tensor(15.4098, device='cuda:0'), 'backend.10.bias': tensor(164.4810, device='cuda:0'), 'output_layer.bias': tensor(-1631.0771, device='cuda:0'), 'backend.2.weight': tensor(50694.0078, device='cuda:0'), 'backend.6.bias': tensor(19.7635, device='cuda:0'), 'backend.0.weight': tensor(40206.7070, device='cuda:0'), 'output_layer.weight': tensor(-1673.1040, device='cuda:0'), 'backend.4.weight': tensor(40128.5312, device='cuda:0'), 'backend.4.bias': tensor(15.1423, device='cuda:0')}
INFO:root:==> Training scene: 4
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.4615840912, MAE: 20.6086139679, MSE: 20.6086138743
INFO:root:(Meta-training) post train loss: 40.9029541016, MAE: 445.036529541, MSE: 445.036532911
INFO:root:(Meta-training) pre-training test MAE: 5.16553211212, MSE: 5.16553212086
INFO:root:(Meta-training) post-training test MAE: 416.225189209, MSE: 416.225186948
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(4165.6025, device='cuda:0'), 'backend.0.bias': tensor(1.2552, device='cuda:0'), 'backend.10.weight': tensor(6280.8545, device='cuda:0'), 'backend.8.bias': tensor(4.6585, device='cuda:0'), 'backend.6.weight': tensor(5465.5020, device='cuda:0'), 'backend.2.bias': tensor(1.7907, device='cuda:0'), 'backend.10.bias': tensor(20.7245, device='cuda:0'), 'output_layer.bias': tensor(-399.2968, device='cuda:0'), 'backend.2.weight': tensor(4626.5186, device='cuda:0'), 'backend.6.bias': tensor(2.8286, device='cuda:0'), 'backend.0.weight': tensor(3231.8464, device='cuda:0'), 'output_layer.weight': tensor(-509.0807, device='cuda:0'), 'backend.4.weight': tensor(3166.0188, device='cuda:0'), 'backend.4.bias': tensor(1.3925, device='cuda:0')}
INFO:root:==> Training scene: 5
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.41042947769, MAE: 1.06506919861, MSE: 1.06506917783
INFO:root:(Meta-training) post train loss: 5.75271034241, MAE: 29.7909946442, MSE: 29.790994561
INFO:root:(Meta-training) pre-training test MAE: 1.51247358322, MSE: 1.51247361531
INFO:root:(Meta-training) post-training test MAE: 36.4608764648, MSE: 36.4608763994
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(193.4940, device='cuda:0'), 'backend.0.bias': tensor(0.0475, device='cuda:0'), 'backend.10.weight': tensor(358.9218, device='cuda:0'), 'backend.8.bias': tensor(0.3138, device='cuda:0'), 'backend.6.weight': tensor(274.9008, device='cuda:0'), 'backend.2.bias': tensor(0.1141, device='cuda:0'), 'backend.10.bias': tensor(0.9936, device='cuda:0'), 'output_layer.bias': tensor(-40.2127, device='cuda:0'), 'backend.2.weight': tensor(234.8242, device='cuda:0'), 'backend.6.bias': tensor(0.1891, device='cuda:0'), 'backend.0.weight': tensor(113.9339, device='cuda:0'), 'output_layer.weight': tensor(-42.4104, device='cuda:0'), 'backend.4.weight': tensor(104.0559, device='cuda:0'), 'backend.4.bias': tensor(0.0485, device='cuda:0')}
INFO:root:==> Training scene: 6
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 23.9756088257, MAE: 51.1384086609, MSE: 51.1384074718
INFO:root:(Meta-training) post train loss: 379.122955322, MAE: 1486.74523926, MSE: 1486.74527072
INFO:root:(Meta-training) pre-training test MAE: 50.7359962463, MSE: 50.7359966633
INFO:root:(Meta-training) post-training test MAE: 1449.84887695, MSE: 1449.84887143
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(51738.8750, device='cuda:0'), 'backend.0.bias': tensor(17.5429, device='cuda:0'), 'backend.10.weight': tensor(53416.8359, device='cuda:0'), 'backend.8.bias': tensor(34.5272, device='cuda:0'), 'backend.6.weight': tensor(71763.4766, device='cuda:0'), 'backend.2.bias': tensor(18.8598, device='cuda:0'), 'backend.10.bias': tensor(210.3816, device='cuda:0'), 'output_layer.bias': tensor(-2045.6969, device='cuda:0'), 'backend.2.weight': tensor(69992.0156, device='cuda:0'), 'backend.6.bias': tensor(25.1155, device='cuda:0'), 'backend.0.weight': tensor(55486.6641, device='cuda:0'), 'output_layer.weight': tensor(-1768.9500, device='cuda:0'), 'backend.4.weight': tensor(56900.5391, device='cuda:0'), 'backend.4.bias': tensor(18.8455, device='cuda:0')}
INFO:root:==> Training scene: 7
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 12.6079626083, MAE: 19.31524086, MSE: 19.3152406593
INFO:root:(Meta-training) post train loss: 52.5039024353, MAE: 508.095611572, MSE: 508.095617232
INFO:root:(Meta-training) pre-training test MAE: 38.8709869385, MSE: 38.8709867804
INFO:root:(Meta-training) post-training test MAE: 533.328552246, MSE: 533.328551411
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(8189.1025, device='cuda:0'), 'backend.0.bias': tensor(2.8491, device='cuda:0'), 'backend.10.weight': tensor(10965.9102, device='cuda:0'), 'backend.8.bias': tensor(6.8243, device='cuda:0'), 'backend.6.weight': tensor(11341.8174, device='cuda:0'), 'backend.2.bias': tensor(3.4834, device='cuda:0'), 'backend.10.bias': tensor(40.1263, device='cuda:0'), 'output_layer.bias': tensor(-607.5925, device='cuda:0'), 'backend.2.weight': tensor(10623.4062, device='cuda:0'), 'backend.6.bias': tensor(4.9186, device='cuda:0'), 'backend.0.weight': tensor(7960.3975, device='cuda:0'), 'output_layer.weight': tensor(-733.5707, device='cuda:0'), 'backend.4.weight': tensor(7729.2627, device='cuda:0'), 'backend.4.bias': tensor(3.0016, device='cuda:0')}
INFO:root:==> Training scene: 8
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 22.1039962769, MAE: 46.7138175964, MSE: 46.7138166292
INFO:root:(Meta-training) post train loss: 147.217056274, MAE: 905.128295898, MSE: 905.128305822
INFO:root:(Meta-training) pre-training test MAE: 47.0304641724, MSE: 47.0304635524
INFO:root:(Meta-training) post-training test MAE: 927.783630371, MSE: 927.783615667
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(14353.9629, device='cuda:0'), 'backend.0.bias': tensor(5.1018, device='cuda:0'), 'backend.10.weight': tensor(17235.0918, device='cuda:0'), 'backend.8.bias': tensor(14.1180, device='cuda:0'), 'backend.6.weight': tensor(19129.1250, device='cuda:0'), 'backend.2.bias': tensor(6.1244, device='cuda:0'), 'backend.10.bias': tensor(77.6443, device='cuda:0'), 'output_layer.bias': tensor(-979.0513, device='cuda:0'), 'backend.2.weight': tensor(18002.8359, device='cuda:0'), 'backend.6.bias': tensor(8.9951, device='cuda:0'), 'backend.0.weight': tensor(13462.9805, device='cuda:0'), 'output_layer.weight': tensor(-908.9608, device='cuda:0'), 'backend.4.weight': tensor(13989.1660, device='cuda:0'), 'backend.4.bias': tensor(5.6351, device='cuda:0')}
INFO:root:==> Training scene: 9
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 15.5649223328, MAE: 30.1861457825, MSE: 30.1861453177
INFO:root:(Meta-training) post train loss: 226.211349487, MAE: 1130.46337891, MSE: 1130.46340056
INFO:root:(Meta-training) pre-training test MAE: 10.4716968536, MSE: 10.4716967634
INFO:root:(Meta-training) post-training test MAE: 919.62713623, MSE: 919.62713232
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(25303.7734, device='cuda:0'), 'backend.0.bias': tensor(8.5189, device='cuda:0'), 'backend.10.weight': tensor(31586.5566, device='cuda:0'), 'backend.8.bias': tensor(16.6407, device='cuda:0'), 'backend.6.weight': tensor(34904.5430, device='cuda:0'), 'backend.2.bias': tensor(9.2294, device='cuda:0'), 'backend.10.bias': tensor(114.2296, device='cuda:0'), 'output_layer.bias': tensor(-1216.5660, device='cuda:0'), 'backend.2.weight': tensor(33509.7500, device='cuda:0'), 'backend.6.bias': tensor(12.0249, device='cuda:0'), 'backend.0.weight': tensor(27330.3496, device='cuda:0'), 'output_layer.weight': tensor(-1779.3706, device='cuda:0'), 'backend.4.weight': tensor(25463.2109, device='cuda:0'), 'backend.4.bias': tensor(8.5938, device='cuda:0')}
INFO:root:==> Training scene: 10
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 41.4564437866, MAE: 94.2858886719, MSE: 94.285890257
INFO:root:(Meta-training) post train loss: 2592.21435547, MAE: 3867.38305664, MSE: 3867.38309455
INFO:root:(Meta-training) pre-training test MAE: 4.53879547119, MSE: 4.5387954502
INFO:root:(Meta-training) post-training test MAE: 3629.98022461, MSE: 3629.98016524
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(365701.9062, device='cuda:0'), 'backend.0.bias': tensor(111.7291, device='cuda:0'), 'backend.10.weight': tensor(267977.6875, device='cuda:0'), 'backend.8.bias': tensor(206.6200, device='cuda:0'), 'backend.6.weight': tensor(540736.9375, device='cuda:0'), 'backend.2.bias': tensor(116.9883, device='cuda:0'), 'backend.10.bias': tensor(1117.5330, device='cuda:0'), 'output_layer.bias': tensor(-8538.7490, device='cuda:0'), 'backend.2.weight': tensor(549863.5000, device='cuda:0'), 'backend.6.bias': tensor(150.4593, device='cuda:0'), 'backend.0.weight': tensor(462078.5000, device='cuda:0'), 'output_layer.weight': tensor(-2080.1328, device='cuda:0'), 'backend.4.weight': tensor(473462.4062, device='cuda:0'), 'backend.4.bias': tensor(121.2144, device='cuda:0')}
INFO:root:==> Training scene: 11
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 23.8228435516, MAE: 48.7415733337, MSE: 48.7415732901
INFO:root:(Meta-training) post train loss: 354.426269531, MAE: 1437.98828125, MSE: 1437.9882649
INFO:root:(Meta-training) pre-training test MAE: 19.31524086, MSE: 19.3152406593
INFO:root:(Meta-training) post-training test MAE: 1283.51293945, MSE: 1283.5129528
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(38683.1094, device='cuda:0'), 'backend.0.bias': tensor(14.7791, device='cuda:0'), 'backend.10.weight': tensor(42018.7188, device='cuda:0'), 'backend.8.bias': tensor(27.4157, device='cuda:0'), 'backend.6.weight': tensor(53838.5430, device='cuda:0'), 'backend.2.bias': tensor(15.8593, device='cuda:0'), 'backend.10.bias': tensor(170.2896, device='cuda:0'), 'output_layer.bias': tensor(-1674.2820, device='cuda:0'), 'backend.2.weight': tensor(52548.7656, device='cuda:0'), 'backend.6.bias': tensor(20.3295, device='cuda:0'), 'backend.0.weight': tensor(41714.0859, device='cuda:0'), 'output_layer.weight': tensor(-1697.3047, device='cuda:0'), 'backend.4.weight': tensor(41691.0156, device='cuda:0'), 'backend.4.bias': tensor(15.6082, device='cuda:0')}
INFO:root:==> Training scene: 12
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 54.6767272949, MAE: 119.720092773, MSE: 119.720091842
INFO:root:(Meta-training) post train loss: 3003.85888672, MAE: 4265.56005859, MSE: 4265.55998668
INFO:root:(Meta-training) pre-training test MAE: 58.4968681335, MSE: 58.4968678215
INFO:root:(Meta-training) post-training test MAE: 3870.51586914, MSE: 3870.51585709
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(340635.5000, device='cuda:0'), 'backend.0.bias': tensor(112.4788, device='cuda:0'), 'backend.10.weight': tensor(223132.5000, device='cuda:0'), 'backend.8.bias': tensor(227.8602, device='cuda:0'), 'backend.6.weight': tensor(500814.3750, device='cuda:0'), 'backend.2.bias': tensor(124.1809, device='cuda:0'), 'backend.10.bias': tensor(985.3835, device='cuda:0'), 'output_layer.bias': tensor(-8259.3740, device='cuda:0'), 'backend.2.weight': tensor(522883.8125, device='cuda:0'), 'backend.6.bias': tensor(158.9754, device='cuda:0'), 'backend.0.weight': tensor(431307.1250, device='cuda:0'), 'output_layer.weight': tensor(2424.0391, device='cuda:0'), 'backend.4.weight': tensor(458213.5000, device='cuda:0'), 'backend.4.bias': tensor(128.8820, device='cuda:0')}
INFO:root:==> Training scene: 13
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.85727024078, MAE: 3.33396720886, MSE: 3.33396721217
INFO:root:(Meta-training) post train loss: 10.2389068604, MAE: 174.717666626, MSE: 174.717668459
INFO:root:(Meta-training) pre-training test MAE: 4.499106884, MSE: 4.49910684835
INFO:root:(Meta-training) post-training test MAE: 163.564239502, MSE: 163.564237429
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(1334.3943, device='cuda:0'), 'backend.0.bias': tensor(0.4264, device='cuda:0'), 'backend.10.weight': tensor(2294.5776, device='cuda:0'), 'backend.8.bias': tensor(1.4921, device='cuda:0'), 'backend.6.weight': tensor(1933.6218, device='cuda:0'), 'backend.2.bias': tensor(0.6541, device='cuda:0'), 'backend.10.bias': tensor(7.9537, device='cuda:0'), 'output_layer.bias': tensor(-177.6626, device='cuda:0'), 'backend.2.weight': tensor(1757.7593, device='cuda:0'), 'backend.6.bias': tensor(1.0409, device='cuda:0'), 'backend.0.weight': tensor(1115.8763, device='cuda:0'), 'output_layer.weight': tensor(-226.2328, device='cuda:0'), 'backend.4.weight': tensor(977.9769, device='cuda:0'), 'backend.4.bias': tensor(0.4059, device='cuda:0')}
INFO:root:==> Training scene: 14
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 12.4593391418, MAE: 19.0549068451, MSE: 19.054906915
INFO:root:(Meta-training) post train loss: 63.0535240173, MAE: 567.745300293, MSE: 567.745293904
INFO:root:(Meta-training) pre-training test MAE: 59.0544090271, MSE: 59.0544099949
INFO:root:(Meta-training) post-training test MAE: 595.036193848, MSE: 595.036185874
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(11374.3398, device='cuda:0'), 'backend.0.bias': tensor(3.8856, device='cuda:0'), 'backend.10.weight': tensor(14959.3037, device='cuda:0'), 'backend.8.bias': tensor(8.4382, device='cuda:0'), 'backend.6.weight': tensor(15694.9551, device='cuda:0'), 'backend.2.bias': tensor(4.6319, device='cuda:0'), 'backend.10.bias': tensor(52.4979, device='cuda:0'), 'output_layer.bias': tensor(-728.5652, device='cuda:0'), 'backend.2.weight': tensor(14668.6016, device='cuda:0'), 'backend.6.bias': tensor(6.3248, device='cuda:0'), 'backend.0.weight': tensor(10973.6387, device='cuda:0'), 'output_layer.weight': tensor(-916.5609, device='cuda:0'), 'backend.4.weight': tensor(11136.9248, device='cuda:0'), 'backend.4.bias': tensor(4.2230, device='cuda:0')}
INFO:root:==> Training scene: 15
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.44100570679, MAE: 0.198168754578, MSE: 0.198168755071
INFO:root:(Meta-training) post train loss: 5.07434272766, MAE: 67.6072387695, MSE: 67.607239032
INFO:root:(Meta-training) pre-training test MAE: 40.5978431702, MSE: 40.5978424852
INFO:root:(Meta-training) post-training test MAE: 64.0241394043, MSE: 64.0241386668
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(418.6210, device='cuda:0'), 'backend.0.bias': tensor(0.1131, device='cuda:0'), 'backend.10.weight': tensor(711.2491, device='cuda:0'), 'backend.8.bias': tensor(0.5573, device='cuda:0'), 'backend.6.weight': tensor(580.2672, device='cuda:0'), 'backend.2.bias': tensor(0.2140, device='cuda:0'), 'backend.10.bias': tensor(1.9403, device='cuda:0'), 'output_layer.bias': tensor(-64.0684, device='cuda:0'), 'backend.2.weight': tensor(501.4863, device='cuda:0'), 'backend.6.bias': tensor(0.3432, device='cuda:0'), 'backend.0.weight': tensor(310.1677, device='cuda:0'), 'output_layer.weight': tensor(-70.5041, device='cuda:0'), 'backend.4.weight': tensor(295.2207, device='cuda:0'), 'backend.4.bias': tensor(0.1257, device='cuda:0')}
INFO:root:==> Training scene: 16
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.7893037796, MAE: 24.1131229401, MSE: 24.1131227341
INFO:root:(Meta-training) post train loss: 47.3434753418, MAE: 484.744506836, MSE: 484.744504224
INFO:root:(Meta-training) pre-training test MAE: 27.6004104614, MSE: 27.600410392
INFO:root:(Meta-training) post-training test MAE: 486.81930542, MSE: 486.819300408
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(5169.1777, device='cuda:0'), 'backend.0.bias': tensor(1.5651, device='cuda:0'), 'backend.10.weight': tensor(7900.3652, device='cuda:0'), 'backend.8.bias': tensor(5.4398, device='cuda:0'), 'backend.6.weight': tensor(6849.8101, device='cuda:0'), 'backend.2.bias': tensor(2.0992, device='cuda:0'), 'backend.10.bias': tensor(32.5798, device='cuda:0'), 'output_layer.bias': tensor(-486.1096, device='cuda:0'), 'backend.2.weight': tensor(5969.8823, device='cuda:0'), 'backend.6.bias': tensor(3.3522, device='cuda:0'), 'backend.0.weight': tensor(4244.0225, device='cuda:0'), 'output_layer.weight': tensor(-584.4904, device='cuda:0'), 'backend.4.weight': tensor(4159.9854, device='cuda:0'), 'backend.4.bias': tensor(1.6588, device='cuda:0')}
INFO:root:==> Training scene: 17
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.9336948395, MAE: 33.2851295471, MSE: 33.2851303489
INFO:root:(Meta-training) post train loss: 97.2934036255, MAE: 735.107666016, MSE: 735.107645179
INFO:root:(Meta-training) pre-training test MAE: 59.3954277039, MSE: 59.3954282292
INFO:root:(Meta-training) post-training test MAE: 690.414611816, MSE: 690.414617277
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.8229064941406, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.9803466796875, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142578125, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2705841064453, '0.bias': 0.012057911604642868, '6.weight': -82.45707702636719, '8.weight': -35.569644927978516, '2.bias': 0.029189331457018852, '10.bias': 0.3597584664821625, '0.weight': -108.17760467529297}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(11168.4824, device='cuda:0'), 'backend.0.bias': tensor(3.1218, device='cuda:0'), 'backend.10.weight': tensor(15507.0264, device='cuda:0'), 'backend.8.bias': tensor(9.8319, device='cuda:0'), 'backend.6.weight': tensor(14654.4922, device='cuda:0'), 'backend.2.bias': tensor(3.9066, device='cuda:0'), 'backend.10.bias': tensor(57.8945, device='cuda:0'), 'output_layer.bias': tensor(-763.3455, device='cuda:0'), 'backend.2.weight': tensor(12478.4590, device='cuda:0'), 'backend.6.bias': tensor(6.1280, device='cuda:0'), 'backend.0.weight': tensor(9138.7510, device='cuda:0'), 'output_layer.weight': tensor(-1022.5327, device='cuda:0'), 'backend.4.weight': tensor(9214.9004, device='cuda:0'), 'backend.4.bias': tensor(3.3124, device='cuda:0')}
INFO:root:==> Training scene: 18
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 12.7663850784, MAE: 18.4024887085, MSE: 18.4024884407
INFO:root:(Meta-training) post train loss: 66.2781448364, MAE: 588.347045898, MSE: 588.347048943
INFO:root:(Meta-training) pre-training test MAE: 165.643936157, MSE: 165.643937597
INFO:root:(Meta-training) post-training test MAE: 619.783325195, MSE: 619.783329076
INFO:root:==========================
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:10.2249026775, MAE: 101.208065414, MSE: 101.208065817
INFO:root:(Meta-testing) test MAE: 101.54141922, MSE: 101.541420168
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.92773497105, MAE: 3.70236587524, MSE: 3.70236584572
INFO:root:(Meta-training) post train loss: 2.13366675377, MAE: 37.6027603149, MSE: 37.6027595968
INFO:root:(Meta-training) pre-training test MAE: 6.88640213013, MSE: 6.88640217694
INFO:root:(Meta-training) post-training test MAE: 40.4782524109, MSE: 40.4782520818
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-43.9210, device='cuda:0'), 'backend.0.bias': tensor(0.0013, device='cuda:0'), 'backend.10.weight': tensor(-2.8210, device='cuda:0'), 'backend.8.bias': tensor(-0.1662, device='cuda:0'), 'backend.6.weight': tensor(-52.1225, device='cuda:0'), 'backend.2.bias': tensor(-0.0119, device='cuda:0'), 'backend.10.bias': tensor(0.1539, device='cuda:0'), 'output_layer.bias': tensor(-30.3483, device='cuda:0'), 'backend.2.weight': tensor(-93.3561, device='cuda:0'), 'backend.6.bias': tensor(-0.0265, device='cuda:0'), 'backend.0.weight': tensor(-21.5634, device='cuda:0'), 'output_layer.weight': tensor(-5.2881, device='cuda:0'), 'backend.4.weight': tensor(-96.7639, device='cuda:0'), 'backend.4.bias': tensor(-0.0339, device='cuda:0')}
INFO:root:==> Training scene: 2
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.4576377869, MAE: 14.0155792236, MSE: 14.0155792746
INFO:root:(Meta-training) post train loss: 28.2439670563, MAE: 246.063415527, MSE: 246.063412813
INFO:root:(Meta-training) pre-training test MAE: 8.87585067749, MSE: 8.875850583
INFO:root:(Meta-training) post-training test MAE: 235.911239624, MSE: 235.911240261
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-1020.3320, device='cuda:0'), 'backend.0.bias': tensor(-0.1067, device='cuda:0'), 'backend.10.weight': tensor(-2049.0684, device='cuda:0'), 'backend.8.bias': tensor(-5.0614, device='cuda:0'), 'backend.6.weight': tensor(-1269.1732, device='cuda:0'), 'backend.2.bias': tensor(-0.5702, device='cuda:0'), 'backend.10.bias': tensor(-49.0953, device='cuda:0'), 'output_layer.bias': tensor(-201.3323, device='cuda:0'), 'backend.2.weight': tensor(-2259.6045, device='cuda:0'), 'backend.6.bias': tensor(-1.0513, device='cuda:0'), 'backend.0.weight': tensor(-684.9939, device='cuda:0'), 'output_layer.weight': tensor(-48.6113, device='cuda:0'), 'backend.4.weight': tensor(-2496.2798, device='cuda:0'), 'backend.4.bias': tensor(-1.3280, device='cuda:0')}
INFO:root:==> Training scene: 3
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.215716362, MAE: 12.3267059326, MSE: 12.3267058703
INFO:root:(Meta-training) post train loss: 13.1575832367, MAE: 155.954437256, MSE: 155.95443921
INFO:root:(Meta-training) pre-training test MAE: 17.9829978943, MSE: 17.9829979178
INFO:root:(Meta-training) post-training test MAE: 149.803665161, MSE: 149.803667084
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-411.3109, device='cuda:0'), 'backend.0.bias': tensor(-0.1084, device='cuda:0'), 'backend.10.weight': tensor(-577.3654, device='cuda:0'), 'backend.8.bias': tensor(-1.6774, device='cuda:0'), 'backend.6.weight': tensor(-752.4692, device='cuda:0'), 'backend.2.bias': tensor(-0.3535, device='cuda:0'), 'backend.10.bias': tensor(-13.2628, device='cuda:0'), 'output_layer.bias': tensor(-113.9397, device='cuda:0'), 'backend.2.weight': tensor(-1495.3287, device='cuda:0'), 'backend.6.bias': tensor(-0.6486, device='cuda:0'), 'backend.0.weight': tensor(-532.8908, device='cuda:0'), 'output_layer.weight': tensor(-24.8956, device='cuda:0'), 'backend.4.weight': tensor(-1443.4919, device='cuda:0'), 'backend.4.bias': tensor(-0.7667, device='cuda:0')}
INFO:root:==> Training scene: 4
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.40858054161, MAE: 3.46781778336, MSE: 3.46781785142
INFO:root:(Meta-training) post train loss: 1.24631130695, MAE: 40.1663703918, MSE: 40.1663700161
INFO:root:(Meta-training) pre-training test MAE: 5.10420227051, MSE: 5.1042023119
INFO:root:(Meta-training) post-training test MAE: 38.2077407837, MSE: 38.207740327
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-22.4932, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(-6.9668, device='cuda:0'), 'backend.8.bias': tensor(-0.0887, device='cuda:0'), 'backend.6.weight': tensor(1.9747, device='cuda:0'), 'backend.2.bias': tensor(-0.0034, device='cuda:0'), 'backend.10.bias': tensor(-0.2023, device='cuda:0'), 'output_layer.bias': tensor(-28.7350, device='cuda:0'), 'backend.2.weight': tensor(-43.8065, device='cuda:0'), 'backend.6.bias': tensor(0.0327, device='cuda:0'), 'backend.0.weight': tensor(-7.9347, device='cuda:0'), 'output_layer.weight': tensor(-4.6944, device='cuda:0'), 'backend.4.weight': tensor(-74.9707, device='cuda:0'), 'backend.4.bias': tensor(-0.0318, device='cuda:0')}
INFO:root:==> Training scene: 5
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.464849472, MAE: 11.5086917877, MSE: 11.5086915716
INFO:root:(Meta-training) post train loss: 12.0098371506, MAE: 157.504074097, MSE: 157.504073608
INFO:root:(Meta-training) pre-training test MAE: 6.65334415436, MSE: 6.65334403491
INFO:root:(Meta-training) post-training test MAE: 148.859954834, MSE: 148.859958046
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-168.4950, device='cuda:0'), 'backend.0.bias': tensor(-0.0335, device='cuda:0'), 'backend.10.weight': tensor(-512.0421, device='cuda:0'), 'backend.8.bias': tensor(-0.8689, device='cuda:0'), 'backend.6.weight': tensor(-290.6690, device='cuda:0'), 'backend.2.bias': tensor(-0.2067, device='cuda:0'), 'backend.10.bias': tensor(-12.1426, device='cuda:0'), 'output_layer.bias': tensor(-113.5457, device='cuda:0'), 'backend.2.weight': tensor(-810.5503, device='cuda:0'), 'backend.6.bias': tensor(-0.2528, device='cuda:0'), 'backend.0.weight': tensor(-189.6144, device='cuda:0'), 'output_layer.weight': tensor(-21.5855, device='cuda:0'), 'backend.4.weight': tensor(-870.6675, device='cuda:0'), 'backend.4.bias': tensor(-0.5180, device='cuda:0')}
INFO:root:==> Training scene: 6
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.31700372696, MAE: 4.50811004639, MSE: 4.50810994402
INFO:root:(Meta-training) post train loss: 2.54581308365, MAE: 56.9175300598, MSE: 56.9175300291
INFO:root:(Meta-training) pre-training test MAE: 3.33308029175, MSE: 3.33308034573
INFO:root:(Meta-training) post-training test MAE: 57.6218643188, MSE: 57.6218647466
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-37.6213, device='cuda:0'), 'backend.0.bias': tensor(0.0053, device='cuda:0'), 'backend.10.weight': tensor(-48.7510, device='cuda:0'), 'backend.8.bias': tensor(-0.1999, device='cuda:0'), 'backend.6.weight': tensor(-3.2663, device='cuda:0'), 'backend.2.bias': tensor(-0.0192, device='cuda:0'), 'backend.10.bias': tensor(-1.0821, device='cuda:0'), 'output_layer.bias': tensor(-43.8108, device='cuda:0'), 'backend.2.weight': tensor(-99.3718, device='cuda:0'), 'backend.6.bias': tensor(0.0174, device='cuda:0'), 'backend.0.weight': tensor(-8.4586, device='cuda:0'), 'output_layer.weight': tensor(-7.1186, device='cuda:0'), 'backend.4.weight': tensor(-117.8177, device='cuda:0'), 'backend.4.bias': tensor(-0.0676, device='cuda:0')}
INFO:root:==> Training scene: 7
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.56835842133, MAE: 9.11410331726, MSE: 9.11410331697
INFO:root:(Meta-training) post train loss: 8.68908500671, MAE: 118.70375061, MSE: 118.703749217
INFO:root:(Meta-training) pre-training test MAE: 7.59414863586, MSE: 7.59414860186
INFO:root:(Meta-training) post-training test MAE: 119.183746338, MSE: 119.183747319
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-183.1739, device='cuda:0'), 'backend.0.bias': tensor(-0.0085, device='cuda:0'), 'backend.10.weight': tensor(-210.6387, device='cuda:0'), 'backend.8.bias': tensor(-0.9138, device='cuda:0'), 'backend.6.weight': tensor(-301.4147, device='cuda:0'), 'backend.2.bias': tensor(-0.1017, device='cuda:0'), 'backend.10.bias': tensor(-4.8148, device='cuda:0'), 'output_layer.bias': tensor(-90.9324, device='cuda:0'), 'backend.2.weight': tensor(-551.6275, device='cuda:0'), 'backend.6.bias': tensor(-0.2307, device='cuda:0'), 'backend.0.weight': tensor(-168.9219, device='cuda:0'), 'output_layer.weight': tensor(-16.1698, device='cuda:0'), 'backend.4.weight': tensor(-548.3022, device='cuda:0'), 'backend.4.bias': tensor(-0.2530, device='cuda:0')}
INFO:root:==> Training scene: 8
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.70169210434, MAE: 4.29832458496, MSE: 4.29832450693
INFO:root:(Meta-training) post train loss: 3.9628610611, MAE: 41.1326179504, MSE: 41.1326173725
INFO:root:(Meta-training) pre-training test MAE: 0.344522476196, MSE: 0.34452247522
INFO:root:(Meta-training) post-training test MAE: 45.7303619385, MSE: 45.730363144
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-90.5592, device='cuda:0'), 'backend.0.bias': tensor(-0.0234, device='cuda:0'), 'backend.10.weight': tensor(-131.2070, device='cuda:0'), 'backend.8.bias': tensor(-0.3804, device='cuda:0'), 'backend.6.weight': tensor(-169.8558, device='cuda:0'), 'backend.2.bias': tensor(-0.0816, device='cuda:0'), 'backend.10.bias': tensor(-2.6672, device='cuda:0'), 'output_layer.bias': tensor(-34.8099, device='cuda:0'), 'backend.2.weight': tensor(-365.8164, device='cuda:0'), 'backend.6.bias': tensor(-0.1439, device='cuda:0'), 'backend.0.weight': tensor(-121.5346, device='cuda:0'), 'output_layer.weight': tensor(-7.2147, device='cuda:0'), 'backend.4.weight': tensor(-379.3095, device='cuda:0'), 'backend.4.bias': tensor(-0.1953, device='cuda:0')}
INFO:root:==> Training scene: 9
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.31722784042, MAE: 1.57554912567, MSE: 1.57554914801
INFO:root:(Meta-training) post train loss: 4.04796600342, MAE: 13.7908372879, MSE: 13.7908373504
INFO:root:(Meta-training) pre-training test MAE: 5.13178634644, MSE: 5.13178641226
INFO:root:(Meta-training) post-training test MAE: 10.5187911987, MSE: 10.5187910962
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(12.7442, device='cuda:0'), 'backend.0.bias': tensor(0.0095, device='cuda:0'), 'backend.10.weight': tensor(-5.2698, device='cuda:0'), 'backend.8.bias': tensor(0.0464, device='cuda:0'), 'backend.6.weight': tensor(44.8917, device='cuda:0'), 'backend.2.bias': tensor(0.0177, device='cuda:0'), 'backend.10.bias': tensor(-0.2285, device='cuda:0'), 'output_layer.bias': tensor(-7.7328, device='cuda:0'), 'backend.2.weight': tensor(82.0613, device='cuda:0'), 'backend.6.bias': tensor(0.0495, device='cuda:0'), 'backend.0.weight': tensor(42.8595, device='cuda:0'), 'output_layer.weight': tensor(-1.1357, device='cuda:0'), 'backend.4.weight': tensor(46.6689, device='cuda:0'), 'backend.4.bias': tensor(0.0206, device='cuda:0')}
INFO:root:==> Training scene: 10
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 2.62649679184, MAE: 0.140889167786, MSE: 0.14088916471
INFO:root:(Meta-training) post train loss: 1.72036850452, MAE: 8.40645599365, MSE: 8.40645601949
INFO:root:(Meta-training) pre-training test MAE: 2.28190612793, MSE: 2.28190613808
INFO:root:(Meta-training) post-training test MAE: 9.29603385925, MSE: 9.29603380517
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(29.3622, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(14.4824, device='cuda:0'), 'backend.8.bias': tensor(0.1243, device='cuda:0'), 'backend.6.weight': tensor(20.2013, device='cuda:0'), 'backend.2.bias': tensor(0.0180, device='cuda:0'), 'backend.10.bias': tensor(0.5394, device='cuda:0'), 'output_layer.bias': tensor(7.4570, device='cuda:0'), 'backend.2.weight': tensor(65.5934, device='cuda:0'), 'backend.6.bias': tensor(0.0065, device='cuda:0'), 'backend.0.weight': tensor(18.4875, device='cuda:0'), 'output_layer.weight': tensor(1.3642, device='cuda:0'), 'backend.4.weight': tensor(55.7639, device='cuda:0'), 'backend.4.bias': tensor(0.0333, device='cuda:0')}
INFO:root:==> Training scene: 11
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 20.0581626892, MAE: 3.79273986816, MSE: 3.79273981411
INFO:root:(Meta-training) post train loss: 15.4374341965, MAE: 60.0539627075, MSE: 60.0539633632
INFO:root:(Meta-training) pre-training test MAE: 1.65007305145, MSE: 1.65007306717
INFO:root:(Meta-training) post-training test MAE: 46.8975715637, MSE: 46.8975726901
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-285.1152, device='cuda:0'), 'backend.0.bias': tensor(-0.0562, device='cuda:0'), 'backend.10.weight': tensor(-397.6520, device='cuda:0'), 'backend.8.bias': tensor(-1.2813, device='cuda:0'), 'backend.6.weight': tensor(-501.0741, device='cuda:0'), 'backend.2.bias': tensor(-0.1695, device='cuda:0'), 'backend.10.bias': tensor(-8.2408, device='cuda:0'), 'output_layer.bias': tensor(-36.3815, device='cuda:0'), 'backend.2.weight': tensor(-722.0635, device='cuda:0'), 'backend.6.bias': tensor(-0.4861, device='cuda:0'), 'backend.0.weight': tensor(-277.7652, device='cuda:0'), 'output_layer.weight': tensor(-10.3747, device='cuda:0'), 'backend.4.weight': tensor(-798.2845, device='cuda:0'), 'backend.4.bias': tensor(-0.4068, device='cuda:0')}
INFO:root:==> Training scene: 12
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.26931238174, MAE: 9.15769100189, MSE: 9.15769098289
INFO:root:(Meta-training) post train loss: 5.25304222107, MAE: 128.482192993, MSE: 128.48219265
INFO:root:(Meta-training) pre-training test MAE: 4.61597824097, MSE: 4.61597820524
INFO:root:(Meta-training) post-training test MAE: 141.958709717, MSE: 141.958710161
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(260.6507, device='cuda:0'), 'backend.0.bias': tensor(0.0241, device='cuda:0'), 'backend.10.weight': tensor(468.7807, device='cuda:0'), 'backend.8.bias': tensor(1.2948, device='cuda:0'), 'backend.6.weight': tensor(381.9536, device='cuda:0'), 'backend.2.bias': tensor(0.2002, device='cuda:0'), 'backend.10.bias': tensor(12.5315, device='cuda:0'), 'output_layer.bias': tensor(110.0442, device='cuda:0'), 'backend.2.weight': tensor(951.6744, device='cuda:0'), 'backend.6.bias': tensor(0.2520, device='cuda:0'), 'backend.0.weight': tensor(256.8109, device='cuda:0'), 'output_layer.weight': tensor(24.2919, device='cuda:0'), 'backend.4.weight': tensor(1108.7393, device='cuda:0'), 'backend.4.bias': tensor(0.5716, device='cuda:0')}
INFO:root:==> Training scene: 13
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.15585327148, MAE: 0.122278213501, MSE: 0.122278211939
INFO:root:(Meta-training) post train loss: 6.03297519684, MAE: 16.0758647919, MSE: 16.0758651762
INFO:root:(Meta-training) pre-training test MAE: 6.88552856445, MSE: 6.88552854815
INFO:root:(Meta-training) post-training test MAE: 24.3776416779, MSE: 24.3776415836
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(63.4808, device='cuda:0'), 'backend.0.bias': tensor(0.0233, device='cuda:0'), 'backend.10.weight': tensor(82.2610, device='cuda:0'), 'backend.8.bias': tensor(0.2575, device='cuda:0'), 'backend.6.weight': tensor(116.4730, device='cuda:0'), 'backend.2.bias': tensor(0.0472, device='cuda:0'), 'backend.10.bias': tensor(1.7025, device='cuda:0'), 'output_layer.bias': tensor(19.4742, device='cuda:0'), 'backend.2.weight': tensor(230.1301, device='cuda:0'), 'backend.6.bias': tensor(0.0803, device='cuda:0'), 'backend.0.weight': tensor(113.1909, device='cuda:0'), 'output_layer.weight': tensor(4.3418, device='cuda:0'), 'backend.4.weight': tensor(236.4320, device='cuda:0'), 'backend.4.bias': tensor(0.1142, device='cuda:0')}
INFO:root:==> Training scene: 14
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.2247161865, MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post train loss: 11.2101097107, MAE: 134.058197021, MSE: 134.058194861
INFO:root:(Meta-training) pre-training test MAE: 9.19702339172, MSE: 9.19702319208
INFO:root:(Meta-training) post-training test MAE: 132.98664856, MSE: 132.986650528
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-412.4737, device='cuda:0'), 'backend.0.bias': tensor(-0.0713, device='cuda:0'), 'backend.10.weight': tensor(-431.9995, device='cuda:0'), 'backend.8.bias': tensor(-1.9927, device='cuda:0'), 'backend.6.weight': tensor(-607.5552, device='cuda:0'), 'backend.2.bias': tensor(-0.2443, device='cuda:0'), 'backend.10.bias': tensor(-9.6425, device='cuda:0'), 'output_layer.bias': tensor(-102.2852, device='cuda:0'), 'backend.2.weight': tensor(-871.2731, device='cuda:0'), 'backend.6.bias': tensor(-0.6839, device='cuda:0'), 'backend.0.weight': tensor(-302.5356, device='cuda:0'), 'output_layer.weight': tensor(-20.8222, device='cuda:0'), 'backend.4.weight': tensor(-984.5646, device='cuda:0'), 'backend.4.bias': tensor(-0.5933, device='cuda:0')}
INFO:root:==> Training scene: 15
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.0185213089, MAE: 6.06261253357, MSE: 6.06261263084
INFO:root:(Meta-training) post train loss: 5.02552652359, MAE: 89.3602752686, MSE: 89.3602752293
INFO:root:(Meta-training) pre-training test MAE: 2.2882976532, MSE: 2.28829766213
INFO:root:(Meta-training) post-training test MAE: 88.706703186, MSE: 88.7067043381
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(73.9416, device='cuda:0'), 'backend.0.bias': tensor(-0.0452, device='cuda:0'), 'backend.10.weight': tensor(228.9542, device='cuda:0'), 'backend.8.bias': tensor(0.1953, device='cuda:0'), 'backend.6.weight': tensor(-42.0229, device='cuda:0'), 'backend.2.bias': tensor(-0.0187, device='cuda:0'), 'backend.10.bias': tensor(7.8502, device='cuda:0'), 'output_layer.bias': tensor(67.6426, device='cuda:0'), 'backend.2.weight': tensor(47.4640, device='cuda:0'), 'backend.6.bias': tensor(-0.2108, device='cuda:0'), 'backend.0.weight': tensor(-75.9561, device='cuda:0'), 'output_layer.weight': tensor(11.4994, device='cuda:0'), 'backend.4.weight': tensor(242.4803, device='cuda:0'), 'backend.4.bias': tensor(0.1128, device='cuda:0')}
INFO:root:==> Training scene: 16
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.7963008881, MAE: 16.1687660217, MSE: 16.1687657413
INFO:root:(Meta-training) post train loss: 22.4242458344, MAE: 229.407485962, MSE: 229.407482373
INFO:root:(Meta-training) pre-training test MAE: 6.00388336182, MSE: 6.00388337666
INFO:root:(Meta-training) post-training test MAE: 239.257141113, MSE: 239.257142984
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-988.6005, device='cuda:0'), 'backend.0.bias': tensor(-0.2824, device='cuda:0'), 'backend.10.weight': tensor(-1988.3594, device='cuda:0'), 'backend.8.bias': tensor(-5.0329, device='cuda:0'), 'backend.6.weight': tensor(-2082.1543, device='cuda:0'), 'backend.2.bias': tensor(-1.0028, device='cuda:0'), 'backend.10.bias': tensor(-44.8206, device='cuda:0'), 'output_layer.bias': tensor(-201.1472, device='cuda:0'), 'backend.2.weight': tensor(-3871.7910, device='cuda:0'), 'backend.6.bias': tensor(-2.2654, device='cuda:0'), 'backend.0.weight': tensor(-1286.4838, device='cuda:0'), 'output_layer.weight': tensor(-56.6222, device='cuda:0'), 'backend.4.weight': tensor(-4343.2554, device='cuda:0'), 'backend.4.bias': tensor(-2.4096, device='cuda:0')}
INFO:root:==> Training scene: 17
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 32.0257339478, MAE: 15.1991195679, MSE: 15.1991193617
INFO:root:(Meta-training) post train loss: 48.2651062012, MAE: 335.650817871, MSE: 335.650813719
INFO:root:(Meta-training) pre-training test MAE: 11.0977325439, MSE: 11.0977325598
INFO:root:(Meta-training) post-training test MAE: 336.292419434, MSE: 336.292422974
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-7079.0273, device='cuda:0'), 'backend.0.bias': tensor(-1.0678, device='cuda:0'), 'backend.10.weight': tensor(-9176.1582, device='cuda:0'), 'backend.8.bias': tensor(-32.7449, device='cuda:0'), 'backend.6.weight': tensor(-9999.3701, device='cuda:0'), 'backend.2.bias': tensor(-3.5476, device='cuda:0'), 'backend.10.bias': tensor(-201.9896, device='cuda:0'), 'output_layer.bias': tensor(-380.1562, device='cuda:0'), 'backend.2.weight': tensor(-13915.4160, device='cuda:0'), 'backend.6.bias': tensor(-10.0968, device='cuda:0'), 'backend.0.weight': tensor(-4359.9873, device='cuda:0'), 'output_layer.weight': tensor(-154.6839, device='cuda:0'), 'backend.4.weight': tensor(-14321.6836, device='cuda:0'), 'backend.4.bias': tensor(-7.5350, device='cuda:0')}
INFO:root:==> Training scene: 18
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.19173002243, MAE: 9.96483707428, MSE: 9.96483724213
INFO:root:(Meta-training) post train loss: 8.31143093109, MAE: 108.922950745, MSE: 108.92294976
INFO:root:(Meta-training) pre-training test MAE: 26.310459137, MSE: 26.31045865
INFO:root:(Meta-training) post-training test MAE: 94.4987640381, MSE: 94.4987650796
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-88.2477, device='cuda:0'), 'backend.0.bias': tensor(0.0020, device='cuda:0'), 'backend.10.weight': tensor(-150.8411, device='cuda:0'), 'backend.8.bias': tensor(-0.5698, device='cuda:0'), 'backend.6.weight': tensor(-90.5708, device='cuda:0'), 'backend.2.bias': tensor(-0.0589, device='cuda:0'), 'backend.10.bias': tensor(-4.4715, device='cuda:0'), 'output_layer.bias': tensor(-71.4431, device='cuda:0'), 'backend.2.weight': tensor(-212.6744, device='cuda:0'), 'backend.6.bias': tensor(-0.1036, device='cuda:0'), 'backend.0.weight': tensor(-35.0562, device='cuda:0'), 'output_layer.weight': tensor(-12.1312, device='cuda:0'), 'backend.4.weight': tensor(-304.2588, device='cuda:0'), 'backend.4.bias': tensor(-0.2161, device='cuda:0')}
INFO:root:==> Training scene: 19
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.85736942291, MAE: 15.1381454468, MSE: 15.1381455981
INFO:root:(Meta-training) post train loss: 11.7894163132, MAE: 200.715957642, MSE: 200.71595485
INFO:root:(Meta-training) pre-training test MAE: 19.7869281769, MSE: 19.786928058
INFO:root:(Meta-training) post-training test MAE: 196.792785645, MSE: 196.792790375
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-82.1093, device='cuda:0'), 'backend.0.bias': tensor(0.0720, device='cuda:0'), 'backend.10.weight': tensor(-106.0497, device='cuda:0'), 'backend.8.bias': tensor(-0.6434, device='cuda:0'), 'backend.6.weight': tensor(60.6098, device='cuda:0'), 'backend.2.bias': tensor(0.0389, device='cuda:0'), 'backend.10.bias': tensor(-4.0570, device='cuda:0'), 'output_layer.bias': tensor(-149.3103, device='cuda:0'), 'backend.2.weight': tensor(-19.7751, device='cuda:0'), 'backend.6.bias': tensor(0.1884, device='cuda:0'), 'backend.0.weight': tensor(94.8992, device='cuda:0'), 'output_layer.weight': tensor(-21.7000, device='cuda:0'), 'backend.4.weight': tensor(-218.3605, device='cuda:0'), 'backend.4.bias': tensor(-0.1340, device='cuda:0')}
INFO:root:==> Training scene: 20
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.6179828644, MAE: 19.8658561707, MSE: 19.8658564426
INFO:root:(Meta-training) post train loss: 23.2383213043, MAE: 305.630065918, MSE: 305.630061308
INFO:root:(Meta-training) pre-training test MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post-training test MAE: 309.446777344, MSE: 309.446771978
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(58.7686, device='cuda:0'), 'backend.0.bias': tensor(0.1086, device='cuda:0'), 'backend.10.weight': tensor(-648.2241, device='cuda:0'), 'backend.8.bias': tensor(0.4562, device='cuda:0'), 'backend.6.weight': tensor(345.6556, device='cuda:0'), 'backend.2.bias': tensor(-0.1202, device='cuda:0'), 'backend.10.bias': tensor(-15.2989, device='cuda:0'), 'output_layer.bias': tensor(-243.9008, device='cuda:0'), 'backend.2.weight': tensor(-578.7979, device='cuda:0'), 'backend.6.bias': tensor(0.6730, device='cuda:0'), 'backend.0.weight': tensor(372.4923, device='cuda:0'), 'output_layer.weight': tensor(-42.9096, device='cuda:0'), 'backend.4.weight': tensor(-832.2754, device='cuda:0'), 'backend.4.bias': tensor(-0.4173, device='cuda:0')}
INFO:root:==> Training scene: 21
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.92966938019, MAE: 7.99254989624, MSE: 7.99255000362
INFO:root:(Meta-training) post train loss: 7.9303984642, MAE: 103.157691956, MSE: 103.157693681
INFO:root:(Meta-training) pre-training test MAE: 17.2073936462, MSE: 17.2073934943
INFO:root:(Meta-training) post-training test MAE: 94.2486724854, MSE: 94.2486737307
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-110.2387, device='cuda:0'), 'backend.0.bias': tensor(-0.0146, device='cuda:0'), 'backend.10.weight': tensor(-230.1305, device='cuda:0'), 'backend.8.bias': tensor(-0.4253, device='cuda:0'), 'backend.6.weight': tensor(-117.1571, device='cuda:0'), 'backend.2.bias': tensor(-0.0757, device='cuda:0'), 'backend.10.bias': tensor(-5.3008, device='cuda:0'), 'output_layer.bias': tensor(-71.6464, device='cuda:0'), 'backend.2.weight': tensor(-347.9861, device='cuda:0'), 'backend.6.bias': tensor(-0.0327, device='cuda:0'), 'backend.0.weight': tensor(-114.7507, device='cuda:0'), 'output_layer.weight': tensor(-14.5011, device='cuda:0'), 'backend.4.weight': tensor(-442.1409, device='cuda:0'), 'backend.4.bias': tensor(-0.2187, device='cuda:0')}
INFO:root:==> Training scene: 22
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.6123580933, MAE: 10.1582298279, MSE: 10.1582299753
INFO:root:(Meta-training) post train loss: 13.2736635208, MAE: 153.450271606, MSE: 153.450273145
INFO:root:(Meta-training) pre-training test MAE: 16.6812591553, MSE: 16.6812590741
INFO:root:(Meta-training) post-training test MAE: 142.571716309, MSE: 142.571713041
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-348.8337, device='cuda:0'), 'backend.0.bias': tensor(-0.1027, device='cuda:0'), 'backend.10.weight': tensor(-844.5209, device='cuda:0'), 'backend.8.bias': tensor(-1.7194, device='cuda:0'), 'backend.6.weight': tensor(-814.8106, device='cuda:0'), 'backend.2.bias': tensor(-0.4311, device='cuda:0'), 'backend.10.bias': tensor(-20.1072, device='cuda:0'), 'output_layer.bias': tensor(-113.4044, device='cuda:0'), 'backend.2.weight': tensor(-1628.4746, device='cuda:0'), 'backend.6.bias': tensor(-0.7616, device='cuda:0'), 'backend.0.weight': tensor(-452.7469, device='cuda:0'), 'output_layer.weight': tensor(-25.8738, device='cuda:0'), 'backend.4.weight': tensor(-1727.8400, device='cuda:0'), 'backend.4.bias': tensor(-1.0229, device='cuda:0')}
INFO:root:==> Training scene: 23
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 21.1111278534, MAE: 0.63020324707, MSE: 0.630203236541
INFO:root:(Meta-training) post train loss: 22.0809345245, MAE: 13.3690032959, MSE: 13.3690035203
INFO:root:(Meta-training) pre-training test MAE: 6.70138835907, MSE: 6.70138847426
INFO:root:(Meta-training) post-training test MAE: 37.1159133911, MSE: 37.1159138976
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(16.0167, device='cuda:0'), 'backend.0.bias': tensor(0.0425, device='cuda:0'), 'backend.10.weight': tensor(-114.7200, device='cuda:0'), 'backend.8.bias': tensor(-0.0449, device='cuda:0'), 'backend.6.weight': tensor(201.0810, device='cuda:0'), 'backend.2.bias': tensor(0.0558, device='cuda:0'), 'backend.10.bias': tensor(-2.8130, device='cuda:0'), 'output_layer.bias': tensor(-25.3122, device='cuda:0'), 'backend.2.weight': tensor(294.5784, device='cuda:0'), 'backend.6.bias': tensor(0.1817, device='cuda:0'), 'backend.0.weight': tensor(233.2812, device='cuda:0'), 'output_layer.weight': tensor(-4.9482, device='cuda:0'), 'backend.4.weight': tensor(177.3403, device='cuda:0'), 'backend.4.bias': tensor(0.0573, device='cuda:0')}
INFO:root:==> Training scene: 24
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.3689892292, MAE: 3.61751317978, MSE: 3.61751322588
INFO:root:(Meta-training) post train loss: 1.41690576077, MAE: 57.1678237915, MSE: 57.1678244841
INFO:root:(Meta-training) pre-training test MAE: 3.67163085938, MSE: 3.67163085126
INFO:root:(Meta-training) post-training test MAE: 62.9182167053, MSE: 62.9182159974
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(67.4450, device='cuda:0'), 'backend.0.bias': tensor(-0.0376, device='cuda:0'), 'backend.10.weight': tensor(95.9710, device='cuda:0'), 'backend.8.bias': tensor(0.2977, device='cuda:0'), 'backend.6.weight': tensor(-43.1883, device='cuda:0'), 'backend.2.bias': tensor(-0.0293, device='cuda:0'), 'backend.10.bias': tensor(3.6065, device='cuda:0'), 'output_layer.bias': tensor(48.0856, device='cuda:0'), 'backend.2.weight': tensor(-23.3053, device='cuda:0'), 'backend.6.bias': tensor(-0.1360, device='cuda:0'), 'backend.0.weight': tensor(-73.2256, device='cuda:0'), 'output_layer.weight': tensor(7.2894, device='cuda:0'), 'backend.4.weight': tensor(94.5628, device='cuda:0'), 'backend.4.bias': tensor(0.0419, device='cuda:0')}
INFO:root:==> Training scene: 25
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.78185081482, MAE: 3.64704179764, MSE: 3.647041789
INFO:root:(Meta-training) post train loss: 1.5337716341, MAE: 41.5643882751, MSE: 41.5643884674
INFO:root:(Meta-training) pre-training test MAE: 7.03860282898, MSE: 7.03860292617
INFO:root:(Meta-training) post-training test MAE: 38.4184913635, MSE: 38.4184912347
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(6.1834, device='cuda:0'), 'backend.0.bias': tensor(0.0124, device='cuda:0'), 'backend.10.weight': tensor(-7.2555, device='cuda:0'), 'backend.8.bias': tensor(0.0298, device='cuda:0'), 'backend.6.weight': tensor(31.5153, device='cuda:0'), 'backend.2.bias': tensor(0.0100, device='cuda:0'), 'backend.10.bias': tensor(-0.1930, device='cuda:0'), 'output_layer.bias': tensor(-28.9806, device='cuda:0'), 'backend.2.weight': tensor(31.5567, device='cuda:0'), 'backend.6.bias': tensor(0.0482, device='cuda:0'), 'backend.0.weight': tensor(44.4503, device='cuda:0'), 'output_layer.weight': tensor(-4.4127, device='cuda:0'), 'backend.4.weight': tensor(9.8322, device='cuda:0'), 'backend.4.bias': tensor(0.0038, device='cuda:0')}
INFO:root:==> Training scene: 26
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.51275110245, MAE: 4.93081665039, MSE: 4.93081656946
INFO:root:(Meta-training) post train loss: 6.66961288452, MAE: 63.5387802124, MSE: 63.5387796048
INFO:root:(Meta-training) pre-training test MAE: 1.70257949829, MSE: 1.70257951593
INFO:root:(Meta-training) post-training test MAE: 74.05909729, MSE: 74.0590980231
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-64.9164, device='cuda:0'), 'backend.0.bias': tensor(0.0207, device='cuda:0'), 'backend.10.weight': tensor(-215.7396, device='cuda:0'), 'backend.8.bias': tensor(-0.2159, device='cuda:0'), 'backend.6.weight': tensor(-53.6763, device='cuda:0'), 'backend.2.bias': tensor(0.0031, device='cuda:0'), 'backend.10.bias': tensor(-5.1249, device='cuda:0'), 'output_layer.bias': tensor(-58.9641, device='cuda:0'), 'backend.2.weight': tensor(-154.8738, device='cuda:0'), 'backend.6.bias': tensor(0.1189, device='cuda:0'), 'backend.0.weight': tensor(-51.5998, device='cuda:0'), 'output_layer.weight': tensor(-9.6605, device='cuda:0'), 'backend.4.weight': tensor(-269.6783, device='cuda:0'), 'backend.4.bias': tensor(-0.1026, device='cuda:0')}
INFO:root:==> Training scene: 27
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.81052994728, MAE: 3.4300737381, MSE: 3.43007370984
INFO:root:(Meta-training) post train loss: 1.85474944115, MAE: 49.2230949402, MSE: 49.2230950463
INFO:root:(Meta-training) pre-training test MAE: 0.405708312988, MSE: 0.405708318655
INFO:root:(Meta-training) post-training test MAE: 53.5645370483, MSE: 53.5645374102
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(21.7239, device='cuda:0'), 'backend.0.bias': tensor(-0.0415, device='cuda:0'), 'backend.10.weight': tensor(88.3675, device='cuda:0'), 'backend.8.bias': tensor(0.0254, device='cuda:0'), 'backend.6.weight': tensor(-91.4464, device='cuda:0'), 'backend.2.bias': tensor(-0.0413, device='cuda:0'), 'backend.10.bias': tensor(3.2484, device='cuda:0'), 'output_layer.bias': tensor(40.5884, device='cuda:0'), 'backend.2.weight': tensor(-47.4420, device='cuda:0'), 'backend.6.bias': tensor(-0.2370, device='cuda:0'), 'backend.0.weight': tensor(-68.5267, device='cuda:0'), 'output_layer.weight': tensor(6.0570, device='cuda:0'), 'backend.4.weight': tensor(54.8532, device='cuda:0'), 'backend.4.bias': tensor(-0.0010, device='cuda:0')}
INFO:root:==> Training scene: 28
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.91805839539, MAE: 16.495388031, MSE: 16.4953884269
INFO:root:(Meta-training) post train loss: 16.5992279053, MAE: 248.975265503, MSE: 248.975267032
INFO:root:(Meta-training) pre-training test MAE: 5.10612487793, MSE: 5.10612491749
INFO:root:(Meta-training) post-training test MAE: 254.839996338, MSE: 254.839992691
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-218.2436, device='cuda:0'), 'backend.0.bias': tensor(0.0600, device='cuda:0'), 'backend.10.weight': tensor(-483.3945, device='cuda:0'), 'backend.8.bias': tensor(-0.9689, device='cuda:0'), 'backend.6.weight': tensor(58.4666, device='cuda:0'), 'backend.2.bias': tensor(-0.1581, device='cuda:0'), 'backend.10.bias': tensor(-8.8787, device='cuda:0'), 'output_layer.bias': tensor(-200.1620, device='cuda:0'), 'backend.2.weight': tensor(-680.3275, device='cuda:0'), 'backend.6.bias': tensor(0.2169, device='cuda:0'), 'backend.0.weight': tensor(194.6782, device='cuda:0'), 'output_layer.weight': tensor(-33.2362, device='cuda:0'), 'backend.4.weight': tensor(-900.4709, device='cuda:0'), 'backend.4.bias': tensor(-0.4924, device='cuda:0')}
INFO:root:==> Training scene: 29
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.79754734039, MAE: 17.5090179443, MSE: 17.5090178007
INFO:root:(Meta-training) post train loss: 19.8869838715, MAE: 259.828735352, MSE: 259.828729647
INFO:root:(Meta-training) pre-training test MAE: 19.3920478821, MSE: 19.3920476916
INFO:root:(Meta-training) post-training test MAE: 262.822540283, MSE: 262.822539939
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-562.1874, device='cuda:0'), 'backend.0.bias': tensor(-0.0445, device='cuda:0'), 'backend.10.weight': tensor(-752.2290, device='cuda:0'), 'backend.8.bias': tensor(-2.6582, device='cuda:0'), 'backend.6.weight': tensor(-1082.9219, device='cuda:0'), 'backend.2.bias': tensor(-0.3633, device='cuda:0'), 'backend.10.bias': tensor(-19.6488, device='cuda:0'), 'output_layer.bias': tensor(-208.3303, device='cuda:0'), 'backend.2.weight': tensor(-1791.1677, device='cuda:0'), 'backend.6.bias': tensor(-0.9017, device='cuda:0'), 'backend.0.weight': tensor(-419.6158, device='cuda:0'), 'output_layer.weight': tensor(-41.2734, device='cuda:0'), 'backend.4.weight': tensor(-1991.5449, device='cuda:0'), 'backend.4.bias': tensor(-0.9737, device='cuda:0')}
INFO:root:==> Training scene: 30
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.79670476913, MAE: 2.56892776489, MSE: 2.56892779772
INFO:root:(Meta-training) post train loss: 5.16473007202, MAE: 24.4140777588, MSE: 24.4140775
INFO:root:(Meta-training) pre-training test MAE: 1.84230804443, MSE: 1.84230806249
INFO:root:(Meta-training) post-training test MAE: 22.7580795288, MSE: 22.7580793518
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-46.0849, device='cuda:0'), 'backend.0.bias': tensor(-0.0036, device='cuda:0'), 'backend.10.weight': tensor(-73.4197, device='cuda:0'), 'backend.8.bias': tensor(-0.1900, device='cuda:0'), 'backend.6.weight': tensor(-62.4278, device='cuda:0'), 'backend.2.bias': tensor(-0.0266, device='cuda:0'), 'backend.10.bias': tensor(-1.6552, device='cuda:0'), 'output_layer.bias': tensor(-17.0427, device='cuda:0'), 'backend.2.weight': tensor(-127.3651, device='cuda:0'), 'backend.6.bias': tensor(-0.0366, device='cuda:0'), 'backend.0.weight': tensor(-25.0328, device='cuda:0'), 'output_layer.weight': tensor(-3.4376, device='cuda:0'), 'backend.4.weight': tensor(-128.4537, device='cuda:0'), 'backend.4.bias': tensor(-0.0640, device='cuda:0')}
INFO:root:==> Training scene: 31
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.92816901207, MAE: 6.54268741608, MSE: 6.54268743565
INFO:root:(Meta-training) post train loss: 3.94747567177, MAE: 79.0179595947, MSE: 79.0179592917
INFO:root:(Meta-training) pre-training test MAE: 2.77071666718, MSE: 2.77071666233
INFO:root:(Meta-training) post-training test MAE: 81.9200592041, MSE: 81.9200585699
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-42.4969, device='cuda:0'), 'backend.0.bias': tensor(0.0191, device='cuda:0'), 'backend.10.weight': tensor(-89.6895, device='cuda:0'), 'backend.8.bias': tensor(-0.1760, device='cuda:0'), 'backend.6.weight': tensor(25.6620, device='cuda:0'), 'backend.2.bias': tensor(-0.0125, device='cuda:0'), 'backend.10.bias': tensor(-2.3425, device='cuda:0'), 'output_layer.bias': tensor(-62.3058, device='cuda:0'), 'backend.2.weight': tensor(-101.7161, device='cuda:0'), 'backend.6.bias': tensor(0.0798, device='cuda:0'), 'backend.0.weight': tensor(28.3380, device='cuda:0'), 'output_layer.weight': tensor(-10.7214, device='cuda:0'), 'backend.4.weight': tensor(-192.2546, device='cuda:0'), 'backend.4.bias': tensor(-0.0999, device='cuda:0')}
INFO:root:==> Training scene: 32
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.5723743439, MAE: 3.49564743042, MSE: 3.49564744882
INFO:root:(Meta-training) post train loss: 8.17095661163, MAE: 36.8633918762, MSE: 36.8633919759
INFO:root:(Meta-training) pre-training test MAE: 3.27803039551, MSE: 3.27803041451
INFO:root:(Meta-training) post-training test MAE: 33.7333984375, MSE: 33.733397971
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-57.7780, device='cuda:0'), 'backend.0.bias': tensor(-0.0101, device='cuda:0'), 'backend.10.weight': tensor(-168.3473, device='cuda:0'), 'backend.8.bias': tensor(-0.3028, device='cuda:0'), 'backend.6.weight': tensor(-124.3879, device='cuda:0'), 'backend.2.bias': tensor(-0.0514, device='cuda:0'), 'backend.10.bias': tensor(-3.7849, device='cuda:0'), 'output_layer.bias': tensor(-26.0395, device='cuda:0'), 'backend.2.weight': tensor(-202.7419, device='cuda:0'), 'backend.6.bias': tensor(-0.1365, device='cuda:0'), 'backend.0.weight': tensor(-33.2555, device='cuda:0'), 'output_layer.weight': tensor(-5.5097, device='cuda:0'), 'backend.4.weight': tensor(-261.7993, device='cuda:0'), 'backend.4.bias': tensor(-0.1488, device='cuda:0')}
INFO:root:===> Updating meta network
INFO:root:===> Gradients updated: {'backend.8.weight': tensor([[[[ 7.7916e-01,  8.5607e-01,  7.9229e-01],
          [ 9.0868e-01,  7.7736e-01,  6.4876e-01],
          [ 9.0064e-01,  9.4987e-01,  7.5753e-01]],

         [[ 1.1307e-01,  1.0704e-01,  9.0648e-02],
          [ 1.2795e-01,  1.0473e-01,  1.2942e-01],
          [ 1.3047e-01,  1.6048e-01,  1.4018e-01]],

         [[ 7.5768e-01,  7.1184e-01,  8.0713e-01],
          [ 7.5325e-01,  7.6828e-01,  8.4883e-01],
          [ 6.4983e-01,  8.1942e-01,  6.6784e-01]],

         ...,

         [[ 4.8735e-03,  5.3943e-03,  5.6951e-03],
          [ 4.0222e-03,  5.7924e-03,  2.3920e-03],
          [ 5.1352e-03,  6.9411e-03,  1.8353e-03]],

         [[ 2.1338e-02,  1.4164e-02,  1.3132e-02],
          [ 1.4678e-02,  1.8111e-02,  1.2113e-02],
          [ 1.1622e-02,  1.0919e-02,  8.9136e-03]],

         [[ 8.8305e-01,  8.2144e-01,  7.5310e-01],
          [ 8.2313e-01,  8.4059e-01,  7.4162e-01],
          [ 8.5086e-01,  7.3575e-01,  7.3748e-01]]],


        [[[-4.9812e-01, -5.0378e-01, -5.1191e-01],
          [-4.0563e-01, -2.9149e-01, -3.7377e-01],
          [-2.8067e-01, -3.3813e-01, -3.9142e-01]],

         [[-3.6184e-02, -4.4533e-02, -3.7252e-02],
          [-3.7537e-02, -2.0504e-02, -3.5804e-02],
          [-3.6210e-02, -6.8324e-02, -4.4339e-02]],

         [[-3.7382e-01, -3.9211e-01, -4.3686e-01],
          [-4.6847e-01, -4.9453e-01, -5.1677e-01],
          [-5.1365e-01, -5.5016e-01, -3.8768e-01]],

         ...,

         [[-5.0242e-03, -1.1526e-03, -2.1686e-03],
          [-3.8029e-03, -3.3367e-03, -1.4324e-03],
          [-3.0780e-03, -4.2156e-03, -4.6184e-03]],

         [[-5.8553e-03, -1.7621e-02, -2.0924e-02],
          [-2.2585e-02, -2.9423e-02, -2.1775e-02],
          [-1.7520e-02, -1.5502e-02, -9.9938e-03]],

         [[-3.5619e-01, -4.2216e-01, -4.5200e-01],
          [-4.1187e-01, -5.1697e-01, -4.8196e-01],
          [-2.5478e-01, -2.9194e-01, -3.7740e-01]]],


        [[[-5.0192e-01, -1.6550e-01, -3.0481e-01],
          [-4.3925e-01, -2.2387e-01, -4.2957e-01],
          [-2.3618e-01, -4.3159e-01, -5.8229e-01]],

         [[-1.4857e-02, -4.3006e-02, -5.9084e-02],
          [-6.6491e-03, -6.0455e-02, -7.7892e-02],
          [-2.2638e-02, -5.3768e-02, -7.4316e-02]],

         [[ 8.3277e-02,  2.6159e-02, -2.1678e-01],
          [-1.3345e-01, -2.8881e-01, -1.2474e-01],
          [-3.7338e-01, -2.9140e-01, -1.1983e-01]],

         ...,

         [[-8.1380e-03, -4.9586e-03, -2.1028e-03],
          [-4.4010e-03, -1.6209e-03,  3.1506e-03],
          [-6.1099e-04,  1.2553e-03, -5.3141e-03]],

         [[ 1.1792e-02, -2.7060e-03, -3.8838e-03],
          [-1.7545e-03, -1.5361e-02, -9.7132e-03],
          [-3.5432e-03, -5.4996e-03, -2.7219e-03]],

         [[-7.8814e-03, -2.6094e-01, -2.7988e-01],
          [-1.4145e-01, -1.4226e-01, -3.1542e-01],
          [ 2.1231e-02, -2.0337e-01, -2.4090e-01]]],


        ...,


        [[[-2.9929e-01, -3.0268e-01, -2.6287e-01],
          [-2.9783e-01, -3.2070e-01, -2.3949e-01],
          [-3.1233e-01, -3.2161e-01, -2.6809e-01]],

         [[-3.4950e-02, -4.1251e-02, -3.6930e-02],
          [-3.8473e-02, -3.4362e-02, -3.8018e-02],
          [-3.6614e-02, -3.9380e-02, -3.5096e-02]],

         [[-1.7141e-01, -1.5779e-01, -1.4476e-01],
          [-1.7421e-01, -1.4054e-01, -1.5374e-01],
          [-1.1284e-01, -1.3553e-01, -1.4858e-01]],

         ...,

         [[-3.5638e-03, -2.7827e-03, -2.7394e-03],
          [-3.8445e-03, -3.7023e-03, -1.9840e-03],
          [-5.2670e-03, -4.6121e-03, -2.3858e-03]],

         [[-4.0673e-03, -2.9856e-03, -2.4182e-03],
          [-3.0785e-03, -2.0582e-03, -2.0237e-03],
          [-1.1365e-03, -2.0668e-03, -1.9191e-03]],

         [[-2.2178e-01, -2.4374e-01, -2.2302e-01],
          [-2.0329e-01, -2.1494e-01, -2.0253e-01],
          [-2.2834e-01, -2.2162e-01, -2.1170e-01]]],


        [[[-1.9047e-01, -5.0808e-01, -6.5153e-01],
          [-5.2507e-01, -5.0222e-01, -7.7457e-01],
          [-2.1515e-01,  8.5311e-02, -3.5444e-01]],

         [[ 3.1729e-02, -1.1143e-01,  1.3258e-02],
          [-6.2913e-02,  5.6850e-02, -3.5361e-02],
          [-4.4692e-02, -6.0705e-02, -1.5646e-02]],

         [[-2.1752e-01, -4.0753e-01,  1.6298e-01],
          [-2.4689e-01,  2.1465e-01, -1.9746e-01],
          [-3.6736e-01, -3.6167e-01, -3.7535e-01]],

         ...,

         [[-1.1183e-02, -9.8646e-03, -4.9527e-03],
          [-1.2929e-02, -9.7746e-03, -1.4052e-02],
          [-9.3557e-03, -6.5620e-03, -3.3317e-03]],

         [[ 8.0947e-03,  1.3655e-02,  8.0054e-03],
          [-5.6984e-03,  1.6568e-03, -4.8272e-03],
          [-4.1137e-03,  1.1965e-03,  4.5942e-03]],

         [[ 1.2224e-01,  3.1816e-01, -1.0588e-02],
          [-2.2470e-02, -3.1923e-01, -2.2589e-01],
          [ 2.7741e-03,  5.2618e-03,  1.2989e-02]]],


        [[[-4.9065e-01, -5.2073e-01, -5.2142e-01],
          [-6.1824e-01, -4.1892e-01, -5.3042e-01],
          [-7.6838e-01, -4.8344e-01, -6.1932e-01]],

         [[-1.0348e-01, -5.7851e-02, -8.9387e-02],
          [-8.2591e-02, -8.9406e-02, -8.5119e-02],
          [-9.8153e-02, -1.1333e-01, -1.1592e-01]],

         [[-5.3413e-01, -5.2772e-01, -4.8901e-01],
          [-3.7988e-01, -3.6942e-01, -5.1767e-01],
          [-4.2634e-01, -3.9946e-01, -4.8190e-01]],

         ...,

         [[-1.6936e-03, -4.2673e-03, -6.6555e-03],
          [-3.8203e-03, -4.7557e-03, -4.0910e-03],
          [-4.4072e-03, -1.1244e-03, -1.3580e-03]],

         [[-1.8638e-02, -5.6253e-03, -1.0104e-02],
          [-2.4483e-04, -1.3705e-03, -3.9372e-03],
          [-5.8171e-03, -9.9686e-03, -7.9207e-03]],

         [[-6.9425e-01, -5.7233e-01, -5.7277e-01],
          [-5.3208e-01, -6.1464e-01, -5.7705e-01],
          [-6.7009e-01, -4.8128e-01, -5.7393e-01]]]], device='cuda:0'), 'backend.0.bias': tensor([ 3.7435e-02,  8.6870e-03,  2.9686e-02,  9.5616e-02, -7.9369e-03,
        -2.2906e-01,  2.1799e-02,  1.2916e-01, -1.1742e-01,  5.3096e-02,
         6.5154e-02, -3.3858e-02, -1.8881e-01,  6.5476e-02,  1.1124e-01,
        -1.6870e-02, -9.0779e-02, -5.9170e-02, -1.5688e-02, -6.3593e-03,
        -1.0433e-01,  1.4871e-02,  2.4667e-01,  3.6994e-02, -5.4464e-02,
         1.1374e-02, -1.7108e-01, -2.9400e-02, -1.2781e-01, -2.2293e-02,
         5.0196e-02, -4.6587e-02, -4.9303e-02, -6.8110e-02, -1.1202e-01,
         1.1110e-01,  4.5687e-02,  1.5133e-01,  3.5386e-02, -2.8245e-02,
         4.8510e-02, -1.7623e-01,  1.0987e-01, -1.7990e-01,  3.6820e-02,
         6.6114e-03,  8.1241e-03,  1.3467e-01,  2.1310e-02, -2.2370e-02,
        -3.5821e-02,  1.0288e-01, -2.3761e-01,  1.0829e-01, -1.2286e-01,
         4.3771e-02,  9.0972e-02,  5.4290e-03,  6.3613e-03,  6.7665e-02,
        -8.3071e-03,  2.5766e-02,  1.2529e-01,  9.5696e-02, -3.2555e-02,
         1.1469e-03,  4.7836e-02, -1.0141e-01, -5.9006e-02,  1.1059e-01,
         1.9443e-03,  3.8479e-02,  1.3207e-02, -2.1735e-02, -5.8063e-03,
         5.6675e-02,  6.5929e-02,  2.8957e-02,  1.0560e-01,  8.2579e-03,
        -4.4968e-02,  1.1853e-03, -1.6334e-01,  3.3129e-02,  1.4978e-02,
        -5.1272e-02,  1.3312e-02, -1.1537e-01,  1.1990e-01, -2.9755e-03,
         2.5822e-02, -1.2387e-01,  3.3274e-02,  1.4201e-01, -1.8099e-02,
        -8.3502e-02, -1.2276e-01, -1.7765e-01, -1.7965e-01,  1.4993e-01,
        -2.8553e-04, -9.3298e-03,  1.3635e-01,  3.1085e-03,  3.3440e-02,
        -1.6650e-02, -3.7137e-02,  1.8647e-02, -1.6222e-02, -1.3726e-01,
        -2.6881e-02,  1.3328e-01, -2.0468e-02, -1.7346e-02,  1.0684e-01,
        -9.4517e-03, -3.3735e-02,  5.2324e-02, -6.5748e-02,  5.0565e-02,
         6.0393e-02, -2.3554e-02, -1.8967e-01,  6.2571e-03,  7.2337e-02,
        -1.7122e-02, -2.7183e-03, -9.6275e-02,  4.6937e-04, -2.2710e-01,
         6.5837e-03,  3.1450e-02, -7.9214e-03, -1.7999e-01,  1.5686e-01,
        -1.3605e-02, -3.6704e-02, -1.8343e-01,  1.3468e-01,  1.1925e-02,
        -1.4944e-02, -9.2967e-03,  3.1527e-02, -3.5561e-02,  8.4169e-03,
        -7.3547e-02,  6.9652e-02,  1.4172e-01, -5.6149e-02,  8.2017e-02,
         5.3280e-02,  9.1900e-02,  2.8366e-03, -1.3483e-02,  7.4776e-02,
         6.9654e-03, -2.7512e-02, -3.0704e-02, -2.0543e-01,  1.8875e-01,
         6.9805e-02,  3.3832e-02, -2.7313e-02, -2.0109e-01, -5.1880e-02,
         2.3721e-03,  1.0829e-01, -3.6843e-02, -8.6512e-02, -2.1700e-01,
        -7.0291e-02,  6.8957e-02,  3.1385e-02,  1.3123e-02, -3.2298e-02,
        -1.0123e-01,  8.2451e-02, -1.8406e-02,  2.7769e-02, -1.5899e-01,
         4.5781e-03,  1.1976e-02,  7.1428e-03,  4.3334e-03, -1.7068e-01,
        -3.9195e-02,  4.2247e-02,  8.9103e-02, -5.1268e-03, -5.4139e-02,
         1.3958e-03, -8.0118e-02, -5.2303e-02,  8.1236e-03,  1.2798e-01,
         8.6178e-02,  5.2952e-02,  7.4546e-02, -3.3938e-03,  1.7204e-01,
        -1.1362e-01,  1.4207e-01,  2.1858e-01,  9.2226e-02, -1.9899e-01,
         3.6390e-02, -1.1806e-01, -8.2607e-02,  9.6324e-02,  3.8893e-02,
        -4.3597e-03, -1.4082e-01,  8.5450e-02,  7.8837e-02,  4.1851e-02,
         1.1331e-02,  7.4670e-02,  6.7291e-02, -7.1615e-02, -1.5780e-01,
        -9.5902e-03, -2.2307e-02, -6.0844e-02,  9.7201e-02, -1.1720e-01,
         1.0030e-01, -1.0908e-02, -3.6493e-02, -2.5845e-04, -7.7158e-02,
        -1.7274e-01,  2.3192e-02, -1.9714e-02,  3.5283e-02, -1.4302e-01,
         1.2823e-02,  4.7919e-02, -1.6809e-01,  5.6044e-02,  7.4026e-02,
         2.2771e-02, -1.4494e-01, -4.2029e-02, -6.3802e-02,  1.2182e-02,
         4.3359e-02,  5.3709e-02,  4.2697e-02, -2.8497e-02,  1.4108e-01,
        -5.5334e-03,  9.1693e-02,  6.3695e-02, -3.4250e-02, -2.8300e-02,
        -5.3445e-02,  2.9542e-03, -5.0378e-02,  1.6559e-02,  1.2318e-01,
        -4.0903e-04, -9.3539e-02, -6.3956e-02, -1.3604e-02, -5.2656e-02,
         3.6483e-02, -9.6794e-02, -8.6377e-02,  4.8820e-04,  8.6020e-03,
        -1.0094e-01, -5.5458e-02, -6.2279e-03,  2.4521e-02,  1.6359e-01,
        -3.3315e-02,  4.5278e-02,  5.1334e-02, -1.2520e-01,  9.1645e-02,
        -5.9487e-02, -1.1458e-01, -6.1015e-02, -2.1344e-01,  2.6370e-02,
         1.8459e-02, -8.5143e-04,  3.9910e-01,  2.6680e-02, -1.6055e-01,
        -6.4647e-02, -5.6141e-02,  1.0158e-02, -1.4173e-02,  7.4237e-02,
         3.7756e-02, -7.6092e-02, -5.3068e-02,  4.9687e-02, -2.6026e-01,
        -1.8112e-01,  1.3090e-01,  2.7320e-02,  2.0812e-02,  3.8818e-02,
         4.0497e-02, -4.4816e-02, -3.4689e-02, -6.9139e-02,  1.2729e-01,
        -1.7978e-01,  3.2796e-02, -4.3860e-02,  9.0157e-02,  3.4747e-02,
        -5.8768e-02, -2.9963e-02, -2.5517e-03, -2.6110e-03, -3.0463e-02,
         4.8107e-02, -1.5035e-01,  4.0940e-02, -8.9532e-02, -2.2504e-02,
         2.5582e-02,  9.0480e-02,  6.8586e-02,  1.1664e-01, -1.2780e-02,
         1.4530e-02,  2.3292e-02, -8.2613e-02,  7.2054e-02,  6.5944e-03,
         5.9477e-02,  2.1407e-02, -1.0625e-01, -1.0625e-01, -8.5956e-02,
         8.7438e-02,  6.5845e-02,  1.9993e-02, -2.2160e-02, -7.1828e-02,
        -1.4765e-03, -2.1725e-02,  4.5513e-02,  4.6463e-02, -5.6595e-02,
         7.0408e-02, -7.1068e-02,  8.3108e-02,  7.8467e-02,  9.3381e-02,
         6.4295e-04,  4.0035e-02, -3.3877e-03,  4.2069e-02, -1.4598e-01,
         7.9622e-02,  1.4402e-01, -4.1292e-02,  4.3087e-02, -1.2322e-01,
        -1.4230e-01, -1.5479e-02, -1.5638e-01,  7.6902e-02, -1.8434e-02,
        -3.0860e-02, -7.7828e-02,  4.6240e-02,  1.0648e-01,  6.2954e-02,
         3.3869e-02,  5.2017e-02,  7.5417e-02, -1.0650e-01, -8.4436e-04,
        -1.1416e-01,  5.3097e-02,  1.0518e-01,  1.0734e-01, -8.4019e-02,
         1.3562e-01, -1.2335e-01, -4.9152e-02,  1.2402e-01, -8.0861e-02,
         1.4998e-01, -2.3119e-02,  1.0668e-01, -5.9596e-02, -1.0735e-02,
         4.4335e-02,  2.6922e-02, -5.7335e-02,  1.0289e-01,  2.2908e-01,
        -6.2296e-02,  4.3519e-02,  3.5142e-02, -3.7511e-02, -1.5319e-01,
        -1.7330e-01, -1.7242e-01,  1.1273e-01,  8.8121e-02,  1.7928e-02,
         1.5912e-01, -8.8504e-03,  3.6247e-03, -1.5004e-02, -9.1842e-02,
         2.3673e-02,  2.8330e-02,  2.2836e-02,  4.4368e-02, -6.7738e-02,
        -5.3700e-02, -3.3513e-03, -1.7342e-02, -9.4061e-03,  5.4576e-02,
        -5.9962e-02, -4.1891e-03, -5.1600e-02, -1.4494e-02, -7.0578e-02,
        -1.0849e-01,  1.7600e-01, -9.0256e-02,  1.1788e-01, -3.2404e-03,
         5.9320e-02, -6.7924e-02, -6.7786e-02,  3.3781e-02,  3.1116e-02,
        -1.1967e-01,  1.1624e-01, -6.5046e-02,  6.9480e-02,  3.6162e-02,
         1.8169e-02, -1.1414e-02, -2.2335e-02, -5.7600e-02,  4.2443e-02,
         1.4756e-02,  2.9848e-02,  9.0882e-02, -1.8335e-02, -1.7758e-01,
         6.6599e-02, -4.1335e-02, -5.6227e-02, -2.5876e-02, -1.4190e-01,
         2.3720e-03,  1.5120e-02,  8.3823e-03,  1.7196e-02,  4.8926e-02,
        -1.8419e-01,  1.6445e-04, -5.8987e-03, -2.3125e-01, -1.4528e-01,
         2.8597e-02,  4.2600e-02, -3.7204e-02,  1.2312e-02,  1.3099e-01,
        -3.3445e-02, -1.1550e-01, -3.2144e-02, -5.2978e-02,  3.4272e-02,
        -1.4026e-02, -7.2396e-03,  5.4505e-03, -2.1931e-02, -1.5544e-02,
         5.1916e-02,  6.7203e-03, -2.1290e-01,  8.3985e-02,  9.0955e-02,
        -1.9859e-02,  5.5643e-02,  7.0865e-02, -6.5067e-02, -1.8820e-02,
        -2.6492e-03, -1.0377e-02, -2.6327e-02,  1.3805e-01,  7.2933e-03,
         6.3785e-02, -1.9616e-02,  5.1570e-03, -6.8187e-02,  2.9798e-02,
         9.7753e-02,  1.3504e-01, -1.2660e-01,  6.2471e-04,  6.9422e-02,
         2.6583e-02,  5.3619e-02], device='cuda:0'), 'backend.10.weight': tensor([[[[-2.1959e-01, -3.3617e-01, -3.1556e-01],
          [-4.1270e-01, -3.4179e-01, -3.8507e-01],
          [-5.4396e-01, -5.1190e-01, -5.2420e-01]],

         [[-1.8068e-01, -1.1518e-01, -9.5162e-02],
          [-5.3012e-02, -3.9710e-02, -3.9326e-02],
          [-1.9610e-02, -1.2150e-02, -1.1782e-02]],

         [[-5.8630e-01, -4.5302e-01, -3.9153e-01],
          [-5.4708e-01, -2.9469e-01, -3.2340e-01],
          [-3.8501e-01, -3.9806e-01, -5.7451e-01]],

         ...,

         [[-9.7577e-02, -7.3513e-02, -7.1505e-02],
          [-5.3139e-02, -8.2465e-02, -6.4261e-02],
          [-5.2220e-02, -5.2126e-02, -5.7822e-02]],

         [[-7.6080e-01, -6.6570e-01, -8.5296e-01],
          [-6.0264e-01, -6.6787e-01, -6.7292e-01],
          [-1.1411e+00, -6.8185e-01, -6.6706e-01]],

         [[-1.8829e-01, -1.7584e-01, -2.0558e-01],
          [-1.6771e-01, -2.0710e-01, -3.6579e-01],
          [-1.1624e-01, -1.1664e-01, -1.4307e-01]]],


        [[[-2.3476e+00, -2.6140e+00, -2.5955e+00],
          [-3.0088e+00, -2.9354e+00, -2.9637e+00],
          [-3.3367e+00, -3.2346e+00, -3.2560e+00]],

         [[-3.5227e-01, -3.1430e-01, -2.8929e-01],
          [-3.8315e-01, -3.6267e-01, -3.4866e-01],
          [-1.9386e-01, -1.8508e-01, -1.6998e-01]],

         [[-2.3411e+00, -2.0769e+00, -1.9700e+00],
          [-2.4370e+00, -2.0338e+00, -2.0448e+00],
          [-1.9506e+00, -1.8898e+00, -2.0975e+00]],

         ...,

         [[-7.2566e-01, -7.4311e-01, -7.0555e-01],
          [-6.7706e-01, -7.6847e-01, -7.2329e-01],
          [-6.1617e-01, -6.6311e-01, -6.7480e-01]],

         [[-4.6668e+00, -4.4965e+00, -4.7603e+00],
          [-4.8601e+00, -4.4961e+00, -4.5276e+00],
          [-5.5612e+00, -4.5514e+00, -4.3601e+00]],

         [[-5.4382e-01, -5.9398e-01, -6.5607e-01],
          [-5.7637e-01, -6.7748e-01, -8.0152e-01],
          [-4.7273e-01, -5.1591e-01, -6.0473e-01]]],


        [[[ 5.0461e-01,  5.0912e-01,  5.1985e-01],
          [ 5.1670e-01,  5.3388e-01,  5.4456e-01],
          [ 5.2959e-01,  5.4138e-01,  5.4454e-01]],

         [[ 8.5475e-03,  1.2207e-02,  1.2803e-02],
          [ 2.4507e-02,  2.6864e-02,  2.6616e-02],
          [ 2.4521e-02,  2.6697e-02,  2.7364e-02]],

         [[ 1.6012e-01,  1.9595e-01,  1.9410e-01],
          [ 1.9142e-01,  2.1182e-01,  1.9630e-01],
          [ 1.9157e-01,  2.1010e-01,  2.0856e-01]],

         ...,

         [[ 1.0573e-01,  1.0355e-01,  1.0533e-01],
          [ 1.1294e-01,  1.1248e-01,  1.1330e-01],
          [ 1.1578e-01,  1.1593e-01,  1.1540e-01]],

         [[ 5.8944e-01,  6.1057e-01,  6.0976e-01],
          [ 5.8719e-01,  6.4044e-01,  6.4838e-01],
          [ 6.2204e-01,  6.5195e-01,  6.4490e-01]],

         [[ 3.2154e-02,  3.4026e-02,  2.0880e-02],
          [ 3.2994e-02,  4.0004e-02,  2.7592e-02],
          [ 3.6006e-02,  4.3411e-02,  3.7159e-02]]],


        ...,


        [[[ 1.8190e-01,  1.7046e-01,  1.6139e-01],
          [ 1.8184e-01,  1.8455e-01,  1.6810e-01],
          [ 1.5529e-01,  1.4892e-01,  1.3226e-01]],

         [[ 6.4873e-03,  1.1624e-02,  1.2358e-02],
          [ 5.4277e-02,  5.7847e-02,  5.7604e-02],
          [ 2.9974e-02,  3.2117e-02,  3.0282e-02]],

         [[ 7.2629e-02,  8.3997e-02,  7.7993e-02],
          [ 1.4803e-01,  1.6411e-01,  1.4653e-01],
          [ 1.2448e-01,  1.1466e-01,  9.5875e-02]],

         ...,

         [[ 2.1645e-02,  2.1378e-02,  2.0795e-02],
          [ 2.4206e-02,  2.2717e-02,  2.0400e-02],
          [ 1.9733e-02,  1.8385e-02,  1.5471e-02]],

         [[ 2.3900e-01,  2.4282e-01,  2.2168e-01],
          [ 2.5852e-01,  2.4316e-01,  2.4233e-01],
          [ 1.6479e-01,  1.7964e-01,  1.5443e-01]],

         [[ 1.5493e-02,  1.5617e-02,  2.1987e-02],
          [ 3.8231e-02,  3.1676e-02,  3.4201e-02],
          [ 3.2448e-02,  4.2885e-02,  4.5704e-02]]],


        [[[-1.1759e+00, -1.6960e+00, -1.5655e+00],
          [-2.0424e+00, -1.9111e+00, -1.9262e+00],
          [-2.5530e+00, -2.4313e+00, -2.4598e+00]],

         [[-5.2375e-01, -3.9010e-01, -3.5612e-01],
          [-1.7797e-01, -1.4278e-01, -1.5336e-01],
          [-5.4150e-02, -3.4322e-02, -4.5135e-02]],

         [[-2.4280e+00, -2.0517e+00, -1.8042e+00],
          [-2.3026e+00, -1.3931e+00, -1.5063e+00],
          [-1.5431e+00, -1.5189e+00, -2.2005e+00]],

         ...,

         [[-3.9746e-01, -3.2304e-01, -2.6708e-01],
          [-2.9420e-01, -3.7322e-01, -3.1304e-01],
          [-2.4681e-01, -2.3344e-01, -2.4592e-01]],

         [[-3.1743e+00, -3.0652e+00, -3.6059e+00],
          [-2.6640e+00, -2.7461e+00, -2.8847e+00],
          [-4.6844e+00, -3.0260e+00, -2.9310e+00]],

         [[-6.6746e-01, -6.5959e-01, -6.4882e-01],
          [-5.9409e-01, -7.4414e-01, -1.1450e+00],
          [-3.8093e-01, -3.7266e-01, -4.6022e-01]]],


        [[[-2.0956e-02, -2.0874e-02, -1.9518e-02],
          [-2.7313e-02, -2.4516e-02, -2.2938e-02],
          [-3.3471e-02, -3.3802e-02, -3.1649e-02]],

         [[-7.0705e-03, -8.3364e-03, -8.0707e-03],
          [-1.5045e-03, -2.1105e-03, -1.4246e-03],
          [-2.9155e-04, -2.5145e-04, -2.7530e-04]],

         [[-2.9277e-02, -2.6434e-02, -2.3441e-02],
          [-2.4026e-02, -2.1748e-02, -2.1338e-02],
          [-1.7061e-02, -2.5575e-02, -2.2425e-02]],

         ...,

         [[-3.2052e-03, -2.6869e-03, -1.9415e-03],
          [-1.3244e-03, -1.4512e-03, -1.2490e-03],
          [-1.7377e-03, -2.1666e-03, -1.5998e-03]],

         [[-3.7680e-02, -3.7452e-02, -3.5263e-02],
          [-3.3036e-02, -3.4708e-02, -2.4630e-02],
          [-4.1510e-02, -3.3301e-02, -3.4321e-02]],

         [[-1.6050e-02, -1.3616e-02, -1.1221e-02],
          [-9.7573e-03, -1.1921e-02, -1.2731e-02],
          [-5.4952e-03, -6.2394e-03, -4.1736e-03]]]], device='cuda:0'), 'backend.8.bias': tensor([ 4.9737e+00, -3.2972e+00, -1.2807e+00,  7.2607e-01, -1.5039e+00,
         1.6829e-01,  4.9959e-01, -2.1996e+00, -8.1899e-01, -1.3867e+00,
        -2.9949e-01, -4.3840e+00,  3.9718e-01, -3.1363e+00, -3.8491e+00,
        -2.6649e+00, -4.2858e-03, -5.9884e-01,  2.8110e+00, -2.2734e+00,
        -3.7313e-01,  7.8965e+00, -2.7427e-01, -4.5185e+00, -4.7506e-01,
         6.7307e+00,  2.4345e+00,  7.2646e+00, -3.2969e+00, -2.1476e+00,
        -1.9279e+00, -1.8337e+00, -1.6325e+00, -6.2015e-01, -9.9722e-01,
        -4.8325e+00,  2.9649e+00, -1.7396e+00, -1.6582e+00, -2.2803e+00,
         8.5869e-01,  3.3220e+00, -1.2001e+00,  9.5225e-02, -6.5972e-01,
         2.6132e+00, -3.0081e+00,  2.7432e+00, -2.9369e+00, -5.7038e-01,
        -4.1127e+00, -5.6515e+00, -3.8666e-01, -3.7298e+00,  7.6422e-01,
        -2.0456e+00, -2.0734e+00,  2.8771e-01, -2.2529e+00,  3.3025e+00,
         3.9578e+00, -2.1992e+00, -7.6605e-01, -1.0977e+00,  1.1327e-01,
        -3.4376e+00, -6.3099e-01, -7.0960e+00,  2.1510e+00,  1.8661e+00,
         2.0419e-01, -8.1414e-01,  4.6508e+00, -2.5497e+00, -4.1238e-01,
        -3.9497e+00,  2.1542e+00, -1.6452e+00, -1.1187e+00,  2.3748e+00,
        -5.8479e+00,  1.0999e+00,  9.7701e-02,  1.6046e+01, -1.4923e-01,
         3.7003e+00,  8.8302e-01, -4.3128e+00, -3.0774e+00,  5.0140e+00,
        -3.2504e+00,  2.5759e+00,  8.8291e-01, -1.0728e-01, -4.5346e-01,
        -2.7930e+00, -5.8308e+00, -1.6652e+00, -3.4447e-01, -4.6627e+00,
        -3.4878e+00, -2.0511e+00, -6.1618e-03,  5.6120e+00, -1.7159e-01,
        -5.2394e-01, -4.4822e-01,  1.6986e+00, -1.6533e+00, -2.3031e+00,
         2.8576e+00, -3.0470e+00, -5.3538e+00, -1.7170e+00,  8.7231e-01,
        -6.4554e+00, -1.1155e+00, -1.7039e+00,  9.7583e+00,  4.5824e-02,
         6.5802e+00, -2.2104e+00,  1.9929e+00, -5.2730e-02, -1.6266e+00,
        -1.3862e+00, -1.2762e+00, -3.9050e+00], device='cuda:0'), 'backend.6.weight': tensor([[[[ 1.7659e-02, -2.6832e-02,  1.1385e-02],
          [-9.5984e-03, -6.9888e-02, -7.4893e-02],
          [-5.2249e-02, -5.5227e-02, -7.9817e-02]],

         [[ 3.0972e-02,  5.7662e-02, -3.3492e-03],
          [-1.8450e-02, -1.3400e-02, -2.8494e-02],
          [-3.6402e-02, -7.0430e-02, -3.7302e-02]],

         [[-8.8065e-02, -1.2215e-01, -9.8337e-02],
          [-8.9382e-02, -4.0194e-02, -8.8762e-02],
          [-6.7900e-02, -6.4821e-02, -2.2596e-02]],

         ...,

         [[ 7.3210e-02, -2.9444e-02,  3.3526e-02],
          [ 1.1094e-02, -1.5080e-02, -2.0852e-02],
          [-5.2141e-02, -7.4994e-02, -8.7375e-02]],

         [[ 6.4951e-02,  5.9654e-02, -4.4958e-03],
          [-3.5679e-02,  6.1586e-02, -3.2397e-02],
          [-2.3371e-02, -6.1786e-02, -2.3975e-02]],

         [[-4.3150e-02, -2.9797e-02, -3.8652e-03],
          [-2.6559e-02, -1.7023e-02,  2.6666e-02],
          [ 4.5345e-02,  5.3840e-02,  8.0433e-02]]],


        [[[-1.8931e-02, -1.3767e-02, -2.2328e-02],
          [-1.7999e-02, -1.7059e-02, -1.7739e-02],
          [-1.7193e-03,  2.6562e-03, -3.2753e-03]],

         [[-4.8769e-03, -9.9159e-03, -1.8203e-02],
          [-9.3298e-03, -3.3824e-03, -1.0877e-02],
          [ 3.6880e-03, -3.0339e-03,  1.1092e-03]],

         [[-1.9346e-02, -1.9373e-02, -7.3063e-03],
          [ 1.2831e-02,  5.7140e-05, -5.6078e-03],
          [-1.6917e-02, -1.6682e-02, -2.7383e-02]],

         ...,

         [[-3.2147e-02, -5.1278e-02, -5.4455e-02],
          [-2.2433e-02, -6.8818e-03, -2.5640e-02],
          [-2.3895e-02, -3.1762e-02, -3.6114e-02]],

         [[-2.0606e-02, -3.0017e-02, -4.2409e-02],
          [-3.8846e-02, -2.1023e-02, -2.3158e-02],
          [-1.8858e-02, -2.0132e-02, -2.1347e-02]],

         [[ 3.0966e-02,  2.2453e-02,  2.1628e-02],
          [-1.4633e-02,  3.5283e-03,  8.0416e-04],
          [ 3.7989e-03, -2.6810e-03,  6.2535e-03]]],


        [[[ 1.6407e-01,  1.0967e-01,  1.5278e-01],
          [ 1.9659e-01,  1.5155e-01,  1.5199e-01],
          [ 1.1946e-01,  1.4954e-01,  1.1909e-01]],

         [[ 6.7720e-02,  1.4779e-01,  1.6977e-01],
          [ 1.0759e-01,  1.5109e-01,  1.3400e-01],
          [ 1.4679e-01,  1.1283e-01,  7.9237e-02]],

         [[ 4.3010e-01,  4.1349e-01,  3.3435e-01],
          [ 3.3523e-01,  3.7894e-01,  3.6660e-01],
          [ 3.4610e-01,  3.0348e-01,  3.2541e-01]],

         ...,

         [[ 1.7422e-01,  1.2320e-01,  1.7807e-01],
          [ 1.3168e-01,  1.4664e-01,  7.5703e-02],
          [ 8.7482e-02,  1.2710e-01,  1.0617e-01]],

         [[ 2.8918e-01,  2.1335e-01,  3.0835e-01],
          [ 2.9417e-01,  2.6610e-01,  3.8148e-01],
          [ 3.5822e-01,  1.8312e-01,  2.4299e-01]],

         [[ 6.2543e-01,  6.9266e-01,  6.6342e-01],
          [ 6.4601e-01,  6.5722e-01,  6.6194e-01],
          [ 7.1699e-01,  7.2908e-01,  6.5543e-01]]],


        ...,


        [[[-3.0835e-03, -5.4564e-03, -4.0023e-03],
          [-4.0692e-03, -5.8402e-03, -5.1373e-03],
          [-3.0648e-03, -2.8590e-03, -4.6755e-03]],

         [[-3.8954e-03, -4.8944e-03, -5.4124e-03],
          [-1.1260e-02, -8.1189e-03, -8.4610e-03],
          [-7.5158e-03, -1.0222e-02, -8.0837e-03]],

         [[-1.4891e-02, -1.4623e-02, -2.0755e-02],
          [-2.3570e-02, -1.8869e-02, -2.5201e-02],
          [-2.3054e-02, -2.1368e-02, -1.9387e-02]],

         ...,

         [[-7.3070e-03, -1.0875e-02, -7.4364e-03],
          [-6.0823e-03, -5.9057e-03, -9.7994e-03],
          [-5.6780e-03, -4.5554e-03, -5.1283e-03]],

         [[-6.7615e-03, -8.6668e-03, -1.2406e-02],
          [-1.7809e-02, -1.6932e-02, -1.4824e-02],
          [-1.3919e-02, -1.8692e-02, -1.7843e-02]],

         [[-1.1690e-02, -1.2990e-02, -9.4363e-03],
          [-3.4773e-02, -3.4121e-02, -3.0164e-02],
          [-3.9312e-02, -4.2817e-02, -4.0379e-02]]],


        [[[-1.1916e-02, -8.5964e-03, -1.0027e-02],
          [-9.8618e-03, -1.3041e-02, -9.8268e-03],
          [-1.3514e-02, -1.5581e-02, -1.3258e-02]],

         [[-4.4534e-03, -6.6128e-03, -5.6980e-03],
          [-4.0484e-03, -4.0086e-03, -5.0111e-03],
          [-4.2607e-03, -4.7118e-03, -7.7489e-03]],

         [[-2.5376e-02, -2.8867e-02, -3.2323e-02],
          [-1.9552e-02, -2.3627e-02, -2.7003e-02],
          [-1.9886e-02, -1.9896e-02, -2.6292e-02]],

         ...,

         [[-8.8458e-03, -8.3307e-03, -7.5917e-03],
          [-1.1403e-02, -1.1842e-02, -1.1067e-02],
          [-1.5496e-02, -1.6875e-02, -1.5704e-02]],

         [[-1.7235e-02, -2.2534e-02, -1.8845e-02],
          [-1.8398e-02, -1.8702e-02, -1.9821e-02],
          [-2.2295e-02, -1.8882e-02, -2.1458e-02]],

         [[-2.3912e-02, -3.0531e-02, -3.6398e-02],
          [-2.0194e-02, -2.3741e-02, -3.0163e-02],
          [-1.7457e-02, -1.2982e-02, -2.0532e-02]]],


        [[[-3.1058e-02,  1.6961e-02, -5.0719e-02],
          [-2.3574e-02,  2.1136e-02, -5.6137e-04],
          [-7.0931e-02, -4.7650e-02, -1.5537e-02]],

         [[ 4.7572e-02, -7.3372e-03,  3.1954e-02],
          [ 1.1158e-01,  5.7628e-02, -1.6493e-04],
          [ 1.5486e-03, -5.2596e-03, -5.0020e-03]],

         [[ 5.3417e-02,  2.0064e-01,  1.3220e-01],
          [-1.2124e-01, -1.6742e-01, -8.4609e-02],
          [-2.1417e-01, -2.5808e-01, -3.0919e-01]],

         ...,

         [[ 2.0335e-02,  1.1659e-01, -2.2835e-02],
          [ 1.9424e-01,  2.3623e-01,  1.9429e-01],
          [ 8.7267e-03,  4.6950e-02,  3.9763e-02]],

         [[-2.1546e-02,  4.8327e-02,  2.2329e-02],
          [ 1.4283e-01,  4.5180e-02, -4.6277e-02],
          [ 1.0123e-01,  2.4752e-01,  1.2154e-01]],

         [[-3.1303e-01, -2.8268e-01, -2.1845e-01],
          [-1.3687e-01, -1.7780e-01, -2.2222e-01],
          [-6.3113e-03,  3.5331e-02,  1.3386e-01]]]], device='cuda:0'), 'backend.2.bias': tensor([-9.5445e-02,  1.2119e-01, -7.2405e-03, -1.1388e-01, -1.4564e-01,
        -1.3561e-02,  3.4900e-03,  7.2915e-02,  7.2378e-02, -8.7557e-02,
        -2.1074e-01, -4.4166e-02, -1.4090e-04, -2.8609e-02, -7.1423e-02,
        -1.7638e-01,  7.6595e-02, -9.6582e-02, -3.9317e-02,  1.0934e-02,
        -9.4695e-03, -5.9579e-03, -1.8186e-01,  6.3055e-02, -9.9821e-02,
         6.5251e-02, -1.8788e-01, -2.5884e-02, -7.8024e-02, -1.6218e-01,
         2.9943e-02,  2.5167e-02, -1.4130e-01, -1.0984e-02,  1.9060e-01,
        -6.5443e-02,  2.4095e-01,  2.0356e-01,  5.0611e-02,  3.8263e-01,
         8.4442e-02,  5.4968e-04,  5.1974e-03, -5.1441e-03, -1.3074e-01,
        -9.0037e-02, -1.0445e-01, -7.5578e-02, -4.8599e-02, -1.1293e-01,
         1.2864e-02, -6.1113e-02,  3.9259e-02,  2.2158e-02, -1.2546e-01,
         5.5565e-02, -8.7546e-02, -4.8289e-01,  2.3837e-02,  2.4712e-04,
         1.9772e-02,  3.4710e-02, -1.0664e-01, -8.6264e-03, -3.3262e-02,
        -2.8562e-02,  1.6658e-02, -3.4660e-02, -2.5922e-01,  1.1552e-01,
         1.8185e-02, -1.5381e-01, -5.6102e-02, -5.9996e-02, -2.5072e-01,
        -1.1116e-01,  1.4273e-01, -2.8125e-02,  2.4978e-01,  1.3900e-01,
        -2.2722e-01,  1.6405e-02,  1.9515e-02, -1.4806e-02,  2.3785e-02,
        -2.5480e-02, -9.9123e-02,  5.5196e-03,  9.6750e-03,  9.0131e-04,
         1.0361e-01, -8.6628e-02,  8.5515e-02,  8.5151e-02,  4.3013e-01,
        -1.7292e-01,  2.5248e-01, -2.4306e-02, -1.4437e-01, -9.8620e-02,
        -2.0639e-02, -2.6135e-02, -3.1095e-01,  2.7444e-01,  1.5304e-02,
        -5.0389e-02, -7.4309e-02,  6.4031e-02,  1.5671e-02,  1.0776e-01,
         5.7240e-02, -6.2661e-02, -6.3628e-02, -1.7401e-01, -1.7384e-01,
        -2.9030e-02, -3.5191e-02, -1.0351e-01,  5.5875e-02, -3.7032e-02,
        -9.5959e-02, -8.1393e-02, -1.5220e-01,  1.9719e-01, -1.1948e-01,
        -1.6690e-01, -9.5103e-02,  1.5894e-01, -4.6987e-02,  8.7202e-03,
        -4.3616e-02,  1.1448e-01, -2.8034e-02,  1.1368e-01, -6.3129e-02,
         2.6934e-03,  2.8195e-02, -7.3618e-02, -1.2489e-01, -6.5034e-04,
         3.3711e-01, -2.7533e-02, -1.2788e-01, -1.1739e-01, -1.4322e-01,
        -6.4528e-02,  4.3952e-02,  4.8670e-02,  1.0127e-01, -5.3154e-02,
         1.9053e-02,  5.7654e-03, -2.0637e-01,  4.9392e-02,  1.0601e-01,
         2.6320e-01,  9.8343e-03, -4.2333e-02,  4.7637e-02,  4.1250e-02,
        -4.3121e-02,  4.6515e-02, -1.8736e-02, -1.7739e-01,  1.6252e-01,
         5.0901e-02,  5.9270e-02, -7.1254e-02, -1.3990e-01, -1.2609e-02,
         1.3635e-01, -1.9156e-02,  9.9166e-02,  9.7897e-03, -7.9732e-03,
         9.6064e-02, -1.1978e-02, -2.6992e-02,  5.5695e-02, -2.0710e-02,
        -7.5230e-03,  9.6907e-02, -2.6946e-02,  1.9297e-02, -1.2362e-01,
        -2.1191e-01,  2.5299e-02, -4.3557e-02,  5.8504e-02,  2.8254e-03,
         3.3446e-03, -2.0438e-01, -1.5362e-01, -7.2068e-02, -1.3362e-01,
        -6.9235e-02,  7.7495e-03, -2.2435e-01, -5.0222e-02, -6.3785e-02,
         1.4208e-01, -1.0317e-01, -4.3363e-02,  2.3452e-01, -1.0269e-02,
        -2.0785e-01, -1.0589e-01, -1.0867e-01,  7.9162e-02,  2.6168e-02,
        -3.6232e-02,  2.0472e-01, -4.7378e-02, -2.2673e-01,  8.8925e-02,
        -1.1418e-01, -3.3485e-02,  1.1014e-01,  5.6062e-02, -5.1878e-03,
         5.2242e-02,  4.1363e-01,  1.6679e-01, -2.8167e-02, -1.5872e-01,
         1.9175e-01, -2.1028e-03,  2.7883e-01,  1.0203e-01, -3.1565e-03,
        -1.3493e-01,  2.3950e-02,  6.8333e-03, -2.6369e-02, -1.9131e-03,
        -2.4801e-02, -9.5862e-02,  3.1373e-01,  1.0827e-01, -3.9025e-01,
         1.2343e-02,  1.6870e-01, -1.3238e-02,  9.2256e-02, -1.0211e-01,
        -2.7446e-01, -1.4298e-01,  4.5026e-03,  9.2050e-02, -9.7813e-03,
        -1.4301e-01, -5.0959e-02,  1.0820e-01,  7.1858e-02, -1.1097e-01,
        -2.3026e-02, -1.9033e-01, -3.1622e-01, -1.0966e-01,  2.0770e-02,
        -1.2985e-01,  7.2911e-02, -6.8903e-03,  2.2239e-02,  4.5560e-02,
         4.6646e-02,  1.0876e-01,  1.8415e-01,  2.5826e-02, -3.4768e-03,
        -3.4906e-02, -1.1110e-01, -7.4018e-05, -5.3388e-02, -2.1667e-01,
         2.3660e-01,  8.3034e-02,  1.6274e-01, -6.9703e-02, -2.4589e-03,
         3.3348e-01, -5.4762e-02,  2.8822e-02, -5.8685e-02,  3.8901e-02,
        -2.1664e-01,  2.5276e-03,  1.5021e-01, -1.5283e-02,  5.2183e-03,
         3.5758e-02,  9.5710e-02,  2.2947e-01, -8.4496e-03,  1.3985e-01,
         3.1626e-02,  2.7621e-01,  1.1268e-01,  7.1205e-03,  6.4727e-02,
         5.0483e-02, -1.1644e-01, -1.0756e-01,  7.3279e-02,  2.8580e-01,
        -1.7353e-01,  2.0275e-01, -5.0729e-01, -2.1405e-01, -1.3283e-01,
        -1.5441e-02, -9.0186e-02,  1.2485e-01,  7.0706e-03,  5.6441e-02,
        -2.2062e-02, -3.1489e-01,  7.7756e-02, -2.7833e-02, -3.0603e-02,
         6.8869e-02, -7.9890e-02, -2.6294e-02,  1.7893e-02,  1.6964e-01,
         8.7095e-02,  1.7398e-02, -2.1467e-01,  2.5736e-02,  1.3859e-02,
         8.3725e-03, -2.8858e-01,  1.6843e-03,  5.3384e-02,  9.3108e-02,
         6.1977e-03, -5.2588e-02,  1.9725e-01, -3.6482e-01, -1.1734e-01,
         2.1406e-01, -1.0737e-02, -3.6181e-01,  5.7253e-01, -5.5064e-02,
         3.8287e-02, -5.8543e-01,  2.0143e-01,  5.1507e-03,  1.5529e-01,
        -5.8387e-02,  9.6521e-02,  3.9095e-03,  1.5408e-01, -6.9697e-04,
         3.3011e-01,  8.9383e-02,  1.8885e-01, -1.6546e-02,  1.7784e-03,
        -6.3066e-02, -2.0381e-02, -7.3932e-02,  5.7188e-02, -2.2169e-01,
        -1.7594e-01,  7.2578e-02,  8.9699e-02,  1.4016e-01,  1.4531e-01,
        -4.8203e-02, -7.4432e-02, -1.2661e-01,  2.2443e-02, -1.7195e-01,
         5.1155e-02, -1.6276e-02, -8.0199e-02,  1.0578e-01, -3.3089e-02,
         1.2326e-01,  1.1279e-01,  1.3939e-02, -2.6169e-01, -4.8322e-02,
         1.8079e-01, -8.4013e-02,  4.3008e-02, -2.0496e-01, -4.6511e-02,
         2.2161e-01,  2.0267e-02, -2.6134e-01, -6.8643e-02,  1.0455e-02,
        -1.6853e-02, -4.4687e-01, -2.6737e-01, -5.5871e-02, -7.4339e-02,
        -4.4164e-01, -6.0503e-02, -4.2870e-02,  2.1000e-01, -3.5374e-02,
         1.9708e-01,  8.2759e-03, -6.6383e-03,  9.9982e-03, -1.5929e-01,
        -9.6029e-02, -8.3696e-02, -2.3543e-01, -3.2169e-02,  2.4580e-02,
        -4.3336e-01, -1.3247e-01,  3.6893e-02, -1.4186e-01,  5.9493e-03,
        -9.1728e-02, -1.2927e-01,  8.5177e-02, -1.1441e-03,  4.2594e-02,
         5.3824e-02, -1.4818e-01, -7.7128e-02, -2.5508e-02,  2.2265e-01,
        -6.6041e-02, -1.0947e-01, -4.1537e-01, -2.4047e-02,  2.0213e-01,
        -1.0381e-01,  3.8256e-02, -2.7223e-02, -4.7806e-02, -1.2562e-02,
        -1.4074e-02, -1.2187e-01,  1.6063e-01, -1.7875e-01, -1.2774e-03,
         1.0068e-01,  3.8112e-02, -1.4348e-01,  1.2196e-01,  1.3996e-03,
        -1.0433e-02,  6.5087e-02,  1.1839e-02, -7.3006e-02, -2.5583e-01,
         2.6133e-03,  1.5689e-01,  1.7598e-01,  6.9529e-02, -6.1461e-02,
        -9.7275e-02,  3.5660e-02,  4.7909e-02,  8.2740e-02,  1.4096e-02,
         4.9414e-02,  4.2052e-02,  1.4344e-01, -6.2792e-02,  4.0574e-04,
         1.5250e-01, -1.7522e-01, -5.9427e-02, -1.0787e-01, -2.6625e-03,
         4.5773e-02, -1.4194e-01,  3.6366e-01,  1.7674e-01,  3.2443e-01,
        -2.4558e-01,  1.8082e-02, -3.6560e-01,  2.6439e-03,  9.1669e-02,
         7.1562e-03, -9.6866e-02, -6.1576e-02, -3.0196e-01, -1.1254e-01,
        -5.5088e-02, -5.7570e-02,  1.0761e-01, -2.8558e-02, -4.1266e-01,
         4.0287e-02,  2.9998e-02, -6.0387e-02,  3.4556e-02, -2.6565e-01,
        -3.9134e-02, -5.7811e-02,  1.2102e-01,  5.8585e-02, -1.1471e-02,
         4.9082e-02, -1.0090e-01, -8.9323e-02, -9.7824e-02,  7.6052e-02,
        -2.5763e-01,  1.2562e-02], device='cuda:0'), 'backend.10.bias': tensor([-5.8029e+00, -5.3878e+01,  1.0696e+01,  2.2877e+01, -1.1114e+01,
         2.1028e-01, -3.5056e+00, -4.7255e+00, -1.8161e+00,  5.6120e-01,
        -4.5989e+00, -1.4484e+01, -2.5311e+01, -2.5464e-01, -1.0811e+01,
        -1.0108e+01,  2.4036e+00,  7.8466e-01, -1.4855e+01, -3.5416e+01,
         3.4983e+00, -1.6306e+01, -2.6800e-01, -1.6920e-02,  1.0981e+00,
         2.8397e+01,  8.6920e-01, -1.3417e+00, -4.1239e-01, -3.3987e+01,
        -1.3303e+01, -3.8404e+00, -7.8278e-01,  4.7887e-02, -2.9392e-01,
        -4.3888e+01,  3.2917e-01, -5.0268e+01, -4.0567e-01,  8.4493e-01,
         5.0143e+00, -5.7116e+01,  7.1828e-02,  1.0728e+00,  4.6707e-01,
        -3.4152e+01, -7.9422e+00,  4.3289e-01,  1.0090e+01, -6.5736e-01,
        -2.2008e+01,  1.0102e+00, -2.4218e-01, -1.8479e+01, -2.5554e-02,
         7.1699e+00,  1.1377e+00,  1.8071e+00,  4.5674e+00,  8.1736e+00,
         1.3086e+00,  2.5759e+00, -2.7065e+01, -2.6927e-01], device='cuda:0'), 'output_layer.bias': tensor([-2368.7073], device='cuda:0'), 'backend.2.weight': tensor([[[[-2.6743e-02, -3.9613e-02, -8.0124e-03],
          [-1.7407e-02, -5.3059e-02, -2.6566e-02],
          [-3.5892e-02, -4.0332e-02, -1.3288e-02]],

         [[-8.8574e-03, -7.8051e-03, -8.0927e-03],
          [-1.2177e-02, -8.5559e-03, -4.6050e-03],
          [-1.0736e-02, -2.2353e-03, -2.1007e-03]],

         [[-5.4202e-02, -2.8204e-02, -6.6150e-02],
          [-9.3614e-02, -8.7684e-02, -1.0216e-01],
          [-8.6319e-02, -6.5350e-02, -6.5384e-02]],

         ...,

         [[-6.8695e-02, -1.2343e-01, -6.7855e-02],
          [-5.2469e-02, -1.2090e-01, -9.2997e-02],
          [-1.5116e-01, -1.8670e-01, -1.7145e-01]],

         [[-3.5143e-02, -2.8826e-02, -2.5545e-02],
          [-4.4439e-02, -3.8221e-02, -3.8729e-02],
          [-2.2132e-02, -2.8051e-02, -2.6021e-02]],

         [[-2.7208e-02, -1.4604e-02, -2.6463e-02],
          [-1.3160e-02, -1.7328e-02, -2.3120e-02],
          [-3.2825e-02, -1.9329e-02, -3.9087e-02]]],


        [[[ 7.7715e-02,  3.7033e-02,  5.9199e-02],
          [ 6.9623e-02,  3.8972e-02,  3.4251e-02],
          [ 5.2240e-02,  4.0356e-02,  4.5524e-02]],

         [[ 8.7287e-03,  1.0781e-02,  1.1893e-02],
          [ 7.5952e-03,  7.7004e-03,  8.8368e-03],
          [ 1.1768e-02,  6.2631e-03,  1.1725e-02]],

         [[ 7.2417e-02,  8.9045e-02,  8.2415e-02],
          [ 8.0393e-02,  7.5212e-02,  6.3762e-02],
          [ 7.1169e-02,  1.0387e-01,  9.9012e-02]],

         ...,

         [[ 1.4388e-01,  1.0236e-01,  1.3851e-01],
          [ 1.2052e-01,  1.1338e-01,  1.7003e-01],
          [ 1.5285e-01,  1.2835e-01,  1.4204e-01]],

         [[ 6.6305e-02,  5.3928e-02,  5.6094e-02],
          [ 4.6763e-02,  4.0123e-02,  2.8896e-02],
          [ 3.1198e-02,  4.4880e-02,  4.0969e-02]],

         [[ 2.8077e-02,  3.7205e-02,  3.6338e-02],
          [ 1.5342e-02,  4.2387e-02,  3.7634e-02],
          [ 1.9189e-02,  3.1697e-02,  4.1698e-02]]],


        [[[-9.8587e-03, -5.9423e-04, -1.5896e-03],
          [-1.4475e-03,  7.3031e-03, -3.8601e-03],
          [-8.3027e-03, -4.1755e-05, -1.1306e-02]],

         [[-6.2675e-04, -3.3450e-04,  7.6568e-05],
          [ 4.1101e-03,  6.4968e-04, -1.6109e-03],
          [ 1.8856e-03,  1.6983e-03, -2.0550e-03]],

         [[-1.1350e-02, -4.0536e-03, -9.0499e-03],
          [-2.9620e-03, -7.6362e-03, -1.2745e-02],
          [-1.6146e-02, -2.2903e-02, -9.9329e-03]],

         ...,

         [[-1.6460e-02, -2.5880e-02, -7.2913e-03],
          [-3.2705e-02,  8.7731e-03, -2.2338e-02],
          [-3.5239e-03,  5.4258e-03, -9.8811e-03]],

         [[ 5.0209e-03, -4.1994e-03,  3.6659e-03],
          [ 7.6037e-03, -2.2850e-03,  6.1386e-03],
          [-9.2010e-03, -6.9944e-03, -5.7208e-03]],

         [[-4.1632e-03, -5.1095e-03,  1.0458e-03],
          [-7.3520e-03, -3.9127e-03,  8.5427e-03],
          [-5.4502e-03, -4.1668e-03, -1.1901e-02]]],


        ...,


        [[[-8.8293e-03,  4.3760e-03,  6.6472e-02],
          [-8.1440e-03,  2.4337e-02,  4.2201e-02],
          [-1.7272e-02,  3.1402e-02,  6.8162e-02]],

         [[-4.0399e-03,  5.5718e-03,  1.0041e-02],
          [ 2.1243e-03,  7.6128e-03,  1.1768e-03],
          [ 6.4543e-04,  9.1157e-03,  6.0502e-03]],

         [[-2.5100e-02,  1.5325e-02, -1.1128e-03],
          [ 1.4319e-03,  2.7356e-02, -5.7305e-03],
          [-1.0064e-02,  1.4974e-03, -1.9914e-03]],

         ...,

         [[ 2.0682e-01,  1.0093e-01,  1.4818e-01],
          [ 6.5354e-02,  1.9605e-01,  2.1523e-01],
          [ 1.7583e-01,  1.0938e-01,  1.1586e-01]],

         [[-1.5126e-02, -9.0462e-03,  1.3630e-03],
          [-2.0700e-02, -1.1768e-02, -4.5528e-03],
          [-1.5403e-02, -1.9581e-02, -1.5351e-02]],

         [[ 8.9633e-03,  4.3921e-02,  3.4449e-02],
          [ 3.6678e-02,  5.0559e-02,  1.8873e-02],
          [ 3.5363e-02,  5.3386e-02,  2.4553e-02]]],


        [[[-6.4072e-02, -7.1424e-02, -1.3557e-01],
          [-1.0439e-01, -1.0575e-01, -1.1695e-01],
          [-1.1025e-01, -1.1215e-01, -1.0477e-01]],

         [[-1.5107e-02, -2.1762e-02, -2.7486e-02],
          [-2.0304e-02, -1.2360e-02, -2.1811e-02],
          [-2.3954e-02, -1.2940e-02, -1.2730e-02]],

         [[-1.3944e-01, -1.1372e-01, -1.1283e-01],
          [-1.5474e-01, -1.2211e-01, -1.1001e-01],
          [-1.8234e-01, -1.5628e-01, -1.4351e-01]],

         ...,

         [[-4.4711e-01, -4.0074e-01, -4.7918e-01],
          [-3.8266e-01, -4.4923e-01, -4.4080e-01],
          [-4.6186e-01, -4.5300e-01, -4.6996e-01]],

         [[-2.4721e-02, -3.4567e-02, -2.5146e-02],
          [-3.2767e-02, -3.5458e-02, -3.5849e-02],
          [-2.8946e-02, -3.0527e-02, -3.7150e-02]],

         [[-6.7309e-02, -7.3472e-02, -8.8186e-02],
          [-9.3797e-02, -9.4707e-02, -9.7848e-02],
          [-9.2637e-02, -8.5534e-02, -7.9305e-02]]],


        [[[-3.6618e-02, -1.3965e-02, -1.0298e-02],
          [-8.8741e-02, -4.4204e-02, -1.8938e-02],
          [-7.0731e-02, -3.1268e-02,  2.7327e-02]],

         [[-9.3139e-03,  8.7449e-04, -9.4223e-03],
          [-5.9765e-03, -2.6661e-03, -8.2794e-03],
          [ 3.5148e-03,  4.4634e-03, -7.3957e-04]],

         [[ 7.3819e-02,  4.9794e-02,  1.5393e-02],
          [ 1.2660e-01,  1.1228e-01,  9.8424e-02],
          [ 4.8682e-02,  5.5706e-02,  1.0727e-01]],

         ...,

         [[-8.3064e-02, -1.9624e-02,  9.4107e-02],
          [-1.6091e-02,  5.3197e-02,  5.2261e-02],
          [ 5.3617e-02,  5.5292e-02,  4.2046e-02]],

         [[-3.1702e-02, -4.6874e-02, -5.6751e-02],
          [-1.4009e-02, -1.7437e-02,  8.5364e-03],
          [-3.1721e-03, -1.3173e-02, -6.2189e-03]],

         [[-1.9243e-03,  1.0770e-02,  9.0743e-03],
          [-1.2533e-02, -1.8939e-04, -3.9591e-03],
          [-4.5675e-03, -1.1593e-02,  7.9187e-03]]]], device='cuda:0'), 'backend.6.bias': tensor([-8.3898e-02, -1.6170e-02,  1.1420e+00, -5.7550e-02,  5.3863e-01,
        -8.3389e-01,  1.1408e-01,  3.1572e-02, -1.6201e-01, -2.2798e-01,
        -1.0613e+00,  1.7285e-02, -1.9214e+00, -1.1184e-01, -6.8129e-01,
         2.2950e-02, -1.4048e+00, -2.4419e-01,  9.4105e-01,  2.4619e-01,
         3.1539e-01, -3.4581e-01,  4.3028e-01,  2.8217e-03, -6.5242e-01,
         1.2156e+00, -1.1701e+00,  9.7104e-02,  1.8542e-01, -8.4766e-01,
        -8.2549e-02,  8.8012e-01,  1.3529e+00,  1.4453e-01, -1.8760e-01,
         2.3450e-01, -5.5986e-02,  4.2681e-01, -3.5006e-01,  5.4509e-01,
        -8.3722e-01,  6.0962e-02,  8.9384e-03, -6.9759e-03,  2.5819e-01,
        -8.1418e-01, -1.1959e+00,  7.2191e-01, -1.3468e-01, -9.9605e-01,
         2.0732e+00,  7.9013e-01,  1.2127e+00, -1.5427e-01,  2.0351e-01,
        -5.0857e-01, -2.5497e-01, -2.5927e-01, -5.9106e-03, -1.0637e-01,
        -7.7560e-01, -3.9563e-01, -5.0864e-01, -4.2363e-01, -1.1203e-01,
         1.5607e+00,  1.1222e+00, -2.8460e-01, -5.2958e-01,  4.4043e-01,
        -2.0771e+00,  1.1595e+00,  5.9845e-01,  6.1728e-02,  3.3175e-02,
        -4.1539e-01,  5.6374e-01, -1.5174e+00, -9.2519e-01, -7.4753e-01,
         2.4032e-03, -7.1819e-02, -3.7930e-01, -1.2810e+00,  1.7283e+00,
        -1.5669e-02, -1.0817e-01,  4.1597e-01, -5.1974e-01, -2.8064e-01,
         4.1466e-01, -2.6418e-01, -9.3956e-01,  1.0207e+00,  2.1993e-01,
         7.7891e-01, -1.2826e-02, -9.0745e-01,  5.0318e-01, -1.2849e+00,
        -1.3128e+00,  1.6148e-02,  1.0761e-01,  1.2552e-02, -7.9037e-01,
        -4.6911e-01, -1.1417e+00, -7.8195e-02,  2.5991e-03,  1.5220e-02,
         5.2965e-02, -5.6886e-01,  2.0896e-01, -2.1517e-02,  4.7351e-01,
        -1.4713e+00, -3.6948e-01,  2.1909e-02,  1.2982e+00,  1.3832e+00,
        -4.6231e-01, -2.0406e-02,  2.7874e-02, -1.9149e+00,  1.5788e+00,
        -8.4886e-01,  1.3790e+00,  3.3353e+00, -1.1661e+00, -4.0027e-01,
         1.9986e-01,  1.0771e+00,  9.1899e-01, -6.6466e-01,  4.5549e-01,
         1.8903e+00, -7.6614e-01,  2.3348e-02, -1.0125e+00, -2.0532e+00,
        -8.9911e-01,  1.2650e+00, -1.0543e+00,  8.2443e-01, -8.1073e-01,
        -4.6521e-02, -4.7335e-04, -3.0504e-01, -9.6903e-03, -5.8532e-01,
        -5.4516e-01, -6.6429e-01, -2.3238e-02,  2.0377e+00,  1.8188e+00,
        -7.2864e-01, -2.5927e-02,  4.8815e-02, -2.2780e-04, -5.5808e-01,
        -3.7023e-01, -1.1683e-01, -1.0920e+00, -8.0477e-03,  8.5099e-02,
         1.4044e+00, -1.8893e-02, -1.2077e-01, -2.6243e-01, -4.0546e-01,
         2.1495e-02,  9.4086e-02, -6.4142e-01, -1.6538e+00, -8.9191e-01,
        -4.8411e-01,  1.4857e-02,  5.2869e-01,  1.6901e-01, -2.0868e-01,
         1.7790e-02,  4.9152e-01,  4.9781e-01, -7.0547e-01,  1.7543e-01,
        -7.4892e-01, -5.0036e-01, -6.2179e-02,  3.3095e-02,  1.9181e+00,
         4.4187e-01,  2.4910e-01, -3.7713e-01,  1.5005e+00,  3.7024e-01,
        -1.5421e-01, -2.9336e-01, -2.8169e-01, -1.0113e-01, -1.9074e+00,
        -6.8935e-01, -6.8837e-01,  1.9108e-01, -6.8252e-01, -6.3966e-01,
         1.6775e-01,  8.4237e-01, -4.1269e-01,  1.0999e+00,  1.0861e+00,
         5.0100e-01,  2.0692e-02, -7.4591e-01, -4.0649e-01,  3.1674e-01,
         4.7350e-02, -1.3426e-02,  4.4528e-01, -1.0489e+00, -1.3415e+00,
         3.2184e-01,  8.5183e-01, -3.3267e-01, -2.9079e-01, -4.9677e-01,
        -1.3985e-01,  4.5515e-02,  6.9376e-01, -1.9076e+00,  1.0484e+00,
        -5.9901e-01,  1.0391e+00, -3.5584e-01, -1.5562e-01, -7.4192e-01,
         1.9428e+00, -1.1659e+00, -4.8476e-02, -9.1319e-02, -1.1107e+00,
        -7.8743e-01, -1.0142e+00,  1.9766e-02,  6.6773e-02, -1.4531e-01,
        -2.2162e-01,  3.6885e-01, -3.8783e-01,  3.8288e-01, -7.1044e-01,
        -2.3415e-01, -3.7066e-01,  5.3615e-01, -6.6176e-02, -6.9477e-02,
         9.0343e-04], device='cuda:0'), 'backend.0.weight': tensor([[[[-1.0966e-02, -1.7620e-02, -1.1160e-02],
          [-3.1533e-03, -5.4649e-03, -6.9498e-03],
          [ 4.9164e-03,  6.9466e-03,  1.3817e-03]],

         [[-9.4746e-02, -8.2677e-02, -6.6368e-02],
          [ 5.5744e-03, -1.3242e-02, -4.1412e-02],
          [ 9.9204e-02,  7.3024e-02, -2.9844e-03]],

         [[ 5.2261e-02,  5.8763e-02,  5.5728e-02],
          [ 6.1536e-02,  8.4553e-02,  3.7036e-02],
          [ 1.0334e-01,  9.4032e-02,  6.6058e-02]],

         ...,

         [[ 4.8515e-04,  4.6797e-04,  3.1705e-03],
          [ 1.0355e-04, -2.0711e-03, -2.6304e-03],
          [ 7.7474e-04, -3.3156e-03, -2.7114e-03]],

         [[ 2.9969e-03, -6.2076e-03,  2.7157e-02],
          [-5.4847e-03, -1.4381e-02,  8.3939e-04],
          [-1.3332e-03,  7.5210e-03, -1.0118e-02]],

         [[ 7.4050e-02,  9.7492e-02,  1.3282e-01],
          [ 8.5056e-02,  8.1243e-02,  8.0769e-02],
          [ 7.5955e-02,  9.3831e-02,  8.4564e-02]]],


        [[[ 3.3563e-03,  5.4455e-03,  3.4571e-03],
          [ 7.2756e-03,  8.1888e-03,  2.1705e-03],
          [ 5.1404e-04,  5.7356e-03,  8.8268e-03]],

         [[ 1.1157e-01,  1.0452e-01,  8.9039e-02],
          [ 9.8321e-02,  1.2030e-01,  8.4502e-02],
          [ 8.3782e-02,  8.3956e-02,  6.3718e-02]],

         [[ 1.8970e-02,  2.2374e-02,  1.1429e-02],
          [ 1.7493e-02,  1.1410e-02,  1.2681e-02],
          [ 4.9716e-04, -3.6673e-03, -6.4817e-03]],

         ...,

         [[ 4.9068e-03,  4.3096e-03,  2.7918e-04],
          [ 3.1393e-03,  2.7693e-03,  4.3251e-03],
          [-1.0944e-03,  2.5520e-03,  2.1074e-03]],

         [[ 1.2171e-02,  1.2222e-02,  7.5670e-03],
          [ 1.7481e-02,  2.1930e-02,  1.4792e-02],
          [ 1.9990e-02,  2.3994e-02,  2.8636e-02]],

         [[ 9.6592e-03, -4.9509e-03,  1.7026e-02],
          [ 5.5919e-03, -9.2159e-03,  2.0788e-02],
          [-8.4710e-03, -1.2852e-04,  8.8651e-03]]],


        [[[ 1.0118e-02,  1.2773e-02,  7.2158e-03],
          [ 1.0303e-02,  1.2340e-02,  4.9386e-03],
          [ 1.7318e-02,  2.1505e-02,  1.9963e-03]],

         [[ 2.1414e-01,  1.4136e-01,  1.1734e-01],
          [ 2.9939e-01,  2.4250e-01,  1.0767e-01],
          [ 2.0077e-01,  2.0029e-01,  4.3076e-02]],

         [[ 4.6795e-02,  5.1594e-02,  4.4767e-02],
          [ 3.4120e-02,  5.9091e-02,  4.1478e-02],
          [ 7.0840e-02,  7.7755e-02,  7.5425e-02]],

         ...,

         [[-6.3573e-04, -4.8425e-04, -4.7804e-03],
          [ 1.0010e-02,  5.5798e-03,  5.0049e-03],
          [ 8.7089e-03,  4.7926e-03,  6.8314e-03]],

         [[ 5.1334e-02,  2.5492e-02,  5.5960e-03],
          [ 4.4768e-02,  3.4322e-02,  7.7112e-03],
          [ 3.5575e-02,  4.2392e-02,  2.2568e-02]],

         [[ 5.0627e-02,  2.1956e-02,  8.0026e-02],
          [-2.6768e-02,  7.8543e-03,  5.7528e-02],
          [ 7.2560e-02,  8.3124e-02,  7.9691e-02]]],


        ...,


        [[[ 2.0044e-02,  6.3764e-03,  5.0229e-04],
          [ 2.1295e-02,  8.4861e-03, -6.0195e-03],
          [ 1.8922e-02,  1.4829e-02,  8.0008e-03]],

         [[ 2.1408e-01,  1.7944e-01,  2.6112e-02],
          [ 2.9567e-01,  2.6751e-01,  9.5501e-02],
          [ 2.9140e-01,  2.5383e-01,  8.2905e-02]],

         [[ 1.7747e-01,  1.9658e-01,  1.8618e-01],
          [ 7.2050e-02,  4.3126e-02,  1.0901e-01],
          [ 1.5234e-01,  1.9395e-01,  1.6791e-01]],

         ...,

         [[ 3.3875e-03, -5.1798e-04,  1.4071e-03],
          [ 3.2952e-03,  6.6850e-04, -3.8085e-03],
          [ 9.4261e-03,  8.2753e-03,  4.3094e-03]],

         [[ 6.2549e-02,  3.2152e-02, -9.1817e-03],
          [ 6.9781e-02,  1.9211e-02, -1.8663e-02],
          [ 7.1130e-02,  4.4201e-02,  1.8720e-03]],

         [[ 2.4898e-01,  2.3219e-01,  3.5021e-01],
          [ 3.2860e-02,  3.7564e-02,  1.8472e-01],
          [ 1.1135e-01,  1.3887e-01,  1.8595e-01]]],


        [[[ 4.4694e-02,  4.3510e-02,  3.1192e-02],
          [ 4.5765e-02,  4.5040e-02,  4.3091e-02],
          [ 5.0478e-02,  5.0647e-02,  4.6611e-02]],

         [[ 4.8131e-01,  4.9007e-01,  4.3751e-01],
          [ 4.3487e-01,  4.5149e-01,  4.4866e-01],
          [ 3.1297e-01,  3.5288e-01,  3.5300e-01]],

         [[ 4.8869e-02,  5.6783e-02,  6.4834e-02],
          [ 3.0822e-02,  3.8095e-02,  4.7185e-02],
          [ 6.1478e-02,  5.3462e-02,  4.0250e-02]],

         ...,

         [[ 1.1525e-02,  1.3004e-02,  1.0198e-02],
          [ 5.2148e-03,  1.3582e-03,  8.1860e-03],
          [ 6.3621e-03,  2.3228e-03,  4.0532e-03]],

         [[ 6.6033e-02,  5.6165e-02,  2.7975e-02],
          [ 5.5589e-02,  5.5610e-02,  3.7571e-02],
          [ 2.7231e-02,  1.7299e-02, -1.6123e-03]],

         [[ 4.3124e-02,  2.8379e-02,  3.5880e-02],
          [ 1.2767e-02,  2.6669e-02,  2.7428e-02],
          [ 5.3279e-02,  7.6973e-02,  1.1788e-02]]],


        [[[ 9.0564e-03,  9.5053e-03,  1.0586e-02],
          [ 1.3179e-02,  1.0427e-02,  1.5776e-02],
          [ 1.5143e-02,  1.6777e-02,  1.7506e-02]],

         [[ 1.0941e-01,  1.0080e-01,  1.7831e-01],
          [ 1.3935e-01,  1.4261e-01,  2.3914e-01],
          [ 1.8722e-01,  1.9382e-01,  2.4268e-01]],

         [[ 5.9846e-02,  6.3961e-02,  5.8496e-02],
          [ 9.4832e-02,  1.2499e-01,  1.2457e-01],
          [ 9.6726e-02,  1.0555e-01,  9.4719e-02]],

         ...,

         [[ 4.8433e-04,  2.5726e-03,  1.3077e-03],
          [ 3.2865e-03,  2.4151e-03,  3.0786e-03],
          [ 3.2823e-03,  2.0314e-03,  1.3949e-03]],

         [[ 1.3699e-02,  7.8327e-03,  2.1781e-02],
          [ 1.6425e-02,  1.2316e-02,  2.7760e-02],
          [ 1.4946e-02,  1.5759e-02,  1.8320e-02]],

         [[ 8.6319e-02,  1.5244e-01,  1.0609e-01],
          [ 1.5536e-01,  1.3366e-01,  1.5492e-01],
          [ 1.0859e-01,  8.9653e-02,  6.4167e-02]]]], device='cuda:0'), 'output_layer.weight': tensor([[[[-1.6358e+00]],

         [[-2.5940e+01]],

         [[-2.2885e+01]],

         [[-4.2481e+01]],

         [[-8.9195e+00]],

         [[-4.3450e-01]],

         [[-4.4648e+00]],

         [[-8.7988e+00]],

         [[-9.7922e+00]],

         [[-6.4884e+00]],

         [[-1.6077e+00]],

         [[-9.1065e+00]],

         [[-9.2577e+00]],

         [[-8.4950e+00]],

         [[-3.1119e+00]],

         [[-4.4014e+00]],

         [[-1.1049e+00]],

         [[-9.0646e+00]],

         [[-1.0693e+01]],

         [[-1.3028e+01]],

         [[-1.9226e+01]],

         [[-5.4063e+00]],

         [[-1.7429e+00]],

         [[-4.2664e-01]],

         [[-1.4460e+00]],

         [[-6.2714e+01]],

         [[-1.6194e+00]],

         [[-1.6695e+00]],

         [[-1.2076e+00]],

         [[-1.8779e+01]],

         [[-4.6703e+00]],

         [[-1.2733e+01]],

         [[-1.3408e+00]],

         [[ 4.5206e-02]],

         [[-4.8045e+00]],

         [[-1.6932e+01]],

         [[-6.8475e-01]],

         [[-2.4269e+01]],

         [[-4.6628e-01]],

         [[-6.4551e+00]],

         [[-3.5551e+00]],

         [[-2.7895e+01]],

         [[-2.5401e-01]],

         [[-4.7532e-01]],

         [[-1.3100e-01]],

         [[-1.7155e+01]],

         [[-2.8089e+00]],

         [[-2.4248e-01]],

         [[-1.8241e+01]],

         [[-4.4686e-01]],

         [[-5.6391e+00]],

         [[-2.1812e+00]],

         [[-1.2111e-01]],

         [[-4.8903e+00]],

         [[-4.5772e-03]],

         [[-2.9828e+01]],

         [[-1.2588e+00]],

         [[-2.7432e+00]],

         [[-3.9311e+00]],

         [[-2.8007e+01]],

         [[-3.5534e+00]],

         [[-2.1570e+00]],

         [[-1.0613e+01]],

         [[-2.9810e-01]]]], device='cuda:0'), 'backend.4.weight': tensor([[[[-1.2049e-02, -6.0804e-02, -5.4470e-02],
          [-8.9143e-03, -8.2507e-02, -6.2419e-02],
          [-1.1261e-02, -5.8706e-02, -4.9844e-04]],

         [[-3.8529e-02, -2.3250e-02,  2.3059e-02],
          [-6.0004e-02,  3.9834e-02,  4.6437e-02],
          [-1.0442e-01, -3.2645e-02, -1.4296e-04]],

         [[-1.3504e-02, -2.6101e-02, -1.9275e-02],
          [-1.5315e-02, -2.7579e-02, -7.4564e-03],
          [-3.1706e-02, -1.0187e-02, -1.2930e-02]],

         ...,

         [[ 4.6737e-03, -5.3108e-02, -8.8509e-02],
          [ 4.9761e-02, -9.0174e-02, -3.2584e-02],
          [-4.8892e-02,  1.3479e-02,  3.9005e-02]],

         [[-5.9419e-02, -1.0136e-01, -1.1546e-01],
          [-7.5363e-02, -4.8470e-02, -2.4965e-02],
          [-4.4913e-02, -1.8796e-02, -1.4597e-02]],

         [[-8.9495e-02, -3.5857e-02, -1.2367e-02],
          [-2.1256e-02, -2.2860e-02, -6.7883e-02],
          [-1.1565e-01, -7.2963e-02, -5.9713e-02]]],


        [[[-6.1422e-02, -7.4409e-02, -5.5027e-02],
          [-8.4431e-02, -5.0343e-02, -1.7649e-02],
          [-4.9211e-02, -2.8633e-02, -3.9525e-02]],

         [[-1.1809e-01, -1.2985e-01, -1.3566e-01],
          [-1.5668e-01, -1.1771e-01, -1.3297e-01],
          [-1.5706e-01, -1.5218e-01, -1.7541e-01]],

         [[-3.7270e-02, -3.6366e-02, -3.9533e-02],
          [-3.3907e-02, -2.5395e-02, -3.3013e-02],
          [-2.8684e-02, -1.9192e-02, -1.9853e-02]],

         ...,

         [[-1.4428e-01, -1.3440e-01, -4.8935e-02],
          [-8.5695e-02, -9.6213e-02, -5.4565e-02],
          [-1.2662e-01, -7.0622e-02, -9.3470e-02]],

         [[-1.1058e-01, -7.2285e-02, -7.5916e-02],
          [-9.1712e-02, -5.9536e-02, -8.4217e-02],
          [-6.3676e-02, -6.2908e-02, -1.0002e-01]],

         [[-2.0823e-01, -2.0906e-01, -2.1805e-01],
          [-1.7230e-01, -2.0222e-01, -2.3789e-01],
          [-2.6540e-01, -2.6746e-01, -2.9672e-01]]],


        [[[ 2.7800e-03,  2.3009e-03, -5.3761e-02],
          [-2.6932e-02,  4.3406e-02, -7.2003e-02],
          [ 1.5602e-03,  1.1808e-02, -7.6259e-02]],

         [[-1.1996e-02,  1.6807e-02,  6.0270e-02],
          [ 7.1742e-02, -4.5469e-03,  5.1582e-02],
          [ 8.9462e-02,  8.7170e-02,  1.6582e-01]],

         [[-3.9850e-03,  9.4203e-03,  2.3183e-02],
          [ 3.4039e-02, -1.6625e-03,  2.0194e-02],
          [ 1.2939e-02, -1.6667e-03,  1.1721e-02]],

         ...,

         [[-5.3541e-02,  1.3020e-01, -1.4320e-01],
          [-8.9343e-02,  8.4100e-02, -1.5566e-01],
          [ 6.7427e-02, -2.3241e-02, -2.0595e-01]],

         [[ 3.7305e-02, -9.8505e-03,  4.2858e-02],
          [ 6.3236e-02, -4.5389e-02, -6.4480e-02],
          [ 6.6969e-03, -1.4844e-01, -1.3272e-02]],

         [[ 6.5943e-02,  8.1315e-04,  5.4290e-02],
          [ 7.0960e-03, -9.7523e-02,  9.8905e-02],
          [ 1.2407e-01,  7.0396e-02,  1.2213e-01]]],


        ...,


        [[[-9.2292e-02, -3.1215e-02, -7.2767e-02],
          [-9.2674e-02, -9.8753e-02, -1.3588e-01],
          [-1.0899e-01, -1.5503e-01, -7.5264e-02]],

         [[-1.1606e-01, -1.4396e-01, -5.8015e-02],
          [-3.7691e-02, -6.5499e-02, -8.3959e-02],
          [-6.8774e-02, -8.4261e-02, -5.5586e-02]],

         [[-3.3650e-02, -2.5016e-02, -3.0571e-02],
          [-2.4607e-02, -3.8932e-02, -3.2553e-02],
          [-2.4547e-02, -2.5013e-02, -2.2983e-02]],

         ...,

         [[-1.4992e-01, -1.0191e-01, -1.7541e-01],
          [-2.3860e-01, -2.6577e-01, -1.5842e-01],
          [-1.5260e-01, -1.9920e-01, -1.9439e-01]],

         [[-2.2625e-01, -2.1584e-01, -1.7163e-01],
          [-1.7381e-01, -1.5323e-01, -1.7070e-01],
          [-1.4792e-01, -1.9673e-01, -1.1021e-01]],

         [[-1.4642e-01, -8.4645e-02, -1.1511e-01],
          [-2.1538e-01, -2.6934e-01, -2.4112e-01],
          [-1.4448e-01, -8.2777e-02, -1.1832e-01]]],


        [[[-1.5638e-01, -1.4835e-01, -1.9036e-01],
          [-1.7547e-01, -8.7566e-02, -1.1183e-01],
          [-8.2429e-02,  2.9826e-02,  2.9443e-02]],

         [[-3.5375e-03,  7.8474e-02,  3.5788e-02],
          [ 2.8734e-02, -8.3442e-02, -3.0321e-02],
          [-1.1562e-01, -1.6252e-01, -1.9590e-01]],

         [[-5.9862e-02, -6.6110e-02, -3.8213e-02],
          [-5.4671e-02, -3.5382e-02, -2.5554e-02],
          [ 9.8651e-03, -6.5196e-03, -9.3012e-03]],

         ...,

         [[-3.2161e-01, -2.8489e-01, -2.5918e-01],
          [-3.2716e-01, -4.6102e-02, -1.2386e-01],
          [-6.2740e-02, -1.9311e-01, -9.9466e-02]],

         [[-2.3160e-01, -2.2290e-01, -1.7311e-01],
          [-1.2878e-01, -1.0607e-01, -1.8933e-01],
          [-1.3857e-01, -1.7024e-01, -8.4571e-02]],

         [[-9.7383e-02, -1.5025e-01, -2.1385e-01],
          [-1.5372e-01, -1.2470e-01, -9.2417e-02],
          [-1.2051e-01, -2.0160e-01, -1.7870e-01]]],


        [[[ 1.4705e-01,  2.1214e-01,  1.3027e-01],
          [ 1.5705e-01,  2.3031e-01,  1.4932e-01],
          [ 2.4698e-01,  3.2268e-01,  2.5551e-01]],

         [[ 4.3678e-01,  4.6324e-01,  4.4893e-01],
          [ 4.4244e-01,  3.3968e-01,  4.9461e-01],
          [ 3.9638e-01,  3.2134e-01,  2.9272e-01]],

         [[ 8.4497e-02,  7.1967e-02,  5.6404e-02],
          [ 5.4277e-02,  3.5380e-02,  4.2072e-02],
          [ 1.0959e-01,  7.9675e-02,  6.8024e-02]],

         ...,

         [[ 2.5636e-01,  3.1694e-01,  2.9748e-01],
          [ 3.4446e-01,  5.3525e-01,  3.9326e-01],
          [ 4.9409e-01,  4.1774e-01,  5.3854e-01]],

         [[ 4.0206e-01,  3.6071e-01,  3.3972e-01],
          [ 4.3792e-01,  3.8572e-01,  3.7576e-01],
          [ 4.6684e-01,  4.0982e-01,  4.3654e-01]],

         [[ 5.7194e-01,  5.3078e-01,  4.8957e-01],
          [ 6.5429e-01,  7.0739e-01,  6.6911e-01],
          [ 6.2929e-01,  4.8608e-01,  4.9186e-01]]]], device='cuda:0'), 'backend.4.bias': tensor([-1.0811e-01, -3.6618e-01,  1.2843e-01, -4.9061e-02, -2.9246e-01,
        -3.0937e-02, -2.1622e-01,  5.0674e-02,  7.6933e-02, -3.7847e-01,
         3.8315e-01,  6.9405e-02,  3.7675e-01,  3.4871e-02, -2.4371e-01,
        -6.7991e-02, -1.8840e-01,  9.8035e-02,  2.0505e-02,  1.9704e-03,
        -1.7969e-01,  3.6393e-01, -1.7572e-01, -4.2377e-01, -7.6813e-02,
        -5.1208e-01,  1.6247e-01,  1.3582e-01, -1.0090e-01, -6.3032e-01,
         2.1797e-01, -3.1502e-02,  2.5710e-02, -1.9573e-01,  4.0428e-02,
        -1.9212e-01, -1.6725e-01,  7.8193e-03,  1.1864e-01, -1.0259e-02,
        -5.1585e-05,  1.6475e-01,  4.8805e-02, -2.7858e-01, -2.8268e-01,
        -2.4049e-02, -1.5400e-03,  5.9488e-02, -3.5742e-01,  8.5504e-02,
        -3.2695e-01, -2.1993e-01, -4.9916e-01, -4.0067e-02, -2.6699e-02,
         3.2183e-01, -3.9358e-01, -1.2468e-02, -5.5512e-01, -3.7874e-01,
        -1.0882e-01, -8.0761e-03, -4.0328e-02, -2.3989e-01,  4.2836e-01,
         1.1270e-01,  5.2402e-03, -4.4078e-02, -1.1977e-01, -5.8301e-01,
        -4.5836e-01, -3.2117e-02, -4.3982e-01, -1.7271e-01, -1.0471e-01,
        -9.2244e-02, -2.5922e-01, -4.8508e-02, -1.3433e-01,  4.9866e-01,
         4.0635e-03,  4.7469e-01,  1.2651e-01,  2.1825e-01,  4.0002e-01,
         5.3297e-02, -4.8195e-02, -7.7324e-03,  3.1431e-02, -2.9858e-01,
         9.6682e-02,  5.9274e-03, -3.5871e-01, -1.8527e-01, -2.1074e-01,
        -2.4776e-02, -4.3068e-03, -4.8011e-01, -2.3097e-02, -4.8732e-01,
        -2.3378e-01,  1.2442e-02,  1.9692e-01,  6.4457e-01, -3.0372e-02,
        -7.6160e-02, -1.2318e-01,  1.7330e-01, -1.0179e-01,  4.4203e-02,
        -1.2982e-01, -1.8453e-01,  2.1299e-01, -5.0390e-02, -2.0802e-01,
         2.6357e-02, -5.6352e-01,  5.0608e-01,  1.8495e-01,  8.3415e-03,
        -3.2192e-02,  5.1196e-01, -1.3433e-02, -5.2051e-02,  1.4465e-01,
         3.7586e-02,  3.4294e-01,  6.9533e-03,  2.2646e-01,  5.1074e-01,
         3.4326e-02, -7.9605e-03,  3.3118e-01, -1.0774e-01, -4.2533e-02,
         3.0071e-02,  6.7278e-03, -7.9038e-01,  4.9788e-02, -4.3896e-01,
        -3.2473e-01, -2.9875e-01, -3.1285e-03, -4.8675e-03,  4.0755e-02,
        -7.9779e-03,  2.4403e-01, -5.4112e-02, -1.1398e-01,  1.1382e-03,
         3.8763e-02,  9.8142e-03, -3.7268e-01, -1.4725e-02,  5.2647e-01,
        -4.4866e-01,  2.7330e-01, -1.6092e-01, -1.5819e-01, -2.0994e-01,
         1.9687e-02, -2.4195e-02, -8.2346e-02, -3.9722e-01, -1.6620e-02,
         4.0971e-02,  3.9076e-01, -5.4414e-01, -1.2593e-01, -1.4784e-01,
        -3.4171e-01, -6.1622e-03, -2.4370e-01, -2.2419e-01,  3.1253e-04,
        -2.3541e-01, -6.4280e-02,  1.3212e-02, -1.1394e-01, -4.1009e-02,
        -8.9198e-02, -5.1328e-02, -3.2771e-01,  5.0165e-03,  2.6738e-01,
         6.9739e-02,  6.9241e-01,  4.3881e-01, -2.2326e-01,  2.3687e-02,
        -3.1278e-01, -9.1270e-02, -2.7651e-01,  1.0137e-01,  1.0068e+00,
        -3.0621e-02, -3.0768e-02, -1.6984e-01,  6.5684e-01,  8.3775e-02,
         4.4154e-01,  2.3669e-01, -1.1397e-01,  3.7618e-03, -2.0286e-02,
        -2.9737e-01,  5.2128e-02, -1.5838e-01, -1.8250e-01,  8.7094e-02,
        -9.9949e-03, -4.6142e-02, -4.2110e-01, -9.8059e-02, -1.8507e-01,
        -6.2263e-03,  1.6868e-02, -1.9719e-01, -2.3422e-01, -3.4677e-01,
         1.6644e-01,  1.2507e-01,  3.9419e-01,  7.4623e-02, -3.1263e-02,
        -3.1772e-01,  8.2826e-02,  1.5915e-02,  9.8656e-02,  1.1933e-02,
        -3.0592e-01, -3.5128e-02,  2.9627e-01,  2.0167e-01,  1.0441e-01,
        -1.0012e-01,  5.5527e-01, -1.0113e-01,  1.1197e-01, -5.4781e-02,
         5.3432e-01,  1.8933e-01,  1.2889e-01, -9.9683e-01, -3.9095e-02,
        -1.6115e-01,  1.7402e-02,  1.7734e-02,  1.6028e-01, -3.4079e-01,
         3.0157e-01,  7.4537e-02, -2.5539e-01, -3.4748e-01,  2.8850e-01,
        -2.7769e-01, -7.4829e-02,  1.7404e-01, -6.9485e-02, -2.7810e-01,
        -1.2865e-01,  2.2681e-01, -2.0876e-01, -4.3858e-01, -1.3636e-01,
        -3.7374e-01, -6.9721e-04,  2.8005e-01,  1.3778e-04, -1.2098e-01,
        -3.6941e-01, -1.2100e-01,  3.8068e-02, -3.8953e-01, -3.6715e-01,
        -4.5713e-02, -3.1230e-02, -1.0634e-01,  1.4168e-01,  2.3006e-01,
        -1.8545e-01, -2.0268e-01, -6.4673e-02, -2.3959e-01,  3.1085e-01,
         3.6060e-01,  1.6343e-02, -2.4542e-01, -8.0531e-02, -2.3345e-01,
        -1.0109e-02, -2.5676e-02,  9.0185e-01,  2.6805e-01,  3.4583e-01,
        -1.8345e-02, -1.3387e-01, -2.4006e-01,  1.4222e-02, -4.0942e-02,
        -1.7020e-01, -1.4158e-01, -2.0830e-01, -1.6937e-01, -8.4634e-02,
        -3.2971e-01, -2.7500e-01,  1.6297e-02, -4.0976e-02, -1.1737e-01,
         1.2762e-02, -1.3446e-01, -1.0032e-01, -1.4785e-01,  1.6940e-01,
        -6.3064e-02, -1.2878e-01,  6.4634e-01, -5.3337e-01,  1.4795e-02,
        -9.2406e-02, -4.7322e-01,  4.4712e-02, -3.0021e-01,  1.7769e-01,
        -4.5306e-01, -1.2880e-01, -3.4058e-02, -1.7092e-01, -3.2663e-01,
        -4.7847e-02, -3.4171e-01,  3.4814e-01, -1.8828e-01, -1.6558e-01,
        -5.7710e-01, -1.1870e-01,  2.7406e-01,  2.3553e-01, -2.6389e-01,
         2.1475e-01, -3.4905e-01,  1.3481e-01, -1.8988e-01, -2.4476e-02,
        -3.1931e-01,  9.0384e-02,  6.3579e-01, -1.4432e-01, -2.4492e-01,
         2.1646e-01,  4.9189e-01,  1.1619e-02,  7.9976e-02,  2.4348e-01,
         1.2597e-02, -1.4821e-01, -7.4586e-02,  1.5593e-01,  1.3075e-01,
         3.0586e-01, -3.6773e-01,  1.8266e-02,  9.1950e-02,  3.1870e-01,
        -2.1595e-01,  3.7490e-01, -2.6143e-02, -3.6379e-01,  8.8123e-03,
         2.6170e-02,  2.5110e-02,  2.6418e-02, -9.9201e-02,  3.0538e-01,
        -1.0716e-02, -1.9231e-01, -2.7256e-01,  1.1161e+00,  1.0306e-02,
        -9.5665e-02, -7.0359e-04, -3.1032e-01, -7.5437e-02,  2.4540e-01,
        -9.1371e-02, -5.9279e-01,  3.0516e-03,  1.4869e-02, -4.7875e-01,
         6.7282e-02, -1.8228e-01,  4.9478e-02,  3.0897e-02,  1.5925e-01,
         1.5402e-02,  3.8059e-02, -2.0829e-01, -1.9951e-01, -4.6217e-02,
        -5.7943e-01, -4.0631e-02,  1.8277e-01, -1.0761e-01, -5.3346e-01,
        -9.1331e-03, -3.6206e-01, -5.0542e-02,  2.9752e-01, -2.0687e-02,
         6.0333e-01,  2.5752e-01,  9.7423e-03,  6.7221e-03, -1.2127e-01,
        -8.0107e-02, -4.5754e-02,  6.7041e-02, -1.8903e-02, -2.1782e-01,
        -3.6457e-01, -2.6520e-02,  6.3350e-01, -3.4595e-01, -3.7133e-02,
        -9.5453e-02, -3.0462e-01, -3.0522e-01, -6.8319e-02, -5.2827e-01,
         1.4542e-01, -1.9183e-01,  1.9122e-03, -5.3522e-03, -1.5697e-01,
         2.8614e-02,  2.2384e-01, -4.2826e-02,  3.7193e-01, -1.0112e-01,
        -7.1846e-02, -1.7502e-01,  3.7556e-02, -6.9689e-01, -3.6152e-01,
        -3.2400e-02, -2.4075e-02, -3.1030e-01,  9.2281e-02, -4.0314e-01,
        -1.1533e-01,  1.2940e-01,  3.9190e-01,  6.1193e-02, -1.3613e-01,
        -2.1752e-02,  9.9641e-02,  2.4689e-01, -1.4850e-03,  1.3127e-01,
        -4.5445e-01,  3.8565e-01, -4.4021e-01,  4.3853e-01, -1.5639e-01,
         2.3228e-01,  4.4087e-02, -5.8860e-02, -1.5626e-03, -1.2278e-01,
        -8.8028e-02, -1.9164e-01, -6.1238e-02,  4.0478e-01, -3.7728e-01,
        -1.1528e-01,  1.1578e-01,  7.6797e-01, -7.4221e-02,  2.1551e-01,
         1.1526e-01, -2.0986e-03,  1.7941e-01, -7.2154e-01,  3.0799e-01,
        -3.7809e-02, -1.0175e-01,  2.5063e-01, -9.7411e-03, -1.2966e-01,
        -9.2820e-03,  5.0412e-02, -1.3581e-01,  2.7528e-01, -1.5140e-01,
         3.9172e-02,  5.3646e-02,  7.7759e-02,  2.6279e-02,  3.7055e-02,
         4.2298e-01, -4.2496e-02, -4.7810e-01, -2.3013e-01,  1.5903e-01,
         1.3805e-01, -1.8588e-01, -2.5382e-01,  1.1852e-02, -2.7152e-01,
        -2.3342e-01,  9.9333e-01], device='cuda:0')}
INFO:root:Summary name (meta-train): train loss is illegal; using _meta-train___train_loss instead.
INFO:root:Summary name (meta-train): train MAE is illegal; using _meta-train___train_MAE instead.
INFO:root:Summary name (meta-train): train MSE is illegal; using _meta-train___train_MSE instead.
INFO:root:Summary name (meta-train): test MAE is illegal; using _meta-train___test_MAE instead.
INFO:root:Summary name (meta-train): test MSE is illegal; using _meta-train___test_MSE instead.
INFO:root:Summary name (meta-test) train loss is illegal; using _meta-test__train_loss instead.
INFO:root:Summary name (meta-test) train MAE is illegal; using _meta-test__train_MAE instead.
INFO:root:Summary name (meta-test) train MSE is illegal; using _meta-test__train_MSE instead.
INFO:root:Summary name (meta-test) test MAE is illegal; using _meta-test__test_MAE instead.
INFO:root:Summary name (meta-test) test MSE is illegal; using _meta-test__test_MSE instead.
INFO:root:===> Training epoch: 2/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:489.379495811, MAE: 1208.24804993, MSE: 1208.24805147
INFO:root:(Meta-testing) test MAE: 1191.54593735, MSE: 1191.54593295
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.88615870476, MAE: 5.28636693954, MSE: 5.28636689005
INFO:root:(Meta-training) post train loss: 2.55021095276, MAE: 3.69266057014, MSE: 3.69266058385
INFO:root:(Meta-training) pre-training test MAE: 2.8181886673, MSE: 2.8181886575
INFO:root:(Meta-training) post-training test MAE: 14.8132400513, MSE: 14.8132401294
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.822998046875, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.98028564453125, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142120361328, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2706298828125, '0.bias': 0.01205790601670742, '6.weight': -82.45709991455078, '8.weight': -35.569644927978516, '2.bias': 0.029188044369220734, '10.bias': 0.3597584664821625, '0.weight': -108.17759704589844}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-72.3537, device='cuda:0'), 'backend.0.bias': tensor(-0.0175, device='cuda:0'), 'backend.10.weight': tensor(-146.6180, device='cuda:0'), 'backend.8.bias': tensor(-0.0953, device='cuda:0'), 'backend.6.weight': tensor(-101.1441, device='cuda:0'), 'backend.2.bias': tensor(-0.0419, device='cuda:0'), 'backend.10.bias': tensor(-0.2738, device='cuda:0'), 'output_layer.bias': tensor(13.7382, device='cuda:0'), 'backend.2.weight': tensor(-87.7124, device='cuda:0'), 'backend.6.bias': tensor(-0.0673, device='cuda:0'), 'backend.0.weight': tensor(-45.9378, device='cuda:0'), 'output_layer.weight': tensor(17.7770, device='cuda:0'), 'backend.4.weight': tensor(-38.0071, device='cuda:0'), 'backend.4.bias': tensor(-0.0194, device='cuda:0')}
INFO:root:==> Training scene: 2
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.1483221054, MAE: 12.8588142395, MSE: 12.8588143246
INFO:root:(Meta-training) post train loss: 24.7597961426, MAE: 319.908416748, MSE: 319.908421955
INFO:root:(Meta-training) pre-training test MAE: 16.1991920471, MSE: 16.1991919045
INFO:root:(Meta-training) post-training test MAE: 321.063964844, MSE: 321.063966076
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.822998046875, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.98028564453125, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142120361328, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2706298828125, '0.bias': 0.01205790601670742, '6.weight': -82.45709991455078, '8.weight': -35.569644927978516, '2.bias': 0.029188044369220734, '10.bias': 0.3597584664821625, '0.weight': -108.17759704589844}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(3071.7373, device='cuda:0'), 'backend.0.bias': tensor(1.0439, device='cuda:0'), 'backend.10.weight': tensor(5227.1094, device='cuda:0'), 'backend.8.bias': tensor(3.4101, device='cuda:0'), 'backend.6.weight': tensor(4269.0098, device='cuda:0'), 'backend.2.bias': tensor(1.3926, device='cuda:0'), 'backend.10.bias': tensor(21.2512, device='cuda:0'), 'output_layer.bias': tensor(-352.2823, device='cuda:0'), 'backend.2.weight': tensor(3795.5938, device='cuda:0'), 'backend.6.bias': tensor(2.2225, device='cuda:0'), 'backend.0.weight': tensor(2667.0796, device='cuda:0'), 'output_layer.weight': tensor(-433.9279, device='cuda:0'), 'backend.4.weight': tensor(2385.2197, device='cuda:0'), 'backend.4.bias': tensor(1.0120, device='cuda:0')}
INFO:root:==> Training scene: 3
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 23.8228435516, MAE: 48.741569519, MSE: 48.7415682812
INFO:root:(Meta-training) post train loss: 354.427886963, MAE: 1437.99169922, MSE: 1437.99169852
INFO:root:(Meta-training) pre-training test MAE: 16.4611282349, MSE: 16.4611284546
INFO:root:(Meta-training) post-training test MAE: 1262.35717773, MSE: 1262.35717014
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.822998046875, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.98028564453125, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142120361328, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2706298828125, '0.bias': 0.01205790601670742, '6.weight': -82.45709991455078, '8.weight': -35.569644927978516, '2.bias': 0.029188044369220734, '10.bias': 0.3597584664821625, '0.weight': -108.17759704589844}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(37341.8359, device='cuda:0'), 'backend.0.bias': tensor(14.3119, device='cuda:0'), 'backend.10.weight': tensor(40712.0156, device='cuda:0'), 'backend.8.bias': tensor(26.6767, device='cuda:0'), 'backend.6.weight': tensor(51949.9688, device='cuda:0'), 'backend.2.bias': tensor(15.4098, device='cuda:0'), 'backend.10.bias': tensor(164.4867, device='cuda:0'), 'output_layer.bias': tensor(-1631.0929, device='cuda:0'), 'backend.2.weight': tensor(50694.3047, device='cuda:0'), 'backend.6.bias': tensor(19.7637, device='cuda:0'), 'backend.0.weight': tensor(40206.4766, device='cuda:0'), 'output_layer.weight': tensor(-1673.1460, device='cuda:0'), 'backend.4.weight': tensor(40128.4531, device='cuda:0'), 'backend.4.bias': tensor(15.1422, device='cuda:0')}
INFO:root:==> Training scene: 4
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.4615831375, MAE: 20.6086215973, MSE: 20.6086212784
INFO:root:(Meta-training) post train loss: 40.902961731, MAE: 445.036590576, MSE: 445.036585575
INFO:root:(Meta-training) pre-training test MAE: 5.165538311, MSE: 5.16553839803
INFO:root:(Meta-training) post-training test MAE: 416.225250244, MSE: 416.225243258
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.822998046875, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.98028564453125, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142120361328, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2706298828125, '0.bias': 0.01205790601670742, '6.weight': -82.45709991455078, '8.weight': -35.569644927978516, '2.bias': 0.029188044369220734, '10.bias': 0.3597584664821625, '0.weight': -108.17759704589844}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(4165.6030, device='cuda:0'), 'backend.0.bias': tensor(1.2551, device='cuda:0'), 'backend.10.weight': tensor(6280.8550, device='cuda:0'), 'backend.8.bias': tensor(4.6585, device='cuda:0'), 'backend.6.weight': tensor(5465.5020, device='cuda:0'), 'backend.2.bias': tensor(1.7907, device='cuda:0'), 'backend.10.bias': tensor(20.7245, device='cuda:0'), 'output_layer.bias': tensor(-399.2969, device='cuda:0'), 'backend.2.weight': tensor(4626.5073, device='cuda:0'), 'backend.6.bias': tensor(2.8286, device='cuda:0'), 'backend.0.weight': tensor(3231.8521, device='cuda:0'), 'output_layer.weight': tensor(-509.0807, device='cuda:0'), 'backend.4.weight': tensor(3166.0186, device='cuda:0'), 'backend.4.bias': tensor(1.3925, device='cuda:0')}
INFO:root:==> Training scene: 5
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.41042613983, MAE: 1.0650472641, MSE: 1.06504724004
INFO:root:(Meta-training) post train loss: 5.75271129608, MAE: 29.7911014557, MSE: 29.7911010973
INFO:root:(Meta-training) pre-training test MAE: 1.51246929169, MSE: 1.51246928034
INFO:root:(Meta-training) post-training test MAE: 36.4609832764, MSE: 36.4609835346
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.822998046875, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.98028564453125, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142120361328, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2706298828125, '0.bias': 0.01205790601670742, '6.weight': -82.45709991455078, '8.weight': -35.569644927978516, '2.bias': 0.029188044369220734, '10.bias': 0.3597584664821625, '0.weight': -108.17759704589844}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(193.4945, device='cuda:0'), 'backend.0.bias': tensor(0.0475, device='cuda:0'), 'backend.10.weight': tensor(358.9228, device='cuda:0'), 'backend.8.bias': tensor(0.3138, device='cuda:0'), 'backend.6.weight': tensor(274.9052, device='cuda:0'), 'backend.2.bias': tensor(0.1141, device='cuda:0'), 'backend.10.bias': tensor(0.9936, device='cuda:0'), 'output_layer.bias': tensor(-40.2129, device='cuda:0'), 'backend.2.weight': tensor(234.8247, device='cuda:0'), 'backend.6.bias': tensor(0.1891, device='cuda:0'), 'backend.0.weight': tensor(113.9340, device='cuda:0'), 'output_layer.weight': tensor(-42.4105, device='cuda:0'), 'backend.4.weight': tensor(104.0569, device='cuda:0'), 'backend.4.bias': tensor(0.0485, device='cuda:0')}
INFO:root:==> Training scene: 6
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 23.975605011, MAE: 51.1384048462, MSE: 51.1384050847
INFO:root:(Meta-training) post train loss: 379.12286377, MAE: 1486.74499512, MSE: 1486.74501849
INFO:root:(Meta-training) pre-training test MAE: 50.7359924316, MSE: 50.7359918514
INFO:root:(Meta-training) post-training test MAE: 1449.84863281, MSE: 1449.84861279
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.822998046875, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.98028564453125, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142120361328, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2706298828125, '0.bias': 0.01205790601670742, '6.weight': -82.45709991455078, '8.weight': -35.569644927978516, '2.bias': 0.029188044369220734, '10.bias': 0.3597584664821625, '0.weight': -108.17759704589844}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(51738.8281, device='cuda:0'), 'backend.0.bias': tensor(17.5429, device='cuda:0'), 'backend.10.weight': tensor(53416.7891, device='cuda:0'), 'backend.8.bias': tensor(34.5272, device='cuda:0'), 'backend.6.weight': tensor(71763.4844, device='cuda:0'), 'backend.2.bias': tensor(18.8598, device='cuda:0'), 'backend.10.bias': tensor(210.3814, device='cuda:0'), 'output_layer.bias': tensor(-2045.6956, device='cuda:0'), 'backend.2.weight': tensor(69992.1719, device='cuda:0'), 'backend.6.bias': tensor(25.1155, device='cuda:0'), 'backend.0.weight': tensor(55486.6523, device='cuda:0'), 'output_layer.weight': tensor(-1768.9449, device='cuda:0'), 'backend.4.weight': tensor(56900.2891, device='cuda:0'), 'backend.4.bias': tensor(18.8454, device='cuda:0')}
INFO:root:==> Training scene: 7
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 12.607963562, MAE: 19.3152389526, MSE: 19.3152390794
INFO:root:(Meta-training) post train loss: 52.5039100647, MAE: 508.095611572, MSE: 508.095617232
INFO:root:(Meta-training) pre-training test MAE: 38.8709793091, MSE: 38.8709789294
INFO:root:(Meta-training) post-training test MAE: 533.328552246, MSE: 533.328551411
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.822998046875, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.81134033203125, '7.weight': -335.98028564453125, '2.weight': -63.11039733886719, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.1142120361328, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.2706298828125, '0.bias': 0.01205790601670742, '6.weight': -82.45709991455078, '8.weight': -35.569644927978516, '2.bias': 0.029188044369220734, '10.bias': 0.3597584664821625, '0.weight': -108.17759704589844}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(8189.1025, device='cuda:0'), 'backend.0.bias': tensor(2.8491, device='cuda:0'), 'backend.10.weight': tensor(10965.9121, device='cuda:0'), 'backend.8.bias': tensor(6.8243, device='cuda:0'), 'backend.6.weight': tensor(11341.8193, device='cuda:0'), 'backend.2.bias': tensor(3.4834, device='cuda:0'), 'backend.10.bias': tensor(40.1263, device='cuda:0'), 'output_layer.bias': tensor(-607.5925, device='cuda:0'), 'backend.2.weight': tensor(10623.3965, device='cuda:0'), 'backend.6.bias': tensor(4.9186, device='cuda:0'), 'backend.0.weight': tensor(7960.4053, device='cuda:0'), 'output_layer.weight': tensor(-733.5708, device='cuda:0'), 'backend.4.weight': tensor(7729.2407, device='cuda:0'), 'backend.4.bias': tensor(3.0016, device='cuda:0')}
INFO:root:==> Training scene: 8
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:10.2249026775, MAE: 101.208072662, MSE: 101.208072391
INFO:root:(Meta-testing) test MAE: 101.541421127, MSE: 101.541421905
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.92773497105, MAE: 3.70236587524, MSE: 3.70236584572
INFO:root:(Meta-training) post train loss: 2.13366675377, MAE: 37.6027603149, MSE: 37.6027595968
INFO:root:(Meta-training) pre-training test MAE: 6.88640213013, MSE: 6.88640217694
INFO:root:(Meta-training) post-training test MAE: 40.4782524109, MSE: 40.4782520818
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-43.9210, device='cuda:0'), 'backend.0.bias': tensor(0.0013, device='cuda:0'), 'backend.10.weight': tensor(-2.8210, device='cuda:0'), 'backend.8.bias': tensor(-0.1662, device='cuda:0'), 'backend.6.weight': tensor(-52.1226, device='cuda:0'), 'backend.2.bias': tensor(-0.0119, device='cuda:0'), 'backend.10.bias': tensor(0.1539, device='cuda:0'), 'output_layer.bias': tensor(-30.3483, device='cuda:0'), 'backend.2.weight': tensor(-93.3560, device='cuda:0'), 'backend.6.bias': tensor(-0.0265, device='cuda:0'), 'backend.0.weight': tensor(-21.5634, device='cuda:0'), 'output_layer.weight': tensor(-5.2881, device='cuda:0'), 'backend.4.weight': tensor(-96.7638, device='cuda:0'), 'backend.4.bias': tensor(-0.0339, device='cuda:0')}
INFO:root:==> Training scene: 2
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.4576377869, MAE: 14.0155792236, MSE: 14.0155792746
INFO:root:(Meta-training) post train loss: 28.2439689636, MAE: 246.063415527, MSE: 246.063412813
INFO:root:(Meta-training) pre-training test MAE: 8.87585067749, MSE: 8.875850583
INFO:root:(Meta-training) post-training test MAE: 235.911209106, MSE: 235.911207144
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-1020.3319, device='cuda:0'), 'backend.0.bias': tensor(-0.1067, device='cuda:0'), 'backend.10.weight': tensor(-2049.0684, device='cuda:0'), 'backend.8.bias': tensor(-5.0614, device='cuda:0'), 'backend.6.weight': tensor(-1269.1729, device='cuda:0'), 'backend.2.bias': tensor(-0.5702, device='cuda:0'), 'backend.10.bias': tensor(-49.0953, device='cuda:0'), 'output_layer.bias': tensor(-201.3323, device='cuda:0'), 'backend.2.weight': tensor(-2259.6045, device='cuda:0'), 'backend.6.bias': tensor(-1.0513, device='cuda:0'), 'backend.0.weight': tensor(-684.9939, device='cuda:0'), 'output_layer.weight': tensor(-48.6113, device='cuda:0'), 'backend.4.weight': tensor(-2496.2798, device='cuda:0'), 'backend.4.bias': tensor(-1.3280, device='cuda:0')}
INFO:root:==> Training scene: 3
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.215716362, MAE: 12.3267059326, MSE: 12.3267058703
INFO:root:(Meta-training) post train loss: 13.1575832367, MAE: 155.954437256, MSE: 155.95443921
INFO:root:(Meta-training) pre-training test MAE: 17.9829978943, MSE: 17.9829979178
INFO:root:(Meta-training) post-training test MAE: 149.803665161, MSE: 149.803667084
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-411.3094, device='cuda:0'), 'backend.0.bias': tensor(-0.1084, device='cuda:0'), 'backend.10.weight': tensor(-577.3647, device='cuda:0'), 'backend.8.bias': tensor(-1.6774, device='cuda:0'), 'backend.6.weight': tensor(-752.4653, device='cuda:0'), 'backend.2.bias': tensor(-0.3535, device='cuda:0'), 'backend.10.bias': tensor(-13.2628, device='cuda:0'), 'output_layer.bias': tensor(-113.9395, device='cuda:0'), 'backend.2.weight': tensor(-1495.3232, device='cuda:0'), 'backend.6.bias': tensor(-0.6486, device='cuda:0'), 'backend.0.weight': tensor(-532.8911, device='cuda:0'), 'output_layer.weight': tensor(-24.8956, device='cuda:0'), 'backend.4.weight': tensor(-1443.4867, device='cuda:0'), 'backend.4.bias': tensor(-0.7667, device='cuda:0')}
INFO:root:==> Training scene: 4
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.40858054161, MAE: 3.46781778336, MSE: 3.46781785142
INFO:root:(Meta-training) post train loss: 1.24631130695, MAE: 40.1663703918, MSE: 40.1663700161
INFO:root:(Meta-training) pre-training test MAE: 5.10420227051, MSE: 5.1042023119
INFO:root:(Meta-training) post-training test MAE: 38.2077407837, MSE: 38.207740327
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-22.4932, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(-6.9668, device='cuda:0'), 'backend.8.bias': tensor(-0.0887, device='cuda:0'), 'backend.6.weight': tensor(1.9747, device='cuda:0'), 'backend.2.bias': tensor(-0.0034, device='cuda:0'), 'backend.10.bias': tensor(-0.2023, device='cuda:0'), 'output_layer.bias': tensor(-28.7350, device='cuda:0'), 'backend.2.weight': tensor(-43.8065, device='cuda:0'), 'backend.6.bias': tensor(0.0327, device='cuda:0'), 'backend.0.weight': tensor(-7.9347, device='cuda:0'), 'output_layer.weight': tensor(-4.6944, device='cuda:0'), 'backend.4.weight': tensor(-74.9707, device='cuda:0'), 'backend.4.bias': tensor(-0.0318, device='cuda:0')}
INFO:root:==> Training scene: 5
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.464849472, MAE: 11.5086917877, MSE: 11.5086915716
INFO:root:(Meta-training) post train loss: 12.0098371506, MAE: 157.504074097, MSE: 157.504073608
INFO:root:(Meta-training) pre-training test MAE: 6.65334415436, MSE: 6.65334403491
INFO:root:(Meta-training) post-training test MAE: 148.859954834, MSE: 148.859958046
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-168.4951, device='cuda:0'), 'backend.0.bias': tensor(-0.0335, device='cuda:0'), 'backend.10.weight': tensor(-512.0421, device='cuda:0'), 'backend.8.bias': tensor(-0.8689, device='cuda:0'), 'backend.6.weight': tensor(-290.6689, device='cuda:0'), 'backend.2.bias': tensor(-0.2067, device='cuda:0'), 'backend.10.bias': tensor(-12.1426, device='cuda:0'), 'output_layer.bias': tensor(-113.5457, device='cuda:0'), 'backend.2.weight': tensor(-810.5502, device='cuda:0'), 'backend.6.bias': tensor(-0.2528, device='cuda:0'), 'backend.0.weight': tensor(-189.6143, device='cuda:0'), 'output_layer.weight': tensor(-21.5855, device='cuda:0'), 'backend.4.weight': tensor(-870.6675, device='cuda:0'), 'backend.4.bias': tensor(-0.5180, device='cuda:0')}
INFO:root:==> Training scene: 6
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.31700372696, MAE: 4.50811004639, MSE: 4.50810994402
INFO:root:(Meta-training) post train loss: 2.54581308365, MAE: 56.9175300598, MSE: 56.9175300291
INFO:root:(Meta-training) pre-training test MAE: 3.33308029175, MSE: 3.33308034573
INFO:root:(Meta-training) post-training test MAE: 57.6218566895, MSE: 57.6218562727
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-37.6213, device='cuda:0'), 'backend.0.bias': tensor(0.0053, device='cuda:0'), 'backend.10.weight': tensor(-48.7510, device='cuda:0'), 'backend.8.bias': tensor(-0.1999, device='cuda:0'), 'backend.6.weight': tensor(-3.2662, device='cuda:0'), 'backend.2.bias': tensor(-0.0192, device='cuda:0'), 'backend.10.bias': tensor(-1.0821, device='cuda:0'), 'output_layer.bias': tensor(-43.8108, device='cuda:0'), 'backend.2.weight': tensor(-99.3718, device='cuda:0'), 'backend.6.bias': tensor(0.0174, device='cuda:0'), 'backend.0.weight': tensor(-8.4586, device='cuda:0'), 'output_layer.weight': tensor(-7.1186, device='cuda:0'), 'backend.4.weight': tensor(-117.8177, device='cuda:0'), 'backend.4.bias': tensor(-0.0676, device='cuda:0')}
INFO:root:==> Training scene: 7
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.56835842133, MAE: 9.11410331726, MSE: 9.11410331697
INFO:root:(Meta-training) post train loss: 8.68908500671, MAE: 118.70375061, MSE: 118.703749217
INFO:root:(Meta-training) pre-training test MAE: 7.59414863586, MSE: 7.59414860186
INFO:root:(Meta-training) post-training test MAE: 119.183746338, MSE: 119.183747319
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-183.1739, device='cuda:0'), 'backend.0.bias': tensor(-0.0085, device='cuda:0'), 'backend.10.weight': tensor(-210.6387, device='cuda:0'), 'backend.8.bias': tensor(-0.9138, device='cuda:0'), 'backend.6.weight': tensor(-301.4147, device='cuda:0'), 'backend.2.bias': tensor(-0.1017, device='cuda:0'), 'backend.10.bias': tensor(-4.8148, device='cuda:0'), 'output_layer.bias': tensor(-90.9324, device='cuda:0'), 'backend.2.weight': tensor(-551.6276, device='cuda:0'), 'backend.6.bias': tensor(-0.2307, device='cuda:0'), 'backend.0.weight': tensor(-168.9219, device='cuda:0'), 'output_layer.weight': tensor(-16.1698, device='cuda:0'), 'backend.4.weight': tensor(-548.3022, device='cuda:0'), 'backend.4.bias': tensor(-0.2530, device='cuda:0')}
INFO:root:==> Training scene: 8
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.70169210434, MAE: 4.29832458496, MSE: 4.29832450693
INFO:root:(Meta-training) post train loss: 3.9628610611, MAE: 41.1326179504, MSE: 41.1326173725
INFO:root:(Meta-training) pre-training test MAE: 0.344522476196, MSE: 0.34452247522
INFO:root:(Meta-training) post-training test MAE: 45.7303619385, MSE: 45.730363144
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-90.5592, device='cuda:0'), 'backend.0.bias': tensor(-0.0234, device='cuda:0'), 'backend.10.weight': tensor(-131.2070, device='cuda:0'), 'backend.8.bias': tensor(-0.3804, device='cuda:0'), 'backend.6.weight': tensor(-169.8558, device='cuda:0'), 'backend.2.bias': tensor(-0.0816, device='cuda:0'), 'backend.10.bias': tensor(-2.6672, device='cuda:0'), 'output_layer.bias': tensor(-34.8099, device='cuda:0'), 'backend.2.weight': tensor(-365.8164, device='cuda:0'), 'backend.6.bias': tensor(-0.1439, device='cuda:0'), 'backend.0.weight': tensor(-121.5346, device='cuda:0'), 'output_layer.weight': tensor(-7.2147, device='cuda:0'), 'backend.4.weight': tensor(-379.3095, device='cuda:0'), 'backend.4.bias': tensor(-0.1953, device='cuda:0')}
INFO:root:==> Training scene: 9
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.31722784042, MAE: 1.57554912567, MSE: 1.57554914801
INFO:root:(Meta-training) post train loss: 4.04796695709, MAE: 13.7908372879, MSE: 13.7908373504
INFO:root:(Meta-training) pre-training test MAE: 5.13178634644, MSE: 5.13178641226
INFO:root:(Meta-training) post-training test MAE: 10.5187931061, MSE: 10.5187932721
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(12.7440, device='cuda:0'), 'backend.0.bias': tensor(0.0095, device='cuda:0'), 'backend.10.weight': tensor(-5.2699, device='cuda:0'), 'backend.8.bias': tensor(0.0464, device='cuda:0'), 'backend.6.weight': tensor(44.8930, device='cuda:0'), 'backend.2.bias': tensor(0.0177, device='cuda:0'), 'backend.10.bias': tensor(-0.2285, device='cuda:0'), 'output_layer.bias': tensor(-7.7328, device='cuda:0'), 'backend.2.weight': tensor(82.0600, device='cuda:0'), 'backend.6.bias': tensor(0.0495, device='cuda:0'), 'backend.0.weight': tensor(42.8591, device='cuda:0'), 'output_layer.weight': tensor(-1.1357, device='cuda:0'), 'backend.4.weight': tensor(46.6682, device='cuda:0'), 'backend.4.bias': tensor(0.0206, device='cuda:0')}
INFO:root:==> Training scene: 10
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 2.62649679184, MAE: 0.140889167786, MSE: 0.14088916471
INFO:root:(Meta-training) post train loss: 1.72036850452, MAE: 8.40645599365, MSE: 8.40645601949
INFO:root:(Meta-training) pre-training test MAE: 2.28190612793, MSE: 2.28190613808
INFO:root:(Meta-training) post-training test MAE: 9.29603385925, MSE: 9.29603380517
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(29.3628, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(14.4852, device='cuda:0'), 'backend.8.bias': tensor(0.1243, device='cuda:0'), 'backend.6.weight': tensor(20.2023, device='cuda:0'), 'backend.2.bias': tensor(0.0180, device='cuda:0'), 'backend.10.bias': tensor(0.5395, device='cuda:0'), 'output_layer.bias': tensor(7.4571, device='cuda:0'), 'backend.2.weight': tensor(65.6158, device='cuda:0'), 'backend.6.bias': tensor(0.0065, device='cuda:0'), 'backend.0.weight': tensor(18.4940, device='cuda:0'), 'output_layer.weight': tensor(1.3643, device='cuda:0'), 'backend.4.weight': tensor(55.8143, device='cuda:0'), 'backend.4.bias': tensor(0.0334, device='cuda:0')}
INFO:root:==> Training scene: 11
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 20.0581626892, MAE: 3.79273986816, MSE: 3.79273981411
INFO:root:(Meta-training) post train loss: 15.4374341965, MAE: 60.0539474487, MSE: 60.0539471018
INFO:root:(Meta-training) pre-training test MAE: 1.65007305145, MSE: 1.65007306717
INFO:root:(Meta-training) post-training test MAE: 46.8975715637, MSE: 46.8975726901
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-285.1150, device='cuda:0'), 'backend.0.bias': tensor(-0.0562, device='cuda:0'), 'backend.10.weight': tensor(-397.6520, device='cuda:0'), 'backend.8.bias': tensor(-1.2813, device='cuda:0'), 'backend.6.weight': tensor(-501.0734, device='cuda:0'), 'backend.2.bias': tensor(-0.1695, device='cuda:0'), 'backend.10.bias': tensor(-8.2408, device='cuda:0'), 'output_layer.bias': tensor(-36.3815, device='cuda:0'), 'backend.2.weight': tensor(-722.0708, device='cuda:0'), 'backend.6.bias': tensor(-0.4861, device='cuda:0'), 'backend.0.weight': tensor(-277.7590, device='cuda:0'), 'output_layer.weight': tensor(-10.3747, device='cuda:0'), 'backend.4.weight': tensor(-798.2838, device='cuda:0'), 'backend.4.bias': tensor(-0.4068, device='cuda:0')}
INFO:root:==> Training scene: 12
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.26931238174, MAE: 9.15769100189, MSE: 9.15769098289
INFO:root:(Meta-training) post train loss: 5.25304222107, MAE: 128.482192993, MSE: 128.48219265
INFO:root:(Meta-training) pre-training test MAE: 4.61597824097, MSE: 4.61597820524
INFO:root:(Meta-training) post-training test MAE: 141.958694458, MSE: 141.958696403
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(260.6506, device='cuda:0'), 'backend.0.bias': tensor(0.0241, device='cuda:0'), 'backend.10.weight': tensor(468.7807, device='cuda:0'), 'backend.8.bias': tensor(1.2948, device='cuda:0'), 'backend.6.weight': tensor(381.9536, device='cuda:0'), 'backend.2.bias': tensor(0.2002, device='cuda:0'), 'backend.10.bias': tensor(12.5315, device='cuda:0'), 'output_layer.bias': tensor(110.0442, device='cuda:0'), 'backend.2.weight': tensor(951.6746, device='cuda:0'), 'backend.6.bias': tensor(0.2520, device='cuda:0'), 'backend.0.weight': tensor(256.8109, device='cuda:0'), 'output_layer.weight': tensor(24.2919, device='cuda:0'), 'backend.4.weight': tensor(1108.7393, device='cuda:0'), 'backend.4.bias': tensor(0.5716, device='cuda:0')}
INFO:root:==> Training scene: 13
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.15585327148, MAE: 0.122278213501, MSE: 0.122278211939
INFO:root:(Meta-training) post train loss: 6.03297519684, MAE: 16.0758647919, MSE: 16.0758651762
INFO:root:(Meta-training) pre-training test MAE: 6.88552856445, MSE: 6.88552854815
INFO:root:(Meta-training) post-training test MAE: 24.3776397705, MSE: 24.3776403318
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(63.4827, device='cuda:0'), 'backend.0.bias': tensor(0.0233, device='cuda:0'), 'backend.10.weight': tensor(82.2645, device='cuda:0'), 'backend.8.bias': tensor(0.2575, device='cuda:0'), 'backend.6.weight': tensor(116.4496, device='cuda:0'), 'backend.2.bias': tensor(0.0472, device='cuda:0'), 'backend.10.bias': tensor(1.7026, device='cuda:0'), 'output_layer.bias': tensor(19.4743, device='cuda:0'), 'backend.2.weight': tensor(230.1284, device='cuda:0'), 'backend.6.bias': tensor(0.0803, device='cuda:0'), 'backend.0.weight': tensor(113.2029, device='cuda:0'), 'output_layer.weight': tensor(4.3419, device='cuda:0'), 'backend.4.weight': tensor(236.4452, device='cuda:0'), 'backend.4.bias': tensor(0.1142, device='cuda:0')}
INFO:root:==> Training scene: 14
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.2247161865, MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post train loss: 11.2101097107, MAE: 134.058197021, MSE: 134.058194861
INFO:root:(Meta-training) pre-training test MAE: 9.19702339172, MSE: 9.19702319208
INFO:root:(Meta-training) post-training test MAE: 132.986633301, MSE: 132.986635842
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-412.4745, device='cuda:0'), 'backend.0.bias': tensor(-0.0713, device='cuda:0'), 'backend.10.weight': tensor(-432.0006, device='cuda:0'), 'backend.8.bias': tensor(-1.9927, device='cuda:0'), 'backend.6.weight': tensor(-607.5580, device='cuda:0'), 'backend.2.bias': tensor(-0.2443, device='cuda:0'), 'backend.10.bias': tensor(-9.6425, device='cuda:0'), 'output_layer.bias': tensor(-102.2852, device='cuda:0'), 'backend.2.weight': tensor(-871.2816, device='cuda:0'), 'backend.6.bias': tensor(-0.6839, device='cuda:0'), 'backend.0.weight': tensor(-302.5306, device='cuda:0'), 'output_layer.weight': tensor(-20.8222, device='cuda:0'), 'backend.4.weight': tensor(-984.5845, device='cuda:0'), 'backend.4.bias': tensor(-0.5933, device='cuda:0')}
INFO:root:==> Training scene: 15
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.0185213089, MAE: 6.06261253357, MSE: 6.06261263084
INFO:root:(Meta-training) post train loss: 5.02552652359, MAE: 89.3602752686, MSE: 89.3602752293
INFO:root:(Meta-training) pre-training test MAE: 2.2882976532, MSE: 2.28829766213
INFO:root:(Meta-training) post-training test MAE: 88.706703186, MSE: 88.7067043381
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(73.9416, device='cuda:0'), 'backend.0.bias': tensor(-0.0452, device='cuda:0'), 'backend.10.weight': tensor(228.9542, device='cuda:0'), 'backend.8.bias': tensor(0.1953, device='cuda:0'), 'backend.6.weight': tensor(-42.0229, device='cuda:0'), 'backend.2.bias': tensor(-0.0187, device='cuda:0'), 'backend.10.bias': tensor(7.8502, device='cuda:0'), 'output_layer.bias': tensor(67.6426, device='cuda:0'), 'backend.2.weight': tensor(47.4639, device='cuda:0'), 'backend.6.bias': tensor(-0.2108, device='cuda:0'), 'backend.0.weight': tensor(-75.9561, device='cuda:0'), 'output_layer.weight': tensor(11.4994, device='cuda:0'), 'backend.4.weight': tensor(242.4803, device='cuda:0'), 'backend.4.bias': tensor(0.1128, device='cuda:0')}
INFO:root:==> Training scene: 16
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.7963008881, MAE: 16.1687660217, MSE: 16.1687657413
INFO:root:(Meta-training) post train loss: 22.4242420197, MAE: 229.407485962, MSE: 229.407482373
INFO:root:(Meta-training) pre-training test MAE: 6.00388336182, MSE: 6.00388337666
INFO:root:(Meta-training) post-training test MAE: 239.257141113, MSE: 239.257142984
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-988.6003, device='cuda:0'), 'backend.0.bias': tensor(-0.2824, device='cuda:0'), 'backend.10.weight': tensor(-1988.3594, device='cuda:0'), 'backend.8.bias': tensor(-5.0329, device='cuda:0'), 'backend.6.weight': tensor(-2082.1543, device='cuda:0'), 'backend.2.bias': tensor(-1.0028, device='cuda:0'), 'backend.10.bias': tensor(-44.8206, device='cuda:0'), 'output_layer.bias': tensor(-201.1472, device='cuda:0'), 'backend.2.weight': tensor(-3871.7910, device='cuda:0'), 'backend.6.bias': tensor(-2.2654, device='cuda:0'), 'backend.0.weight': tensor(-1286.4836, device='cuda:0'), 'output_layer.weight': tensor(-56.6222, device='cuda:0'), 'backend.4.weight': tensor(-4343.2549, device='cuda:0'), 'backend.4.bias': tensor(-2.4096, device='cuda:0')}
INFO:root:==> Training scene: 17
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 32.0257339478, MAE: 15.1991195679, MSE: 15.1991193617
INFO:root:(Meta-training) post train loss: 48.2651100159, MAE: 335.650817871, MSE: 335.650813719
INFO:root:(Meta-training) pre-training test MAE: 11.0977325439, MSE: 11.0977325598
INFO:root:(Meta-training) post-training test MAE: 336.292419434, MSE: 336.292422974
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-7079.0312, device='cuda:0'), 'backend.0.bias': tensor(-1.0678, device='cuda:0'), 'backend.10.weight': tensor(-9176.1621, device='cuda:0'), 'backend.8.bias': tensor(-32.7449, device='cuda:0'), 'backend.6.weight': tensor(-9999.3828, device='cuda:0'), 'backend.2.bias': tensor(-3.5476, device='cuda:0'), 'backend.10.bias': tensor(-201.9896, device='cuda:0'), 'output_layer.bias': tensor(-380.1562, device='cuda:0'), 'backend.2.weight': tensor(-13915.4082, device='cuda:0'), 'backend.6.bias': tensor(-10.0968, device='cuda:0'), 'backend.0.weight': tensor(-4359.9946, device='cuda:0'), 'output_layer.weight': tensor(-154.6839, device='cuda:0'), 'backend.4.weight': tensor(-14321.7217, device='cuda:0'), 'backend.4.bias': tensor(-7.5350, device='cuda:0')}
INFO:root:==> Training scene: 18
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.19173002243, MAE: 9.96483707428, MSE: 9.96483724213
INFO:root:(Meta-training) post train loss: 8.31142997742, MAE: 108.922950745, MSE: 108.92294976
INFO:root:(Meta-training) pre-training test MAE: 26.310459137, MSE: 26.31045865
INFO:root:(Meta-training) post-training test MAE: 94.4987640381, MSE: 94.4987650796
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-88.2477, device='cuda:0'), 'backend.0.bias': tensor(0.0020, device='cuda:0'), 'backend.10.weight': tensor(-150.8411, device='cuda:0'), 'backend.8.bias': tensor(-0.5698, device='cuda:0'), 'backend.6.weight': tensor(-90.5708, device='cuda:0'), 'backend.2.bias': tensor(-0.0589, device='cuda:0'), 'backend.10.bias': tensor(-4.4715, device='cuda:0'), 'output_layer.bias': tensor(-71.4431, device='cuda:0'), 'backend.2.weight': tensor(-212.6744, device='cuda:0'), 'backend.6.bias': tensor(-0.1036, device='cuda:0'), 'backend.0.weight': tensor(-35.0562, device='cuda:0'), 'output_layer.weight': tensor(-12.1312, device='cuda:0'), 'backend.4.weight': tensor(-304.2589, device='cuda:0'), 'backend.4.bias': tensor(-0.2161, device='cuda:0')}
INFO:root:==> Training scene: 19
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.85736942291, MAE: 15.1381454468, MSE: 15.1381455981
INFO:root:(Meta-training) post train loss: 11.7894163132, MAE: 200.715942383, MSE: 200.715945119
INFO:root:(Meta-training) pre-training test MAE: 19.7869281769, MSE: 19.786928058
INFO:root:(Meta-training) post-training test MAE: 196.792785645, MSE: 196.792790375
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-82.1092, device='cuda:0'), 'backend.0.bias': tensor(0.0720, device='cuda:0'), 'backend.10.weight': tensor(-106.0497, device='cuda:0'), 'backend.8.bias': tensor(-0.6434, device='cuda:0'), 'backend.6.weight': tensor(60.6098, device='cuda:0'), 'backend.2.bias': tensor(0.0389, device='cuda:0'), 'backend.10.bias': tensor(-4.0570, device='cuda:0'), 'output_layer.bias': tensor(-149.3103, device='cuda:0'), 'backend.2.weight': tensor(-19.7755, device='cuda:0'), 'backend.6.bias': tensor(0.1884, device='cuda:0'), 'backend.0.weight': tensor(94.8992, device='cuda:0'), 'output_layer.weight': tensor(-21.7000, device='cuda:0'), 'backend.4.weight': tensor(-218.3605, device='cuda:0'), 'backend.4.bias': tensor(-0.1340, device='cuda:0')}
INFO:root:==> Training scene: 20
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.6179828644, MAE: 19.8658561707, MSE: 19.8658564426
INFO:root:(Meta-training) post train loss: 23.2383213043, MAE: 305.630065918, MSE: 305.630061308
INFO:root:(Meta-training) pre-training test MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post-training test MAE: 309.446777344, MSE: 309.446771978
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(58.7686, device='cuda:0'), 'backend.0.bias': tensor(0.1086, device='cuda:0'), 'backend.10.weight': tensor(-648.2241, device='cuda:0'), 'backend.8.bias': tensor(0.4562, device='cuda:0'), 'backend.6.weight': tensor(345.6556, device='cuda:0'), 'backend.2.bias': tensor(-0.1202, device='cuda:0'), 'backend.10.bias': tensor(-15.2989, device='cuda:0'), 'output_layer.bias': tensor(-243.9008, device='cuda:0'), 'backend.2.weight': tensor(-578.7977, device='cuda:0'), 'backend.6.bias': tensor(0.6730, device='cuda:0'), 'backend.0.weight': tensor(372.4923, device='cuda:0'), 'output_layer.weight': tensor(-42.9096, device='cuda:0'), 'backend.4.weight': tensor(-832.2753, device='cuda:0'), 'backend.4.bias': tensor(-0.4173, device='cuda:0')}
INFO:root:==> Training scene: 21
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.92966938019, MAE: 7.99254989624, MSE: 7.99255000362
INFO:root:(Meta-training) post train loss: 7.9303984642, MAE: 103.157691956, MSE: 103.157693681
INFO:root:(Meta-training) pre-training test MAE: 17.2073936462, MSE: 17.2073934943
INFO:root:(Meta-training) post-training test MAE: 94.2486724854, MSE: 94.2486737307
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-110.2388, device='cuda:0'), 'backend.0.bias': tensor(-0.0146, device='cuda:0'), 'backend.10.weight': tensor(-230.1305, device='cuda:0'), 'backend.8.bias': tensor(-0.4253, device='cuda:0'), 'backend.6.weight': tensor(-117.1571, device='cuda:0'), 'backend.2.bias': tensor(-0.0757, device='cuda:0'), 'backend.10.bias': tensor(-5.3008, device='cuda:0'), 'output_layer.bias': tensor(-71.6464, device='cuda:0'), 'backend.2.weight': tensor(-347.9861, device='cuda:0'), 'backend.6.bias': tensor(-0.0327, device='cuda:0'), 'backend.0.weight': tensor(-114.7507, device='cuda:0'), 'output_layer.weight': tensor(-14.5011, device='cuda:0'), 'backend.4.weight': tensor(-442.1410, device='cuda:0'), 'backend.4.bias': tensor(-0.2187, device='cuda:0')}
INFO:root:==> Training scene: 22
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.6123580933, MAE: 10.1582298279, MSE: 10.1582299753
INFO:root:(Meta-training) post train loss: 13.2736635208, MAE: 153.450256348, MSE: 153.450254052
INFO:root:(Meta-training) pre-training test MAE: 16.6812591553, MSE: 16.6812590741
INFO:root:(Meta-training) post-training test MAE: 142.571716309, MSE: 142.571713041
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-348.8332, device='cuda:0'), 'backend.0.bias': tensor(-0.1027, device='cuda:0'), 'backend.10.weight': tensor(-844.5209, device='cuda:0'), 'backend.8.bias': tensor(-1.7194, device='cuda:0'), 'backend.6.weight': tensor(-814.8101, device='cuda:0'), 'backend.2.bias': tensor(-0.4311, device='cuda:0'), 'backend.10.bias': tensor(-20.1072, device='cuda:0'), 'output_layer.bias': tensor(-113.4044, device='cuda:0'), 'backend.2.weight': tensor(-1628.4744, device='cuda:0'), 'backend.6.bias': tensor(-0.7616, device='cuda:0'), 'backend.0.weight': tensor(-452.7469, device='cuda:0'), 'output_layer.weight': tensor(-25.8738, device='cuda:0'), 'backend.4.weight': tensor(-1727.8403, device='cuda:0'), 'backend.4.bias': tensor(-1.0229, device='cuda:0')}
INFO:root:==> Training scene: 23
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 21.1111278534, MAE: 0.63020324707, MSE: 0.630203236541
INFO:root:(Meta-training) post train loss: 22.0809345245, MAE: 13.3690032959, MSE: 13.3690035203
INFO:root:(Meta-training) pre-training test MAE: 6.70138835907, MSE: 6.70138847426
INFO:root:(Meta-training) post-training test MAE: 37.1159133911, MSE: 37.1159138976
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(16.0151, device='cuda:0'), 'backend.0.bias': tensor(0.0425, device='cuda:0'), 'backend.10.weight': tensor(-114.7230, device='cuda:0'), 'backend.8.bias': tensor(-0.0450, device='cuda:0'), 'backend.6.weight': tensor(201.0753, device='cuda:0'), 'backend.2.bias': tensor(0.0558, device='cuda:0'), 'backend.10.bias': tensor(-2.8131, device='cuda:0'), 'output_layer.bias': tensor(-25.3123, device='cuda:0'), 'backend.2.weight': tensor(294.5614, device='cuda:0'), 'backend.6.bias': tensor(0.1817, device='cuda:0'), 'backend.0.weight': tensor(233.2775, device='cuda:0'), 'output_layer.weight': tensor(-4.9482, device='cuda:0'), 'backend.4.weight': tensor(177.3442, device='cuda:0'), 'backend.4.bias': tensor(0.0573, device='cuda:0')}
INFO:root:==> Training scene: 24
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.3689892292, MAE: 3.61751317978, MSE: 3.61751322588
INFO:root:(Meta-training) post train loss: 1.41690564156, MAE: 57.1678237915, MSE: 57.1678244841
INFO:root:(Meta-training) pre-training test MAE: 3.67163085938, MSE: 3.67163085126
INFO:root:(Meta-training) post-training test MAE: 62.9182128906, MSE: 62.9182121171
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(67.4449, device='cuda:0'), 'backend.0.bias': tensor(-0.0376, device='cuda:0'), 'backend.10.weight': tensor(95.9710, device='cuda:0'), 'backend.8.bias': tensor(0.2977, device='cuda:0'), 'backend.6.weight': tensor(-43.1883, device='cuda:0'), 'backend.2.bias': tensor(-0.0293, device='cuda:0'), 'backend.10.bias': tensor(3.6065, device='cuda:0'), 'output_layer.bias': tensor(48.0856, device='cuda:0'), 'backend.2.weight': tensor(-23.3053, device='cuda:0'), 'backend.6.bias': tensor(-0.1360, device='cuda:0'), 'backend.0.weight': tensor(-73.2256, device='cuda:0'), 'output_layer.weight': tensor(7.2894, device='cuda:0'), 'backend.4.weight': tensor(94.5628, device='cuda:0'), 'backend.4.bias': tensor(0.0419, device='cuda:0')}
INFO:root:==> Training scene: 25
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.78185081482, MAE: 3.64704179764, MSE: 3.647041789
INFO:root:(Meta-training) post train loss: 1.53377175331, MAE: 41.5643844604, MSE: 41.5643840621
INFO:root:(Meta-training) pre-training test MAE: 7.03860282898, MSE: 7.03860292617
INFO:root:(Meta-training) post-training test MAE: 38.4184913635, MSE: 38.4184912347
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(6.1834, device='cuda:0'), 'backend.0.bias': tensor(0.0124, device='cuda:0'), 'backend.10.weight': tensor(-7.2555, device='cuda:0'), 'backend.8.bias': tensor(0.0298, device='cuda:0'), 'backend.6.weight': tensor(31.5153, device='cuda:0'), 'backend.2.bias': tensor(0.0100, device='cuda:0'), 'backend.10.bias': tensor(-0.1930, device='cuda:0'), 'output_layer.bias': tensor(-28.9806, device='cuda:0'), 'backend.2.weight': tensor(31.5567, device='cuda:0'), 'backend.6.bias': tensor(0.0482, device='cuda:0'), 'backend.0.weight': tensor(44.4503, device='cuda:0'), 'output_layer.weight': tensor(-4.4127, device='cuda:0'), 'backend.4.weight': tensor(9.8322, device='cuda:0'), 'backend.4.bias': tensor(0.0038, device='cuda:0')}
INFO:root:==> Training scene: 26
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.51275110245, MAE: 4.93081665039, MSE: 4.93081656946
INFO:root:(Meta-training) post train loss: 6.66961288452, MAE: 63.5387802124, MSE: 63.5387796048
INFO:root:(Meta-training) pre-training test MAE: 1.70257949829, MSE: 1.70257951593
INFO:root:(Meta-training) post-training test MAE: 74.05909729, MSE: 74.0590980231
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-64.9164, device='cuda:0'), 'backend.0.bias': tensor(0.0207, device='cuda:0'), 'backend.10.weight': tensor(-215.7396, device='cuda:0'), 'backend.8.bias': tensor(-0.2159, device='cuda:0'), 'backend.6.weight': tensor(-53.6763, device='cuda:0'), 'backend.2.bias': tensor(0.0031, device='cuda:0'), 'backend.10.bias': tensor(-5.1249, device='cuda:0'), 'output_layer.bias': tensor(-58.9641, device='cuda:0'), 'backend.2.weight': tensor(-154.8734, device='cuda:0'), 'backend.6.bias': tensor(0.1189, device='cuda:0'), 'backend.0.weight': tensor(-51.5997, device='cuda:0'), 'output_layer.weight': tensor(-9.6605, device='cuda:0'), 'backend.4.weight': tensor(-269.6788, device='cuda:0'), 'backend.4.bias': tensor(-0.1026, device='cuda:0')}
INFO:root:==> Training scene: 27
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.81052994728, MAE: 3.4300737381, MSE: 3.43007370984
INFO:root:(Meta-training) post train loss: 1.85474944115, MAE: 49.2230949402, MSE: 49.2230950463
INFO:root:(Meta-training) pre-training test MAE: 0.405708312988, MSE: 0.405708318655
INFO:root:(Meta-training) post-training test MAE: 53.5645370483, MSE: 53.5645374102
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(21.7239, device='cuda:0'), 'backend.0.bias': tensor(-0.0415, device='cuda:0'), 'backend.10.weight': tensor(88.3675, device='cuda:0'), 'backend.8.bias': tensor(0.0254, device='cuda:0'), 'backend.6.weight': tensor(-91.4464, device='cuda:0'), 'backend.2.bias': tensor(-0.0413, device='cuda:0'), 'backend.10.bias': tensor(3.2484, device='cuda:0'), 'output_layer.bias': tensor(40.5884, device='cuda:0'), 'backend.2.weight': tensor(-47.4420, device='cuda:0'), 'backend.6.bias': tensor(-0.2370, device='cuda:0'), 'backend.0.weight': tensor(-68.5267, device='cuda:0'), 'output_layer.weight': tensor(6.0570, device='cuda:0'), 'backend.4.weight': tensor(54.8532, device='cuda:0'), 'backend.4.bias': tensor(-0.0010, device='cuda:0')}
INFO:root:==> Training scene: 28
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.91805839539, MAE: 16.495388031, MSE: 16.4953884269
INFO:root:(Meta-training) post train loss: 16.5992279053, MAE: 248.975204468, MSE: 248.975204275
INFO:root:(Meta-training) pre-training test MAE: 5.10612487793, MSE: 5.10612491749
INFO:root:(Meta-training) post-training test MAE: 254.839996338, MSE: 254.839992691
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-218.2436, device='cuda:0'), 'backend.0.bias': tensor(0.0600, device='cuda:0'), 'backend.10.weight': tensor(-483.3945, device='cuda:0'), 'backend.8.bias': tensor(-0.9689, device='cuda:0'), 'backend.6.weight': tensor(58.4666, device='cuda:0'), 'backend.2.bias': tensor(-0.1581, device='cuda:0'), 'backend.10.bias': tensor(-8.8787, device='cuda:0'), 'output_layer.bias': tensor(-200.1620, device='cuda:0'), 'backend.2.weight': tensor(-680.3274, device='cuda:0'), 'backend.6.bias': tensor(0.2169, device='cuda:0'), 'backend.0.weight': tensor(194.6783, device='cuda:0'), 'output_layer.weight': tensor(-33.2362, device='cuda:0'), 'backend.4.weight': tensor(-900.4709, device='cuda:0'), 'backend.4.bias': tensor(-0.4924, device='cuda:0')}
INFO:root:==> Training scene: 29
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.79754734039, MAE: 17.5090179443, MSE: 17.5090178007
INFO:root:(Meta-training) post train loss: 19.8869838715, MAE: 259.828735352, MSE: 259.828729647
INFO:root:(Meta-training) pre-training test MAE: 19.3920478821, MSE: 19.3920476916
INFO:root:(Meta-training) post-training test MAE: 262.822509766, MSE: 262.822510214
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-562.1880, device='cuda:0'), 'backend.0.bias': tensor(-0.0445, device='cuda:0'), 'backend.10.weight': tensor(-752.2289, device='cuda:0'), 'backend.8.bias': tensor(-2.6582, device='cuda:0'), 'backend.6.weight': tensor(-1082.9235, device='cuda:0'), 'backend.2.bias': tensor(-0.3633, device='cuda:0'), 'backend.10.bias': tensor(-19.6488, device='cuda:0'), 'output_layer.bias': tensor(-208.3303, device='cuda:0'), 'backend.2.weight': tensor(-1791.1686, device='cuda:0'), 'backend.6.bias': tensor(-0.9017, device='cuda:0'), 'backend.0.weight': tensor(-419.6126, device='cuda:0'), 'output_layer.weight': tensor(-41.2734, device='cuda:0'), 'backend.4.weight': tensor(-1991.5341, device='cuda:0'), 'backend.4.bias': tensor(-0.9737, device='cuda:0')}
INFO:root:==> Training scene: 30
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.79670476913, MAE: 2.56892776489, MSE: 2.56892779772
INFO:root:(Meta-training) post train loss: 5.16473007202, MAE: 24.4140777588, MSE: 24.4140775
INFO:root:(Meta-training) pre-training test MAE: 1.84230804443, MSE: 1.84230806249
INFO:root:(Meta-training) post-training test MAE: 22.7580795288, MSE: 22.7580793518
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-46.0853, device='cuda:0'), 'backend.0.bias': tensor(-0.0036, device='cuda:0'), 'backend.10.weight': tensor(-73.4210, device='cuda:0'), 'backend.8.bias': tensor(-0.1900, device='cuda:0'), 'backend.6.weight': tensor(-62.4290, device='cuda:0'), 'backend.2.bias': tensor(-0.0266, device='cuda:0'), 'backend.10.bias': tensor(-1.6552, device='cuda:0'), 'output_layer.bias': tensor(-17.0427, device='cuda:0'), 'backend.2.weight': tensor(-127.3578, device='cuda:0'), 'backend.6.bias': tensor(-0.0366, device='cuda:0'), 'backend.0.weight': tensor(-25.0367, device='cuda:0'), 'output_layer.weight': tensor(-3.4376, device='cuda:0'), 'backend.4.weight': tensor(-128.4347, device='cuda:0'), 'backend.4.bias': tensor(-0.0640, device='cuda:0')}
INFO:root:==> Training scene: 31
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.92816901207, MAE: 6.54268741608, MSE: 6.54268743565
INFO:root:(Meta-training) post train loss: 3.94747591019, MAE: 79.0179595947, MSE: 79.0179592917
INFO:root:(Meta-training) pre-training test MAE: 2.77071666718, MSE: 2.77071666233
INFO:root:(Meta-training) post-training test MAE: 81.9200592041, MSE: 81.9200585699
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-42.4969, device='cuda:0'), 'backend.0.bias': tensor(0.0191, device='cuda:0'), 'backend.10.weight': tensor(-89.6895, device='cuda:0'), 'backend.8.bias': tensor(-0.1760, device='cuda:0'), 'backend.6.weight': tensor(25.6620, device='cuda:0'), 'backend.2.bias': tensor(-0.0125, device='cuda:0'), 'backend.10.bias': tensor(-2.3425, device='cuda:0'), 'output_layer.bias': tensor(-62.3058, device='cuda:0'), 'backend.2.weight': tensor(-101.7161, device='cuda:0'), 'backend.6.bias': tensor(0.0798, device='cuda:0'), 'backend.0.weight': tensor(28.3379, device='cuda:0'), 'output_layer.weight': tensor(-10.7214, device='cuda:0'), 'backend.4.weight': tensor(-192.2546, device='cuda:0'), 'backend.4.bias': tensor(-0.0999, device='cuda:0')}
INFO:root:==> Training scene: 32
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.5723743439, MAE: 3.49564743042, MSE: 3.49564744882
INFO:root:(Meta-training) post train loss: 8.17095661163, MAE: 36.8633918762, MSE: 36.8633919759
INFO:root:(Meta-training) pre-training test MAE: 3.27803039551, MSE: 3.27803041451
INFO:root:(Meta-training) post-training test MAE: 33.7333984375, MSE: 33.733397971
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-57.7771, device='cuda:0'), 'backend.0.bias': tensor(-0.0101, device='cuda:0'), 'backend.10.weight': tensor(-168.3690, device='cuda:0'), 'backend.8.bias': tensor(-0.3028, device='cuda:0'), 'backend.6.weight': tensor(-124.5657, device='cuda:0'), 'backend.2.bias': tensor(-0.0514, device='cuda:0'), 'backend.10.bias': tensor(-3.7853, device='cuda:0'), 'output_layer.bias': tensor(-26.0408, device='cuda:0'), 'backend.2.weight': tensor(-202.7009, device='cuda:0'), 'backend.6.bias': tensor(-0.1367, device='cuda:0'), 'backend.0.weight': tensor(-33.2378, device='cuda:0'), 'output_layer.weight': tensor(-5.5101, device='cuda:0'), 'backend.4.weight': tensor(-261.8320, device='cuda:0'), 'backend.4.bias': tensor(-0.1489, device='cuda:0')}
INFO:root:===> Updating meta network
INFO:root:===> Gradients updated: {'backend.8.weight': tensor([[[[ 7.7916e-01,  8.5607e-01,  7.9229e-01],
          [ 9.0868e-01,  7.7736e-01,  6.4876e-01],
          [ 9.0064e-01,  9.4987e-01,  7.5753e-01]],

         [[ 1.1307e-01,  1.0704e-01,  9.0649e-02],
          [ 1.2796e-01,  1.0473e-01,  1.2942e-01],
          [ 1.3047e-01,  1.6048e-01,  1.4018e-01]],

         [[ 7.5768e-01,  7.1184e-01,  8.0713e-01],
          [ 7.5325e-01,  7.6828e-01,  8.4883e-01],
          [ 6.4983e-01,  8.1942e-01,  6.6784e-01]],

         ...,

         [[ 4.8735e-03,  5.3943e-03,  5.6951e-03],
          [ 4.0223e-03,  5.7926e-03,  2.3920e-03],
          [ 5.1352e-03,  6.9413e-03,  1.8356e-03]],

         [[ 2.1338e-02,  1.4164e-02,  1.3132e-02],
          [ 1.4678e-02,  1.8111e-02,  1.2113e-02],
          [ 1.1622e-02,  1.0919e-02,  8.9136e-03]],

         [[ 8.8305e-01,  8.2144e-01,  7.5310e-01],
          [ 8.2313e-01,  8.4059e-01,  7.4162e-01],
          [ 8.5086e-01,  7.3575e-01,  7.3748e-01]]],


        [[[-4.9812e-01, -5.0378e-01, -5.1191e-01],
          [-4.0563e-01, -2.9149e-01, -3.7377e-01],
          [-2.8067e-01, -3.3813e-01, -3.9142e-01]],

         [[-3.6185e-02, -4.4534e-02, -3.7252e-02],
          [-3.7536e-02, -2.0504e-02, -3.5803e-02],
          [-3.6210e-02, -6.8325e-02, -4.4340e-02]],

         [[-3.7382e-01, -3.9211e-01, -4.3686e-01],
          [-4.6847e-01, -4.9453e-01, -5.1677e-01],
          [-5.1365e-01, -5.5016e-01, -3.8768e-01]],

         ...,

         [[-5.0242e-03, -1.1525e-03, -2.1685e-03],
          [-3.8029e-03, -3.3366e-03, -1.4324e-03],
          [-3.0780e-03, -4.2158e-03, -4.6185e-03]],

         [[-5.8557e-03, -1.7622e-02, -2.0925e-02],
          [-2.2585e-02, -2.9423e-02, -2.1775e-02],
          [-1.7520e-02, -1.5502e-02, -9.9941e-03]],

         [[-3.5619e-01, -4.2216e-01, -4.5200e-01],
          [-4.1187e-01, -5.1698e-01, -4.8196e-01],
          [-2.5478e-01, -2.9195e-01, -3.7740e-01]]],


        [[[-5.0192e-01, -1.6550e-01, -3.0481e-01],
          [-4.3925e-01, -2.2387e-01, -4.2957e-01],
          [-2.3618e-01, -4.3159e-01, -5.8229e-01]],

         [[-1.4857e-02, -4.3006e-02, -5.9084e-02],
          [-6.6484e-03, -6.0455e-02, -7.7892e-02],
          [-2.2638e-02, -5.3768e-02, -7.4316e-02]],

         [[ 8.3277e-02,  2.6159e-02, -2.1678e-01],
          [-1.3345e-01, -2.8881e-01, -1.2474e-01],
          [-3.7338e-01, -2.9140e-01, -1.1983e-01]],

         ...,

         [[-8.1383e-03, -4.9587e-03, -2.1028e-03],
          [-4.4010e-03, -1.6209e-03,  3.1505e-03],
          [-6.1085e-04,  1.2552e-03, -5.3144e-03]],

         [[ 1.1792e-02, -2.7062e-03, -3.8843e-03],
          [-1.7548e-03, -1.5361e-02, -9.7133e-03],
          [-3.5432e-03, -5.4995e-03, -2.7219e-03]],

         [[-7.8807e-03, -2.6094e-01, -2.7988e-01],
          [-1.4145e-01, -1.4226e-01, -3.1542e-01],
          [ 2.1230e-02, -2.0338e-01, -2.4090e-01]]],


        ...,


        [[[-2.9929e-01, -3.0268e-01, -2.6287e-01],
          [-2.9783e-01, -3.2071e-01, -2.3949e-01],
          [-3.1233e-01, -3.2161e-01, -2.6809e-01]],

         [[-3.4950e-02, -4.1251e-02, -3.6930e-02],
          [-3.8473e-02, -3.4362e-02, -3.8018e-02],
          [-3.6614e-02, -3.9380e-02, -3.5096e-02]],

         [[-1.7141e-01, -1.5779e-01, -1.4476e-01],
          [-1.7421e-01, -1.4054e-01, -1.5374e-01],
          [-1.1284e-01, -1.3553e-01, -1.4858e-01]],

         ...,

         [[-3.5639e-03, -2.7827e-03, -2.7394e-03],
          [-3.8445e-03, -3.7023e-03, -1.9841e-03],
          [-5.2670e-03, -4.6121e-03, -2.3858e-03]],

         [[-4.0673e-03, -2.9856e-03, -2.4181e-03],
          [-3.0785e-03, -2.0582e-03, -2.0237e-03],
          [-1.1365e-03, -2.0668e-03, -1.9191e-03]],

         [[-2.2178e-01, -2.4374e-01, -2.2302e-01],
          [-2.0329e-01, -2.1494e-01, -2.0253e-01],
          [-2.2835e-01, -2.2162e-01, -2.1170e-01]]],


        [[[-1.9047e-01, -5.0808e-01, -6.5154e-01],
          [-5.2507e-01, -5.0222e-01, -7.7457e-01],
          [-2.1515e-01,  8.5308e-02, -3.5444e-01]],

         [[ 3.1730e-02, -1.1143e-01,  1.3258e-02],
          [-6.2913e-02,  5.6852e-02, -3.5360e-02],
          [-4.4693e-02, -6.0705e-02, -1.5647e-02]],

         [[-2.1752e-01, -4.0752e-01,  1.6297e-01],
          [-2.4689e-01,  2.1465e-01, -1.9746e-01],
          [-3.6736e-01, -3.6167e-01, -3.7535e-01]],

         ...,

         [[-1.1183e-02, -9.8649e-03, -4.9530e-03],
          [-1.2929e-02, -9.7741e-03, -1.4051e-02],
          [-9.3559e-03, -6.5621e-03, -3.3314e-03]],

         [[ 8.0945e-03,  1.3654e-02,  8.0040e-03],
          [-5.6980e-03,  1.6568e-03, -4.8266e-03],
          [-4.1135e-03,  1.1966e-03,  4.5939e-03]],

         [[ 1.2224e-01,  3.1816e-01, -1.0589e-02],
          [-2.2472e-02, -3.1923e-01, -2.2589e-01],
          [ 2.7717e-03,  5.2609e-03,  1.2988e-02]]],


        [[[-4.9065e-01, -5.2073e-01, -5.2142e-01],
          [-6.1824e-01, -4.1892e-01, -5.3042e-01],
          [-7.6838e-01, -4.8344e-01, -6.1932e-01]],

         [[-1.0348e-01, -5.7851e-02, -8.9387e-02],
          [-8.2592e-02, -8.9406e-02, -8.5119e-02],
          [-9.8153e-02, -1.1333e-01, -1.1592e-01]],

         [[-5.3413e-01, -5.2772e-01, -4.8901e-01],
          [-3.7988e-01, -3.6942e-01, -5.1767e-01],
          [-4.2634e-01, -3.9946e-01, -4.8190e-01]],

         ...,

         [[-1.6936e-03, -4.2673e-03, -6.6556e-03],
          [-3.8203e-03, -4.7557e-03, -4.0911e-03],
          [-4.4072e-03, -1.1244e-03, -1.3581e-03]],

         [[-1.8637e-02, -5.6245e-03, -1.0102e-02],
          [-2.4484e-04, -1.3706e-03, -3.9374e-03],
          [-5.8170e-03, -9.9687e-03, -7.9207e-03]],

         [[-6.9425e-01, -5.7233e-01, -5.7277e-01],
          [-5.3208e-01, -6.1464e-01, -5.7705e-01],
          [-6.7009e-01, -4.8128e-01, -5.7393e-01]]]], device='cuda:0'), 'backend.0.bias': tensor([ 3.7435e-02,  8.6868e-03,  2.9687e-02,  9.5615e-02, -7.9368e-03,
        -2.2906e-01,  2.1799e-02,  1.2916e-01, -1.1742e-01,  5.3095e-02,
         6.5154e-02, -3.3857e-02, -1.8881e-01,  6.5476e-02,  1.1124e-01,
        -1.6869e-02, -9.0779e-02, -5.9171e-02, -1.5687e-02, -6.3599e-03,
        -1.0433e-01,  1.4868e-02,  2.4667e-01,  3.6993e-02, -5.4466e-02,
         1.1374e-02, -1.7108e-01, -2.9399e-02, -1.2781e-01, -2.2293e-02,
         5.0197e-02, -4.6588e-02, -4.9303e-02, -6.8111e-02, -1.1202e-01,
         1.1110e-01,  4.5685e-02,  1.5133e-01,  3.5386e-02, -2.8244e-02,
         4.8509e-02, -1.7623e-01,  1.0987e-01, -1.7990e-01,  3.6821e-02,
         6.6093e-03,  8.1258e-03,  1.3467e-01,  2.1311e-02, -2.2371e-02,
        -3.5822e-02,  1.0288e-01, -2.3761e-01,  1.0828e-01, -1.2286e-01,
         4.3771e-02,  9.0976e-02,  5.4290e-03,  6.3597e-03,  6.7666e-02,
        -8.3076e-03,  2.5766e-02,  1.2529e-01,  9.5695e-02, -3.2555e-02,
         1.1473e-03,  4.7835e-02, -1.0141e-01, -5.9007e-02,  1.1059e-01,
         1.9457e-03,  3.8479e-02,  1.3206e-02, -2.1735e-02, -5.8058e-03,
         5.6675e-02,  6.5929e-02,  2.8954e-02,  1.0560e-01,  8.2580e-03,
        -4.4967e-02,  1.1845e-03, -1.6334e-01,  3.3130e-02,  1.4980e-02,
        -5.1273e-02,  1.3311e-02, -1.1537e-01,  1.1990e-01, -2.9764e-03,
         2.5823e-02, -1.2387e-01,  3.3274e-02,  1.4201e-01, -1.8099e-02,
        -8.3500e-02, -1.2276e-01, -1.7765e-01, -1.7965e-01,  1.4993e-01,
        -2.8350e-04, -9.3304e-03,  1.3635e-01,  3.1082e-03,  3.3438e-02,
        -1.6648e-02, -3.7137e-02,  1.8647e-02, -1.6222e-02, -1.3726e-01,
        -2.6879e-02,  1.3328e-01, -2.0468e-02, -1.7346e-02,  1.0685e-01,
        -9.4513e-03, -3.3734e-02,  5.2324e-02, -6.5747e-02,  5.0566e-02,
         6.0394e-02, -2.3553e-02, -1.8967e-01,  6.2577e-03,  7.2337e-02,
        -1.7122e-02, -2.7200e-03, -9.6275e-02,  4.6924e-04, -2.2710e-01,
         6.5825e-03,  3.1450e-02, -7.9218e-03, -1.7999e-01,  1.5686e-01,
        -1.3608e-02, -3.6705e-02, -1.8343e-01,  1.3468e-01,  1.1924e-02,
        -1.4944e-02, -9.2971e-03,  3.1527e-02, -3.5560e-02,  8.4170e-03,
        -7.3547e-02,  6.9649e-02,  1.4172e-01, -5.6148e-02,  8.2017e-02,
         5.3280e-02,  9.1900e-02,  2.8378e-03, -1.3483e-02,  7.4776e-02,
         6.9646e-03, -2.7512e-02, -3.0704e-02, -2.0543e-01,  1.8875e-01,
         6.9804e-02,  3.3834e-02, -2.7313e-02, -2.0109e-01, -5.1881e-02,
         2.3692e-03,  1.0829e-01, -3.6844e-02, -8.6512e-02, -2.1700e-01,
        -7.0292e-02,  6.8957e-02,  3.1386e-02,  1.3123e-02, -3.2300e-02,
        -1.0123e-01,  8.2451e-02, -1.8405e-02,  2.7769e-02, -1.5899e-01,
         4.5790e-03,  1.1975e-02,  7.1425e-03,  4.3330e-03, -1.7068e-01,
        -3.9194e-02,  4.2246e-02,  8.9102e-02, -5.1278e-03, -5.4139e-02,
         1.3973e-03, -8.0118e-02, -5.2303e-02,  8.1219e-03,  1.2798e-01,
         8.6179e-02,  5.2950e-02,  7.4546e-02, -3.3945e-03,  1.7204e-01,
        -1.1362e-01,  1.4206e-01,  2.1858e-01,  9.2227e-02, -1.9899e-01,
         3.6389e-02, -1.1806e-01, -8.2607e-02,  9.6325e-02,  3.8894e-02,
        -4.3596e-03, -1.4082e-01,  8.5449e-02,  7.8836e-02,  4.1850e-02,
         1.1328e-02,  7.4670e-02,  6.7290e-02, -7.1616e-02, -1.5780e-01,
        -9.5889e-03, -2.2306e-02, -6.0844e-02,  9.7202e-02, -1.1720e-01,
         1.0030e-01, -1.0907e-02, -3.6494e-02, -2.5834e-04, -7.7159e-02,
        -1.7274e-01,  2.3191e-02, -1.9711e-02,  3.5280e-02, -1.4302e-01,
         1.2825e-02,  4.7918e-02, -1.6809e-01,  5.6044e-02,  7.4026e-02,
         2.2772e-02, -1.4494e-01, -4.2030e-02, -6.3803e-02,  1.2182e-02,
         4.3357e-02,  5.3708e-02,  4.2698e-02, -2.8498e-02,  1.4108e-01,
        -5.5316e-03,  9.1692e-02,  6.3695e-02, -3.4250e-02, -2.8302e-02,
        -5.3445e-02,  2.9543e-03, -5.0376e-02,  1.6558e-02,  1.2318e-01,
        -4.0761e-04, -9.3538e-02, -6.3956e-02, -1.3604e-02, -5.2657e-02,
         3.6483e-02, -9.6794e-02, -8.6376e-02,  4.8664e-04,  8.6021e-03,
        -1.0094e-01, -5.5459e-02, -6.2278e-03,  2.4522e-02,  1.6359e-01,
        -3.3313e-02,  4.5278e-02,  5.1332e-02, -1.2520e-01,  9.1645e-02,
        -5.9487e-02, -1.1458e-01, -6.1016e-02, -2.1344e-01,  2.6369e-02,
         1.8460e-02, -8.5247e-04,  3.9910e-01,  2.6680e-02, -1.6055e-01,
        -6.4645e-02, -5.6139e-02,  1.0158e-02, -1.4174e-02,  7.4238e-02,
         3.7757e-02, -7.6092e-02, -5.3070e-02,  4.9686e-02, -2.6026e-01,
        -1.8112e-01,  1.3090e-01,  2.7321e-02,  2.0812e-02,  3.8819e-02,
         4.0497e-02, -4.4817e-02, -3.4690e-02, -6.9138e-02,  1.2728e-01,
        -1.7978e-01,  3.2795e-02, -4.3860e-02,  9.0157e-02,  3.4749e-02,
        -5.8772e-02, -2.9963e-02, -2.5511e-03, -2.6109e-03, -3.0463e-02,
         4.8108e-02, -1.5034e-01,  4.0939e-02, -8.9531e-02, -2.2503e-02,
         2.5582e-02,  9.0480e-02,  6.8585e-02,  1.1664e-01, -1.2778e-02,
         1.4531e-02,  2.3291e-02, -8.2612e-02,  7.2054e-02,  6.5945e-03,
         5.9478e-02,  2.1409e-02, -1.0625e-01, -1.0625e-01, -8.5955e-02,
         8.7440e-02,  6.5846e-02,  1.9994e-02, -2.2161e-02, -7.1827e-02,
        -1.4752e-03, -2.1726e-02,  4.5513e-02,  4.6463e-02, -5.6593e-02,
         7.0406e-02, -7.1067e-02,  8.3108e-02,  7.8468e-02,  9.3380e-02,
         6.4197e-04,  4.0035e-02, -3.3858e-03,  4.2069e-02, -1.4598e-01,
         7.9621e-02,  1.4402e-01, -4.1291e-02,  4.3087e-02, -1.2321e-01,
        -1.4229e-01, -1.5476e-02, -1.5638e-01,  7.6902e-02, -1.8434e-02,
        -3.0861e-02, -7.7829e-02,  4.6241e-02,  1.0649e-01,  6.2955e-02,
         3.3869e-02,  5.2016e-02,  7.5418e-02, -1.0650e-01, -8.4455e-04,
        -1.1416e-01,  5.3096e-02,  1.0518e-01,  1.0734e-01, -8.4019e-02,
         1.3562e-01, -1.2334e-01, -4.9151e-02,  1.2403e-01, -8.0861e-02,
         1.4998e-01, -2.3119e-02,  1.0668e-01, -5.9597e-02, -1.0736e-02,
         4.4334e-02,  2.6921e-02, -5.7335e-02,  1.0289e-01,  2.2908e-01,
        -6.2295e-02,  4.3519e-02,  3.5141e-02, -3.7513e-02, -1.5320e-01,
        -1.7330e-01, -1.7242e-01,  1.1273e-01,  8.8121e-02,  1.7926e-02,
         1.5912e-01, -8.8509e-03,  3.6228e-03, -1.5002e-02, -9.1839e-02,
         2.3673e-02,  2.8329e-02,  2.2835e-02,  4.4367e-02, -6.7740e-02,
        -5.3699e-02, -3.3518e-03, -1.7343e-02, -9.4083e-03,  5.4577e-02,
        -5.9961e-02, -4.1872e-03, -5.1599e-02, -1.4495e-02, -7.0580e-02,
        -1.0849e-01,  1.7600e-01, -9.0257e-02,  1.1788e-01, -3.2402e-03,
         5.9322e-02, -6.7923e-02, -6.7786e-02,  3.3781e-02,  3.1117e-02,
        -1.1967e-01,  1.1624e-01, -6.5048e-02,  6.9480e-02,  3.6161e-02,
         1.8170e-02, -1.1414e-02, -2.2334e-02, -5.7602e-02,  4.2444e-02,
         1.4755e-02,  2.9847e-02,  9.0883e-02, -1.8335e-02, -1.7758e-01,
         6.6599e-02, -4.1333e-02, -5.6230e-02, -2.5875e-02, -1.4190e-01,
         2.3748e-03,  1.5121e-02,  8.3824e-03,  1.7195e-02,  4.8924e-02,
        -1.8419e-01,  1.6578e-04, -5.8999e-03, -2.3125e-01, -1.4528e-01,
         2.8597e-02,  4.2600e-02, -3.7203e-02,  1.2312e-02,  1.3099e-01,
        -3.3446e-02, -1.1550e-01, -3.2145e-02, -5.2976e-02,  3.4270e-02,
        -1.4025e-02, -7.2389e-03,  5.4485e-03, -2.1931e-02, -1.5543e-02,
         5.1916e-02,  6.7209e-03, -2.1290e-01,  8.3986e-02,  9.0955e-02,
        -1.9859e-02,  5.5644e-02,  7.0865e-02, -6.5067e-02, -1.8819e-02,
        -2.6506e-03, -1.0377e-02, -2.6327e-02,  1.3805e-01,  7.2933e-03,
         6.3786e-02, -1.9616e-02,  5.1557e-03, -6.8185e-02,  2.9798e-02,
         9.7752e-02,  1.3504e-01, -1.2660e-01,  6.2462e-04,  6.9422e-02,
         2.6582e-02,  5.3618e-02], device='cuda:0'), 'backend.10.weight': tensor([[[[-2.1959e-01, -3.3617e-01, -3.1556e-01],
          [-4.1270e-01, -3.4179e-01, -3.8507e-01],
          [-5.4396e-01, -5.1190e-01, -5.2420e-01]],

         [[-1.8068e-01, -1.1519e-01, -9.5161e-02],
          [-5.3011e-02, -3.9709e-02, -3.9325e-02],
          [-1.9610e-02, -1.2149e-02, -1.1782e-02]],

         [[-5.8630e-01, -4.5302e-01, -3.9153e-01],
          [-5.4708e-01, -2.9469e-01, -3.2340e-01],
          [-3.8501e-01, -3.9807e-01, -5.7451e-01]],

         ...,

         [[-9.7577e-02, -7.3513e-02, -7.1505e-02],
          [-5.3139e-02, -8.2465e-02, -6.4261e-02],
          [-5.2220e-02, -5.2127e-02, -5.7822e-02]],

         [[-7.6080e-01, -6.6571e-01, -8.5296e-01],
          [-6.0264e-01, -6.6787e-01, -6.7292e-01],
          [-1.1411e+00, -6.8185e-01, -6.6706e-01]],

         [[-1.8829e-01, -1.7583e-01, -2.0558e-01],
          [-1.6771e-01, -2.0710e-01, -3.6579e-01],
          [-1.1624e-01, -1.1664e-01, -1.4306e-01]]],


        [[[-2.3476e+00, -2.6140e+00, -2.5955e+00],
          [-3.0088e+00, -2.9354e+00, -2.9637e+00],
          [-3.3367e+00, -3.2346e+00, -3.2560e+00]],

         [[-3.5227e-01, -3.1430e-01, -2.8929e-01],
          [-3.8315e-01, -3.6267e-01, -3.4866e-01],
          [-1.9386e-01, -1.8508e-01, -1.6998e-01]],

         [[-2.3411e+00, -2.0769e+00, -1.9700e+00],
          [-2.4370e+00, -2.0338e+00, -2.0448e+00],
          [-1.9506e+00, -1.8898e+00, -2.0975e+00]],

         ...,

         [[-7.2566e-01, -7.4311e-01, -7.0555e-01],
          [-6.7706e-01, -7.6847e-01, -7.2329e-01],
          [-6.1618e-01, -6.6311e-01, -6.7481e-01]],

         [[-4.6668e+00, -4.4965e+00, -4.7603e+00],
          [-4.8601e+00, -4.4961e+00, -4.5276e+00],
          [-5.5612e+00, -4.5514e+00, -4.3601e+00]],

         [[-5.4382e-01, -5.9398e-01, -6.5607e-01],
          [-5.7638e-01, -6.7748e-01, -8.0152e-01],
          [-4.7273e-01, -5.1591e-01, -6.0473e-01]]],


        [[[ 5.0461e-01,  5.0912e-01,  5.1985e-01],
          [ 5.1670e-01,  5.3388e-01,  5.4456e-01],
          [ 5.2959e-01,  5.4138e-01,  5.4454e-01]],

         [[ 8.5475e-03,  1.2207e-02,  1.2803e-02],
          [ 2.4507e-02,  2.6864e-02,  2.6616e-02],
          [ 2.4521e-02,  2.6697e-02,  2.7364e-02]],

         [[ 1.6012e-01,  1.9595e-01,  1.9410e-01],
          [ 1.9142e-01,  2.1182e-01,  1.9630e-01],
          [ 1.9157e-01,  2.1010e-01,  2.0856e-01]],

         ...,

         [[ 1.0573e-01,  1.0355e-01,  1.0533e-01],
          [ 1.1294e-01,  1.1248e-01,  1.1330e-01],
          [ 1.1578e-01,  1.1593e-01,  1.1540e-01]],

         [[ 5.8945e-01,  6.1057e-01,  6.0976e-01],
          [ 5.8720e-01,  6.4044e-01,  6.4838e-01],
          [ 6.2204e-01,  6.5195e-01,  6.4490e-01]],

         [[ 3.2154e-02,  3.4026e-02,  2.0880e-02],
          [ 3.2994e-02,  4.0004e-02,  2.7592e-02],
          [ 3.6006e-02,  4.3411e-02,  3.7158e-02]]],


        ...,


        [[[ 1.8190e-01,  1.7046e-01,  1.6139e-01],
          [ 1.8184e-01,  1.8455e-01,  1.6810e-01],
          [ 1.5529e-01,  1.4892e-01,  1.3226e-01]],

         [[ 6.4871e-03,  1.1624e-02,  1.2358e-02],
          [ 5.4277e-02,  5.7847e-02,  5.7604e-02],
          [ 2.9974e-02,  3.2117e-02,  3.0282e-02]],

         [[ 7.2629e-02,  8.3997e-02,  7.7993e-02],
          [ 1.4803e-01,  1.6411e-01,  1.4653e-01],
          [ 1.2448e-01,  1.1466e-01,  9.5875e-02]],

         ...,

         [[ 2.1644e-02,  2.1378e-02,  2.0795e-02],
          [ 2.4206e-02,  2.2717e-02,  2.0400e-02],
          [ 1.9733e-02,  1.8385e-02,  1.5471e-02]],

         [[ 2.3900e-01,  2.4282e-01,  2.2168e-01],
          [ 2.5852e-01,  2.4316e-01,  2.4233e-01],
          [ 1.6480e-01,  1.7964e-01,  1.5443e-01]],

         [[ 1.5493e-02,  1.5617e-02,  2.1987e-02],
          [ 3.8231e-02,  3.1676e-02,  3.4201e-02],
          [ 3.2448e-02,  4.2885e-02,  4.5704e-02]]],


        [[[-1.1759e+00, -1.6960e+00, -1.5655e+00],
          [-2.0424e+00, -1.9111e+00, -1.9262e+00],
          [-2.5530e+00, -2.4314e+00, -2.4598e+00]],

         [[-5.2375e-01, -3.9010e-01, -3.5612e-01],
          [-1.7797e-01, -1.4278e-01, -1.5335e-01],
          [-5.4149e-02, -3.4321e-02, -4.5134e-02]],

         [[-2.4280e+00, -2.0517e+00, -1.8042e+00],
          [-2.3026e+00, -1.3931e+00, -1.5063e+00],
          [-1.5431e+00, -1.5189e+00, -2.2006e+00]],

         ...,

         [[-3.9746e-01, -3.2304e-01, -2.6708e-01],
          [-2.9420e-01, -3.7322e-01, -3.1304e-01],
          [-2.4681e-01, -2.3344e-01, -2.4592e-01]],

         [[-3.1743e+00, -3.0652e+00, -3.6059e+00],
          [-2.6640e+00, -2.7461e+00, -2.8847e+00],
          [-4.6844e+00, -3.0260e+00, -2.9310e+00]],

         [[-6.6746e-01, -6.5959e-01, -6.4882e-01],
          [-5.9409e-01, -7.4414e-01, -1.1450e+00],
          [-3.8093e-01, -3.7266e-01, -4.6022e-01]]],


        [[[-2.0956e-02, -2.0874e-02, -1.9518e-02],
          [-2.7313e-02, -2.4516e-02, -2.2938e-02],
          [-3.3471e-02, -3.3802e-02, -3.1649e-02]],

         [[-7.0705e-03, -8.3364e-03, -8.0707e-03],
          [-1.5045e-03, -2.1105e-03, -1.4246e-03],
          [-2.9152e-04, -2.5144e-04, -2.7530e-04]],

         [[-2.9277e-02, -2.6434e-02, -2.3441e-02],
          [-2.4026e-02, -2.1748e-02, -2.1338e-02],
          [-1.7061e-02, -2.5575e-02, -2.2425e-02]],

         ...,

         [[-3.2052e-03, -2.6869e-03, -1.9415e-03],
          [-1.3244e-03, -1.4512e-03, -1.2490e-03],
          [-1.7377e-03, -2.1666e-03, -1.5998e-03]],

         [[-3.7681e-02, -3.7452e-02, -3.5264e-02],
          [-3.3036e-02, -3.4708e-02, -2.4630e-02],
          [-4.1510e-02, -3.3301e-02, -3.4321e-02]],

         [[-1.6050e-02, -1.3616e-02, -1.1221e-02],
          [-9.7573e-03, -1.1921e-02, -1.2731e-02],
          [-5.4952e-03, -6.2394e-03, -4.1736e-03]]]], device='cuda:0'), 'backend.8.bias': tensor([ 4.9737e+00, -3.2972e+00, -1.2807e+00,  7.2608e-01, -1.5039e+00,
         1.6829e-01,  4.9959e-01, -2.1996e+00, -8.1899e-01, -1.3866e+00,
        -2.9949e-01, -4.3840e+00,  3.9718e-01, -3.1363e+00, -3.8491e+00,
        -2.6649e+00, -4.2858e-03, -5.9884e-01,  2.8110e+00, -2.2734e+00,
        -3.7313e-01,  7.8966e+00, -2.7427e-01, -4.5185e+00, -4.7506e-01,
         6.7307e+00,  2.4345e+00,  7.2646e+00, -3.2969e+00, -2.1476e+00,
        -1.9279e+00, -1.8337e+00, -1.6325e+00, -6.2015e-01, -9.9722e-01,
        -4.8325e+00,  2.9649e+00, -1.7396e+00, -1.6582e+00, -2.2803e+00,
         8.5869e-01,  3.3221e+00, -1.2001e+00,  9.5225e-02, -6.5972e-01,
         2.6132e+00, -3.0081e+00,  2.7432e+00, -2.9369e+00, -5.7038e-01,
        -4.1127e+00, -5.6516e+00, -3.8666e-01, -3.7298e+00,  7.6422e-01,
        -2.0456e+00, -2.0734e+00,  2.8771e-01, -2.2529e+00,  3.3025e+00,
         3.9578e+00, -2.1992e+00, -7.6606e-01, -1.0977e+00,  1.1326e-01,
        -3.4376e+00, -6.3099e-01, -7.0960e+00,  2.1510e+00,  1.8661e+00,
         2.0419e-01, -8.1414e-01,  4.6508e+00, -2.5497e+00, -4.1238e-01,
        -3.9497e+00,  2.1542e+00, -1.6452e+00, -1.1187e+00,  2.3748e+00,
        -5.8479e+00,  1.0999e+00,  9.7701e-02,  1.6046e+01, -1.4923e-01,
         3.7003e+00,  8.8302e-01, -4.3128e+00, -3.0774e+00,  5.0141e+00,
        -3.2504e+00,  2.5759e+00,  8.8290e-01, -1.0728e-01, -4.5347e-01,
        -2.7930e+00, -5.8308e+00, -1.6652e+00, -3.4447e-01, -4.6627e+00,
        -3.4878e+00, -2.0511e+00, -6.1618e-03,  5.6120e+00, -1.7160e-01,
        -5.2394e-01, -4.4822e-01,  1.6986e+00, -1.6533e+00, -2.3031e+00,
         2.8576e+00, -3.0470e+00, -5.3538e+00, -1.7170e+00,  8.7231e-01,
        -6.4554e+00, -1.1156e+00, -1.7039e+00,  9.7583e+00,  4.5828e-02,
         6.5802e+00, -2.2104e+00,  1.9929e+00, -5.2730e-02, -1.6266e+00,
        -1.3862e+00, -1.2762e+00, -3.9050e+00], device='cuda:0'), 'backend.6.weight': tensor([[[[ 1.7659e-02, -2.6832e-02,  1.1385e-02],
          [-9.5984e-03, -6.9888e-02, -7.4893e-02],
          [-5.2249e-02, -5.5227e-02, -7.9817e-02]],

         [[ 3.0972e-02,  5.7662e-02, -3.3488e-03],
          [-1.8451e-02, -1.3400e-02, -2.8494e-02],
          [-3.6402e-02, -7.0431e-02, -3.7302e-02]],

         [[-8.8065e-02, -1.2215e-01, -9.8337e-02],
          [-8.9382e-02, -4.0194e-02, -8.8762e-02],
          [-6.7900e-02, -6.4822e-02, -2.2596e-02]],

         ...,

         [[ 7.3210e-02, -2.9444e-02,  3.3526e-02],
          [ 1.1094e-02, -1.5081e-02, -2.0852e-02],
          [-5.2141e-02, -7.4994e-02, -8.7375e-02]],

         [[ 6.4951e-02,  5.9654e-02, -4.4959e-03],
          [-3.5679e-02,  6.1587e-02, -3.2398e-02],
          [-2.3371e-02, -6.1786e-02, -2.3975e-02]],

         [[-4.3150e-02, -2.9796e-02, -3.8644e-03],
          [-2.6559e-02, -1.7022e-02,  2.6667e-02],
          [ 4.5345e-02,  5.3840e-02,  8.0433e-02]]],


        [[[-1.8931e-02, -1.3767e-02, -2.2328e-02],
          [-1.7999e-02, -1.7059e-02, -1.7739e-02],
          [-1.7194e-03,  2.6561e-03, -3.2752e-03]],

         [[-4.8768e-03, -9.9158e-03, -1.8203e-02],
          [-9.3298e-03, -3.3823e-03, -1.0877e-02],
          [ 3.6881e-03, -3.0339e-03,  1.1093e-03]],

         [[-1.9347e-02, -1.9373e-02, -7.3064e-03],
          [ 1.2832e-02,  5.7196e-05, -5.6077e-03],
          [-1.6917e-02, -1.6682e-02, -2.7383e-02]],

         ...,

         [[-3.2147e-02, -5.1278e-02, -5.4454e-02],
          [-2.2433e-02, -6.8817e-03, -2.5639e-02],
          [-2.3895e-02, -3.1762e-02, -3.6114e-02]],

         [[-2.0606e-02, -3.0017e-02, -4.2409e-02],
          [-3.8847e-02, -2.1023e-02, -2.3159e-02],
          [-1.8859e-02, -2.0132e-02, -2.1347e-02]],

         [[ 3.0966e-02,  2.2453e-02,  2.1628e-02],
          [-1.4633e-02,  3.5283e-03,  8.0406e-04],
          [ 3.7985e-03, -2.6812e-03,  6.2538e-03]]],


        [[[ 1.6407e-01,  1.0967e-01,  1.5278e-01],
          [ 1.9659e-01,  1.5155e-01,  1.5199e-01],
          [ 1.1947e-01,  1.4954e-01,  1.1909e-01]],

         [[ 6.7720e-02,  1.4779e-01,  1.6977e-01],
          [ 1.0759e-01,  1.5109e-01,  1.3400e-01],
          [ 1.4679e-01,  1.1283e-01,  7.9238e-02]],

         [[ 4.3010e-01,  4.1349e-01,  3.3435e-01],
          [ 3.3523e-01,  3.7894e-01,  3.6660e-01],
          [ 3.4610e-01,  3.0348e-01,  3.2541e-01]],

         ...,

         [[ 1.7422e-01,  1.2319e-01,  1.7807e-01],
          [ 1.3168e-01,  1.4664e-01,  7.5703e-02],
          [ 8.7482e-02,  1.2710e-01,  1.0617e-01]],

         [[ 2.8918e-01,  2.1335e-01,  3.0835e-01],
          [ 2.9417e-01,  2.6610e-01,  3.8148e-01],
          [ 3.5822e-01,  1.8312e-01,  2.4299e-01]],

         [[ 6.2543e-01,  6.9266e-01,  6.6342e-01],
          [ 6.4601e-01,  6.5722e-01,  6.6194e-01],
          [ 7.1699e-01,  7.2908e-01,  6.5544e-01]]],


        ...,


        [[[-3.0835e-03, -5.4564e-03, -4.0023e-03],
          [-4.0692e-03, -5.8401e-03, -5.1373e-03],
          [-3.0648e-03, -2.8590e-03, -4.6756e-03]],

         [[-3.8954e-03, -4.8944e-03, -5.4124e-03],
          [-1.1260e-02, -8.1189e-03, -8.4610e-03],
          [-7.5158e-03, -1.0222e-02, -8.0836e-03]],

         [[-1.4891e-02, -1.4623e-02, -2.0755e-02],
          [-2.3570e-02, -1.8869e-02, -2.5201e-02],
          [-2.3054e-02, -2.1368e-02, -1.9387e-02]],

         ...,

         [[-7.3070e-03, -1.0875e-02, -7.4365e-03],
          [-6.0823e-03, -5.9057e-03, -9.7995e-03],
          [-5.6780e-03, -4.5554e-03, -5.1283e-03]],

         [[-6.7615e-03, -8.6668e-03, -1.2406e-02],
          [-1.7809e-02, -1.6932e-02, -1.4825e-02],
          [-1.3919e-02, -1.8692e-02, -1.7844e-02]],

         [[-1.1690e-02, -1.2990e-02, -9.4364e-03],
          [-3.4773e-02, -3.4121e-02, -3.0164e-02],
          [-3.9313e-02, -4.2817e-02, -4.0379e-02]]],


        [[[-1.1916e-02, -8.5964e-03, -1.0027e-02],
          [-9.8618e-03, -1.3041e-02, -9.8269e-03],
          [-1.3514e-02, -1.5581e-02, -1.3258e-02]],

         [[-4.4533e-03, -6.6127e-03, -5.6980e-03],
          [-4.0485e-03, -4.0086e-03, -5.0111e-03],
          [-4.2605e-03, -4.7118e-03, -7.7490e-03]],

         [[-2.5376e-02, -2.8867e-02, -3.2323e-02],
          [-1.9552e-02, -2.3627e-02, -2.7003e-02],
          [-1.9886e-02, -1.9896e-02, -2.6292e-02]],

         ...,

         [[-8.8458e-03, -8.3307e-03, -7.5917e-03],
          [-1.1403e-02, -1.1842e-02, -1.1067e-02],
          [-1.5496e-02, -1.6875e-02, -1.5704e-02]],

         [[-1.7235e-02, -2.2534e-02, -1.8845e-02],
          [-1.8398e-02, -1.8702e-02, -1.9821e-02],
          [-2.2294e-02, -1.8882e-02, -2.1458e-02]],

         [[-2.3913e-02, -3.0531e-02, -3.6398e-02],
          [-2.0194e-02, -2.3742e-02, -3.0163e-02],
          [-1.7456e-02, -1.2982e-02, -2.0532e-02]]],


        [[[-3.1058e-02,  1.6961e-02, -5.0719e-02],
          [-2.3574e-02,  2.1136e-02, -5.6105e-04],
          [-7.0931e-02, -4.7651e-02, -1.5537e-02]],

         [[ 4.7571e-02, -7.3376e-03,  3.1953e-02],
          [ 1.1158e-01,  5.7628e-02, -1.6446e-04],
          [ 1.5482e-03, -5.2595e-03, -5.0019e-03]],

         [[ 5.3417e-02,  2.0064e-01,  1.3220e-01],
          [-1.2124e-01, -1.6742e-01, -8.4608e-02],
          [-2.1417e-01, -2.5808e-01, -3.0919e-01]],

         ...,

         [[ 2.0335e-02,  1.1659e-01, -2.2834e-02],
          [ 1.9424e-01,  2.3623e-01,  1.9429e-01],
          [ 8.7265e-03,  4.6949e-02,  3.9763e-02]],

         [[-2.1546e-02,  4.8327e-02,  2.2329e-02],
          [ 1.4284e-01,  4.5180e-02, -4.6276e-02],
          [ 1.0123e-01,  2.4752e-01,  1.2154e-01]],

         [[-3.1303e-01, -2.8268e-01, -2.1845e-01],
          [-1.3687e-01, -1.7780e-01, -2.2222e-01],
          [-6.3107e-03,  3.5331e-02,  1.3386e-01]]]], device='cuda:0'), 'backend.2.bias': tensor([-9.5446e-02,  1.2118e-01, -7.2399e-03, -1.1388e-01, -1.4564e-01,
        -1.3559e-02,  3.4898e-03,  7.2918e-02,  7.2378e-02, -8.7557e-02,
        -2.1074e-01, -4.4167e-02, -1.4490e-04, -2.8609e-02, -7.1421e-02,
        -1.7638e-01,  7.6595e-02, -9.6583e-02, -3.9318e-02,  1.0934e-02,
        -9.4725e-03, -5.9582e-03, -1.8186e-01,  6.3051e-02, -9.9821e-02,
         6.5248e-02, -1.8788e-01, -2.5883e-02, -7.8020e-02, -1.6218e-01,
         2.9942e-02,  2.5172e-02, -1.4130e-01, -1.0984e-02,  1.9060e-01,
        -6.5443e-02,  2.4095e-01,  2.0355e-01,  5.0609e-02,  3.8263e-01,
         8.4443e-02,  5.4897e-04,  5.1957e-03, -5.1456e-03, -1.3074e-01,
        -9.0038e-02, -1.0444e-01, -7.5575e-02, -4.8597e-02, -1.1293e-01,
         1.2865e-02, -6.1113e-02,  3.9259e-02,  2.2154e-02, -1.2546e-01,
         5.5565e-02, -8.7545e-02, -4.8289e-01,  2.3832e-02,  2.4538e-04,
         1.9772e-02,  3.4710e-02, -1.0664e-01, -8.6274e-03, -3.3260e-02,
        -2.8559e-02,  1.6657e-02, -3.4660e-02, -2.5922e-01,  1.1552e-01,
         1.8184e-02, -1.5381e-01, -5.6099e-02, -5.9997e-02, -2.5072e-01,
        -1.1116e-01,  1.4272e-01, -2.8124e-02,  2.4978e-01,  1.3899e-01,
        -2.2722e-01,  1.6405e-02,  1.9514e-02, -1.4806e-02,  2.3784e-02,
        -2.5480e-02, -9.9125e-02,  5.5201e-03,  9.6783e-03,  9.0117e-04,
         1.0361e-01, -8.6632e-02,  8.5516e-02,  8.5150e-02,  4.3013e-01,
        -1.7292e-01,  2.5248e-01, -2.4304e-02, -1.4437e-01, -9.8616e-02,
        -2.0638e-02, -2.6137e-02, -3.1094e-01,  2.7443e-01,  1.5303e-02,
        -5.0389e-02, -7.4305e-02,  6.4033e-02,  1.5670e-02,  1.0776e-01,
         5.7240e-02, -6.2665e-02, -6.3629e-02, -1.7401e-01, -1.7384e-01,
        -2.9029e-02, -3.5188e-02, -1.0351e-01,  5.5873e-02, -3.7031e-02,
        -9.5961e-02, -8.1390e-02, -1.5220e-01,  1.9719e-01, -1.1948e-01,
        -1.6690e-01, -9.5103e-02,  1.5895e-01, -4.6991e-02,  8.7205e-03,
        -4.3616e-02,  1.1448e-01, -2.8034e-02,  1.1368e-01, -6.3128e-02,
         2.6903e-03,  2.8196e-02, -7.3619e-02, -1.2489e-01, -6.4825e-04,
         3.3710e-01, -2.7533e-02, -1.2788e-01, -1.1738e-01, -1.4322e-01,
        -6.4528e-02,  4.3953e-02,  4.8671e-02,  1.0128e-01, -5.3158e-02,
         1.9053e-02,  5.7650e-03, -2.0636e-01,  4.9392e-02,  1.0601e-01,
         2.6320e-01,  9.8345e-03, -4.2335e-02,  4.7639e-02,  4.1247e-02,
        -4.3124e-02,  4.6514e-02, -1.8738e-02, -1.7739e-01,  1.6252e-01,
         5.0900e-02,  5.9270e-02, -7.1251e-02, -1.3990e-01, -1.2608e-02,
         1.3636e-01, -1.9153e-02,  9.9168e-02,  9.7909e-03, -7.9707e-03,
         9.6061e-02, -1.1978e-02, -2.6988e-02,  5.5693e-02, -2.0706e-02,
        -7.5233e-03,  9.6906e-02, -2.6948e-02,  1.9295e-02, -1.2362e-01,
        -2.1191e-01,  2.5300e-02, -4.3556e-02,  5.8501e-02,  2.8256e-03,
         3.3446e-03, -2.0438e-01, -1.5361e-01, -7.2069e-02, -1.3362e-01,
        -6.9234e-02,  7.7558e-03, -2.2435e-01, -5.0222e-02, -6.3790e-02,
         1.4208e-01, -1.0317e-01, -4.3362e-02,  2.3451e-01, -1.0269e-02,
        -2.0785e-01, -1.0589e-01, -1.0867e-01,  7.9162e-02,  2.6165e-02,
        -3.6231e-02,  2.0472e-01, -4.7377e-02, -2.2673e-01,  8.8925e-02,
        -1.1418e-01, -3.3485e-02,  1.1014e-01,  5.6061e-02, -5.1889e-03,
         5.2244e-02,  4.1363e-01,  1.6679e-01, -2.8168e-02, -1.5872e-01,
         1.9176e-01, -2.0996e-03,  2.7883e-01,  1.0203e-01, -3.1559e-03,
        -1.3493e-01,  2.3950e-02,  6.8327e-03, -2.6369e-02, -1.9134e-03,
        -2.4798e-02, -9.5862e-02,  3.1373e-01,  1.0827e-01, -3.9025e-01,
         1.2347e-02,  1.6870e-01, -1.3238e-02,  9.2258e-02, -1.0211e-01,
        -2.7446e-01, -1.4298e-01,  4.5026e-03,  9.2050e-02, -9.7835e-03,
        -1.4301e-01, -5.0957e-02,  1.0820e-01,  7.1858e-02, -1.1097e-01,
        -2.3029e-02, -1.9033e-01, -3.1622e-01, -1.0966e-01,  2.0771e-02,
        -1.2985e-01,  7.2917e-02, -6.8903e-03,  2.2241e-02,  4.5559e-02,
         4.6640e-02,  1.0876e-01,  1.8415e-01,  2.5828e-02, -3.4739e-03,
        -3.4905e-02, -1.1110e-01, -7.5342e-05, -5.3388e-02, -2.1667e-01,
         2.3660e-01,  8.3035e-02,  1.6274e-01, -6.9704e-02, -2.4593e-03,
         3.3348e-01, -5.4760e-02,  2.8822e-02, -5.8684e-02,  3.8902e-02,
        -2.1664e-01,  2.5290e-03,  1.5021e-01, -1.5284e-02,  5.2178e-03,
         3.5757e-02,  9.5710e-02,  2.2947e-01, -8.4525e-03,  1.3986e-01,
         3.1626e-02,  2.7621e-01,  1.1267e-01,  7.1201e-03,  6.4724e-02,
         5.0482e-02, -1.1644e-01, -1.0756e-01,  7.3278e-02,  2.8580e-01,
        -1.7353e-01,  2.0274e-01, -5.0729e-01, -2.1406e-01, -1.3283e-01,
        -1.5440e-02, -9.0185e-02,  1.2485e-01,  7.0724e-03,  5.6439e-02,
        -2.2060e-02, -3.1489e-01,  7.7756e-02, -2.7833e-02, -3.0608e-02,
         6.8866e-02, -7.9890e-02, -2.6296e-02,  1.7894e-02,  1.6963e-01,
         8.7093e-02,  1.7397e-02, -2.1468e-01,  2.5737e-02,  1.3856e-02,
         8.3726e-03, -2.8858e-01,  1.6859e-03,  5.3386e-02,  9.3108e-02,
         6.1977e-03, -5.2589e-02,  1.9725e-01, -3.6482e-01, -1.1734e-01,
         2.1406e-01, -1.0737e-02, -3.6181e-01,  5.7253e-01, -5.5065e-02,
         3.8286e-02, -5.8543e-01,  2.0143e-01,  5.1467e-03,  1.5529e-01,
        -5.8387e-02,  9.6524e-02,  3.9117e-03,  1.5408e-01, -6.9667e-04,
         3.3011e-01,  8.9386e-02,  1.8885e-01, -1.6546e-02,  1.7824e-03,
        -6.3065e-02, -2.0381e-02, -7.3931e-02,  5.7186e-02, -2.2169e-01,
        -1.7594e-01,  7.2578e-02,  8.9697e-02,  1.4016e-01,  1.4531e-01,
        -4.8202e-02, -7.4429e-02, -1.2660e-01,  2.2441e-02, -1.7194e-01,
         5.1154e-02, -1.6276e-02, -8.0199e-02,  1.0578e-01, -3.3091e-02,
         1.2326e-01,  1.1280e-01,  1.3938e-02, -2.6170e-01, -4.8323e-02,
         1.8080e-01, -8.4015e-02,  4.3010e-02, -2.0496e-01, -4.6512e-02,
         2.2161e-01,  2.0268e-02, -2.6133e-01, -6.8645e-02,  1.0456e-02,
        -1.6854e-02, -4.4688e-01, -2.6737e-01, -5.5870e-02, -7.4339e-02,
        -4.4163e-01, -6.0503e-02, -4.2866e-02,  2.1001e-01, -3.5371e-02,
         1.9708e-01,  8.2744e-03, -6.6395e-03,  9.9981e-03, -1.5928e-01,
        -9.6029e-02, -8.3696e-02, -2.3542e-01, -3.2169e-02,  2.4578e-02,
        -4.3336e-01, -1.3247e-01,  3.6884e-02, -1.4186e-01,  5.9449e-03,
        -9.1733e-02, -1.2927e-01,  8.5177e-02, -1.1442e-03,  4.2597e-02,
         5.3823e-02, -1.4818e-01, -7.7130e-02, -2.5510e-02,  2.2265e-01,
        -6.6040e-02, -1.0947e-01, -4.1537e-01, -2.4050e-02,  2.0213e-01,
        -1.0381e-01,  3.8251e-02, -2.7224e-02, -4.7806e-02, -1.2562e-02,
        -1.4074e-02, -1.2187e-01,  1.6062e-01, -1.7874e-01, -1.2774e-03,
         1.0068e-01,  3.8112e-02, -1.4348e-01,  1.2197e-01,  1.3991e-03,
        -1.0440e-02,  6.5086e-02,  1.1839e-02, -7.3008e-02, -2.5583e-01,
         2.6136e-03,  1.5690e-01,  1.7598e-01,  6.9526e-02, -6.1461e-02,
        -9.7276e-02,  3.5660e-02,  4.7912e-02,  8.2739e-02,  1.4097e-02,
         4.9414e-02,  4.2054e-02,  1.4344e-01, -6.2792e-02,  4.0294e-04,
         1.5250e-01, -1.7522e-01, -5.9424e-02, -1.0787e-01, -2.6672e-03,
         4.5775e-02, -1.4194e-01,  3.6366e-01,  1.7673e-01,  3.2443e-01,
        -2.4558e-01,  1.8080e-02, -3.6560e-01,  2.6436e-03,  9.1669e-02,
         7.1584e-03, -9.6865e-02, -6.1576e-02, -3.0196e-01, -1.1254e-01,
        -5.5087e-02, -5.7569e-02,  1.0761e-01, -2.8560e-02, -4.1266e-01,
         4.0286e-02,  2.9999e-02, -6.0385e-02,  3.4557e-02, -2.6565e-01,
        -3.9134e-02, -5.7808e-02,  1.2102e-01,  5.8583e-02, -1.1470e-02,
         4.9080e-02, -1.0090e-01, -8.9321e-02, -9.7825e-02,  7.6055e-02,
        -2.5764e-01,  1.2564e-02], device='cuda:0'), 'backend.10.bias': tensor([-5.8029e+00, -5.3878e+01,  1.0696e+01,  2.2877e+01, -1.1115e+01,
         2.1028e-01, -3.5056e+00, -4.7255e+00, -1.8161e+00,  5.6121e-01,
        -4.5989e+00, -1.4484e+01, -2.5311e+01, -2.5464e-01, -1.0811e+01,
        -1.0108e+01,  2.4036e+00,  7.8466e-01, -1.4855e+01, -3.5416e+01,
         3.4983e+00, -1.6306e+01, -2.6800e-01, -1.6920e-02,  1.0981e+00,
         2.8397e+01,  8.6920e-01, -1.3417e+00, -4.1239e-01, -3.3987e+01,
        -1.3303e+01, -3.8404e+00, -7.8278e-01,  4.7887e-02, -2.9392e-01,
        -4.3888e+01,  3.2917e-01, -5.0268e+01, -4.0567e-01,  8.4493e-01,
         5.0143e+00, -5.7116e+01,  7.1828e-02,  1.0728e+00,  4.6707e-01,
        -3.4152e+01, -7.9422e+00,  4.3289e-01,  1.0090e+01, -6.5736e-01,
        -2.2008e+01,  1.0102e+00, -2.4218e-01, -1.8479e+01, -2.5554e-02,
         7.1699e+00,  1.1377e+00,  1.8071e+00,  4.5674e+00,  8.1736e+00,
         1.3086e+00,  2.5759e+00, -2.7065e+01, -2.6927e-01], device='cuda:0'), 'output_layer.bias': tensor([-2368.7083], device='cuda:0'), 'backend.2.weight': tensor([[[[-2.6743e-02, -3.9614e-02, -8.0126e-03],
          [-1.7407e-02, -5.3059e-02, -2.6568e-02],
          [-3.5896e-02, -4.0333e-02, -1.3289e-02]],

         [[-8.8569e-03, -7.8051e-03, -8.0936e-03],
          [-1.2177e-02, -8.5556e-03, -4.6051e-03],
          [-1.0736e-02, -2.2352e-03, -2.1008e-03]],

         [[-5.4204e-02, -2.8206e-02, -6.6153e-02],
          [-9.3614e-02, -8.7686e-02, -1.0216e-01],
          [-8.6319e-02, -6.5349e-02, -6.5383e-02]],

         ...,

         [[-6.8698e-02, -1.2343e-01, -6.7858e-02],
          [-5.2472e-02, -1.2091e-01, -9.2999e-02],
          [-1.5116e-01, -1.8670e-01, -1.7145e-01]],

         [[-3.5146e-02, -2.8826e-02, -2.5548e-02],
          [-4.4439e-02, -3.8223e-02, -3.8731e-02],
          [-2.2132e-02, -2.8051e-02, -2.6023e-02]],

         [[-2.7209e-02, -1.4604e-02, -2.6463e-02],
          [-1.3161e-02, -1.7328e-02, -2.3121e-02],
          [-3.2825e-02, -1.9331e-02, -3.9087e-02]]],


        [[[ 7.7710e-02,  3.7034e-02,  5.9199e-02],
          [ 6.9622e-02,  3.8968e-02,  3.4251e-02],
          [ 5.2236e-02,  4.0354e-02,  4.5525e-02]],

         [[ 8.7281e-03,  1.0781e-02,  1.1892e-02],
          [ 7.5952e-03,  7.7005e-03,  8.8369e-03],
          [ 1.1768e-02,  6.2628e-03,  1.1725e-02]],

         [[ 7.2418e-02,  8.9040e-02,  8.2412e-02],
          [ 8.0393e-02,  7.5214e-02,  6.3758e-02],
          [ 7.1168e-02,  1.0386e-01,  9.9016e-02]],

         ...,

         [[ 1.4388e-01,  1.0236e-01,  1.3851e-01],
          [ 1.2052e-01,  1.1337e-01,  1.7002e-01],
          [ 1.5284e-01,  1.2835e-01,  1.4204e-01]],

         [[ 6.6291e-02,  5.3915e-02,  5.6078e-02],
          [ 4.6756e-02,  4.0121e-02,  2.8891e-02],
          [ 3.1187e-02,  4.4871e-02,  4.0962e-02]],

         [[ 2.8075e-02,  3.7204e-02,  3.6337e-02],
          [ 1.5340e-02,  4.2387e-02,  3.7634e-02],
          [ 1.9188e-02,  3.1697e-02,  4.1697e-02]]],


        [[[-9.8588e-03, -5.9501e-04, -1.5907e-03],
          [-1.4481e-03,  7.3022e-03, -3.8607e-03],
          [-8.3030e-03, -4.2585e-05, -1.1306e-02]],

         [[-6.2725e-04, -3.3454e-04,  7.6462e-05],
          [ 4.1101e-03,  6.4964e-04, -1.6110e-03],
          [ 1.8856e-03,  1.6978e-03, -2.0552e-03]],

         [[-1.1350e-02, -4.0577e-03, -9.0500e-03],
          [-2.9628e-03, -7.6355e-03, -1.2748e-02],
          [-1.6145e-02, -2.2905e-02, -9.9339e-03]],

         ...,

         [[-1.6460e-02, -2.5881e-02, -7.2957e-03],
          [-3.2708e-02,  8.7723e-03, -2.2340e-02],
          [-3.5262e-03,  5.4256e-03, -9.8818e-03]],

         [[ 5.0230e-03, -4.1965e-03,  3.6696e-03],
          [ 7.6086e-03, -2.2837e-03,  6.1409e-03],
          [-9.2005e-03, -6.9910e-03, -5.7216e-03]],

         [[-4.1637e-03, -5.1098e-03,  1.0456e-03],
          [-7.3521e-03, -3.9145e-03,  8.5423e-03],
          [-5.4494e-03, -4.1669e-03, -1.1901e-02]]],


        ...,


        [[[-8.8280e-03,  4.3781e-03,  6.6472e-02],
          [-8.1385e-03,  2.4337e-02,  4.2203e-02],
          [-1.7271e-02,  3.1401e-02,  6.8164e-02]],

         [[-4.0401e-03,  5.5717e-03,  1.0041e-02],
          [ 2.1241e-03,  7.6132e-03,  1.1773e-03],
          [ 6.4574e-04,  9.1161e-03,  6.0503e-03]],

         [[-2.5098e-02,  1.5328e-02, -1.1117e-03],
          [ 1.4340e-03,  2.7359e-02, -5.7287e-03],
          [-1.0059e-02,  1.4989e-03, -1.9909e-03]],

         ...,

         [[ 2.0682e-01,  1.0093e-01,  1.4818e-01],
          [ 6.5352e-02,  1.9605e-01,  2.1523e-01],
          [ 1.7583e-01,  1.0937e-01,  1.1586e-01]],

         [[-1.5120e-02, -9.0386e-03,  1.3641e-03],
          [-2.0698e-02, -1.1765e-02, -4.5471e-03],
          [-1.5398e-02, -1.9579e-02, -1.5344e-02]],

         [[ 8.9629e-03,  4.3921e-02,  3.4448e-02],
          [ 3.6678e-02,  5.0561e-02,  1.8873e-02],
          [ 3.5365e-02,  5.3386e-02,  2.4554e-02]]],


        [[[-6.4075e-02, -7.1426e-02, -1.3557e-01],
          [-1.0439e-01, -1.0575e-01, -1.1695e-01],
          [-1.1025e-01, -1.1215e-01, -1.0477e-01]],

         [[-1.5107e-02, -2.1762e-02, -2.7486e-02],
          [-2.0304e-02, -1.2360e-02, -2.1811e-02],
          [-2.3954e-02, -1.2941e-02, -1.2730e-02]],

         [[-1.3945e-01, -1.1372e-01, -1.1284e-01],
          [-1.5474e-01, -1.2212e-01, -1.1001e-01],
          [-1.8234e-01, -1.5628e-01, -1.4351e-01]],

         ...,

         [[-4.4711e-01, -4.0075e-01, -4.7918e-01],
          [-3.8266e-01, -4.4923e-01, -4.4080e-01],
          [-4.6187e-01, -4.5301e-01, -4.6997e-01]],

         [[-2.4722e-02, -3.4570e-02, -2.5148e-02],
          [-3.2767e-02, -3.5459e-02, -3.5848e-02],
          [-2.8946e-02, -3.0528e-02, -3.7150e-02]],

         [[-6.7310e-02, -7.3473e-02, -8.8186e-02],
          [-9.3798e-02, -9.4707e-02, -9.7847e-02],
          [-9.2637e-02, -8.5534e-02, -7.9306e-02]]],


        [[[-3.6619e-02, -1.3962e-02, -1.0299e-02],
          [-8.8741e-02, -4.4201e-02, -1.8939e-02],
          [-7.0731e-02, -3.1265e-02,  2.7327e-02]],

         [[-9.3138e-03,  8.7430e-04, -9.4217e-03],
          [-5.9766e-03, -2.6659e-03, -8.2796e-03],
          [ 3.5146e-03,  4.4633e-03, -7.3963e-04]],

         [[ 7.3822e-02,  4.9793e-02,  1.5397e-02],
          [ 1.2660e-01,  1.1229e-01,  9.8424e-02],
          [ 4.8685e-02,  5.5703e-02,  1.0727e-01]],

         ...,

         [[-8.3063e-02, -1.9621e-02,  9.4109e-02],
          [-1.6088e-02,  5.3199e-02,  5.2264e-02],
          [ 5.3611e-02,  5.5289e-02,  4.2041e-02]],

         [[-3.1701e-02, -4.6874e-02, -5.6747e-02],
          [-1.4008e-02, -1.7434e-02,  8.5385e-03],
          [-3.1729e-03, -1.3171e-02, -6.2187e-03]],

         [[-1.9250e-03,  1.0769e-02,  9.0761e-03],
          [-1.2532e-02, -1.8818e-04, -3.9590e-03],
          [-4.5670e-03, -1.1593e-02,  7.9190e-03]]]], device='cuda:0'), 'backend.6.bias': tensor([-8.3898e-02, -1.6171e-02,  1.1420e+00, -5.7550e-02,  5.3863e-01,
        -8.3389e-01,  1.1408e-01,  3.1572e-02, -1.6201e-01, -2.2798e-01,
        -1.0613e+00,  1.7285e-02, -1.9214e+00, -1.1183e-01, -6.8129e-01,
         2.2950e-02, -1.4048e+00, -2.4419e-01,  9.4105e-01,  2.4619e-01,
         3.1539e-01, -3.4581e-01,  4.3028e-01,  2.8217e-03, -6.5242e-01,
         1.2156e+00, -1.1701e+00,  9.7105e-02,  1.8542e-01, -8.4766e-01,
        -8.2549e-02,  8.8012e-01,  1.3529e+00,  1.4453e-01, -1.8760e-01,
         2.3450e-01, -5.5986e-02,  4.2681e-01, -3.5006e-01,  5.4509e-01,
        -8.3722e-01,  6.0962e-02,  8.9388e-03, -6.9761e-03,  2.5819e-01,
        -8.1418e-01, -1.1959e+00,  7.2166e-01, -1.3468e-01, -9.9605e-01,
         2.0732e+00,  7.9013e-01,  1.2127e+00, -1.5427e-01,  2.0351e-01,
        -5.0857e-01, -2.5497e-01, -2.5927e-01, -5.9106e-03, -1.0637e-01,
        -7.7560e-01, -3.9563e-01, -5.0864e-01, -4.2363e-01, -1.1203e-01,
         1.5607e+00,  1.1222e+00, -2.8460e-01, -5.2958e-01,  4.4043e-01,
        -2.0771e+00,  1.1595e+00,  5.9845e-01,  6.1728e-02,  3.3175e-02,
        -4.1539e-01,  5.6374e-01, -1.5174e+00, -9.2519e-01, -7.4753e-01,
         2.4033e-03, -7.1819e-02, -3.7930e-01, -1.2810e+00,  1.7283e+00,
        -1.5666e-02, -1.0817e-01,  4.1597e-01, -5.1974e-01, -2.8064e-01,
         4.1466e-01, -2.6418e-01, -9.3957e-01,  1.0207e+00,  2.1993e-01,
         7.7892e-01, -1.2826e-02, -9.0745e-01,  5.0318e-01, -1.2849e+00,
        -1.3128e+00,  1.6148e-02,  1.0761e-01,  1.2552e-02, -7.9037e-01,
        -4.6911e-01, -1.1418e+00, -7.8196e-02,  2.5990e-03,  1.5220e-02,
         5.2965e-02, -5.6886e-01,  2.0896e-01, -2.1517e-02,  4.7351e-01,
        -1.4713e+00, -3.6948e-01,  2.1909e-02,  1.2982e+00,  1.3832e+00,
        -4.6231e-01, -2.0406e-02,  2.7873e-02, -1.9149e+00,  1.5788e+00,
        -8.4886e-01,  1.3790e+00,  3.3353e+00, -1.1661e+00, -4.0027e-01,
         1.9986e-01,  1.0772e+00,  9.1899e-01, -6.6467e-01,  4.5549e-01,
         1.8903e+00, -7.6614e-01,  2.3348e-02, -1.0125e+00, -2.0532e+00,
        -8.9911e-01,  1.2650e+00, -1.0543e+00,  8.2443e-01, -8.1073e-01,
        -4.6521e-02, -4.7347e-04, -3.0504e-01, -9.6906e-03, -5.8533e-01,
        -5.4517e-01, -6.6429e-01, -2.3236e-02,  2.0377e+00,  1.8188e+00,
        -7.2864e-01, -2.5927e-02,  4.8815e-02, -2.2779e-04, -5.5808e-01,
        -3.7023e-01, -1.1683e-01, -1.0920e+00, -8.0475e-03,  8.5100e-02,
         1.4044e+00, -1.8894e-02, -1.2077e-01, -2.6243e-01, -4.0546e-01,
         2.1495e-02,  9.4085e-02, -6.4143e-01, -1.6538e+00, -8.9192e-01,
        -4.8410e-01,  1.4858e-02,  5.2869e-01,  1.6901e-01, -2.0868e-01,
         1.7790e-02,  4.9152e-01,  4.9781e-01, -7.0547e-01,  1.7543e-01,
        -7.4892e-01, -5.0036e-01, -6.2179e-02,  3.3095e-02,  1.9181e+00,
         4.4187e-01,  2.4910e-01, -3.7713e-01,  1.5005e+00,  3.7024e-01,
        -1.5421e-01, -2.9336e-01, -2.8169e-01, -1.0113e-01, -1.9074e+00,
        -6.8935e-01, -6.8837e-01,  1.9108e-01, -6.8252e-01, -6.3966e-01,
         1.6775e-01,  8.4237e-01, -4.1269e-01,  1.0999e+00,  1.0861e+00,
         5.0100e-01,  2.0692e-02, -7.4594e-01, -4.0649e-01,  3.1674e-01,
         4.7350e-02, -1.3426e-02,  4.4528e-01, -1.0489e+00, -1.3415e+00,
         3.2184e-01,  8.5183e-01, -3.3267e-01, -2.9079e-01, -4.9677e-01,
        -1.3985e-01,  4.5514e-02,  6.9376e-01, -1.9076e+00,  1.0485e+00,
        -5.9901e-01,  1.0391e+00, -3.5584e-01, -1.5562e-01, -7.4192e-01,
         1.9428e+00, -1.1659e+00, -4.8476e-02, -9.1319e-02, -1.1107e+00,
        -7.8743e-01, -1.0142e+00,  1.9766e-02,  6.6773e-02, -1.4531e-01,
        -2.2162e-01,  3.6885e-01, -3.8783e-01,  3.8288e-01, -7.1044e-01,
        -2.3415e-01, -3.7066e-01,  5.3615e-01, -6.6176e-02, -6.9477e-02,
         9.0343e-04], device='cuda:0'), 'backend.0.weight': tensor([[[[-1.0966e-02, -1.7621e-02, -1.1160e-02],
          [-3.1529e-03, -5.4655e-03, -6.9490e-03],
          [ 4.9165e-03,  6.9457e-03,  1.3815e-03]],

         [[-9.4746e-02, -8.2677e-02, -6.6369e-02],
          [ 5.5759e-03, -1.3239e-02, -4.1413e-02],
          [ 9.9203e-02,  7.3024e-02, -2.9835e-03]],

         [[ 5.2261e-02,  5.8762e-02,  5.5730e-02],
          [ 6.1538e-02,  8.4551e-02,  3.7033e-02],
          [ 1.0334e-01,  9.4035e-02,  6.6054e-02]],

         ...,

         [[ 4.8530e-04,  4.6797e-04,  3.1704e-03],
          [ 1.0341e-04, -2.0709e-03, -2.6303e-03],
          [ 7.7471e-04, -3.3152e-03, -2.7110e-03]],

         [[ 2.9967e-03, -6.2089e-03,  2.7157e-02],
          [-5.4850e-03, -1.4381e-02,  8.3993e-04],
          [-1.3333e-03,  7.5211e-03, -1.0118e-02]],

         [[ 7.4052e-02,  9.7489e-02,  1.3282e-01],
          [ 8.5059e-02,  8.1244e-02,  8.0769e-02],
          [ 7.5956e-02,  9.3830e-02,  8.4562e-02]]],


        [[[ 3.3562e-03,  5.4455e-03,  3.4571e-03],
          [ 7.2755e-03,  8.1888e-03,  2.1705e-03],
          [ 5.1377e-04,  5.7353e-03,  8.8268e-03]],

         [[ 1.1156e-01,  1.0451e-01,  8.9038e-02],
          [ 9.8319e-02,  1.2030e-01,  8.4499e-02],
          [ 8.3782e-02,  8.3954e-02,  6.3716e-02]],

         [[ 1.8970e-02,  2.2375e-02,  1.1430e-02],
          [ 1.7493e-02,  1.1409e-02,  1.2681e-02],
          [ 4.9664e-04, -3.6680e-03, -6.4821e-03]],

         ...,

         [[ 4.9067e-03,  4.3095e-03,  2.7887e-04],
          [ 3.1390e-03,  2.7697e-03,  4.3246e-03],
          [-1.0944e-03,  2.5523e-03,  2.1073e-03]],

         [[ 1.2171e-02,  1.2222e-02,  7.5666e-03],
          [ 1.7480e-02,  2.1930e-02,  1.4792e-02],
          [ 1.9990e-02,  2.3993e-02,  2.8636e-02]],

         [[ 9.6589e-03, -4.9521e-03,  1.7026e-02],
          [ 5.5918e-03, -9.2160e-03,  2.0788e-02],
          [-8.4710e-03, -1.2850e-04,  8.8651e-03]]],


        [[[ 1.0118e-02,  1.2774e-02,  7.2152e-03],
          [ 1.0304e-02,  1.2340e-02,  4.9390e-03],
          [ 1.7318e-02,  2.1505e-02,  1.9969e-03]],

         [[ 2.1415e-01,  1.4136e-01,  1.1734e-01],
          [ 2.9939e-01,  2.4250e-01,  1.0767e-01],
          [ 2.0077e-01,  2.0030e-01,  4.3077e-02]],

         [[ 4.6797e-02,  5.1596e-02,  4.4768e-02],
          [ 3.4122e-02,  5.9094e-02,  4.1481e-02],
          [ 7.0840e-02,  7.7758e-02,  7.5428e-02]],

         ...,

         [[-6.3552e-04, -4.8502e-04, -4.7803e-03],
          [ 1.0010e-02,  5.5793e-03,  5.0049e-03],
          [ 8.7090e-03,  4.7928e-03,  6.8314e-03]],

         [[ 5.1332e-02,  2.5493e-02,  5.5949e-03],
          [ 4.4770e-02,  3.4323e-02,  7.7112e-03],
          [ 3.5577e-02,  4.2394e-02,  2.2569e-02]],

         [[ 5.0632e-02,  2.1957e-02,  8.0027e-02],
          [-2.6765e-02,  7.8514e-03,  5.7535e-02],
          [ 7.2560e-02,  8.3121e-02,  7.9692e-02]]],


        ...,


        [[[ 2.0045e-02,  6.3764e-03,  5.0264e-04],
          [ 2.1295e-02,  8.4856e-03, -6.0192e-03],
          [ 1.8921e-02,  1.4829e-02,  8.0011e-03]],

         [[ 2.1408e-01,  1.7944e-01,  2.6116e-02],
          [ 2.9567e-01,  2.6751e-01,  9.5504e-02],
          [ 2.9139e-01,  2.5382e-01,  8.2908e-02]],

         [[ 1.7746e-01,  1.9658e-01,  1.8618e-01],
          [ 7.2046e-02,  4.3122e-02,  1.0901e-01],
          [ 1.5234e-01,  1.9394e-01,  1.6790e-01]],

         ...,

         [[ 3.3875e-03, -5.1779e-04,  1.4072e-03],
          [ 3.2953e-03,  6.6859e-04, -3.8083e-03],
          [ 9.4259e-03,  8.2752e-03,  4.3090e-03]],

         [[ 6.2550e-02,  3.2151e-02, -9.1815e-03],
          [ 6.9782e-02,  1.9211e-02, -1.8662e-02],
          [ 7.1129e-02,  4.4201e-02,  1.8725e-03]],

         [[ 2.4897e-01,  2.3219e-01,  3.5020e-01],
          [ 3.2866e-02,  3.7562e-02,  1.8471e-01],
          [ 1.1136e-01,  1.3887e-01,  1.8595e-01]]],


        [[[ 4.4693e-02,  4.3510e-02,  3.1191e-02],
          [ 4.5764e-02,  4.5040e-02,  4.3091e-02],
          [ 5.0477e-02,  5.0647e-02,  4.6610e-02]],

         [[ 4.8130e-01,  4.9007e-01,  4.3751e-01],
          [ 4.3486e-01,  4.5149e-01,  4.4865e-01],
          [ 3.1297e-01,  3.5288e-01,  3.5299e-01]],

         [[ 4.8868e-02,  5.6782e-02,  6.4834e-02],
          [ 3.0821e-02,  3.8099e-02,  4.7187e-02],
          [ 6.1475e-02,  5.3461e-02,  4.0252e-02]],

         ...,

         [[ 1.1525e-02,  1.3003e-02,  1.0197e-02],
          [ 5.2147e-03,  1.3580e-03,  8.1857e-03],
          [ 6.3619e-03,  2.3229e-03,  4.0532e-03]],

         [[ 6.6030e-02,  5.6164e-02,  2.7974e-02],
          [ 5.5586e-02,  5.5609e-02,  3.7570e-02],
          [ 2.7228e-02,  1.7299e-02, -1.6127e-03]],

         [[ 4.3123e-02,  2.8382e-02,  3.5878e-02],
          [ 1.2766e-02,  2.6665e-02,  2.7421e-02],
          [ 5.3279e-02,  7.6969e-02,  1.1786e-02]]],


        [[[ 9.0564e-03,  9.5050e-03,  1.0587e-02],
          [ 1.3179e-02,  1.0427e-02,  1.5775e-02],
          [ 1.5143e-02,  1.6777e-02,  1.7506e-02]],

         [[ 1.0941e-01,  1.0080e-01,  1.7831e-01],
          [ 1.3935e-01,  1.4261e-01,  2.3914e-01],
          [ 1.8721e-01,  1.9382e-01,  2.4268e-01]],

         [[ 5.9846e-02,  6.3961e-02,  5.8496e-02],
          [ 9.4832e-02,  1.2498e-01,  1.2457e-01],
          [ 9.6724e-02,  1.0555e-01,  9.4718e-02]],

         ...,

         [[ 4.8404e-04,  2.5726e-03,  1.3075e-03],
          [ 3.2864e-03,  2.4150e-03,  3.0783e-03],
          [ 3.2824e-03,  2.0312e-03,  1.3948e-03]],

         [[ 1.3699e-02,  7.8326e-03,  2.1781e-02],
          [ 1.6425e-02,  1.2317e-02,  2.7760e-02],
          [ 1.4945e-02,  1.5759e-02,  1.8319e-02]],

         [[ 8.6315e-02,  1.5244e-01,  1.0609e-01],
          [ 1.5536e-01,  1.3365e-01,  1.5492e-01],
          [ 1.0859e-01,  8.9651e-02,  6.4165e-02]]]], device='cuda:0'), 'output_layer.weight': tensor([[[[-1.6358e+00]],

         [[-2.5940e+01]],

         [[-2.2885e+01]],

         [[-4.2481e+01]],

         [[-8.9195e+00]],

         [[-4.3450e-01]],

         [[-4.4648e+00]],

         [[-8.7988e+00]],

         [[-9.7922e+00]],

         [[-6.4884e+00]],

         [[-1.6077e+00]],

         [[-9.1065e+00]],

         [[-9.2577e+00]],

         [[-8.4950e+00]],

         [[-3.1119e+00]],

         [[-4.4014e+00]],

         [[-1.1049e+00]],

         [[-9.0646e+00]],

         [[-1.0693e+01]],

         [[-1.3028e+01]],

         [[-1.9226e+01]],

         [[-5.4063e+00]],

         [[-1.7429e+00]],

         [[-4.2664e-01]],

         [[-1.4460e+00]],

         [[-6.2714e+01]],

         [[-1.6194e+00]],

         [[-1.6695e+00]],

         [[-1.2076e+00]],

         [[-1.8779e+01]],

         [[-4.6703e+00]],

         [[-1.2733e+01]],

         [[-1.3408e+00]],

         [[ 4.5206e-02]],

         [[-4.8045e+00]],

         [[-1.6932e+01]],

         [[-6.8475e-01]],

         [[-2.4269e+01]],

         [[-4.6628e-01]],

         [[-6.4551e+00]],

         [[-3.5551e+00]],

         [[-2.7895e+01]],

         [[-2.5401e-01]],

         [[-4.7532e-01]],

         [[-1.3100e-01]],

         [[-1.7155e+01]],

         [[-2.8089e+00]],

         [[-2.4248e-01]],

         [[-1.8241e+01]],

         [[-4.4687e-01]],

         [[-5.6391e+00]],

         [[-2.1812e+00]],

         [[-1.2111e-01]],

         [[-4.8903e+00]],

         [[-4.5773e-03]],

         [[-2.9828e+01]],

         [[-1.2588e+00]],

         [[-2.7432e+00]],

         [[-3.9311e+00]],

         [[-2.8007e+01]],

         [[-3.5534e+00]],

         [[-2.1570e+00]],

         [[-1.0613e+01]],

         [[-2.9810e-01]]]], device='cuda:0'), 'backend.4.weight': tensor([[[[-1.2048e-02, -6.0804e-02, -5.4468e-02],
          [-8.9132e-03, -8.2508e-02, -6.2418e-02],
          [-1.1259e-02, -5.8706e-02, -4.9873e-04]],

         [[-3.8528e-02, -2.3249e-02,  2.3059e-02],
          [-6.0005e-02,  3.9833e-02,  4.6436e-02],
          [-1.0442e-01, -3.2644e-02, -1.4273e-04]],

         [[-1.3504e-02, -2.6101e-02, -1.9275e-02],
          [-1.5315e-02, -2.7579e-02, -7.4562e-03],
          [-3.1707e-02, -1.0187e-02, -1.2931e-02]],

         ...,

         [[ 4.6742e-03, -5.3108e-02, -8.8508e-02],
          [ 4.9763e-02, -9.0174e-02, -3.2583e-02],
          [-4.8892e-02,  1.3480e-02,  3.9005e-02]],

         [[-5.9419e-02, -1.0136e-01, -1.1546e-01],
          [-7.5363e-02, -4.8470e-02, -2.4965e-02],
          [-4.4913e-02, -1.8796e-02, -1.4597e-02]],

         [[-8.9495e-02, -3.5856e-02, -1.2368e-02],
          [-2.1256e-02, -2.2861e-02, -6.7883e-02],
          [-1.1565e-01, -7.2963e-02, -5.9713e-02]]],


        [[[-6.1420e-02, -7.4409e-02, -5.5025e-02],
          [-8.4431e-02, -5.0343e-02, -1.7650e-02],
          [-4.9211e-02, -2.8633e-02, -3.9524e-02]],

         [[-1.1809e-01, -1.2985e-01, -1.3566e-01],
          [-1.5668e-01, -1.1772e-01, -1.3297e-01],
          [-1.5706e-01, -1.5218e-01, -1.7541e-01]],

         [[-3.7270e-02, -3.6366e-02, -3.9533e-02],
          [-3.3907e-02, -2.5395e-02, -3.3013e-02],
          [-2.8684e-02, -1.9192e-02, -1.9853e-02]],

         ...,

         [[-1.4428e-01, -1.3440e-01, -4.8935e-02],
          [-8.5695e-02, -9.6212e-02, -5.4566e-02],
          [-1.2662e-01, -7.0622e-02, -9.3470e-02]],

         [[-1.1058e-01, -7.2285e-02, -7.5916e-02],
          [-9.1712e-02, -5.9537e-02, -8.4218e-02],
          [-6.3676e-02, -6.2908e-02, -1.0002e-01]],

         [[-2.0823e-01, -2.0906e-01, -2.1805e-01],
          [-1.7231e-01, -2.0222e-01, -2.3789e-01],
          [-2.6540e-01, -2.6746e-01, -2.9672e-01]]],


        [[[ 2.7761e-03,  2.2978e-03, -5.3760e-02],
          [-2.6933e-02,  4.3403e-02, -7.2004e-02],
          [ 1.5623e-03,  1.1806e-02, -7.6259e-02]],

         [[-1.1999e-02,  1.6803e-02,  6.0268e-02],
          [ 7.1736e-02, -4.5553e-03,  5.1572e-02],
          [ 8.9458e-02,  8.7167e-02,  1.6582e-01]],

         [[-3.9869e-03,  9.4170e-03,  2.3182e-02],
          [ 3.4039e-02, -1.6630e-03,  2.0192e-02],
          [ 1.2939e-02, -1.6654e-03,  1.1720e-02]],

         ...,

         [[-5.3542e-02,  1.3020e-01, -1.4320e-01],
          [-8.9343e-02,  8.4099e-02, -1.5566e-01],
          [ 6.7427e-02, -2.3242e-02, -2.0595e-01]],

         [[ 3.7305e-02, -9.8498e-03,  4.2858e-02],
          [ 6.3234e-02, -4.5390e-02, -6.4480e-02],
          [ 6.6954e-03, -1.4844e-01, -1.3272e-02]],

         [[ 6.5942e-02,  8.0734e-04,  5.4285e-02],
          [ 7.0936e-03, -9.7528e-02,  9.8900e-02],
          [ 1.2406e-01,  7.0387e-02,  1.2213e-01]]],


        ...,


        [[[-9.2294e-02, -3.1216e-02, -7.2767e-02],
          [-9.2675e-02, -9.8752e-02, -1.3588e-01],
          [-1.0899e-01, -1.5503e-01, -7.5264e-02]],

         [[-1.1606e-01, -1.4396e-01, -5.8016e-02],
          [-3.7691e-02, -6.5500e-02, -8.3960e-02],
          [-6.8774e-02, -8.4261e-02, -5.5588e-02]],

         [[-3.3650e-02, -2.5016e-02, -3.0571e-02],
          [-2.4607e-02, -3.8932e-02, -3.2553e-02],
          [-2.4548e-02, -2.5012e-02, -2.2982e-02]],

         ...,

         [[-1.4992e-01, -1.0191e-01, -1.7541e-01],
          [-2.3860e-01, -2.6577e-01, -1.5842e-01],
          [-1.5260e-01, -1.9920e-01, -1.9439e-01]],

         [[-2.2625e-01, -2.1584e-01, -1.7163e-01],
          [-1.7381e-01, -1.5323e-01, -1.7070e-01],
          [-1.4792e-01, -1.9673e-01, -1.1021e-01]],

         [[-1.4642e-01, -8.4646e-02, -1.1512e-01],
          [-2.1538e-01, -2.6934e-01, -2.4112e-01],
          [-1.4448e-01, -8.2779e-02, -1.1832e-01]]],


        [[[-1.5638e-01, -1.4835e-01, -1.9036e-01],
          [-1.7547e-01, -8.7568e-02, -1.1182e-01],
          [-8.2419e-02,  2.9826e-02,  2.9444e-02]],

         [[-3.5347e-03,  7.8474e-02,  3.5788e-02],
          [ 2.8736e-02, -8.3443e-02, -3.0319e-02],
          [-1.1561e-01, -1.6252e-01, -1.9590e-01]],

         [[-5.9862e-02, -6.6110e-02, -3.8213e-02],
          [-5.4671e-02, -3.5383e-02, -2.5554e-02],
          [ 9.8641e-03, -6.5177e-03, -9.3012e-03]],

         ...,

         [[-3.2161e-01, -2.8489e-01, -2.5918e-01],
          [-3.2716e-01, -4.6101e-02, -1.2386e-01],
          [-6.2740e-02, -1.9311e-01, -9.9467e-02]],

         [[-2.3160e-01, -2.2290e-01, -1.7311e-01],
          [-1.2877e-01, -1.0607e-01, -1.8933e-01],
          [-1.3856e-01, -1.7023e-01, -8.4564e-02]],

         [[-9.7378e-02, -1.5025e-01, -2.1385e-01],
          [-1.5372e-01, -1.2470e-01, -9.2415e-02],
          [-1.2050e-01, -2.0160e-01, -1.7870e-01]]],


        [[[ 1.4705e-01,  2.1214e-01,  1.3027e-01],
          [ 1.5705e-01,  2.3031e-01,  1.4932e-01],
          [ 2.4698e-01,  3.2268e-01,  2.5551e-01]],

         [[ 4.3678e-01,  4.6324e-01,  4.4894e-01],
          [ 4.4244e-01,  3.3969e-01,  4.9461e-01],
          [ 3.9638e-01,  3.2134e-01,  2.9273e-01]],

         [[ 8.4497e-02,  7.1967e-02,  5.6404e-02],
          [ 5.4276e-02,  3.5380e-02,  4.2073e-02],
          [ 1.0959e-01,  7.9675e-02,  6.8024e-02]],

         ...,

         [[ 2.5636e-01,  3.1694e-01,  2.9748e-01],
          [ 3.4446e-01,  5.3526e-01,  3.9326e-01],
          [ 4.9409e-01,  4.1774e-01,  5.3854e-01]],

         [[ 4.0206e-01,  3.6071e-01,  3.3972e-01],
          [ 4.3792e-01,  3.8572e-01,  3.7576e-01],
          [ 4.6685e-01,  4.0983e-01,  4.3655e-01]],

         [[ 5.7194e-01,  5.3079e-01,  4.8957e-01],
          [ 6.5429e-01,  7.0739e-01,  6.6911e-01],
          [ 6.2929e-01,  4.8608e-01,  4.9187e-01]]]], device='cuda:0'), 'backend.4.bias': tensor([-1.0812e-01, -3.6618e-01,  1.2842e-01, -4.9061e-02, -2.9246e-01,
        -3.0940e-02, -2.1621e-01,  5.0669e-02,  7.6933e-02, -3.7847e-01,
         3.8316e-01,  6.9392e-02,  3.7674e-01,  3.4865e-02, -2.4371e-01,
        -6.7996e-02, -1.8840e-01,  9.8036e-02,  2.0499e-02,  1.9589e-03,
        -1.7969e-01,  3.6394e-01, -1.7573e-01, -4.2377e-01, -7.6806e-02,
        -5.1208e-01,  1.6246e-01,  1.3582e-01, -1.0089e-01, -6.3033e-01,
         2.1797e-01, -3.1502e-02,  2.5708e-02, -1.9572e-01,  4.0423e-02,
        -1.9214e-01, -1.6726e-01,  7.8274e-03,  1.1864e-01, -1.0254e-02,
        -5.1442e-05,  1.6473e-01,  4.8805e-02, -2.7859e-01, -2.8268e-01,
        -2.4050e-02, -1.5400e-03,  5.9487e-02, -3.5743e-01,  8.5501e-02,
        -3.2695e-01, -2.1991e-01, -4.9916e-01, -4.0063e-02, -2.6688e-02,
         3.2183e-01, -3.9357e-01, -1.2466e-02, -5.5511e-01, -3.7874e-01,
        -1.0882e-01, -8.0759e-03, -4.0335e-02, -2.3989e-01,  4.2835e-01,
         1.1270e-01,  5.2403e-03, -4.4078e-02, -1.1977e-01, -5.8301e-01,
        -4.5837e-01, -3.2117e-02, -4.3981e-01, -1.7271e-01, -1.0471e-01,
        -9.2244e-02, -2.5923e-01, -4.8508e-02, -1.3433e-01,  4.9865e-01,
         4.0554e-03,  4.7469e-01,  1.2650e-01,  2.1825e-01,  4.0002e-01,
         5.3299e-02, -4.8195e-02, -7.7324e-03,  3.1430e-02, -2.9858e-01,
         9.6679e-02,  5.9243e-03, -3.5871e-01, -1.8527e-01, -2.1072e-01,
        -2.4775e-02, -4.3055e-03, -4.8010e-01, -2.3097e-02, -4.8733e-01,
        -2.3378e-01,  1.2450e-02,  1.9692e-01,  6.4458e-01, -3.0372e-02,
        -7.6163e-02, -1.2317e-01,  1.7330e-01, -1.0179e-01,  4.4206e-02,
        -1.2982e-01, -1.8453e-01,  2.1300e-01, -5.0384e-02, -2.0802e-01,
         2.6361e-02, -5.6353e-01,  5.0608e-01,  1.8496e-01,  8.3390e-03,
        -3.2190e-02,  5.1196e-01, -1.3434e-02, -5.2053e-02,  1.4464e-01,
         3.7586e-02,  3.4294e-01,  6.9648e-03,  2.2646e-01,  5.1073e-01,
         3.4326e-02, -7.9605e-03,  3.3118e-01, -1.0774e-01, -4.2533e-02,
         3.0071e-02,  6.7351e-03, -7.9038e-01,  4.9791e-02, -4.3896e-01,
        -3.2473e-01, -2.9875e-01, -3.1348e-03, -4.8676e-03,  4.0755e-02,
        -7.9778e-03,  2.4404e-01, -5.4111e-02, -1.1398e-01,  1.1369e-03,
         3.8762e-02,  9.8142e-03, -3.7269e-01, -1.4726e-02,  5.2647e-01,
        -4.4866e-01,  2.7330e-01, -1.6093e-01, -1.5819e-01, -2.0994e-01,
         1.9685e-02, -2.4199e-02, -8.2345e-02, -3.9722e-01, -1.6620e-02,
         4.0969e-02,  3.9075e-01, -5.4413e-01, -1.2593e-01, -1.4784e-01,
        -3.4171e-01, -6.1623e-03, -2.4370e-01, -2.2418e-01,  3.0449e-04,
        -2.3542e-01, -6.4281e-02,  1.3205e-02, -1.1394e-01, -4.1008e-02,
        -8.9198e-02, -5.1332e-02, -3.2771e-01,  5.0279e-03,  2.6738e-01,
         6.9736e-02,  6.9241e-01,  4.3881e-01, -2.2326e-01,  2.3691e-02,
        -3.1278e-01, -9.1258e-02, -2.7652e-01,  1.0137e-01,  1.0067e+00,
        -3.0610e-02, -3.0768e-02, -1.6984e-01,  6.5684e-01,  8.3777e-02,
         4.4153e-01,  2.3669e-01, -1.1397e-01,  3.7618e-03, -2.0287e-02,
        -2.9738e-01,  5.2122e-02, -1.5838e-01, -1.8251e-01,  8.7092e-02,
        -9.9948e-03, -4.6142e-02, -4.2110e-01, -9.8055e-02, -1.8508e-01,
        -6.2270e-03,  1.6868e-02, -1.9718e-01, -2.3422e-01, -3.4677e-01,
         1.6644e-01,  1.2507e-01,  3.9420e-01,  7.4626e-02, -3.1263e-02,
        -3.1774e-01,  8.2826e-02,  1.5916e-02,  9.8656e-02,  1.1931e-02,
        -3.0593e-01, -3.5126e-02,  2.9627e-01,  2.0168e-01,  1.0441e-01,
        -1.0012e-01,  5.5526e-01, -1.0112e-01,  1.1197e-01, -5.4777e-02,
         5.3432e-01,  1.8931e-01,  1.2888e-01, -9.9682e-01, -3.9092e-02,
        -1.6113e-01,  1.7402e-02,  1.7736e-02,  1.6027e-01, -3.4079e-01,
         3.0156e-01,  7.4539e-02, -2.5540e-01, -3.4748e-01,  2.8852e-01,
        -2.7768e-01, -7.4830e-02,  1.7404e-01, -6.9480e-02, -2.7810e-01,
        -1.2865e-01,  2.2681e-01, -2.0875e-01, -4.3857e-01, -1.3635e-01,
        -3.7374e-01, -6.9309e-04,  2.8005e-01,  1.3247e-04, -1.2098e-01,
        -3.6941e-01, -1.2099e-01,  3.8067e-02, -3.8953e-01, -3.6714e-01,
        -4.5712e-02, -3.1230e-02, -1.0634e-01,  1.4169e-01,  2.3006e-01,
        -1.8546e-01, -2.0267e-01, -6.4678e-02, -2.3959e-01,  3.1085e-01,
         3.6061e-01,  1.6338e-02, -2.4542e-01, -8.0525e-02, -2.3345e-01,
        -1.0109e-02, -2.5681e-02,  9.0185e-01,  2.6805e-01,  3.4583e-01,
        -1.8347e-02, -1.3388e-01, -2.4006e-01,  1.4226e-02, -4.0939e-02,
        -1.7018e-01, -1.4158e-01, -2.0830e-01, -1.6937e-01, -8.4634e-02,
        -3.2971e-01, -2.7501e-01,  1.6289e-02, -4.0977e-02, -1.1737e-01,
         1.2762e-02, -1.3446e-01, -1.0033e-01, -1.4785e-01,  1.6940e-01,
        -6.3066e-02, -1.2878e-01,  6.4633e-01, -5.3337e-01,  1.4794e-02,
        -9.2401e-02, -4.7321e-01,  4.4711e-02, -3.0021e-01,  1.7768e-01,
        -4.5306e-01, -1.2879e-01, -3.4056e-02, -1.7092e-01, -3.2663e-01,
        -4.7843e-02, -3.4171e-01,  3.4814e-01, -1.8827e-01, -1.6557e-01,
        -5.7711e-01, -1.1870e-01,  2.7405e-01,  2.3554e-01, -2.6390e-01,
         2.1475e-01, -3.4903e-01,  1.3482e-01, -1.8987e-01, -2.4476e-02,
        -3.1930e-01,  9.0383e-02,  6.3579e-01, -1.4432e-01, -2.4493e-01,
         2.1646e-01,  4.9190e-01,  1.1630e-02,  7.9976e-02,  2.4348e-01,
         1.2597e-02, -1.4821e-01, -7.4588e-02,  1.5592e-01,  1.3076e-01,
         3.0585e-01, -3.6773e-01,  1.8266e-02,  9.1949e-02,  3.1869e-01,
        -2.1595e-01,  3.7490e-01, -2.6143e-02, -3.6379e-01,  8.8123e-03,
         2.6170e-02,  2.5108e-02,  2.6420e-02, -9.9200e-02,  3.0538e-01,
        -1.0716e-02, -1.9231e-01, -2.7256e-01,  1.1161e+00,  1.0307e-02,
        -9.5664e-02, -7.0564e-04, -3.1032e-01, -7.5437e-02,  2.4541e-01,
        -9.1378e-02, -5.9279e-01,  3.0525e-03,  1.4869e-02, -4.7875e-01,
         6.7284e-02, -1.8228e-01,  4.9474e-02,  3.0890e-02,  1.5924e-01,
         1.5409e-02,  3.8060e-02, -2.0830e-01, -1.9951e-01, -4.6216e-02,
        -5.7944e-01, -4.0634e-02,  1.8278e-01, -1.0761e-01, -5.3346e-01,
        -9.1331e-03, -3.6206e-01, -5.0548e-02,  2.9751e-01, -2.0689e-02,
         6.0334e-01,  2.5752e-01,  9.7462e-03,  6.7222e-03, -1.2128e-01,
        -8.0106e-02, -4.5751e-02,  6.7042e-02, -1.8903e-02, -2.1782e-01,
        -3.6457e-01, -2.6533e-02,  6.3350e-01, -3.4595e-01, -3.7133e-02,
        -9.5447e-02, -3.0462e-01, -3.0521e-01, -6.8317e-02, -5.2826e-01,
         1.4542e-01, -1.9183e-01,  1.9126e-03, -5.3531e-03, -1.5697e-01,
         2.8604e-02,  2.2384e-01, -4.2827e-02,  3.7193e-01, -1.0113e-01,
        -7.1846e-02, -1.7502e-01,  3.7556e-02, -6.9689e-01, -3.6151e-01,
        -3.2398e-02, -2.4085e-02, -3.1030e-01,  9.2290e-02, -4.0313e-01,
        -1.1534e-01,  1.2941e-01,  3.9191e-01,  6.1184e-02, -1.3612e-01,
        -2.1756e-02,  9.9644e-02,  2.4690e-01, -1.5009e-03,  1.3126e-01,
        -4.5444e-01,  3.8564e-01, -4.4021e-01,  4.3855e-01, -1.5638e-01,
         2.3229e-01,  4.4088e-02, -5.8860e-02, -1.5686e-03, -1.2277e-01,
        -8.8027e-02, -1.9164e-01, -6.1247e-02,  4.0479e-01, -3.7728e-01,
        -1.1528e-01,  1.1578e-01,  7.6795e-01, -7.4226e-02,  2.1551e-01,
         1.1526e-01, -2.0986e-03,  1.7941e-01, -7.2154e-01,  3.0800e-01,
        -3.7801e-02, -1.0173e-01,  2.5063e-01, -9.7411e-03, -1.2966e-01,
        -9.2894e-03,  5.0409e-02, -1.3581e-01,  2.7527e-01, -1.5139e-01,
         3.9171e-02,  5.3645e-02,  7.7754e-02,  2.6264e-02,  3.7059e-02,
         4.2296e-01, -4.2493e-02, -4.7810e-01, -2.3012e-01,  1.5902e-01,
         1.3807e-01, -1.8588e-01, -2.5382e-01,  1.1852e-02, -2.7152e-01,
        -2.3341e-01,  9.9333e-01], device='cuda:0')}
INFO:root:==> Evaluating the model at: 1
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:10.2249025345, MAE: 101.208066845, MSE: 101.208066901
INFO:root:(Meta-testing) test MAE: 101.54141655, MSE: 101.541417764
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.92773497105, MAE: 3.70236587524, MSE: 3.70236584572
INFO:root:(Meta-training) post train loss: 2.13366699219, MAE: 37.6027603149, MSE: 37.6027595968
INFO:root:(Meta-training) pre-training test MAE: 6.88640213013, MSE: 6.88640217694
INFO:root:(Meta-training) post-training test MAE: 40.4782524109, MSE: 40.4782520818
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-43.9210, device='cuda:0'), 'backend.0.bias': tensor(0.0013, device='cuda:0'), 'backend.10.weight': tensor(-2.8210, device='cuda:0'), 'backend.8.bias': tensor(-0.1662, device='cuda:0'), 'backend.6.weight': tensor(-52.1226, device='cuda:0'), 'backend.2.bias': tensor(-0.0119, device='cuda:0'), 'backend.10.bias': tensor(0.1539, device='cuda:0'), 'output_layer.bias': tensor(-30.3483, device='cuda:0'), 'backend.2.weight': tensor(-93.3561, device='cuda:0'), 'backend.6.bias': tensor(-0.0265, device='cuda:0'), 'backend.0.weight': tensor(-21.5634, device='cuda:0'), 'output_layer.weight': tensor(-5.2881, device='cuda:0'), 'backend.4.weight': tensor(-96.7639, device='cuda:0'), 'backend.4.bias': tensor(-0.0339, device='cuda:0')}
INFO:root:==> Training scene: 2
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.4576377869, MAE: 14.0155792236, MSE: 14.0155792746
INFO:root:(Meta-training) post train loss: 28.2439689636, MAE: 246.063415527, MSE: 246.063412813
INFO:root:(Meta-training) pre-training test MAE: 8.87585067749, MSE: 8.875850583
INFO:root:(Meta-training) post-training test MAE: 235.911209106, MSE: 235.911207144
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-1020.3319, device='cuda:0'), 'backend.0.bias': tensor(-0.1067, device='cuda:0'), 'backend.10.weight': tensor(-2049.0684, device='cuda:0'), 'backend.8.bias': tensor(-5.0614, device='cuda:0'), 'backend.6.weight': tensor(-1269.1729, device='cuda:0'), 'backend.2.bias': tensor(-0.5702, device='cuda:0'), 'backend.10.bias': tensor(-49.0953, device='cuda:0'), 'output_layer.bias': tensor(-201.3323, device='cuda:0'), 'backend.2.weight': tensor(-2259.6045, device='cuda:0'), 'backend.6.bias': tensor(-1.0513, device='cuda:0'), 'backend.0.weight': tensor(-684.9938, device='cuda:0'), 'output_layer.weight': tensor(-48.6113, device='cuda:0'), 'backend.4.weight': tensor(-2496.2793, device='cuda:0'), 'backend.4.bias': tensor(-1.3280, device='cuda:0')}
INFO:root:==> Training scene: 3
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.215716362, MAE: 12.3267059326, MSE: 12.3267058703
INFO:root:(Meta-training) post train loss: 13.1575832367, MAE: 155.954437256, MSE: 155.95443921
INFO:root:(Meta-training) pre-training test MAE: 17.9829978943, MSE: 17.9829979178
INFO:root:(Meta-training) post-training test MAE: 149.803665161, MSE: 149.803667084
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-411.3112, device='cuda:0'), 'backend.0.bias': tensor(-0.1084, device='cuda:0'), 'backend.10.weight': tensor(-577.3651, device='cuda:0'), 'backend.8.bias': tensor(-1.6774, device='cuda:0'), 'backend.6.weight': tensor(-752.4684, device='cuda:0'), 'backend.2.bias': tensor(-0.3535, device='cuda:0'), 'backend.10.bias': tensor(-13.2628, device='cuda:0'), 'output_layer.bias': tensor(-113.9397, device='cuda:0'), 'backend.2.weight': tensor(-1495.3282, device='cuda:0'), 'backend.6.bias': tensor(-0.6486, device='cuda:0'), 'backend.0.weight': tensor(-532.8906, device='cuda:0'), 'output_layer.weight': tensor(-24.8956, device='cuda:0'), 'backend.4.weight': tensor(-1443.4912, device='cuda:0'), 'backend.4.bias': tensor(-0.7667, device='cuda:0')}
INFO:root:==> Training scene: 4
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.40858054161, MAE: 3.46781778336, MSE: 3.46781785142
INFO:root:(Meta-training) post train loss: 1.24631130695, MAE: 40.1663703918, MSE: 40.1663700161
INFO:root:(Meta-training) pre-training test MAE: 5.10420227051, MSE: 5.1042023119
INFO:root:(Meta-training) post-training test MAE: 38.2077407837, MSE: 38.207740327
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-22.4932, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(-6.9668, device='cuda:0'), 'backend.8.bias': tensor(-0.0887, device='cuda:0'), 'backend.6.weight': tensor(1.9747, device='cuda:0'), 'backend.2.bias': tensor(-0.0034, device='cuda:0'), 'backend.10.bias': tensor(-0.2023, device='cuda:0'), 'output_layer.bias': tensor(-28.7350, device='cuda:0'), 'backend.2.weight': tensor(-43.8065, device='cuda:0'), 'backend.6.bias': tensor(0.0327, device='cuda:0'), 'backend.0.weight': tensor(-7.9347, device='cuda:0'), 'output_layer.weight': tensor(-4.6944, device='cuda:0'), 'backend.4.weight': tensor(-74.9707, device='cuda:0'), 'backend.4.bias': tensor(-0.0318, device='cuda:0')}
INFO:root:==> Training scene: 5
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.464849472, MAE: 11.5086917877, MSE: 11.5086915716
INFO:root:(Meta-training) post train loss: 12.0098371506, MAE: 157.504074097, MSE: 157.504073608
INFO:root:(Meta-training) pre-training test MAE: 6.65334415436, MSE: 6.65334403491
INFO:root:(Meta-training) post-training test MAE: 148.859954834, MSE: 148.859958046
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-168.4950, device='cuda:0'), 'backend.0.bias': tensor(-0.0335, device='cuda:0'), 'backend.10.weight': tensor(-512.0421, device='cuda:0'), 'backend.8.bias': tensor(-0.8689, device='cuda:0'), 'backend.6.weight': tensor(-290.6690, device='cuda:0'), 'backend.2.bias': tensor(-0.2067, device='cuda:0'), 'backend.10.bias': tensor(-12.1426, device='cuda:0'), 'output_layer.bias': tensor(-113.5457, device='cuda:0'), 'backend.2.weight': tensor(-810.5503, device='cuda:0'), 'backend.6.bias': tensor(-0.2528, device='cuda:0'), 'backend.0.weight': tensor(-189.6144, device='cuda:0'), 'output_layer.weight': tensor(-21.5855, device='cuda:0'), 'backend.4.weight': tensor(-870.6675, device='cuda:0'), 'backend.4.bias': tensor(-0.5180, device='cuda:0')}
INFO:root:==> Training scene: 6
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.31700372696, MAE: 4.50811004639, MSE: 4.50810994402
INFO:root:(Meta-training) post train loss: 2.54581308365, MAE: 56.9175300598, MSE: 56.9175300291
INFO:root:(Meta-training) pre-training test MAE: 3.33308029175, MSE: 3.33308034573
INFO:root:(Meta-training) post-training test MAE: 57.6218566895, MSE: 57.6218562727
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-37.6233, device='cuda:0'), 'backend.0.bias': tensor(0.0053, device='cuda:0'), 'backend.10.weight': tensor(-48.7548, device='cuda:0'), 'backend.8.bias': tensor(-0.1999, device='cuda:0'), 'backend.6.weight': tensor(-3.2772, device='cuda:0'), 'backend.2.bias': tensor(-0.0192, device='cuda:0'), 'backend.10.bias': tensor(-1.0822, device='cuda:0'), 'output_layer.bias': tensor(-43.8109, device='cuda:0'), 'backend.2.weight': tensor(-99.4764, device='cuda:0'), 'backend.6.bias': tensor(0.0174, device='cuda:0'), 'backend.0.weight': tensor(-8.4735, device='cuda:0'), 'output_layer.weight': tensor(-7.1186, device='cuda:0'), 'backend.4.weight': tensor(-117.8860, device='cuda:0'), 'backend.4.bias': tensor(-0.0677, device='cuda:0')}
INFO:root:==> Training scene: 7
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.56835842133, MAE: 9.11410331726, MSE: 9.11410331697
INFO:root:(Meta-training) post train loss: 8.68908500671, MAE: 118.703765869, MSE: 118.703765671
INFO:root:(Meta-training) pre-training test MAE: 7.59414863586, MSE: 7.59414860186
INFO:root:(Meta-training) post-training test MAE: 119.183746338, MSE: 119.183747319
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-183.1738, device='cuda:0'), 'backend.0.bias': tensor(-0.0085, device='cuda:0'), 'backend.10.weight': tensor(-210.6387, device='cuda:0'), 'backend.8.bias': tensor(-0.9138, device='cuda:0'), 'backend.6.weight': tensor(-301.4147, device='cuda:0'), 'backend.2.bias': tensor(-0.1017, device='cuda:0'), 'backend.10.bias': tensor(-4.8148, device='cuda:0'), 'output_layer.bias': tensor(-90.9324, device='cuda:0'), 'backend.2.weight': tensor(-551.6276, device='cuda:0'), 'backend.6.bias': tensor(-0.2307, device='cuda:0'), 'backend.0.weight': tensor(-168.9219, device='cuda:0'), 'output_layer.weight': tensor(-16.1698, device='cuda:0'), 'backend.4.weight': tensor(-548.3022, device='cuda:0'), 'backend.4.bias': tensor(-0.2530, device='cuda:0')}
INFO:root:==> Training scene: 8
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.70169210434, MAE: 4.29832458496, MSE: 4.29832450693
INFO:root:(Meta-training) post train loss: 3.9628610611, MAE: 41.1326179504, MSE: 41.1326173725
INFO:root:(Meta-training) pre-training test MAE: 0.344522476196, MSE: 0.34452247522
INFO:root:(Meta-training) post-training test MAE: 45.7303619385, MSE: 45.730363144
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-90.5592, device='cuda:0'), 'backend.0.bias': tensor(-0.0234, device='cuda:0'), 'backend.10.weight': tensor(-131.2070, device='cuda:0'), 'backend.8.bias': tensor(-0.3804, device='cuda:0'), 'backend.6.weight': tensor(-169.8558, device='cuda:0'), 'backend.2.bias': tensor(-0.0816, device='cuda:0'), 'backend.10.bias': tensor(-2.6672, device='cuda:0'), 'output_layer.bias': tensor(-34.8099, device='cuda:0'), 'backend.2.weight': tensor(-365.8163, device='cuda:0'), 'backend.6.bias': tensor(-0.1439, device='cuda:0'), 'backend.0.weight': tensor(-121.5345, device='cuda:0'), 'output_layer.weight': tensor(-7.2147, device='cuda:0'), 'backend.4.weight': tensor(-379.3095, device='cuda:0'), 'backend.4.bias': tensor(-0.1953, device='cuda:0')}
INFO:root:==> Training scene: 9
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.31722784042, MAE: 1.57554912567, MSE: 1.57554914801
INFO:root:(Meta-training) post train loss: 4.04796648026, MAE: 13.7908353806, MSE: 13.7908351375
INFO:root:(Meta-training) pre-training test MAE: 5.13178634644, MSE: 5.13178641226
INFO:root:(Meta-training) post-training test MAE: 10.5187911987, MSE: 10.5187910962
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(12.7440, device='cuda:0'), 'backend.0.bias': tensor(0.0095, device='cuda:0'), 'backend.10.weight': tensor(-5.2699, device='cuda:0'), 'backend.8.bias': tensor(0.0464, device='cuda:0'), 'backend.6.weight': tensor(44.8930, device='cuda:0'), 'backend.2.bias': tensor(0.0177, device='cuda:0'), 'backend.10.bias': tensor(-0.2285, device='cuda:0'), 'output_layer.bias': tensor(-7.7328, device='cuda:0'), 'backend.2.weight': tensor(82.0600, device='cuda:0'), 'backend.6.bias': tensor(0.0495, device='cuda:0'), 'backend.0.weight': tensor(42.8591, device='cuda:0'), 'output_layer.weight': tensor(-1.1357, device='cuda:0'), 'backend.4.weight': tensor(46.6682, device='cuda:0'), 'backend.4.bias': tensor(0.0206, device='cuda:0')}
INFO:root:==> Training scene: 10
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 2.62649679184, MAE: 0.140889167786, MSE: 0.14088916471
INFO:root:(Meta-training) post train loss: 1.72036850452, MAE: 8.40645599365, MSE: 8.40645601949
INFO:root:(Meta-training) pre-training test MAE: 2.28190612793, MSE: 2.28190613808
INFO:root:(Meta-training) post-training test MAE: 9.2960319519, MSE: 9.29603175338
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(29.3622, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(14.4824, device='cuda:0'), 'backend.8.bias': tensor(0.1243, device='cuda:0'), 'backend.6.weight': tensor(20.2014, device='cuda:0'), 'backend.2.bias': tensor(0.0180, device='cuda:0'), 'backend.10.bias': tensor(0.5394, device='cuda:0'), 'output_layer.bias': tensor(7.4570, device='cuda:0'), 'backend.2.weight': tensor(65.5934, device='cuda:0'), 'backend.6.bias': tensor(0.0065, device='cuda:0'), 'backend.0.weight': tensor(18.4875, device='cuda:0'), 'output_layer.weight': tensor(1.3642, device='cuda:0'), 'backend.4.weight': tensor(55.7639, device='cuda:0'), 'backend.4.bias': tensor(0.0333, device='cuda:0')}
INFO:root:==> Training scene: 11
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 20.0581626892, MAE: 3.79273986816, MSE: 3.79273981411
INFO:root:(Meta-training) post train loss: 15.4374341965, MAE: 60.0539627075, MSE: 60.0539633632
INFO:root:(Meta-training) pre-training test MAE: 1.65007305145, MSE: 1.65007306717
INFO:root:(Meta-training) post-training test MAE: 46.8975715637, MSE: 46.8975726901
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-285.1148, device='cuda:0'), 'backend.0.bias': tensor(-0.0562, device='cuda:0'), 'backend.10.weight': tensor(-397.6510, device='cuda:0'), 'backend.8.bias': tensor(-1.2813, device='cuda:0'), 'backend.6.weight': tensor(-501.0728, device='cuda:0'), 'backend.2.bias': tensor(-0.1695, device='cuda:0'), 'backend.10.bias': tensor(-8.2408, device='cuda:0'), 'output_layer.bias': tensor(-36.3815, device='cuda:0'), 'backend.2.weight': tensor(-722.0421, device='cuda:0'), 'backend.6.bias': tensor(-0.4861, device='cuda:0'), 'backend.0.weight': tensor(-277.7679, device='cuda:0'), 'output_layer.weight': tensor(-10.3747, device='cuda:0'), 'backend.4.weight': tensor(-798.2820, device='cuda:0'), 'backend.4.bias': tensor(-0.4068, device='cuda:0')}
INFO:root:==> Training scene: 12
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.26931238174, MAE: 9.15769100189, MSE: 9.15769098289
INFO:root:(Meta-training) post train loss: 5.25304174423, MAE: 128.482192993, MSE: 128.48219265
INFO:root:(Meta-training) pre-training test MAE: 4.61597824097, MSE: 4.61597820524
INFO:root:(Meta-training) post-training test MAE: 141.958709717, MSE: 141.958710161
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(260.6506, device='cuda:0'), 'backend.0.bias': tensor(0.0241, device='cuda:0'), 'backend.10.weight': tensor(468.7807, device='cuda:0'), 'backend.8.bias': tensor(1.2948, device='cuda:0'), 'backend.6.weight': tensor(381.9536, device='cuda:0'), 'backend.2.bias': tensor(0.2002, device='cuda:0'), 'backend.10.bias': tensor(12.5315, device='cuda:0'), 'output_layer.bias': tensor(110.0442, device='cuda:0'), 'backend.2.weight': tensor(951.6744, device='cuda:0'), 'backend.6.bias': tensor(0.2520, device='cuda:0'), 'backend.0.weight': tensor(256.8109, device='cuda:0'), 'output_layer.weight': tensor(24.2919, device='cuda:0'), 'backend.4.weight': tensor(1108.7393, device='cuda:0'), 'backend.4.bias': tensor(0.5716, device='cuda:0')}
INFO:root:==> Training scene: 13
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.15585327148, MAE: 0.122278213501, MSE: 0.122278211939
INFO:root:(Meta-training) post train loss: 6.03297519684, MAE: 16.0758628845, MSE: 16.0758632778
INFO:root:(Meta-training) pre-training test MAE: 6.88552856445, MSE: 6.88552854815
INFO:root:(Meta-training) post-training test MAE: 24.3776416779, MSE: 24.3776415836
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(63.4827, device='cuda:0'), 'backend.0.bias': tensor(0.0233, device='cuda:0'), 'backend.10.weight': tensor(82.2645, device='cuda:0'), 'backend.8.bias': tensor(0.2575, device='cuda:0'), 'backend.6.weight': tensor(116.4498, device='cuda:0'), 'backend.2.bias': tensor(0.0472, device='cuda:0'), 'backend.10.bias': tensor(1.7026, device='cuda:0'), 'output_layer.bias': tensor(19.4743, device='cuda:0'), 'backend.2.weight': tensor(230.1284, device='cuda:0'), 'backend.6.bias': tensor(0.0803, device='cuda:0'), 'backend.0.weight': tensor(113.2029, device='cuda:0'), 'output_layer.weight': tensor(4.3419, device='cuda:0'), 'backend.4.weight': tensor(236.4450, device='cuda:0'), 'backend.4.bias': tensor(0.1142, device='cuda:0')}
INFO:root:==> Training scene: 14
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.2247161865, MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post train loss: 11.2101106644, MAE: 134.058197021, MSE: 134.058194861
INFO:root:(Meta-training) pre-training test MAE: 9.19702339172, MSE: 9.19702319208
INFO:root:(Meta-training) post-training test MAE: 132.98664856, MSE: 132.986650528
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-412.4737, device='cuda:0'), 'backend.0.bias': tensor(-0.0713, device='cuda:0'), 'backend.10.weight': tensor(-431.9995, device='cuda:0'), 'backend.8.bias': tensor(-1.9927, device='cuda:0'), 'backend.6.weight': tensor(-607.5552, device='cuda:0'), 'backend.2.bias': tensor(-0.2443, device='cuda:0'), 'backend.10.bias': tensor(-9.6425, device='cuda:0'), 'output_layer.bias': tensor(-102.2852, device='cuda:0'), 'backend.2.weight': tensor(-871.2729, device='cuda:0'), 'backend.6.bias': tensor(-0.6839, device='cuda:0'), 'backend.0.weight': tensor(-302.5355, device='cuda:0'), 'output_layer.weight': tensor(-20.8222, device='cuda:0'), 'backend.4.weight': tensor(-984.5646, device='cuda:0'), 'backend.4.bias': tensor(-0.5933, device='cuda:0')}
INFO:root:==> Training scene: 15
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.0185213089, MAE: 6.06261253357, MSE: 6.06261263084
INFO:root:(Meta-training) post train loss: 5.02552700043, MAE: 89.3602752686, MSE: 89.3602752293
INFO:root:(Meta-training) pre-training test MAE: 2.2882976532, MSE: 2.28829766213
INFO:root:(Meta-training) post-training test MAE: 88.706703186, MSE: 88.7067043381
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(73.9416, device='cuda:0'), 'backend.0.bias': tensor(-0.0452, device='cuda:0'), 'backend.10.weight': tensor(228.9542, device='cuda:0'), 'backend.8.bias': tensor(0.1953, device='cuda:0'), 'backend.6.weight': tensor(-42.0229, device='cuda:0'), 'backend.2.bias': tensor(-0.0187, device='cuda:0'), 'backend.10.bias': tensor(7.8502, device='cuda:0'), 'output_layer.bias': tensor(67.6426, device='cuda:0'), 'backend.2.weight': tensor(47.4639, device='cuda:0'), 'backend.6.bias': tensor(-0.2108, device='cuda:0'), 'backend.0.weight': tensor(-75.9561, device='cuda:0'), 'output_layer.weight': tensor(11.4994, device='cuda:0'), 'backend.4.weight': tensor(242.4803, device='cuda:0'), 'backend.4.bias': tensor(0.1128, device='cuda:0')}
INFO:root:==> Training scene: 16
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.7963008881, MAE: 16.1687660217, MSE: 16.1687657413
INFO:root:(Meta-training) post train loss: 22.424243927, MAE: 229.407485962, MSE: 229.407482373
INFO:root:(Meta-training) pre-training test MAE: 6.00388336182, MSE: 6.00388337666
INFO:root:(Meta-training) post-training test MAE: 239.257141113, MSE: 239.257142984
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-988.6003, device='cuda:0'), 'backend.0.bias': tensor(-0.2824, device='cuda:0'), 'backend.10.weight': tensor(-1988.3594, device='cuda:0'), 'backend.8.bias': tensor(-5.0329, device='cuda:0'), 'backend.6.weight': tensor(-2082.1543, device='cuda:0'), 'backend.2.bias': tensor(-1.0028, device='cuda:0'), 'backend.10.bias': tensor(-44.8206, device='cuda:0'), 'output_layer.bias': tensor(-201.1472, device='cuda:0'), 'backend.2.weight': tensor(-3871.7910, device='cuda:0'), 'backend.6.bias': tensor(-2.2654, device='cuda:0'), 'backend.0.weight': tensor(-1286.4836, device='cuda:0'), 'output_layer.weight': tensor(-56.6222, device='cuda:0'), 'backend.4.weight': tensor(-4343.2554, device='cuda:0'), 'backend.4.bias': tensor(-2.4096, device='cuda:0')}
INFO:root:==> Training scene: 17
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 32.0257339478, MAE: 15.1991195679, MSE: 15.1991193617
INFO:root:(Meta-training) post train loss: 48.2651100159, MAE: 335.650817871, MSE: 335.650813719
INFO:root:(Meta-training) pre-training test MAE: 11.0977325439, MSE: 11.0977325598
INFO:root:(Meta-training) post-training test MAE: 336.292419434, MSE: 336.292422974
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-7079.0317, device='cuda:0'), 'backend.0.bias': tensor(-1.0678, device='cuda:0'), 'backend.10.weight': tensor(-9176.1621, device='cuda:0'), 'backend.8.bias': tensor(-32.7449, device='cuda:0'), 'backend.6.weight': tensor(-9999.3828, device='cuda:0'), 'backend.2.bias': tensor(-3.5476, device='cuda:0'), 'backend.10.bias': tensor(-201.9896, device='cuda:0'), 'output_layer.bias': tensor(-380.1562, device='cuda:0'), 'backend.2.weight': tensor(-13915.4082, device='cuda:0'), 'backend.6.bias': tensor(-10.0968, device='cuda:0'), 'backend.0.weight': tensor(-4359.9951, device='cuda:0'), 'output_layer.weight': tensor(-154.6839, device='cuda:0'), 'backend.4.weight': tensor(-14321.7227, device='cuda:0'), 'backend.4.bias': tensor(-7.5350, device='cuda:0')}
INFO:root:==> Training scene: 18
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.19173002243, MAE: 9.96483707428, MSE: 9.96483724213
INFO:root:(Meta-training) post train loss: 8.31143093109, MAE: 108.922950745, MSE: 108.92294976
INFO:root:(Meta-training) pre-training test MAE: 26.310459137, MSE: 26.31045865
INFO:root:(Meta-training) post-training test MAE: 94.4987792969, MSE: 94.4987805808
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-88.2477, device='cuda:0'), 'backend.0.bias': tensor(0.0020, device='cuda:0'), 'backend.10.weight': tensor(-150.8411, device='cuda:0'), 'backend.8.bias': tensor(-0.5698, device='cuda:0'), 'backend.6.weight': tensor(-90.5708, device='cuda:0'), 'backend.2.bias': tensor(-0.0589, device='cuda:0'), 'backend.10.bias': tensor(-4.4715, device='cuda:0'), 'output_layer.bias': tensor(-71.4431, device='cuda:0'), 'backend.2.weight': tensor(-212.6744, device='cuda:0'), 'backend.6.bias': tensor(-0.1036, device='cuda:0'), 'backend.0.weight': tensor(-35.0562, device='cuda:0'), 'output_layer.weight': tensor(-12.1312, device='cuda:0'), 'backend.4.weight': tensor(-304.2588, device='cuda:0'), 'backend.4.bias': tensor(-0.2161, device='cuda:0')}
INFO:root:==> Training scene: 19
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.85736942291, MAE: 15.1381454468, MSE: 15.1381455981
INFO:root:(Meta-training) post train loss: 11.7894163132, MAE: 200.715942383, MSE: 200.715945119
INFO:root:(Meta-training) pre-training test MAE: 19.7869281769, MSE: 19.786928058
INFO:root:(Meta-training) post-training test MAE: 196.792785645, MSE: 196.792790375
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-82.1093, device='cuda:0'), 'backend.0.bias': tensor(0.0720, device='cuda:0'), 'backend.10.weight': tensor(-106.0497, device='cuda:0'), 'backend.8.bias': tensor(-0.6434, device='cuda:0'), 'backend.6.weight': tensor(60.6098, device='cuda:0'), 'backend.2.bias': tensor(0.0389, device='cuda:0'), 'backend.10.bias': tensor(-4.0570, device='cuda:0'), 'output_layer.bias': tensor(-149.3103, device='cuda:0'), 'backend.2.weight': tensor(-19.7755, device='cuda:0'), 'backend.6.bias': tensor(0.1884, device='cuda:0'), 'backend.0.weight': tensor(94.8992, device='cuda:0'), 'output_layer.weight': tensor(-21.7000, device='cuda:0'), 'backend.4.weight': tensor(-218.3605, device='cuda:0'), 'backend.4.bias': tensor(-0.1340, device='cuda:0')}
INFO:root:==> Training scene: 20
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.6179828644, MAE: 19.8658561707, MSE: 19.8658564426
INFO:root:(Meta-training) post train loss: 23.2383213043, MAE: 305.630065918, MSE: 305.630061308
INFO:root:(Meta-training) pre-training test MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post-training test MAE: 309.446746826, MSE: 309.446746731
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(58.7686, device='cuda:0'), 'backend.0.bias': tensor(0.1086, device='cuda:0'), 'backend.10.weight': tensor(-648.2241, device='cuda:0'), 'backend.8.bias': tensor(0.4562, device='cuda:0'), 'backend.6.weight': tensor(345.6556, device='cuda:0'), 'backend.2.bias': tensor(-0.1202, device='cuda:0'), 'backend.10.bias': tensor(-15.2989, device='cuda:0'), 'output_layer.bias': tensor(-243.9008, device='cuda:0'), 'backend.2.weight': tensor(-578.7977, device='cuda:0'), 'backend.6.bias': tensor(0.6730, device='cuda:0'), 'backend.0.weight': tensor(372.4923, device='cuda:0'), 'output_layer.weight': tensor(-42.9096, device='cuda:0'), 'backend.4.weight': tensor(-832.2753, device='cuda:0'), 'backend.4.bias': tensor(-0.4173, device='cuda:0')}
INFO:root:==> Training scene: 21
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.92966938019, MAE: 7.99254989624, MSE: 7.99255000362
INFO:root:(Meta-training) post train loss: 7.93039751053, MAE: 103.157691956, MSE: 103.157693681
INFO:root:(Meta-training) pre-training test MAE: 17.2073936462, MSE: 17.2073934943
INFO:root:(Meta-training) post-training test MAE: 94.2486724854, MSE: 94.2486737307
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-110.2387, device='cuda:0'), 'backend.0.bias': tensor(-0.0146, device='cuda:0'), 'backend.10.weight': tensor(-230.1305, device='cuda:0'), 'backend.8.bias': tensor(-0.4253, device='cuda:0'), 'backend.6.weight': tensor(-117.1571, device='cuda:0'), 'backend.2.bias': tensor(-0.0757, device='cuda:0'), 'backend.10.bias': tensor(-5.3008, device='cuda:0'), 'output_layer.bias': tensor(-71.6464, device='cuda:0'), 'backend.2.weight': tensor(-347.9861, device='cuda:0'), 'backend.6.bias': tensor(-0.0327, device='cuda:0'), 'backend.0.weight': tensor(-114.7507, device='cuda:0'), 'output_layer.weight': tensor(-14.5011, device='cuda:0'), 'backend.4.weight': tensor(-442.1410, device='cuda:0'), 'backend.4.bias': tensor(-0.2187, device='cuda:0')}
INFO:root:==> Training scene: 22
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.6123580933, MAE: 10.1582298279, MSE: 10.1582299753
INFO:root:(Meta-training) post train loss: 13.2736644745, MAE: 153.450256348, MSE: 153.450254052
INFO:root:(Meta-training) pre-training test MAE: 16.6812591553, MSE: 16.6812590741
INFO:root:(Meta-training) post-training test MAE: 142.571716309, MSE: 142.571713041
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-348.8337, device='cuda:0'), 'backend.0.bias': tensor(-0.1027, device='cuda:0'), 'backend.10.weight': tensor(-844.5209, device='cuda:0'), 'backend.8.bias': tensor(-1.7194, device='cuda:0'), 'backend.6.weight': tensor(-814.8105, device='cuda:0'), 'backend.2.bias': tensor(-0.4311, device='cuda:0'), 'backend.10.bias': tensor(-20.1072, device='cuda:0'), 'output_layer.bias': tensor(-113.4044, device='cuda:0'), 'backend.2.weight': tensor(-1628.4746, device='cuda:0'), 'backend.6.bias': tensor(-0.7616, device='cuda:0'), 'backend.0.weight': tensor(-452.7468, device='cuda:0'), 'output_layer.weight': tensor(-25.8738, device='cuda:0'), 'backend.4.weight': tensor(-1727.8400, device='cuda:0'), 'backend.4.bias': tensor(-1.0229, device='cuda:0')}
INFO:root:==> Training scene: 23
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 21.1111278534, MAE: 0.63020324707, MSE: 0.630203236541
INFO:root:(Meta-training) post train loss: 22.0809345245, MAE: 13.3689956665, MSE: 13.3689955309
INFO:root:(Meta-training) pre-training test MAE: 6.70138835907, MSE: 6.70138847426
INFO:root:(Meta-training) post-training test MAE: 37.1159133911, MSE: 37.1159138976
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(16.0151, device='cuda:0'), 'backend.0.bias': tensor(0.0425, device='cuda:0'), 'backend.10.weight': tensor(-114.7229, device='cuda:0'), 'backend.8.bias': tensor(-0.0450, device='cuda:0'), 'backend.6.weight': tensor(201.0754, device='cuda:0'), 'backend.2.bias': tensor(0.0558, device='cuda:0'), 'backend.10.bias': tensor(-2.8131, device='cuda:0'), 'output_layer.bias': tensor(-25.3123, device='cuda:0'), 'backend.2.weight': tensor(294.5615, device='cuda:0'), 'backend.6.bias': tensor(0.1817, device='cuda:0'), 'backend.0.weight': tensor(233.2776, device='cuda:0'), 'output_layer.weight': tensor(-4.9482, device='cuda:0'), 'backend.4.weight': tensor(177.3442, device='cuda:0'), 'backend.4.bias': tensor(0.0573, device='cuda:0')}
INFO:root:==> Training scene: 24
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.3689892292, MAE: 3.61751317978, MSE: 3.61751322588
INFO:root:(Meta-training) post train loss: 1.41690576077, MAE: 57.1678237915, MSE: 57.1678244841
INFO:root:(Meta-training) pre-training test MAE: 3.67163085938, MSE: 3.67163085126
INFO:root:(Meta-training) post-training test MAE: 62.9182167053, MSE: 62.9182159974
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(67.4450, device='cuda:0'), 'backend.0.bias': tensor(-0.0376, device='cuda:0'), 'backend.10.weight': tensor(95.9710, device='cuda:0'), 'backend.8.bias': tensor(0.2977, device='cuda:0'), 'backend.6.weight': tensor(-43.1883, device='cuda:0'), 'backend.2.bias': tensor(-0.0293, device='cuda:0'), 'backend.10.bias': tensor(3.6065, device='cuda:0'), 'output_layer.bias': tensor(48.0856, device='cuda:0'), 'backend.2.weight': tensor(-23.3053, device='cuda:0'), 'backend.6.bias': tensor(-0.1360, device='cuda:0'), 'backend.0.weight': tensor(-73.2256, device='cuda:0'), 'output_layer.weight': tensor(7.2894, device='cuda:0'), 'backend.4.weight': tensor(94.5628, device='cuda:0'), 'backend.4.bias': tensor(0.0419, device='cuda:0')}
INFO:root:==> Training scene: 25
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.78185081482, MAE: 3.64704179764, MSE: 3.647041789
INFO:root:(Meta-training) post train loss: 1.53377175331, MAE: 41.5643920898, MSE: 41.5643914043
INFO:root:(Meta-training) pre-training test MAE: 7.03860282898, MSE: 7.03860292617
INFO:root:(Meta-training) post-training test MAE: 38.4184913635, MSE: 38.4184912347
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(6.1834, device='cuda:0'), 'backend.0.bias': tensor(0.0124, device='cuda:0'), 'backend.10.weight': tensor(-7.2555, device='cuda:0'), 'backend.8.bias': tensor(0.0298, device='cuda:0'), 'backend.6.weight': tensor(31.5153, device='cuda:0'), 'backend.2.bias': tensor(0.0100, device='cuda:0'), 'backend.10.bias': tensor(-0.1930, device='cuda:0'), 'output_layer.bias': tensor(-28.9806, device='cuda:0'), 'backend.2.weight': tensor(31.5566, device='cuda:0'), 'backend.6.bias': tensor(0.0482, device='cuda:0'), 'backend.0.weight': tensor(44.4503, device='cuda:0'), 'output_layer.weight': tensor(-4.4127, device='cuda:0'), 'backend.4.weight': tensor(9.8322, device='cuda:0'), 'backend.4.bias': tensor(0.0038, device='cuda:0')}
INFO:root:==> Training scene: 26
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.51275110245, MAE: 4.93081665039, MSE: 4.93081656946
INFO:root:(Meta-training) post train loss: 6.66961336136, MAE: 63.5387878418, MSE: 63.5387872896
INFO:root:(Meta-training) pre-training test MAE: 1.70257949829, MSE: 1.70257951593
INFO:root:(Meta-training) post-training test MAE: 74.05909729, MSE: 74.0590980231
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-64.9163, device='cuda:0'), 'backend.0.bias': tensor(0.0207, device='cuda:0'), 'backend.10.weight': tensor(-215.7396, device='cuda:0'), 'backend.8.bias': tensor(-0.2159, device='cuda:0'), 'backend.6.weight': tensor(-53.6763, device='cuda:0'), 'backend.2.bias': tensor(0.0031, device='cuda:0'), 'backend.10.bias': tensor(-5.1249, device='cuda:0'), 'output_layer.bias': tensor(-58.9641, device='cuda:0'), 'backend.2.weight': tensor(-154.8738, device='cuda:0'), 'backend.6.bias': tensor(0.1189, device='cuda:0'), 'backend.0.weight': tensor(-51.5998, device='cuda:0'), 'output_layer.weight': tensor(-9.6605, device='cuda:0'), 'backend.4.weight': tensor(-269.6782, device='cuda:0'), 'backend.4.bias': tensor(-0.1026, device='cuda:0')}
INFO:root:==> Training scene: 27
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.81052994728, MAE: 3.4300737381, MSE: 3.43007370984
INFO:root:(Meta-training) post train loss: 1.85474944115, MAE: 49.2230949402, MSE: 49.2230950463
INFO:root:(Meta-training) pre-training test MAE: 0.405708312988, MSE: 0.405708318655
INFO:root:(Meta-training) post-training test MAE: 53.5645370483, MSE: 53.5645374102
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(21.7239, device='cuda:0'), 'backend.0.bias': tensor(-0.0415, device='cuda:0'), 'backend.10.weight': tensor(88.3675, device='cuda:0'), 'backend.8.bias': tensor(0.0254, device='cuda:0'), 'backend.6.weight': tensor(-91.4464, device='cuda:0'), 'backend.2.bias': tensor(-0.0413, device='cuda:0'), 'backend.10.bias': tensor(3.2484, device='cuda:0'), 'output_layer.bias': tensor(40.5884, device='cuda:0'), 'backend.2.weight': tensor(-47.4420, device='cuda:0'), 'backend.6.bias': tensor(-0.2370, device='cuda:0'), 'backend.0.weight': tensor(-68.5267, device='cuda:0'), 'output_layer.weight': tensor(6.0570, device='cuda:0'), 'backend.4.weight': tensor(54.8532, device='cuda:0'), 'backend.4.bias': tensor(-0.0010, device='cuda:0')}
INFO:root:==> Training scene: 28
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.91805839539, MAE: 16.495388031, MSE: 16.4953884269
INFO:root:(Meta-training) post train loss: 16.5992298126, MAE: 248.975204468, MSE: 248.975204275
INFO:root:(Meta-training) pre-training test MAE: 5.10612487793, MSE: 5.10612491749
INFO:root:(Meta-training) post-training test MAE: 254.839996338, MSE: 254.839992691
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-218.2436, device='cuda:0'), 'backend.0.bias': tensor(0.0600, device='cuda:0'), 'backend.10.weight': tensor(-483.3945, device='cuda:0'), 'backend.8.bias': tensor(-0.9689, device='cuda:0'), 'backend.6.weight': tensor(58.4666, device='cuda:0'), 'backend.2.bias': tensor(-0.1581, device='cuda:0'), 'backend.10.bias': tensor(-8.8787, device='cuda:0'), 'output_layer.bias': tensor(-200.1620, device='cuda:0'), 'backend.2.weight': tensor(-680.3275, device='cuda:0'), 'backend.6.bias': tensor(0.2169, device='cuda:0'), 'backend.0.weight': tensor(194.6782, device='cuda:0'), 'output_layer.weight': tensor(-33.2362, device='cuda:0'), 'backend.4.weight': tensor(-900.4709, device='cuda:0'), 'backend.4.bias': tensor(-0.4924, device='cuda:0')}
INFO:root:==> Training scene: 29
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.79754734039, MAE: 17.5090179443, MSE: 17.5090178007
INFO:root:(Meta-training) post train loss: 19.8869838715, MAE: 259.828735352, MSE: 259.828729647
INFO:root:(Meta-training) pre-training test MAE: 19.3920478821, MSE: 19.3920476916
INFO:root:(Meta-training) post-training test MAE: 262.822540283, MSE: 262.822539939
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-562.1874, device='cuda:0'), 'backend.0.bias': tensor(-0.0445, device='cuda:0'), 'backend.10.weight': tensor(-752.2289, device='cuda:0'), 'backend.8.bias': tensor(-2.6582, device='cuda:0'), 'backend.6.weight': tensor(-1082.9219, device='cuda:0'), 'backend.2.bias': tensor(-0.3633, device='cuda:0'), 'backend.10.bias': tensor(-19.6488, device='cuda:0'), 'output_layer.bias': tensor(-208.3302, device='cuda:0'), 'backend.2.weight': tensor(-1791.1672, device='cuda:0'), 'backend.6.bias': tensor(-0.9017, device='cuda:0'), 'backend.0.weight': tensor(-419.6157, device='cuda:0'), 'output_layer.weight': tensor(-41.2734, device='cuda:0'), 'backend.4.weight': tensor(-1991.5448, device='cuda:0'), 'backend.4.bias': tensor(-0.9737, device='cuda:0')}
INFO:root:==> Training scene: 30
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.79670476913, MAE: 2.56892776489, MSE: 2.56892779772
INFO:root:(Meta-training) post train loss: 5.16473007202, MAE: 24.4140777588, MSE: 24.4140775
INFO:root:(Meta-training) pre-training test MAE: 1.84230804443, MSE: 1.84230806249
INFO:root:(Meta-training) post-training test MAE: 22.7580795288, MSE: 22.7580793518
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-46.0851, device='cuda:0'), 'backend.0.bias': tensor(-0.0036, device='cuda:0'), 'backend.10.weight': tensor(-73.4203, device='cuda:0'), 'backend.8.bias': tensor(-0.1900, device='cuda:0'), 'backend.6.weight': tensor(-62.4313, device='cuda:0'), 'backend.2.bias': tensor(-0.0266, device='cuda:0'), 'backend.10.bias': tensor(-1.6552, device='cuda:0'), 'output_layer.bias': tensor(-17.0427, device='cuda:0'), 'backend.2.weight': tensor(-127.3709, device='cuda:0'), 'backend.6.bias': tensor(-0.0367, device='cuda:0'), 'backend.0.weight': tensor(-25.0434, device='cuda:0'), 'output_layer.weight': tensor(-3.4376, device='cuda:0'), 'backend.4.weight': tensor(-128.4456, device='cuda:0'), 'backend.4.bias': tensor(-0.0640, device='cuda:0')}
INFO:root:==> Training scene: 31
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.92816901207, MAE: 6.54268741608, MSE: 6.54268743565
INFO:root:(Meta-training) post train loss: 3.94747614861, MAE: 79.0179672241, MSE: 79.0179685608
INFO:root:(Meta-training) pre-training test MAE: 2.77071666718, MSE: 2.77071666233
INFO:root:(Meta-training) post-training test MAE: 81.9200592041, MSE: 81.9200585699
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-42.4969, device='cuda:0'), 'backend.0.bias': tensor(0.0191, device='cuda:0'), 'backend.10.weight': tensor(-89.6895, device='cuda:0'), 'backend.8.bias': tensor(-0.1760, device='cuda:0'), 'backend.6.weight': tensor(25.6620, device='cuda:0'), 'backend.2.bias': tensor(-0.0125, device='cuda:0'), 'backend.10.bias': tensor(-2.3425, device='cuda:0'), 'output_layer.bias': tensor(-62.3058, device='cuda:0'), 'backend.2.weight': tensor(-101.7161, device='cuda:0'), 'backend.6.bias': tensor(0.0798, device='cuda:0'), 'backend.0.weight': tensor(28.3379, device='cuda:0'), 'output_layer.weight': tensor(-10.7214, device='cuda:0'), 'backend.4.weight': tensor(-192.2546, device='cuda:0'), 'backend.4.bias': tensor(-0.0999, device='cuda:0')}
INFO:root:==> Training scene: 32
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.5723743439, MAE: 3.49564743042, MSE: 3.49564744882
INFO:root:(Meta-training) post train loss: 8.17095661163, MAE: 36.8633918762, MSE: 36.8633919759
INFO:root:(Meta-training) pre-training test MAE: 3.27803039551, MSE: 3.27803041451
INFO:root:(Meta-training) post-training test MAE: 33.7333831787, MSE: 33.7333834963
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-57.7771, device='cuda:0'), 'backend.0.bias': tensor(-0.0101, device='cuda:0'), 'backend.10.weight': tensor(-168.3690, device='cuda:0'), 'backend.8.bias': tensor(-0.3028, device='cuda:0'), 'backend.6.weight': tensor(-124.5657, device='cuda:0'), 'backend.2.bias': tensor(-0.0514, device='cuda:0'), 'backend.10.bias': tensor(-3.7853, device='cuda:0'), 'output_layer.bias': tensor(-26.0408, device='cuda:0'), 'backend.2.weight': tensor(-202.7013, device='cuda:0'), 'backend.6.bias': tensor(-0.1367, device='cuda:0'), 'backend.0.weight': tensor(-33.2377, device='cuda:0'), 'output_layer.weight': tensor(-5.5101, device='cuda:0'), 'backend.4.weight': tensor(-261.8314, device='cuda:0'), 'backend.4.bias': tensor(-0.1489, device='cuda:0')}
INFO:root:===> Updating meta network
INFO:root:===> Gradients updated: {'backend.8.weight': tensor([[[[ 7.7916e-01,  8.5607e-01,  7.9229e-01],
          [ 9.0868e-01,  7.7736e-01,  6.4876e-01],
          [ 9.0064e-01,  9.4987e-01,  7.5753e-01]],

         [[ 1.1307e-01,  1.0704e-01,  9.0649e-02],
          [ 1.2796e-01,  1.0473e-01,  1.2942e-01],
          [ 1.3047e-01,  1.6048e-01,  1.4018e-01]],

         [[ 7.5768e-01,  7.1184e-01,  8.0713e-01],
          [ 7.5325e-01,  7.6828e-01,  8.4883e-01],
          [ 6.4983e-01,  8.1942e-01,  6.6784e-01]],

         ...,

         [[ 4.8735e-03,  5.3943e-03,  5.6950e-03],
          [ 4.0223e-03,  5.7926e-03,  2.3920e-03],
          [ 5.1352e-03,  6.9413e-03,  1.8356e-03]],

         [[ 2.1338e-02,  1.4164e-02,  1.3132e-02],
          [ 1.4678e-02,  1.8111e-02,  1.2113e-02],
          [ 1.1622e-02,  1.0919e-02,  8.9136e-03]],

         [[ 8.8305e-01,  8.2144e-01,  7.5310e-01],
          [ 8.2313e-01,  8.4059e-01,  7.4162e-01],
          [ 8.5086e-01,  7.3575e-01,  7.3748e-01]]],


        [[[-4.9812e-01, -5.0378e-01, -5.1191e-01],
          [-4.0563e-01, -2.9149e-01, -3.7377e-01],
          [-2.8067e-01, -3.3813e-01, -3.9142e-01]],

         [[-3.6185e-02, -4.4533e-02, -3.7252e-02],
          [-3.7536e-02, -2.0504e-02, -3.5803e-02],
          [-3.6210e-02, -6.8325e-02, -4.4340e-02]],

         [[-3.7382e-01, -3.9211e-01, -4.3686e-01],
          [-4.6847e-01, -4.9453e-01, -5.1677e-01],
          [-5.1365e-01, -5.5016e-01, -3.8768e-01]],

         ...,

         [[-5.0242e-03, -1.1525e-03, -2.1685e-03],
          [-3.8029e-03, -3.3366e-03, -1.4325e-03],
          [-3.0781e-03, -4.2158e-03, -4.6185e-03]],

         [[-5.8557e-03, -1.7622e-02, -2.0925e-02],
          [-2.2585e-02, -2.9423e-02, -2.1775e-02],
          [-1.7520e-02, -1.5502e-02, -9.9940e-03]],

         [[-3.5619e-01, -4.2216e-01, -4.5200e-01],
          [-4.1187e-01, -5.1698e-01, -4.8196e-01],
          [-2.5478e-01, -2.9195e-01, -3.7740e-01]]],


        [[[-5.0192e-01, -1.6550e-01, -3.0481e-01],
          [-4.3925e-01, -2.2387e-01, -4.2957e-01],
          [-2.3618e-01, -4.3159e-01, -5.8229e-01]],

         [[-1.4857e-02, -4.3006e-02, -5.9084e-02],
          [-6.6486e-03, -6.0455e-02, -7.7892e-02],
          [-2.2637e-02, -5.3768e-02, -7.4317e-02]],

         [[ 8.3276e-02,  2.6158e-02, -2.1678e-01],
          [-1.3345e-01, -2.8881e-01, -1.2475e-01],
          [-3.7338e-01, -2.9140e-01, -1.1983e-01]],

         ...,

         [[-8.1383e-03, -4.9586e-03, -2.1028e-03],
          [-4.4009e-03, -1.6209e-03,  3.1504e-03],
          [-6.1087e-04,  1.2552e-03, -5.3144e-03]],

         [[ 1.1792e-02, -2.7063e-03, -3.8844e-03],
          [-1.7548e-03, -1.5361e-02, -9.7133e-03],
          [-3.5433e-03, -5.4995e-03, -2.7218e-03]],

         [[-7.8812e-03, -2.6094e-01, -2.7988e-01],
          [-1.4145e-01, -1.4226e-01, -3.1542e-01],
          [ 2.1230e-02, -2.0337e-01, -2.4090e-01]]],


        ...,


        [[[-2.9929e-01, -3.0268e-01, -2.6287e-01],
          [-2.9783e-01, -3.2071e-01, -2.3949e-01],
          [-3.1233e-01, -3.2161e-01, -2.6809e-01]],

         [[-3.4950e-02, -4.1251e-02, -3.6930e-02],
          [-3.8473e-02, -3.4362e-02, -3.8018e-02],
          [-3.6614e-02, -3.9380e-02, -3.5096e-02]],

         [[-1.7141e-01, -1.5779e-01, -1.4476e-01],
          [-1.7421e-01, -1.4054e-01, -1.5374e-01],
          [-1.1284e-01, -1.3553e-01, -1.4858e-01]],

         ...,

         [[-3.5639e-03, -2.7827e-03, -2.7394e-03],
          [-3.8445e-03, -3.7023e-03, -1.9841e-03],
          [-5.2670e-03, -4.6121e-03, -2.3858e-03]],

         [[-4.0673e-03, -2.9856e-03, -2.4181e-03],
          [-3.0785e-03, -2.0582e-03, -2.0237e-03],
          [-1.1365e-03, -2.0668e-03, -1.9191e-03]],

         [[-2.2178e-01, -2.4374e-01, -2.2302e-01],
          [-2.0329e-01, -2.1494e-01, -2.0253e-01],
          [-2.2835e-01, -2.2162e-01, -2.1170e-01]]],


        [[[-1.9047e-01, -5.0808e-01, -6.5154e-01],
          [-5.2507e-01, -5.0222e-01, -7.7457e-01],
          [-2.1515e-01,  8.5308e-02, -3.5444e-01]],

         [[ 3.1730e-02, -1.1143e-01,  1.3258e-02],
          [-6.2912e-02,  5.6852e-02, -3.5360e-02],
          [-4.4693e-02, -6.0705e-02, -1.5646e-02]],

         [[-2.1752e-01, -4.0753e-01,  1.6297e-01],
          [-2.4689e-01,  2.1465e-01, -1.9746e-01],
          [-3.6736e-01, -3.6167e-01, -3.7535e-01]],

         ...,

         [[-1.1183e-02, -9.8649e-03, -4.9529e-03],
          [-1.2929e-02, -9.7741e-03, -1.4051e-02],
          [-9.3559e-03, -6.5622e-03, -3.3314e-03]],

         [[ 8.0945e-03,  1.3655e-02,  8.0041e-03],
          [-5.6982e-03,  1.6567e-03, -4.8266e-03],
          [-4.1134e-03,  1.1965e-03,  4.5939e-03]],

         [[ 1.2224e-01,  3.1816e-01, -1.0589e-02],
          [-2.2472e-02, -3.1923e-01, -2.2589e-01],
          [ 2.7717e-03,  5.2605e-03,  1.2988e-02]]],


        [[[-4.9065e-01, -5.2073e-01, -5.2142e-01],
          [-6.1824e-01, -4.1892e-01, -5.3042e-01],
          [-7.6838e-01, -4.8344e-01, -6.1932e-01]],

         [[-1.0348e-01, -5.7851e-02, -8.9387e-02],
          [-8.2592e-02, -8.9407e-02, -8.5119e-02],
          [-9.8153e-02, -1.1333e-01, -1.1592e-01]],

         [[-5.3413e-01, -5.2772e-01, -4.8901e-01],
          [-3.7988e-01, -3.6942e-01, -5.1767e-01],
          [-4.2634e-01, -3.9946e-01, -4.8190e-01]],

         ...,

         [[-1.6937e-03, -4.2673e-03, -6.6555e-03],
          [-3.8203e-03, -4.7556e-03, -4.0910e-03],
          [-4.4072e-03, -1.1244e-03, -1.3581e-03]],

         [[-1.8637e-02, -5.6245e-03, -1.0102e-02],
          [-2.4476e-04, -1.3707e-03, -3.9374e-03],
          [-5.8170e-03, -9.9686e-03, -7.9207e-03]],

         [[-6.9425e-01, -5.7233e-01, -5.7277e-01],
          [-5.3208e-01, -6.1464e-01, -5.7705e-01],
          [-6.7009e-01, -4.8128e-01, -5.7393e-01]]]], device='cuda:0'), 'backend.0.bias': tensor([ 3.7435e-02,  8.6868e-03,  2.9687e-02,  9.5615e-02, -7.9370e-03,
        -2.2906e-01,  2.1798e-02,  1.2916e-01, -1.1742e-01,  5.3095e-02,
         6.5154e-02, -3.3856e-02, -1.8881e-01,  6.5476e-02,  1.1124e-01,
        -1.6868e-02, -9.0779e-02, -5.9171e-02, -1.5687e-02, -6.3593e-03,
        -1.0433e-01,  1.4868e-02,  2.4667e-01,  3.6994e-02, -5.4465e-02,
         1.1374e-02, -1.7108e-01, -2.9398e-02, -1.2781e-01, -2.2293e-02,
         5.0196e-02, -4.6588e-02, -4.9303e-02, -6.8111e-02, -1.1202e-01,
         1.1110e-01,  4.5685e-02,  1.5133e-01,  3.5387e-02, -2.8244e-02,
         4.8510e-02, -1.7623e-01,  1.0987e-01, -1.7989e-01,  3.6821e-02,
         6.6091e-03,  8.1262e-03,  1.3467e-01,  2.1311e-02, -2.2371e-02,
        -3.5822e-02,  1.0288e-01, -2.3761e-01,  1.0828e-01, -1.2286e-01,
         4.3771e-02,  9.0976e-02,  5.4292e-03,  6.3591e-03,  6.7665e-02,
        -8.3082e-03,  2.5766e-02,  1.2529e-01,  9.5696e-02, -3.2555e-02,
         1.1471e-03,  4.7835e-02, -1.0141e-01, -5.9008e-02,  1.1059e-01,
         1.9460e-03,  3.8479e-02,  1.3206e-02, -2.1735e-02, -5.8060e-03,
         5.6676e-02,  6.5930e-02,  2.8954e-02,  1.0560e-01,  8.2586e-03,
        -4.4968e-02,  1.1845e-03, -1.6334e-01,  3.3130e-02,  1.4980e-02,
        -5.1273e-02,  1.3310e-02, -1.1537e-01,  1.1990e-01, -2.9774e-03,
         2.5823e-02, -1.2387e-01,  3.3274e-02,  1.4201e-01, -1.8098e-02,
        -8.3500e-02, -1.2276e-01, -1.7765e-01, -1.7965e-01,  1.4993e-01,
        -2.8352e-04, -9.3305e-03,  1.3635e-01,  3.1081e-03,  3.3437e-02,
        -1.6648e-02, -3.7137e-02,  1.8646e-02, -1.6221e-02, -1.3726e-01,
        -2.6879e-02,  1.3328e-01, -2.0468e-02, -1.7347e-02,  1.0684e-01,
        -9.4518e-03, -3.3734e-02,  5.2323e-02, -6.5747e-02,  5.0567e-02,
         6.0393e-02, -2.3553e-02, -1.8967e-01,  6.2573e-03,  7.2336e-02,
        -1.7122e-02, -2.7194e-03, -9.6275e-02,  4.6948e-04, -2.2710e-01,
         6.5827e-03,  3.1450e-02, -7.9210e-03, -1.7999e-01,  1.5686e-01,
        -1.3608e-02, -3.6705e-02, -1.8343e-01,  1.3468e-01,  1.1925e-02,
        -1.4943e-02, -9.2979e-03,  3.1526e-02, -3.5560e-02,  8.4172e-03,
        -7.3547e-02,  6.9649e-02,  1.4172e-01, -5.6147e-02,  8.2016e-02,
         5.3280e-02,  9.1900e-02,  2.8380e-03, -1.3482e-02,  7.4777e-02,
         6.9650e-03, -2.7511e-02, -3.0703e-02, -2.0543e-01,  1.8875e-01,
         6.9804e-02,  3.3833e-02, -2.7313e-02, -2.0109e-01, -5.1881e-02,
         2.3695e-03,  1.0829e-01, -3.6844e-02, -8.6512e-02, -2.1700e-01,
        -7.0292e-02,  6.8957e-02,  3.1386e-02,  1.3123e-02, -3.2301e-02,
        -1.0124e-01,  8.2451e-02, -1.8405e-02,  2.7769e-02, -1.5899e-01,
         4.5793e-03,  1.1975e-02,  7.1419e-03,  4.3334e-03, -1.7068e-01,
        -3.9195e-02,  4.2246e-02,  8.9103e-02, -5.1282e-03, -5.4139e-02,
         1.3971e-03, -8.0118e-02, -5.2303e-02,  8.1217e-03,  1.2799e-01,
         8.6179e-02,  5.2950e-02,  7.4546e-02, -3.3942e-03,  1.7204e-01,
        -1.1362e-01,  1.4206e-01,  2.1858e-01,  9.2225e-02, -1.9899e-01,
         3.6390e-02, -1.1806e-01, -8.2607e-02,  9.6324e-02,  3.8894e-02,
        -4.3604e-03, -1.4082e-01,  8.5448e-02,  7.8836e-02,  4.1850e-02,
         1.1329e-02,  7.4670e-02,  6.7290e-02, -7.1616e-02, -1.5780e-01,
        -9.5887e-03, -2.2307e-02, -6.0844e-02,  9.7201e-02, -1.1720e-01,
         1.0030e-01, -1.0908e-02, -3.6494e-02, -2.5891e-04, -7.7159e-02,
        -1.7274e-01,  2.3190e-02, -1.9711e-02,  3.5280e-02, -1.4302e-01,
         1.2824e-02,  4.7918e-02, -1.6809e-01,  5.6044e-02,  7.4026e-02,
         2.2772e-02, -1.4494e-01, -4.2030e-02, -6.3802e-02,  1.2182e-02,
         4.3358e-02,  5.3708e-02,  4.2698e-02, -2.8499e-02,  1.4108e-01,
        -5.5323e-03,  9.1692e-02,  6.3695e-02, -3.4251e-02, -2.8302e-02,
        -5.3445e-02,  2.9552e-03, -5.0377e-02,  1.6559e-02,  1.2318e-01,
        -4.0709e-04, -9.3539e-02, -6.3956e-02, -1.3604e-02, -5.2657e-02,
         3.6484e-02, -9.6794e-02, -8.6375e-02,  4.8662e-04,  8.6020e-03,
        -1.0094e-01, -5.5459e-02, -6.2272e-03,  2.4522e-02,  1.6359e-01,
        -3.3313e-02,  4.5278e-02,  5.1331e-02, -1.2520e-01,  9.1644e-02,
        -5.9488e-02, -1.1458e-01, -6.1016e-02, -2.1344e-01,  2.6369e-02,
         1.8460e-02, -8.5259e-04,  3.9910e-01,  2.6680e-02, -1.6055e-01,
        -6.4645e-02, -5.6139e-02,  1.0158e-02, -1.4174e-02,  7.4237e-02,
         3.7757e-02, -7.6092e-02, -5.3069e-02,  4.9686e-02, -2.6026e-01,
        -1.8112e-01,  1.3090e-01,  2.7320e-02,  2.0812e-02,  3.8818e-02,
         4.0497e-02, -4.4817e-02, -3.4690e-02, -6.9138e-02,  1.2728e-01,
        -1.7978e-01,  3.2795e-02, -4.3860e-02,  9.0157e-02,  3.4749e-02,
        -5.8772e-02, -2.9962e-02, -2.5508e-03, -2.6108e-03, -3.0464e-02,
         4.8108e-02, -1.5034e-01,  4.0939e-02, -8.9530e-02, -2.2504e-02,
         2.5583e-02,  9.0480e-02,  6.8584e-02,  1.1664e-01, -1.2777e-02,
         1.4530e-02,  2.3292e-02, -8.2612e-02,  7.2054e-02,  6.5942e-03,
         5.9477e-02,  2.1409e-02, -1.0625e-01, -1.0625e-01, -8.5956e-02,
         8.7440e-02,  6.5846e-02,  1.9994e-02, -2.2161e-02, -7.1828e-02,
        -1.4759e-03, -2.1726e-02,  4.5512e-02,  4.6463e-02, -5.6594e-02,
         7.0406e-02, -7.1067e-02,  8.3108e-02,  7.8467e-02,  9.3380e-02,
         6.4213e-04,  4.0036e-02, -3.3859e-03,  4.2069e-02, -1.4598e-01,
         7.9622e-02,  1.4402e-01, -4.1291e-02,  4.3087e-02, -1.2321e-01,
        -1.4229e-01, -1.5477e-02, -1.5638e-01,  7.6901e-02, -1.8432e-02,
        -3.0861e-02, -7.7829e-02,  4.6241e-02,  1.0649e-01,  6.2955e-02,
         3.3869e-02,  5.2015e-02,  7.5418e-02, -1.0650e-01, -8.4475e-04,
        -1.1416e-01,  5.3095e-02,  1.0518e-01,  1.0733e-01, -8.4019e-02,
         1.3562e-01, -1.2334e-01, -4.9151e-02,  1.2403e-01, -8.0861e-02,
         1.4998e-01, -2.3118e-02,  1.0668e-01, -5.9597e-02, -1.0736e-02,
         4.4334e-02,  2.6921e-02, -5.7335e-02,  1.0289e-01,  2.2908e-01,
        -6.2295e-02,  4.3519e-02,  3.5141e-02, -3.7513e-02, -1.5320e-01,
        -1.7330e-01, -1.7242e-01,  1.1273e-01,  8.8120e-02,  1.7926e-02,
         1.5912e-01, -8.8513e-03,  3.6226e-03, -1.5002e-02, -9.1840e-02,
         2.3674e-02,  2.8329e-02,  2.2835e-02,  4.4367e-02, -6.7740e-02,
        -5.3699e-02, -3.3517e-03, -1.7343e-02, -9.4075e-03,  5.4577e-02,
        -5.9960e-02, -4.1874e-03, -5.1600e-02, -1.4495e-02, -7.0580e-02,
        -1.0849e-01,  1.7600e-01, -9.0258e-02,  1.1787e-01, -3.2405e-03,
         5.9322e-02, -6.7924e-02, -6.7785e-02,  3.3781e-02,  3.1117e-02,
        -1.1967e-01,  1.1624e-01, -6.5048e-02,  6.9481e-02,  3.6161e-02,
         1.8169e-02, -1.1414e-02, -2.2334e-02, -5.7602e-02,  4.2443e-02,
         1.4756e-02,  2.9847e-02,  9.0883e-02, -1.8335e-02, -1.7758e-01,
         6.6598e-02, -4.1333e-02, -5.6229e-02, -2.5875e-02, -1.4190e-01,
         2.3755e-03,  1.5122e-02,  8.3824e-03,  1.7196e-02,  4.8925e-02,
        -1.8419e-01,  1.6542e-04, -5.8993e-03, -2.3125e-01, -1.4528e-01,
         2.8598e-02,  4.2600e-02, -3.7203e-02,  1.2312e-02,  1.3099e-01,
        -3.3447e-02, -1.1550e-01, -3.2145e-02, -5.2976e-02,  3.4270e-02,
        -1.4025e-02, -7.2385e-03,  5.4486e-03, -2.1931e-02, -1.5543e-02,
         5.1916e-02,  6.7197e-03, -2.1290e-01,  8.3986e-02,  9.0955e-02,
        -1.9859e-02,  5.5643e-02,  7.0866e-02, -6.5067e-02, -1.8819e-02,
        -2.6501e-03, -1.0376e-02, -2.6326e-02,  1.3805e-01,  7.2933e-03,
         6.3786e-02, -1.9616e-02,  5.1551e-03, -6.8186e-02,  2.9799e-02,
         9.7751e-02,  1.3504e-01, -1.2660e-01,  6.2455e-04,  6.9421e-02,
         2.6581e-02,  5.3619e-02], device='cuda:0'), 'backend.10.weight': tensor([[[[-2.1959e-01, -3.3617e-01, -3.1556e-01],
          [-4.1270e-01, -3.4180e-01, -3.8507e-01],
          [-5.4396e-01, -5.1190e-01, -5.2420e-01]],

         [[-1.8068e-01, -1.1519e-01, -9.5161e-02],
          [-5.3012e-02, -3.9709e-02, -3.9325e-02],
          [-1.9610e-02, -1.2149e-02, -1.1782e-02]],

         [[-5.8630e-01, -4.5302e-01, -3.9153e-01],
          [-5.4708e-01, -2.9469e-01, -3.2340e-01],
          [-3.8501e-01, -3.9807e-01, -5.7451e-01]],

         ...,

         [[-9.7577e-02, -7.3513e-02, -7.1505e-02],
          [-5.3139e-02, -8.2465e-02, -6.4261e-02],
          [-5.2220e-02, -5.2127e-02, -5.7822e-02]],

         [[-7.6080e-01, -6.6571e-01, -8.5296e-01],
          [-6.0264e-01, -6.6787e-01, -6.7292e-01],
          [-1.1411e+00, -6.8185e-01, -6.6706e-01]],

         [[-1.8829e-01, -1.7583e-01, -2.0558e-01],
          [-1.6771e-01, -2.0710e-01, -3.6579e-01],
          [-1.1624e-01, -1.1664e-01, -1.4306e-01]]],


        [[[-2.3476e+00, -2.6140e+00, -2.5955e+00],
          [-3.0088e+00, -2.9354e+00, -2.9637e+00],
          [-3.3367e+00, -3.2346e+00, -3.2560e+00]],

         [[-3.5227e-01, -3.1430e-01, -2.8929e-01],
          [-3.8315e-01, -3.6267e-01, -3.4866e-01],
          [-1.9386e-01, -1.8508e-01, -1.6998e-01]],

         [[-2.3411e+00, -2.0769e+00, -1.9700e+00],
          [-2.4370e+00, -2.0338e+00, -2.0448e+00],
          [-1.9506e+00, -1.8898e+00, -2.0975e+00]],

         ...,

         [[-7.2566e-01, -7.4311e-01, -7.0555e-01],
          [-6.7706e-01, -7.6847e-01, -7.2329e-01],
          [-6.1618e-01, -6.6311e-01, -6.7481e-01]],

         [[-4.6668e+00, -4.4965e+00, -4.7603e+00],
          [-4.8601e+00, -4.4961e+00, -4.5276e+00],
          [-5.5612e+00, -4.5514e+00, -4.3601e+00]],

         [[-5.4382e-01, -5.9398e-01, -6.5607e-01],
          [-5.7637e-01, -6.7748e-01, -8.0152e-01],
          [-4.7273e-01, -5.1591e-01, -6.0473e-01]]],


        [[[ 5.0461e-01,  5.0912e-01,  5.1986e-01],
          [ 5.1670e-01,  5.3388e-01,  5.4456e-01],
          [ 5.2959e-01,  5.4138e-01,  5.4454e-01]],

         [[ 8.5475e-03,  1.2207e-02,  1.2803e-02],
          [ 2.4507e-02,  2.6864e-02,  2.6616e-02],
          [ 2.4521e-02,  2.6697e-02,  2.7364e-02]],

         [[ 1.6012e-01,  1.9595e-01,  1.9410e-01],
          [ 1.9142e-01,  2.1182e-01,  1.9630e-01],
          [ 1.9157e-01,  2.1010e-01,  2.0856e-01]],

         ...,

         [[ 1.0573e-01,  1.0355e-01,  1.0533e-01],
          [ 1.1294e-01,  1.1248e-01,  1.1330e-01],
          [ 1.1578e-01,  1.1593e-01,  1.1540e-01]],

         [[ 5.8945e-01,  6.1057e-01,  6.0976e-01],
          [ 5.8720e-01,  6.4044e-01,  6.4838e-01],
          [ 6.2204e-01,  6.5195e-01,  6.4490e-01]],

         [[ 3.2154e-02,  3.4026e-02,  2.0880e-02],
          [ 3.2994e-02,  4.0004e-02,  2.7592e-02],
          [ 3.6006e-02,  4.3411e-02,  3.7158e-02]]],


        ...,


        [[[ 1.8190e-01,  1.7046e-01,  1.6139e-01],
          [ 1.8184e-01,  1.8455e-01,  1.6810e-01],
          [ 1.5529e-01,  1.4892e-01,  1.3226e-01]],

         [[ 6.4871e-03,  1.1624e-02,  1.2358e-02],
          [ 5.4277e-02,  5.7847e-02,  5.7604e-02],
          [ 2.9974e-02,  3.2117e-02,  3.0282e-02]],

         [[ 7.2629e-02,  8.3997e-02,  7.7993e-02],
          [ 1.4803e-01,  1.6411e-01,  1.4653e-01],
          [ 1.2448e-01,  1.1466e-01,  9.5875e-02]],

         ...,

         [[ 2.1645e-02,  2.1378e-02,  2.0795e-02],
          [ 2.4206e-02,  2.2717e-02,  2.0400e-02],
          [ 1.9733e-02,  1.8385e-02,  1.5471e-02]],

         [[ 2.3900e-01,  2.4282e-01,  2.2168e-01],
          [ 2.5852e-01,  2.4316e-01,  2.4233e-01],
          [ 1.6480e-01,  1.7964e-01,  1.5443e-01]],

         [[ 1.5493e-02,  1.5617e-02,  2.1987e-02],
          [ 3.8231e-02,  3.1676e-02,  3.4201e-02],
          [ 3.2448e-02,  4.2885e-02,  4.5704e-02]]],


        [[[-1.1759e+00, -1.6960e+00, -1.5655e+00],
          [-2.0424e+00, -1.9111e+00, -1.9262e+00],
          [-2.5530e+00, -2.4314e+00, -2.4598e+00]],

         [[-5.2375e-01, -3.9010e-01, -3.5612e-01],
          [-1.7797e-01, -1.4278e-01, -1.5335e-01],
          [-5.4149e-02, -3.4321e-02, -4.5134e-02]],

         [[-2.4280e+00, -2.0517e+00, -1.8042e+00],
          [-2.3026e+00, -1.3931e+00, -1.5063e+00],
          [-1.5431e+00, -1.5189e+00, -2.2006e+00]],

         ...,

         [[-3.9746e-01, -3.2304e-01, -2.6708e-01],
          [-2.9420e-01, -3.7322e-01, -3.1304e-01],
          [-2.4681e-01, -2.3344e-01, -2.4592e-01]],

         [[-3.1743e+00, -3.0652e+00, -3.6059e+00],
          [-2.6640e+00, -2.7461e+00, -2.8847e+00],
          [-4.6844e+00, -3.0260e+00, -2.9310e+00]],

         [[-6.6746e-01, -6.5959e-01, -6.4882e-01],
          [-5.9409e-01, -7.4414e-01, -1.1450e+00],
          [-3.8093e-01, -3.7266e-01, -4.6022e-01]]],


        [[[-2.0956e-02, -2.0874e-02, -1.9518e-02],
          [-2.7313e-02, -2.4516e-02, -2.2938e-02],
          [-3.3471e-02, -3.3802e-02, -3.1649e-02]],

         [[-7.0705e-03, -8.3364e-03, -8.0707e-03],
          [-1.5045e-03, -2.1105e-03, -1.4246e-03],
          [-2.9152e-04, -2.5143e-04, -2.7530e-04]],

         [[-2.9277e-02, -2.6434e-02, -2.3441e-02],
          [-2.4026e-02, -2.1748e-02, -2.1338e-02],
          [-1.7061e-02, -2.5575e-02, -2.2425e-02]],

         ...,

         [[-3.2052e-03, -2.6869e-03, -1.9415e-03],
          [-1.3244e-03, -1.4512e-03, -1.2490e-03],
          [-1.7377e-03, -2.1666e-03, -1.5999e-03]],

         [[-3.7681e-02, -3.7452e-02, -3.5264e-02],
          [-3.3036e-02, -3.4708e-02, -2.4630e-02],
          [-4.1510e-02, -3.3301e-02, -3.4321e-02]],

         [[-1.6050e-02, -1.3616e-02, -1.1221e-02],
          [-9.7573e-03, -1.1921e-02, -1.2731e-02],
          [-5.4952e-03, -6.2394e-03, -4.1736e-03]]]], device='cuda:0'), 'backend.8.bias': tensor([ 4.9737e+00, -3.2972e+00, -1.2807e+00,  7.2607e-01, -1.5039e+00,
         1.6829e-01,  4.9959e-01, -2.1996e+00, -8.1899e-01, -1.3867e+00,
        -2.9949e-01, -4.3840e+00,  3.9718e-01, -3.1363e+00, -3.8491e+00,
        -2.6649e+00, -4.2858e-03, -5.9884e-01,  2.8110e+00, -2.2734e+00,
        -3.7313e-01,  7.8966e+00, -2.7427e-01, -4.5185e+00, -4.7506e-01,
         6.7307e+00,  2.4345e+00,  7.2646e+00, -3.2969e+00, -2.1476e+00,
        -1.9279e+00, -1.8337e+00, -1.6325e+00, -6.2015e-01, -9.9722e-01,
        -4.8325e+00,  2.9649e+00, -1.7396e+00, -1.6582e+00, -2.2803e+00,
         8.5869e-01,  3.3221e+00, -1.2001e+00,  9.5225e-02, -6.5972e-01,
         2.6132e+00, -3.0081e+00,  2.7432e+00, -2.9369e+00, -5.7038e-01,
        -4.1127e+00, -5.6516e+00, -3.8666e-01, -3.7298e+00,  7.6422e-01,
        -2.0456e+00, -2.0734e+00,  2.8771e-01, -2.2529e+00,  3.3025e+00,
         3.9578e+00, -2.1992e+00, -7.6605e-01, -1.0977e+00,  1.1327e-01,
        -3.4376e+00, -6.3099e-01, -7.0960e+00,  2.1510e+00,  1.8661e+00,
         2.0419e-01, -8.1415e-01,  4.6508e+00, -2.5497e+00, -4.1238e-01,
        -3.9497e+00,  2.1542e+00, -1.6452e+00, -1.1187e+00,  2.3748e+00,
        -5.8479e+00,  1.0999e+00,  9.7701e-02,  1.6046e+01, -1.4923e-01,
         3.7003e+00,  8.8302e-01, -4.3128e+00, -3.0774e+00,  5.0141e+00,
        -3.2504e+00,  2.5759e+00,  8.8290e-01, -1.0728e-01, -4.5346e-01,
        -2.7930e+00, -5.8308e+00, -1.6652e+00, -3.4447e-01, -4.6627e+00,
        -3.4878e+00, -2.0511e+00, -6.1619e-03,  5.6120e+00, -1.7159e-01,
        -5.2394e-01, -4.4822e-01,  1.6986e+00, -1.6533e+00, -2.3031e+00,
         2.8576e+00, -3.0470e+00, -5.3538e+00, -1.7170e+00,  8.7231e-01,
        -6.4554e+00, -1.1156e+00, -1.7039e+00,  9.7583e+00,  4.5823e-02,
         6.5802e+00, -2.2104e+00,  1.9929e+00, -5.2730e-02, -1.6266e+00,
        -1.3862e+00, -1.2762e+00, -3.9050e+00], device='cuda:0'), 'backend.6.weight': tensor([[[[ 1.7659e-02, -2.6832e-02,  1.1385e-02],
          [-9.5983e-03, -6.9888e-02, -7.4893e-02],
          [-5.2248e-02, -5.5227e-02, -7.9817e-02]],

         [[ 3.0972e-02,  5.7662e-02, -3.3489e-03],
          [-1.8451e-02, -1.3400e-02, -2.8494e-02],
          [-3.6402e-02, -7.0431e-02, -3.7302e-02]],

         [[-8.8066e-02, -1.2215e-01, -9.8338e-02],
          [-8.9382e-02, -4.0194e-02, -8.8762e-02],
          [-6.7900e-02, -6.4822e-02, -2.2596e-02]],

         ...,

         [[ 7.3210e-02, -2.9444e-02,  3.3527e-02],
          [ 1.1094e-02, -1.5081e-02, -2.0852e-02],
          [-5.2141e-02, -7.4994e-02, -8.7375e-02]],

         [[ 6.4951e-02,  5.9654e-02, -4.4960e-03],
          [-3.5679e-02,  6.1586e-02, -3.2398e-02],
          [-2.3371e-02, -6.1786e-02, -2.3975e-02]],

         [[-4.3150e-02, -2.9796e-02, -3.8643e-03],
          [-2.6560e-02, -1.7023e-02,  2.6667e-02],
          [ 4.5345e-02,  5.3840e-02,  8.0433e-02]]],


        [[[-1.8931e-02, -1.3767e-02, -2.2328e-02],
          [-1.7999e-02, -1.7059e-02, -1.7739e-02],
          [-1.7193e-03,  2.6561e-03, -3.2752e-03]],

         [[-4.8769e-03, -9.9158e-03, -1.8203e-02],
          [-9.3299e-03, -3.3823e-03, -1.0877e-02],
          [ 3.6881e-03, -3.0339e-03,  1.1093e-03]],

         [[-1.9346e-02, -1.9373e-02, -7.3059e-03],
          [ 1.2832e-02,  5.7465e-05, -5.6075e-03],
          [-1.6917e-02, -1.6682e-02, -2.7383e-02]],

         ...,

         [[-3.2147e-02, -5.1278e-02, -5.4454e-02],
          [-2.2433e-02, -6.8817e-03, -2.5640e-02],
          [-2.3895e-02, -3.1762e-02, -3.6114e-02]],

         [[-2.0606e-02, -3.0017e-02, -4.2409e-02],
          [-3.8846e-02, -2.1023e-02, -2.3158e-02],
          [-1.8858e-02, -2.0132e-02, -2.1347e-02]],

         [[ 3.0966e-02,  2.2454e-02,  2.1628e-02],
          [-1.4633e-02,  3.5285e-03,  8.0430e-04],
          [ 3.7988e-03, -2.6809e-03,  6.2538e-03]]],


        [[[ 1.6407e-01,  1.0967e-01,  1.5278e-01],
          [ 1.9659e-01,  1.5155e-01,  1.5199e-01],
          [ 1.1947e-01,  1.4954e-01,  1.1909e-01]],

         [[ 6.7720e-02,  1.4779e-01,  1.6977e-01],
          [ 1.0759e-01,  1.5109e-01,  1.3400e-01],
          [ 1.4679e-01,  1.1283e-01,  7.9238e-02]],

         [[ 4.3010e-01,  4.1349e-01,  3.3435e-01],
          [ 3.3523e-01,  3.7894e-01,  3.6660e-01],
          [ 3.4610e-01,  3.0348e-01,  3.2541e-01]],

         ...,

         [[ 1.7422e-01,  1.2319e-01,  1.7807e-01],
          [ 1.3168e-01,  1.4664e-01,  7.5703e-02],
          [ 8.7482e-02,  1.2710e-01,  1.0617e-01]],

         [[ 2.8918e-01,  2.1335e-01,  3.0835e-01],
          [ 2.9417e-01,  2.6610e-01,  3.8148e-01],
          [ 3.5822e-01,  1.8312e-01,  2.4299e-01]],

         [[ 6.2543e-01,  6.9266e-01,  6.6342e-01],
          [ 6.4601e-01,  6.5722e-01,  6.6194e-01],
          [ 7.1699e-01,  7.2908e-01,  6.5544e-01]]],


        ...,


        [[[-3.0835e-03, -5.4564e-03, -4.0023e-03],
          [-4.0692e-03, -5.8401e-03, -5.1373e-03],
          [-3.0648e-03, -2.8590e-03, -4.6755e-03]],

         [[-3.8954e-03, -4.8944e-03, -5.4123e-03],
          [-1.1260e-02, -8.1189e-03, -8.4610e-03],
          [-7.5158e-03, -1.0222e-02, -8.0837e-03]],

         [[-1.4891e-02, -1.4623e-02, -2.0755e-02],
          [-2.3570e-02, -1.8869e-02, -2.5201e-02],
          [-2.3054e-02, -2.1368e-02, -1.9387e-02]],

         ...,

         [[-7.3070e-03, -1.0875e-02, -7.4364e-03],
          [-6.0824e-03, -5.9057e-03, -9.7995e-03],
          [-5.6780e-03, -4.5554e-03, -5.1283e-03]],

         [[-6.7616e-03, -8.6668e-03, -1.2406e-02],
          [-1.7809e-02, -1.6932e-02, -1.4825e-02],
          [-1.3919e-02, -1.8692e-02, -1.7844e-02]],

         [[-1.1690e-02, -1.2990e-02, -9.4364e-03],
          [-3.4773e-02, -3.4121e-02, -3.0164e-02],
          [-3.9313e-02, -4.2817e-02, -4.0379e-02]]],


        [[[-1.1916e-02, -8.5964e-03, -1.0027e-02],
          [-9.8618e-03, -1.3041e-02, -9.8269e-03],
          [-1.3514e-02, -1.5581e-02, -1.3258e-02]],

         [[-4.4533e-03, -6.6127e-03, -5.6980e-03],
          [-4.0484e-03, -4.0086e-03, -5.0111e-03],
          [-4.2605e-03, -4.7118e-03, -7.7490e-03]],

         [[-2.5376e-02, -2.8867e-02, -3.2323e-02],
          [-1.9552e-02, -2.3627e-02, -2.7003e-02],
          [-1.9886e-02, -1.9896e-02, -2.6292e-02]],

         ...,

         [[-8.8458e-03, -8.3307e-03, -7.5918e-03],
          [-1.1403e-02, -1.1842e-02, -1.1067e-02],
          [-1.5496e-02, -1.6875e-02, -1.5704e-02]],

         [[-1.7235e-02, -2.2534e-02, -1.8846e-02],
          [-1.8398e-02, -1.8702e-02, -1.9821e-02],
          [-2.2294e-02, -1.8882e-02, -2.1458e-02]],

         [[-2.3913e-02, -3.0531e-02, -3.6398e-02],
          [-2.0194e-02, -2.3742e-02, -3.0163e-02],
          [-1.7456e-02, -1.2982e-02, -2.0532e-02]]],


        [[[-3.1058e-02,  1.6961e-02, -5.0719e-02],
          [-2.3574e-02,  2.1136e-02, -5.6111e-04],
          [-7.0931e-02, -4.7651e-02, -1.5537e-02]],

         [[ 4.7571e-02, -7.3376e-03,  3.1953e-02],
          [ 1.1158e-01,  5.7628e-02, -1.6457e-04],
          [ 1.5481e-03, -5.2596e-03, -5.0020e-03]],

         [[ 5.3417e-02,  2.0064e-01,  1.3220e-01],
          [-1.2124e-01, -1.6742e-01, -8.4608e-02],
          [-2.1417e-01, -2.5808e-01, -3.0919e-01]],

         ...,

         [[ 2.0335e-02,  1.1659e-01, -2.2834e-02],
          [ 1.9424e-01,  2.3623e-01,  1.9429e-01],
          [ 8.7264e-03,  4.6949e-02,  3.9763e-02]],

         [[-2.1546e-02,  4.8327e-02,  2.2329e-02],
          [ 1.4284e-01,  4.5180e-02, -4.6276e-02],
          [ 1.0123e-01,  2.4752e-01,  1.2154e-01]],

         [[-3.1303e-01, -2.8268e-01, -2.1845e-01],
          [-1.3687e-01, -1.7780e-01, -2.2222e-01],
          [-6.3108e-03,  3.5331e-02,  1.3386e-01]]]], device='cuda:0'), 'backend.2.bias': tensor([-9.5444e-02,  1.2118e-01, -7.2392e-03, -1.1388e-01, -1.4564e-01,
        -1.3559e-02,  3.4900e-03,  7.2919e-02,  7.2378e-02, -8.7558e-02,
        -2.1074e-01, -4.4167e-02, -1.4517e-04, -2.8609e-02, -7.1422e-02,
        -1.7638e-01,  7.6595e-02, -9.6583e-02, -3.9318e-02,  1.0934e-02,
        -9.4708e-03, -5.9568e-03, -1.8186e-01,  6.3052e-02, -9.9820e-02,
         6.5248e-02, -1.8788e-01, -2.5883e-02, -7.8021e-02, -1.6218e-01,
         2.9942e-02,  2.5173e-02, -1.4130e-01, -1.0983e-02,  1.9060e-01,
        -6.5442e-02,  2.4095e-01,  2.0355e-01,  5.0609e-02,  3.8263e-01,
         8.4442e-02,  5.4896e-04,  5.1957e-03, -5.1470e-03, -1.3074e-01,
        -9.0038e-02, -1.0444e-01, -7.5573e-02, -4.8597e-02, -1.1293e-01,
         1.2866e-02, -6.1113e-02,  3.9259e-02,  2.2155e-02, -1.2546e-01,
         5.5563e-02, -8.7543e-02, -4.8289e-01,  2.3834e-02,  2.4616e-04,
         1.9772e-02,  3.4711e-02, -1.0664e-01, -8.6276e-03, -3.3263e-02,
        -2.8560e-02,  1.6659e-02, -3.4660e-02, -2.5922e-01,  1.1552e-01,
         1.8184e-02, -1.5381e-01, -5.6099e-02, -5.9998e-02, -2.5072e-01,
        -1.1116e-01,  1.4272e-01, -2.8125e-02,  2.4978e-01,  1.3900e-01,
        -2.2722e-01,  1.6406e-02,  1.9515e-02, -1.4806e-02,  2.3783e-02,
        -2.5479e-02, -9.9126e-02,  5.5197e-03,  9.6800e-03,  8.9836e-04,
         1.0361e-01, -8.6633e-02,  8.5515e-02,  8.5148e-02,  4.3013e-01,
        -1.7292e-01,  2.5248e-01, -2.4306e-02, -1.4437e-01, -9.8616e-02,
        -2.0639e-02, -2.6137e-02, -3.1094e-01,  2.7443e-01,  1.5304e-02,
        -5.0390e-02, -7.4305e-02,  6.4033e-02,  1.5671e-02,  1.0776e-01,
         5.7241e-02, -6.2665e-02, -6.3631e-02, -1.7401e-01, -1.7384e-01,
        -2.9029e-02, -3.5189e-02, -1.0351e-01,  5.5872e-02, -3.7028e-02,
        -9.5963e-02, -8.1390e-02, -1.5220e-01,  1.9719e-01, -1.1948e-01,
        -1.6690e-01, -9.5104e-02,  1.5895e-01, -4.6992e-02,  8.7210e-03,
        -4.3617e-02,  1.1448e-01, -2.8033e-02,  1.1368e-01, -6.3128e-02,
         2.6903e-03,  2.8196e-02, -7.3620e-02, -1.2489e-01, -6.4820e-04,
         3.3711e-01, -2.7533e-02, -1.2788e-01, -1.1738e-01, -1.4322e-01,
        -6.4528e-02,  4.3952e-02,  4.8670e-02,  1.0128e-01, -5.3158e-02,
         1.9053e-02,  5.7651e-03, -2.0636e-01,  4.9392e-02,  1.0601e-01,
         2.6320e-01,  9.8338e-03, -4.2334e-02,  4.7638e-02,  4.1247e-02,
        -4.3124e-02,  4.6514e-02, -1.8739e-02, -1.7739e-01,  1.6252e-01,
         5.0900e-02,  5.9270e-02, -7.1251e-02, -1.3990e-01, -1.2606e-02,
         1.3636e-01, -1.9153e-02,  9.9166e-02,  9.7898e-03, -7.9689e-03,
         9.6062e-02, -1.1978e-02, -2.6989e-02,  5.5690e-02, -2.0705e-02,
        -7.5232e-03,  9.6906e-02, -2.6949e-02,  1.9294e-02, -1.2362e-01,
        -2.1191e-01,  2.5299e-02, -4.3555e-02,  5.8500e-02,  2.8265e-03,
         3.3447e-03, -2.0438e-01, -1.5362e-01, -7.2068e-02, -1.3362e-01,
        -6.9233e-02,  7.7563e-03, -2.2435e-01, -5.0221e-02, -6.3791e-02,
         1.4208e-01, -1.0317e-01, -4.3361e-02,  2.3451e-01, -1.0269e-02,
        -2.0785e-01, -1.0588e-01, -1.0867e-01,  7.9159e-02,  2.6166e-02,
        -3.6232e-02,  2.0472e-01, -4.7376e-02, -2.2673e-01,  8.8925e-02,
        -1.1418e-01, -3.3486e-02,  1.1014e-01,  5.6062e-02, -5.1887e-03,
         5.2244e-02,  4.1363e-01,  1.6679e-01, -2.8170e-02, -1.5872e-01,
         1.9176e-01, -2.1000e-03,  2.7883e-01,  1.0203e-01, -3.1546e-03,
        -1.3493e-01,  2.3951e-02,  6.8330e-03, -2.6367e-02, -1.9137e-03,
        -2.4798e-02, -9.5864e-02,  3.1372e-01,  1.0827e-01, -3.9025e-01,
         1.2347e-02,  1.6870e-01, -1.3240e-02,  9.2258e-02, -1.0211e-01,
        -2.7446e-01, -1.4298e-01,  4.5025e-03,  9.2051e-02, -9.7850e-03,
        -1.4302e-01, -5.0958e-02,  1.0820e-01,  7.1857e-02, -1.1097e-01,
        -2.3029e-02, -1.9032e-01, -3.1622e-01, -1.0966e-01,  2.0771e-02,
        -1.2985e-01,  7.2917e-02, -6.8903e-03,  2.2243e-02,  4.5559e-02,
         4.6642e-02,  1.0876e-01,  1.8415e-01,  2.5827e-02, -3.4739e-03,
        -3.4905e-02, -1.1110e-01, -7.4530e-05, -5.3388e-02, -2.1667e-01,
         2.3660e-01,  8.3034e-02,  1.6274e-01, -6.9703e-02, -2.4589e-03,
         3.3348e-01, -5.4758e-02,  2.8822e-02, -5.8685e-02,  3.8903e-02,
        -2.1663e-01,  2.5281e-03,  1.5021e-01, -1.5285e-02,  5.2173e-03,
         3.5756e-02,  9.5711e-02,  2.2947e-01, -8.4514e-03,  1.3986e-01,
         3.1626e-02,  2.7621e-01,  1.1267e-01,  7.1205e-03,  6.4727e-02,
         5.0483e-02, -1.1644e-01, -1.0756e-01,  7.3279e-02,  2.8580e-01,
        -1.7353e-01,  2.0274e-01, -5.0729e-01, -2.1406e-01, -1.3283e-01,
        -1.5439e-02, -9.0183e-02,  1.2485e-01,  7.0724e-03,  5.6439e-02,
        -2.2060e-02, -3.1489e-01,  7.7755e-02, -2.7833e-02, -3.0607e-02,
         6.8864e-02, -7.9890e-02, -2.6296e-02,  1.7895e-02,  1.6963e-01,
         8.7095e-02,  1.7394e-02, -2.1468e-01,  2.5737e-02,  1.3855e-02,
         8.3725e-03, -2.8858e-01,  1.6856e-03,  5.3387e-02,  9.3109e-02,
         6.1979e-03, -5.2586e-02,  1.9725e-01, -3.6482e-01, -1.1734e-01,
         2.1406e-01, -1.0737e-02, -3.6181e-01,  5.7253e-01, -5.5063e-02,
         3.8287e-02, -5.8543e-01,  2.0143e-01,  5.1463e-03,  1.5530e-01,
        -5.8389e-02,  9.6524e-02,  3.9104e-03,  1.5408e-01, -6.9836e-04,
         3.3011e-01,  8.9390e-02,  1.8885e-01, -1.6545e-02,  1.7813e-03,
        -6.3069e-02, -2.0381e-02, -7.3931e-02,  5.7187e-02, -2.2169e-01,
        -1.7594e-01,  7.2577e-02,  8.9697e-02,  1.4016e-01,  1.4531e-01,
        -4.8203e-02, -7.4428e-02, -1.2660e-01,  2.2440e-02, -1.7195e-01,
         5.1157e-02, -1.6276e-02, -8.0198e-02,  1.0578e-01, -3.3091e-02,
         1.2326e-01,  1.1280e-01,  1.3938e-02, -2.6170e-01, -4.8323e-02,
         1.8080e-01, -8.4015e-02,  4.3010e-02, -2.0496e-01, -4.6514e-02,
         2.2161e-01,  2.0267e-02, -2.6133e-01, -6.8646e-02,  1.0455e-02,
        -1.6855e-02, -4.4688e-01, -2.6737e-01, -5.5871e-02, -7.4337e-02,
        -4.4163e-01, -6.0502e-02, -4.2867e-02,  2.1000e-01, -3.5373e-02,
         1.9708e-01,  8.2754e-03, -6.6392e-03,  9.9985e-03, -1.5928e-01,
        -9.6030e-02, -8.3696e-02, -2.3542e-01, -3.2169e-02,  2.4576e-02,
        -4.3335e-01, -1.3247e-01,  3.6885e-02, -1.4186e-01,  5.9461e-03,
        -9.1733e-02, -1.2927e-01,  8.5177e-02, -1.1441e-03,  4.2597e-02,
         5.3825e-02, -1.4818e-01, -7.7130e-02, -2.5510e-02,  2.2265e-01,
        -6.6041e-02, -1.0947e-01, -4.1537e-01, -2.4049e-02,  2.0213e-01,
        -1.0381e-01,  3.8251e-02, -2.7223e-02, -4.7805e-02, -1.2561e-02,
        -1.4074e-02, -1.2187e-01,  1.6062e-01, -1.7874e-01, -1.2772e-03,
         1.0068e-01,  3.8112e-02, -1.4348e-01,  1.2197e-01,  1.3995e-03,
        -1.0439e-02,  6.5088e-02,  1.1839e-02, -7.3008e-02, -2.5583e-01,
         2.6148e-03,  1.5690e-01,  1.7598e-01,  6.9527e-02, -6.1460e-02,
        -9.7276e-02,  3.5660e-02,  4.7912e-02,  8.2737e-02,  1.4097e-02,
         4.9413e-02,  4.2054e-02,  1.4344e-01, -6.2792e-02,  4.0246e-04,
         1.5250e-01, -1.7522e-01, -5.9423e-02, -1.0787e-01, -2.6685e-03,
         4.5776e-02, -1.4194e-01,  3.6366e-01,  1.7674e-01,  3.2443e-01,
        -2.4558e-01,  1.8080e-02, -3.6560e-01,  2.6439e-03,  9.1668e-02,
         7.1591e-03, -9.6864e-02, -6.1575e-02, -3.0196e-01, -1.1254e-01,
        -5.5085e-02, -5.7569e-02,  1.0761e-01, -2.8559e-02, -4.1266e-01,
         4.0286e-02,  2.9999e-02, -6.0385e-02,  3.4556e-02, -2.6565e-01,
        -3.9136e-02, -5.7809e-02,  1.2102e-01,  5.8583e-02, -1.1469e-02,
         4.9079e-02, -1.0090e-01, -8.9323e-02, -9.7827e-02,  7.6054e-02,
        -2.5764e-01,  1.2564e-02], device='cuda:0'), 'backend.10.bias': tensor([-5.8029e+00, -5.3878e+01,  1.0696e+01,  2.2877e+01, -1.1115e+01,
         2.1028e-01, -3.5056e+00, -4.7255e+00, -1.8161e+00,  5.6121e-01,
        -4.5989e+00, -1.4484e+01, -2.5311e+01, -2.5464e-01, -1.0811e+01,
        -1.0108e+01,  2.4036e+00,  7.8466e-01, -1.4855e+01, -3.5416e+01,
         3.4983e+00, -1.6306e+01, -2.6800e-01, -1.6920e-02,  1.0981e+00,
         2.8397e+01,  8.6920e-01, -1.3417e+00, -4.1239e-01, -3.3987e+01,
        -1.3303e+01, -3.8404e+00, -7.8278e-01,  4.7887e-02, -2.9392e-01,
        -4.3888e+01,  3.2917e-01, -5.0268e+01, -4.0567e-01,  8.4493e-01,
         5.0143e+00, -5.7116e+01,  7.1828e-02,  1.0728e+00,  4.6707e-01,
        -3.4152e+01, -7.9423e+00,  4.3289e-01,  1.0090e+01, -6.5736e-01,
        -2.2008e+01,  1.0102e+00, -2.4218e-01, -1.8479e+01, -2.5554e-02,
         7.1699e+00,  1.1377e+00,  1.8071e+00,  4.5674e+00,  8.1736e+00,
         1.3086e+00,  2.5759e+00, -2.7065e+01, -2.6927e-01], device='cuda:0'), 'output_layer.bias': tensor([-2368.7085], device='cuda:0'), 'backend.2.weight': tensor([[[[-2.6738e-02, -3.9613e-02, -8.0086e-03],
          [-1.7404e-02, -5.3062e-02, -2.6566e-02],
          [-3.5891e-02, -4.0332e-02, -1.3288e-02]],

         [[-8.8580e-03, -7.8051e-03, -8.0928e-03],
          [-1.2177e-02, -8.5552e-03, -4.6050e-03],
          [-1.0736e-02, -2.2346e-03, -2.1008e-03]],

         [[-5.4202e-02, -2.8205e-02, -6.6149e-02],
          [-9.3614e-02, -8.7683e-02, -1.0216e-01],
          [-8.6320e-02, -6.5345e-02, -6.5383e-02]],

         ...,

         [[-6.8697e-02, -1.2342e-01, -6.7857e-02],
          [-5.2468e-02, -1.2091e-01, -9.2998e-02],
          [-1.5116e-01, -1.8670e-01, -1.7145e-01]],

         [[-3.5144e-02, -2.8828e-02, -2.5548e-02],
          [-4.4438e-02, -3.8224e-02, -3.8731e-02],
          [-2.2132e-02, -2.8051e-02, -2.6023e-02]],

         [[-2.7208e-02, -1.4605e-02, -2.6464e-02],
          [-1.3161e-02, -1.7328e-02, -2.3119e-02],
          [-3.2824e-02, -1.9330e-02, -3.9086e-02]]],


        [[[ 7.7712e-02,  3.7034e-02,  5.9199e-02],
          [ 6.9622e-02,  3.8968e-02,  3.4251e-02],
          [ 5.2235e-02,  4.0353e-02,  4.5524e-02]],

         [[ 8.7286e-03,  1.0781e-02,  1.1893e-02],
          [ 7.5953e-03,  7.7005e-03,  8.8367e-03],
          [ 1.1768e-02,  6.2633e-03,  1.1724e-02]],

         [[ 7.2416e-02,  8.9040e-02,  8.2410e-02],
          [ 8.0393e-02,  7.5214e-02,  6.3761e-02],
          [ 7.1168e-02,  1.0386e-01,  9.9016e-02]],

         ...,

         [[ 1.4388e-01,  1.0236e-01,  1.3851e-01],
          [ 1.2052e-01,  1.1337e-01,  1.7001e-01],
          [ 1.5285e-01,  1.2835e-01,  1.4203e-01]],

         [[ 6.6291e-02,  5.3913e-02,  5.6078e-02],
          [ 4.6756e-02,  4.0121e-02,  2.8890e-02],
          [ 3.1188e-02,  4.4871e-02,  4.0963e-02]],

         [[ 2.8076e-02,  3.7205e-02,  3.6338e-02],
          [ 1.5340e-02,  4.2387e-02,  3.7633e-02],
          [ 1.9189e-02,  3.1697e-02,  4.1697e-02]]],


        [[[-9.8591e-03, -5.9435e-04, -1.5901e-03],
          [-1.4481e-03,  7.3029e-03, -3.8602e-03],
          [-8.3025e-03, -4.2081e-05, -1.1306e-02]],

         [[-6.2677e-04, -3.3449e-04,  7.6605e-05],
          [ 4.1102e-03,  6.4966e-04, -1.6109e-03],
          [ 1.8855e-03,  1.6980e-03, -2.0550e-03]],

         [[-1.1348e-02, -4.0542e-03, -9.0500e-03],
          [-2.9626e-03, -7.6351e-03, -1.2747e-02],
          [-1.6145e-02, -2.2904e-02, -9.9329e-03]],

         ...,

         [[-1.6460e-02, -2.5879e-02, -7.2921e-03],
          [-3.2705e-02,  8.7728e-03, -2.2338e-02],
          [-3.5230e-03,  5.4277e-03, -9.8812e-03]],

         [[ 5.0232e-03, -4.1964e-03,  3.6696e-03],
          [ 7.6091e-03, -2.2833e-03,  6.1415e-03],
          [-9.2003e-03, -6.9910e-03, -5.7210e-03]],

         [[-4.1634e-03, -5.1097e-03,  1.0458e-03],
          [-7.3520e-03, -3.9129e-03,  8.5426e-03],
          [-5.4494e-03, -4.1670e-03, -1.1901e-02]]],


        ...,


        [[[-8.8282e-03,  4.3768e-03,  6.6470e-02],
          [-8.1392e-03,  2.4335e-02,  4.2201e-02],
          [-1.7271e-02,  3.1400e-02,  6.8162e-02]],

         [[-4.0399e-03,  5.5715e-03,  1.0041e-02],
          [ 2.1243e-03,  7.6126e-03,  1.1768e-03],
          [ 6.4521e-04,  9.1153e-03,  6.0501e-03]],

         [[-2.5100e-02,  1.5328e-02, -1.1100e-03],
          [ 1.4342e-03,  2.7359e-02, -5.7296e-03],
          [-1.0061e-02,  1.4971e-03, -1.9917e-03]],

         ...,

         [[ 2.0682e-01,  1.0093e-01,  1.4818e-01],
          [ 6.5352e-02,  1.9606e-01,  2.1523e-01],
          [ 1.7583e-01,  1.0938e-01,  1.1586e-01]],

         [[-1.5124e-02, -9.0417e-03,  1.3640e-03],
          [-2.0700e-02, -1.1766e-02, -4.5475e-03],
          [-1.5399e-02, -1.9581e-02, -1.5346e-02]],

         [[ 8.9628e-03,  4.3922e-02,  3.4448e-02],
          [ 3.6678e-02,  5.0560e-02,  1.8872e-02],
          [ 3.5364e-02,  5.3386e-02,  2.4553e-02]]],


        [[[-6.4075e-02, -7.1426e-02, -1.3558e-01],
          [-1.0439e-01, -1.0575e-01, -1.1695e-01],
          [-1.1025e-01, -1.1215e-01, -1.0477e-01]],

         [[-1.5107e-02, -2.1761e-02, -2.7486e-02],
          [-2.0304e-02, -1.2360e-02, -2.1811e-02],
          [-2.3954e-02, -1.2941e-02, -1.2730e-02]],

         [[-1.3944e-01, -1.1372e-01, -1.1284e-01],
          [-1.5474e-01, -1.2212e-01, -1.1001e-01],
          [-1.8234e-01, -1.5628e-01, -1.4351e-01]],

         ...,

         [[-4.4711e-01, -4.0074e-01, -4.7918e-01],
          [-3.8266e-01, -4.4923e-01, -4.4080e-01],
          [-4.6187e-01, -4.5300e-01, -4.6997e-01]],

         [[-2.4720e-02, -3.4569e-02, -2.5149e-02],
          [-3.2766e-02, -3.5457e-02, -3.5847e-02],
          [-2.8945e-02, -3.0526e-02, -3.7149e-02]],

         [[-6.7309e-02, -7.3472e-02, -8.8186e-02],
          [-9.3798e-02, -9.4707e-02, -9.7847e-02],
          [-9.2637e-02, -8.5534e-02, -7.9306e-02]]],


        [[[-3.6619e-02, -1.3961e-02, -1.0301e-02],
          [-8.8742e-02, -4.4198e-02, -1.8942e-02],
          [-7.0732e-02, -3.1262e-02,  2.7324e-02]],

         [[-9.3142e-03,  8.7462e-04, -9.4222e-03],
          [-5.9762e-03, -2.6659e-03, -8.2793e-03],
          [ 3.5156e-03,  4.4630e-03, -7.3936e-04]],

         [[ 7.3822e-02,  4.9794e-02,  1.5397e-02],
          [ 1.2660e-01,  1.1229e-01,  9.8425e-02],
          [ 4.8687e-02,  5.5703e-02,  1.0727e-01]],

         ...,

         [[-8.3061e-02, -1.9624e-02,  9.4111e-02],
          [-1.6089e-02,  5.3198e-02,  5.2265e-02],
          [ 5.3611e-02,  5.5292e-02,  4.2042e-02]],

         [[-3.1701e-02, -4.6874e-02, -5.6749e-02],
          [-1.4007e-02, -1.7434e-02,  8.5373e-03],
          [-3.1720e-03, -1.3168e-02, -6.2185e-03]],

         [[-1.9240e-03,  1.0770e-02,  9.0756e-03],
          [-1.2533e-02, -1.8815e-04, -3.9583e-03],
          [-4.5659e-03, -1.1592e-02,  7.9180e-03]]]], device='cuda:0'), 'backend.6.bias': tensor([-8.3898e-02, -1.6170e-02,  1.1420e+00, -5.7550e-02,  5.3863e-01,
        -8.3389e-01,  1.1408e-01,  3.1572e-02, -1.6201e-01, -2.2798e-01,
        -1.0613e+00,  1.7285e-02, -1.9214e+00, -1.1184e-01, -6.8129e-01,
         2.2950e-02, -1.4048e+00, -2.4419e-01,  9.4105e-01,  2.4619e-01,
         3.1539e-01, -3.4581e-01,  4.3028e-01,  2.8217e-03, -6.5242e-01,
         1.2156e+00, -1.1701e+00,  9.7104e-02,  1.8542e-01, -8.4766e-01,
        -8.2549e-02,  8.8012e-01,  1.3529e+00,  1.4453e-01, -1.8760e-01,
         2.3450e-01, -5.5987e-02,  4.2681e-01, -3.5007e-01,  5.4509e-01,
        -8.3722e-01,  6.0962e-02,  8.9386e-03, -6.9753e-03,  2.5819e-01,
        -8.1418e-01, -1.1959e+00,  7.2166e-01, -1.3468e-01, -9.9605e-01,
         2.0732e+00,  7.9013e-01,  1.2127e+00, -1.5427e-01,  2.0351e-01,
        -5.0857e-01, -2.5497e-01, -2.5927e-01, -5.9101e-03, -1.0637e-01,
        -7.7560e-01, -3.9563e-01, -5.0864e-01, -4.2363e-01, -1.1203e-01,
         1.5607e+00,  1.1222e+00, -2.8460e-01, -5.2958e-01,  4.4043e-01,
        -2.0771e+00,  1.1595e+00,  5.9845e-01,  6.1728e-02,  3.3175e-02,
        -4.1539e-01,  5.6375e-01, -1.5174e+00, -9.2519e-01, -7.4753e-01,
         2.4033e-03, -7.1819e-02, -3.7930e-01, -1.2810e+00,  1.7283e+00,
        -1.5666e-02, -1.0817e-01,  4.1597e-01, -5.1974e-01, -2.8064e-01,
         4.1466e-01, -2.6418e-01, -9.3957e-01,  1.0207e+00,  2.1993e-01,
         7.7892e-01, -1.2826e-02, -9.0745e-01,  5.0318e-01, -1.2849e+00,
        -1.3128e+00,  1.6148e-02,  1.0761e-01,  1.2552e-02, -7.9037e-01,
        -4.6911e-01, -1.1418e+00, -7.8196e-02,  2.5990e-03,  1.5220e-02,
         5.2965e-02, -5.6886e-01,  2.0896e-01, -2.1517e-02,  4.7351e-01,
        -1.4713e+00, -3.6948e-01,  2.1909e-02,  1.2982e+00,  1.3832e+00,
        -4.6231e-01, -2.0406e-02,  2.7874e-02, -1.9149e+00,  1.5788e+00,
        -8.4886e-01,  1.3790e+00,  3.3353e+00, -1.1661e+00, -4.0027e-01,
         1.9986e-01,  1.0771e+00,  9.1899e-01, -6.6467e-01,  4.5549e-01,
         1.8903e+00, -7.6614e-01,  2.3348e-02, -1.0125e+00, -2.0532e+00,
        -8.9911e-01,  1.2650e+00, -1.0543e+00,  8.2443e-01, -8.1073e-01,
        -4.6521e-02, -4.7326e-04, -3.0504e-01, -9.6905e-03, -5.8533e-01,
        -5.4517e-01, -6.6429e-01, -2.3237e-02,  2.0377e+00,  1.8188e+00,
        -7.2864e-01, -2.5928e-02,  4.8815e-02, -2.2779e-04, -5.5808e-01,
        -3.7023e-01, -1.1683e-01, -1.0920e+00, -8.0476e-03,  8.5100e-02,
         1.4044e+00, -1.8894e-02, -1.2077e-01, -2.6243e-01, -4.0546e-01,
         2.1496e-02,  9.4086e-02, -6.4143e-01, -1.6538e+00, -8.9192e-01,
        -4.8411e-01,  1.4858e-02,  5.2869e-01,  1.6901e-01, -2.0868e-01,
         1.7790e-02,  4.9152e-01,  4.9781e-01, -7.0547e-01,  1.7543e-01,
        -7.4892e-01, -5.0036e-01, -6.2179e-02,  3.3095e-02,  1.9181e+00,
         4.4188e-01,  2.4910e-01, -3.7713e-01,  1.5005e+00,  3.7024e-01,
        -1.5421e-01, -2.9336e-01, -2.8169e-01, -1.0113e-01, -1.9074e+00,
        -6.8935e-01, -6.8837e-01,  1.9108e-01, -6.8252e-01, -6.3966e-01,
         1.6775e-01,  8.4237e-01, -4.1269e-01,  1.0999e+00,  1.0861e+00,
         5.0100e-01,  2.0692e-02, -7.4594e-01, -4.0649e-01,  3.1674e-01,
         4.7350e-02, -1.3426e-02,  4.4528e-01, -1.0489e+00, -1.3415e+00,
         3.2184e-01,  8.5183e-01, -3.3267e-01, -2.9079e-01, -4.9677e-01,
        -1.3985e-01,  4.5514e-02,  6.9376e-01, -1.9076e+00,  1.0485e+00,
        -5.9901e-01,  1.0391e+00, -3.5584e-01, -1.5562e-01, -7.4192e-01,
         1.9428e+00, -1.1659e+00, -4.8476e-02, -9.1319e-02, -1.1107e+00,
        -7.8743e-01, -1.0142e+00,  1.9766e-02,  6.6773e-02, -1.4531e-01,
        -2.2162e-01,  3.6885e-01, -3.8783e-01,  3.8288e-01, -7.1044e-01,
        -2.3415e-01, -3.7066e-01,  5.3615e-01, -6.6176e-02, -6.9477e-02,
         9.0328e-04], device='cuda:0'), 'backend.0.weight': tensor([[[[-1.0965e-02, -1.7621e-02, -1.1160e-02],
          [-3.1522e-03, -5.4649e-03, -6.9491e-03],
          [ 4.9172e-03,  6.9461e-03,  1.3815e-03]],

         [[-9.4742e-02, -8.2677e-02, -6.6369e-02],
          [ 5.5755e-03, -1.3247e-02, -4.1414e-02],
          [ 9.9203e-02,  7.3023e-02, -2.9837e-03]],

         [[ 5.2263e-02,  5.8763e-02,  5.5730e-02],
          [ 6.1538e-02,  8.4551e-02,  3.7032e-02],
          [ 1.0334e-01,  9.4034e-02,  6.6054e-02]],

         ...,

         [[ 4.8523e-04,  4.6800e-04,  3.1705e-03],
          [ 1.0356e-04, -2.0711e-03, -2.6303e-03],
          [ 7.7477e-04, -3.3155e-03, -2.7112e-03]],

         [[ 2.9972e-03, -6.2091e-03,  2.7156e-02],
          [-5.4838e-03, -1.4382e-02,  8.3724e-04],
          [-1.3313e-03,  7.5204e-03, -1.0119e-02]],

         [[ 7.4048e-02,  9.7492e-02,  1.3282e-01],
          [ 8.5057e-02,  8.1243e-02,  8.0770e-02],
          [ 7.5957e-02,  9.3832e-02,  8.4564e-02]]],


        [[[ 3.3563e-03,  5.4453e-03,  3.4572e-03],
          [ 7.2755e-03,  8.1887e-03,  2.1705e-03],
          [ 5.1397e-04,  5.7356e-03,  8.8268e-03]],

         [[ 1.1156e-01,  1.0452e-01,  8.9038e-02],
          [ 9.8319e-02,  1.2030e-01,  8.4502e-02],
          [ 8.3780e-02,  8.3955e-02,  6.3717e-02]],

         [[ 1.8970e-02,  2.2374e-02,  1.1430e-02],
          [ 1.7493e-02,  1.1409e-02,  1.2681e-02],
          [ 4.9749e-04, -3.6670e-03, -6.4817e-03]],

         ...,

         [[ 4.9068e-03,  4.3096e-03,  2.7921e-04],
          [ 3.1393e-03,  2.7693e-03,  4.3251e-03],
          [-1.0944e-03,  2.5519e-03,  2.1074e-03]],

         [[ 1.2171e-02,  1.2222e-02,  7.5669e-03],
          [ 1.7481e-02,  2.1930e-02,  1.4792e-02],
          [ 1.9990e-02,  2.3992e-02,  2.8637e-02]],

         [[ 9.6593e-03, -4.9516e-03,  1.7026e-02],
          [ 5.5919e-03, -9.2158e-03,  2.0788e-02],
          [-8.4709e-03, -1.2849e-04,  8.8651e-03]]],


        [[[ 1.0118e-02,  1.2774e-02,  7.2153e-03],
          [ 1.0305e-02,  1.2341e-02,  4.9393e-03],
          [ 1.7319e-02,  2.1505e-02,  1.9970e-03]],

         [[ 2.1415e-01,  1.4136e-01,  1.1735e-01],
          [ 2.9939e-01,  2.4250e-01,  1.0767e-01],
          [ 2.0077e-01,  2.0030e-01,  4.3087e-02]],

         [[ 4.6796e-02,  5.1594e-02,  4.4769e-02],
          [ 3.4122e-02,  5.9093e-02,  4.1480e-02],
          [ 7.0840e-02,  7.7758e-02,  7.5428e-02]],

         ...,

         [[-6.3571e-04, -4.8430e-04, -4.7803e-03],
          [ 1.0010e-02,  5.5797e-03,  5.0049e-03],
          [ 8.7089e-03,  4.7927e-03,  6.8310e-03]],

         [[ 5.1332e-02,  2.5495e-02,  5.5952e-03],
          [ 4.4769e-02,  3.4323e-02,  7.7120e-03],
          [ 3.5576e-02,  4.2394e-02,  2.2569e-02]],

         [[ 5.0627e-02,  2.1955e-02,  8.0027e-02],
          [-2.6765e-02,  7.8546e-03,  5.7529e-02],
          [ 7.2560e-02,  8.3124e-02,  7.9690e-02]]],


        ...,


        [[[ 2.0044e-02,  6.3766e-03,  5.0225e-04],
          [ 2.1294e-02,  8.4856e-03, -6.0190e-03],
          [ 1.8921e-02,  1.4829e-02,  8.0016e-03]],

         [[ 2.1407e-01,  1.7944e-01,  2.6115e-02],
          [ 2.9567e-01,  2.6751e-01,  9.5502e-02],
          [ 2.9139e-01,  2.5383e-01,  8.2909e-02]],

         [[ 1.7746e-01,  1.9658e-01,  1.8618e-01],
          [ 7.2046e-02,  4.3122e-02,  1.0901e-01],
          [ 1.5234e-01,  1.9394e-01,  1.6791e-01]],

         ...,

         [[ 3.3875e-03, -5.1800e-04,  1.4071e-03],
          [ 3.2952e-03,  6.6850e-04, -3.8086e-03],
          [ 9.4259e-03,  8.2752e-03,  4.3091e-03]],

         [[ 6.2549e-02,  3.2152e-02, -9.1811e-03],
          [ 6.9781e-02,  1.9213e-02, -1.8661e-02],
          [ 7.1128e-02,  4.4202e-02,  1.8729e-03]],

         [[ 2.4898e-01,  2.3219e-01,  3.5021e-01],
          [ 3.2861e-02,  3.7562e-02,  1.8471e-01],
          [ 1.1136e-01,  1.3887e-01,  1.8594e-01]]],


        [[[ 4.4694e-02,  4.3509e-02,  3.1192e-02],
          [ 4.5764e-02,  4.5039e-02,  4.3092e-02],
          [ 5.0478e-02,  5.0647e-02,  4.6611e-02]],

         [[ 4.8130e-01,  4.9008e-01,  4.3751e-01],
          [ 4.3486e-01,  4.5149e-01,  4.4866e-01],
          [ 3.1297e-01,  3.5288e-01,  3.5299e-01]],

         [[ 4.8869e-02,  5.6781e-02,  6.4834e-02],
          [ 3.0821e-02,  3.8096e-02,  4.7186e-02],
          [ 6.1475e-02,  5.3461e-02,  4.0252e-02]],

         ...,

         [[ 1.1525e-02,  1.3004e-02,  1.0198e-02],
          [ 5.2148e-03,  1.3582e-03,  8.1859e-03],
          [ 6.3622e-03,  2.3228e-03,  4.0534e-03]],

         [[ 6.6030e-02,  5.6164e-02,  2.7975e-02],
          [ 5.5587e-02,  5.5609e-02,  3.7569e-02],
          [ 2.7228e-02,  1.7298e-02, -1.6129e-03]],

         [[ 4.3122e-02,  2.8378e-02,  3.5879e-02],
          [ 1.2766e-02,  2.6669e-02,  2.7427e-02],
          [ 5.3280e-02,  7.6970e-02,  1.1787e-02]]],


        [[[ 9.0564e-03,  9.5050e-03,  1.0587e-02],
          [ 1.3180e-02,  1.0427e-02,  1.5775e-02],
          [ 1.5143e-02,  1.6777e-02,  1.7505e-02]],

         [[ 1.0941e-01,  1.0080e-01,  1.7831e-01],
          [ 1.3935e-01,  1.4261e-01,  2.3914e-01],
          [ 1.8722e-01,  1.9382e-01,  2.4268e-01]],

         [[ 5.9846e-02,  6.3960e-02,  5.8495e-02],
          [ 9.4833e-02,  1.2498e-01,  1.2457e-01],
          [ 9.6724e-02,  1.0555e-01,  9.4718e-02]],

         ...,

         [[ 4.8431e-04,  2.5726e-03,  1.3078e-03],
          [ 3.2865e-03,  2.4151e-03,  3.0787e-03],
          [ 3.2824e-03,  2.0312e-03,  1.3947e-03]],

         [[ 1.3700e-02,  7.8332e-03,  2.1782e-02],
          [ 1.6425e-02,  1.2317e-02,  2.7762e-02],
          [ 1.4945e-02,  1.5760e-02,  1.8320e-02]],

         [[ 8.6320e-02,  1.5244e-01,  1.0609e-01],
          [ 1.5536e-01,  1.3366e-01,  1.5492e-01],
          [ 1.0859e-01,  8.9653e-02,  6.4167e-02]]]], device='cuda:0'), 'output_layer.weight': tensor([[[[-1.6358e+00]],

         [[-2.5940e+01]],

         [[-2.2885e+01]],

         [[-4.2481e+01]],

         [[-8.9195e+00]],

         [[-4.3450e-01]],

         [[-4.4648e+00]],

         [[-8.7988e+00]],

         [[-9.7922e+00]],

         [[-6.4884e+00]],

         [[-1.6077e+00]],

         [[-9.1065e+00]],

         [[-9.2577e+00]],

         [[-8.4950e+00]],

         [[-3.1119e+00]],

         [[-4.4014e+00]],

         [[-1.1049e+00]],

         [[-9.0646e+00]],

         [[-1.0693e+01]],

         [[-1.3028e+01]],

         [[-1.9226e+01]],

         [[-5.4063e+00]],

         [[-1.7429e+00]],

         [[-4.2664e-01]],

         [[-1.4460e+00]],

         [[-6.2714e+01]],

         [[-1.6194e+00]],

         [[-1.6695e+00]],

         [[-1.2076e+00]],

         [[-1.8779e+01]],

         [[-4.6703e+00]],

         [[-1.2733e+01]],

         [[-1.3408e+00]],

         [[ 4.5206e-02]],

         [[-4.8045e+00]],

         [[-1.6932e+01]],

         [[-6.8475e-01]],

         [[-2.4269e+01]],

         [[-4.6628e-01]],

         [[-6.4551e+00]],

         [[-3.5551e+00]],

         [[-2.7895e+01]],

         [[-2.5401e-01]],

         [[-4.7532e-01]],

         [[-1.3100e-01]],

         [[-1.7155e+01]],

         [[-2.8089e+00]],

         [[-2.4248e-01]],

         [[-1.8241e+01]],

         [[-4.4687e-01]],

         [[-5.6391e+00]],

         [[-2.1812e+00]],

         [[-1.2111e-01]],

         [[-4.8903e+00]],

         [[-4.5772e-03]],

         [[-2.9828e+01]],

         [[-1.2588e+00]],

         [[-2.7432e+00]],

         [[-3.9311e+00]],

         [[-2.8007e+01]],

         [[-3.5534e+00]],

         [[-2.1570e+00]],

         [[-1.0613e+01]],

         [[-2.9810e-01]]]], device='cuda:0'), 'backend.4.weight': tensor([[[[-1.2048e-02, -6.0804e-02, -5.4468e-02],
          [-8.9131e-03, -8.2508e-02, -6.2418e-02],
          [-1.1260e-02, -5.8706e-02, -4.9869e-04]],

         [[-3.8528e-02, -2.3249e-02,  2.3059e-02],
          [-6.0005e-02,  3.9833e-02,  4.6436e-02],
          [-1.0442e-01, -3.2644e-02, -1.4266e-04]],

         [[-1.3504e-02, -2.6101e-02, -1.9275e-02],
          [-1.5315e-02, -2.7579e-02, -7.4561e-03],
          [-3.1707e-02, -1.0187e-02, -1.2931e-02]],

         ...,

         [[ 4.6742e-03, -5.3108e-02, -8.8508e-02],
          [ 4.9763e-02, -9.0174e-02, -3.2583e-02],
          [-4.8892e-02,  1.3480e-02,  3.9005e-02]],

         [[-5.9419e-02, -1.0136e-01, -1.1546e-01],
          [-7.5362e-02, -4.8470e-02, -2.4966e-02],
          [-4.4913e-02, -1.8796e-02, -1.4597e-02]],

         [[-8.9494e-02, -3.5856e-02, -1.2368e-02],
          [-2.1256e-02, -2.2861e-02, -6.7883e-02],
          [-1.1565e-01, -7.2963e-02, -5.9713e-02]]],


        [[[-6.1420e-02, -7.4409e-02, -5.5026e-02],
          [-8.4431e-02, -5.0343e-02, -1.7650e-02],
          [-4.9211e-02, -2.8633e-02, -3.9524e-02]],

         [[-1.1809e-01, -1.2985e-01, -1.3566e-01],
          [-1.5668e-01, -1.1772e-01, -1.3297e-01],
          [-1.5706e-01, -1.5218e-01, -1.7541e-01]],

         [[-3.7270e-02, -3.6366e-02, -3.9533e-02],
          [-3.3907e-02, -2.5395e-02, -3.3014e-02],
          [-2.8684e-02, -1.9192e-02, -1.9853e-02]],

         ...,

         [[-1.4428e-01, -1.3440e-01, -4.8935e-02],
          [-8.5696e-02, -9.6213e-02, -5.4566e-02],
          [-1.2662e-01, -7.0622e-02, -9.3470e-02]],

         [[-1.1058e-01, -7.2285e-02, -7.5917e-02],
          [-9.1712e-02, -5.9537e-02, -8.4218e-02],
          [-6.3677e-02, -6.2909e-02, -1.0002e-01]],

         [[-2.0823e-01, -2.0906e-01, -2.1805e-01],
          [-1.7231e-01, -2.0222e-01, -2.3789e-01],
          [-2.6540e-01, -2.6746e-01, -2.9672e-01]]],


        [[[ 2.7761e-03,  2.2979e-03, -5.3760e-02],
          [-2.6933e-02,  4.3403e-02, -7.2004e-02],
          [ 1.5626e-03,  1.1805e-02, -7.6259e-02]],

         [[-1.1999e-02,  1.6803e-02,  6.0268e-02],
          [ 7.1736e-02, -4.5555e-03,  5.1571e-02],
          [ 8.9458e-02,  8.7167e-02,  1.6582e-01]],

         [[-3.9869e-03,  9.4170e-03,  2.3182e-02],
          [ 3.4039e-02, -1.6630e-03,  2.0193e-02],
          [ 1.2939e-02, -1.6654e-03,  1.1720e-02]],

         ...,

         [[-5.3542e-02,  1.3020e-01, -1.4320e-01],
          [-8.9343e-02,  8.4099e-02, -1.5566e-01],
          [ 6.7427e-02, -2.3243e-02, -2.0595e-01]],

         [[ 3.7305e-02, -9.8499e-03,  4.2857e-02],
          [ 6.3234e-02, -4.5390e-02, -6.4480e-02],
          [ 6.6953e-03, -1.4844e-01, -1.3272e-02]],

         [[ 6.5942e-02,  8.0735e-04,  5.4285e-02],
          [ 7.0934e-03, -9.7529e-02,  9.8900e-02],
          [ 1.2406e-01,  7.0387e-02,  1.2213e-01]]],


        ...,


        [[[-9.2294e-02, -3.1216e-02, -7.2767e-02],
          [-9.2675e-02, -9.8752e-02, -1.3588e-01],
          [-1.0899e-01, -1.5502e-01, -7.5264e-02]],

         [[-1.1606e-01, -1.4396e-01, -5.8016e-02],
          [-3.7691e-02, -6.5499e-02, -8.3960e-02],
          [-6.8773e-02, -8.4261e-02, -5.5588e-02]],

         [[-3.3650e-02, -2.5016e-02, -3.0571e-02],
          [-2.4607e-02, -3.8932e-02, -3.2553e-02],
          [-2.4548e-02, -2.5012e-02, -2.2982e-02]],

         ...,

         [[-1.4992e-01, -1.0191e-01, -1.7541e-01],
          [-2.3860e-01, -2.6577e-01, -1.5842e-01],
          [-1.5260e-01, -1.9920e-01, -1.9439e-01]],

         [[-2.2625e-01, -2.1584e-01, -1.7163e-01],
          [-1.7381e-01, -1.5323e-01, -1.7070e-01],
          [-1.4792e-01, -1.9673e-01, -1.1021e-01]],

         [[-1.4642e-01, -8.4646e-02, -1.1512e-01],
          [-2.1538e-01, -2.6934e-01, -2.4112e-01],
          [-1.4448e-01, -8.2778e-02, -1.1832e-01]]],


        [[[-1.5638e-01, -1.4835e-01, -1.9036e-01],
          [-1.7547e-01, -8.7568e-02, -1.1182e-01],
          [-8.2419e-02,  2.9827e-02,  2.9444e-02]],

         [[-3.5344e-03,  7.8474e-02,  3.5788e-02],
          [ 2.8736e-02, -8.3442e-02, -3.0318e-02],
          [-1.1561e-01, -1.6252e-01, -1.9590e-01]],

         [[-5.9862e-02, -6.6110e-02, -3.8213e-02],
          [-5.4671e-02, -3.5383e-02, -2.5554e-02],
          [ 9.8642e-03, -6.5176e-03, -9.3011e-03]],

         ...,

         [[-3.2161e-01, -2.8489e-01, -2.5918e-01],
          [-3.2716e-01, -4.6101e-02, -1.2386e-01],
          [-6.2740e-02, -1.9311e-01, -9.9467e-02]],

         [[-2.3160e-01, -2.2290e-01, -1.7311e-01],
          [-1.2877e-01, -1.0607e-01, -1.8933e-01],
          [-1.3856e-01, -1.7023e-01, -8.4564e-02]],

         [[-9.7377e-02, -1.5025e-01, -2.1385e-01],
          [-1.5372e-01, -1.2470e-01, -9.2415e-02],
          [-1.2050e-01, -2.0160e-01, -1.7870e-01]]],


        [[[ 1.4705e-01,  2.1214e-01,  1.3027e-01],
          [ 1.5705e-01,  2.3031e-01,  1.4932e-01],
          [ 2.4698e-01,  3.2268e-01,  2.5551e-01]],

         [[ 4.3678e-01,  4.6324e-01,  4.4894e-01],
          [ 4.4244e-01,  3.3969e-01,  4.9461e-01],
          [ 3.9638e-01,  3.2134e-01,  2.9273e-01]],

         [[ 8.4497e-02,  7.1967e-02,  5.6404e-02],
          [ 5.4276e-02,  3.5380e-02,  4.2073e-02],
          [ 1.0959e-01,  7.9675e-02,  6.8024e-02]],

         ...,

         [[ 2.5636e-01,  3.1694e-01,  2.9748e-01],
          [ 3.4446e-01,  5.3526e-01,  3.9326e-01],
          [ 4.9409e-01,  4.1774e-01,  5.3854e-01]],

         [[ 4.0206e-01,  3.6071e-01,  3.3972e-01],
          [ 4.3792e-01,  3.8572e-01,  3.7576e-01],
          [ 4.6685e-01,  4.0983e-01,  4.3655e-01]],

         [[ 5.7194e-01,  5.3079e-01,  4.8957e-01],
          [ 6.5429e-01,  7.0739e-01,  6.6911e-01],
          [ 6.2929e-01,  4.8608e-01,  4.9187e-01]]]], device='cuda:0'), 'backend.4.bias': tensor([-1.0812e-01, -3.6618e-01,  1.2842e-01, -4.9061e-02, -2.9246e-01,
        -3.0940e-02, -2.1621e-01,  5.0669e-02,  7.6933e-02, -3.7847e-01,
         3.8316e-01,  6.9392e-02,  3.7674e-01,  3.4865e-02, -2.4371e-01,
        -6.7996e-02, -1.8840e-01,  9.8036e-02,  2.0499e-02,  1.9590e-03,
        -1.7969e-01,  3.6394e-01, -1.7573e-01, -4.2377e-01, -7.6806e-02,
        -5.1208e-01,  1.6246e-01,  1.3582e-01, -1.0089e-01, -6.3033e-01,
         2.1797e-01, -3.1502e-02,  2.5708e-02, -1.9572e-01,  4.0422e-02,
        -1.9214e-01, -1.6726e-01,  7.8270e-03,  1.1864e-01, -1.0253e-02,
        -5.1458e-05,  1.6473e-01,  4.8805e-02, -2.7859e-01, -2.8268e-01,
        -2.4050e-02, -1.5401e-03,  5.9487e-02, -3.5743e-01,  8.5502e-02,
        -3.2695e-01, -2.1991e-01, -4.9916e-01, -4.0063e-02, -2.6687e-02,
         3.2183e-01, -3.9357e-01, -1.2466e-02, -5.5511e-01, -3.7874e-01,
        -1.0882e-01, -8.0759e-03, -4.0335e-02, -2.3989e-01,  4.2835e-01,
         1.1270e-01,  5.2402e-03, -4.4078e-02, -1.1977e-01, -5.8301e-01,
        -4.5837e-01, -3.2117e-02, -4.3981e-01, -1.7271e-01, -1.0471e-01,
        -9.2244e-02, -2.5923e-01, -4.8508e-02, -1.3433e-01,  4.9865e-01,
         4.0550e-03,  4.7469e-01,  1.2650e-01,  2.1825e-01,  4.0002e-01,
         5.3299e-02, -4.8195e-02, -7.7325e-03,  3.1430e-02, -2.9858e-01,
         9.6678e-02,  5.9244e-03, -3.5871e-01, -1.8527e-01, -2.1074e-01,
        -2.4776e-02, -4.3057e-03, -4.8010e-01, -2.3097e-02, -4.8733e-01,
        -2.3378e-01,  1.2449e-02,  1.9692e-01,  6.4458e-01, -3.0372e-02,
        -7.6163e-02, -1.2317e-01,  1.7330e-01, -1.0179e-01,  4.4206e-02,
        -1.2982e-01, -1.8453e-01,  2.1300e-01, -5.0384e-02, -2.0802e-01,
         2.6361e-02, -5.6353e-01,  5.0608e-01,  1.8496e-01,  8.3391e-03,
        -3.2191e-02,  5.1196e-01, -1.3433e-02, -5.2053e-02,  1.4464e-01,
         3.7586e-02,  3.4294e-01,  6.9647e-03,  2.2646e-01,  5.1073e-01,
         3.4326e-02, -7.9606e-03,  3.3117e-01, -1.0774e-01, -4.2533e-02,
         3.0071e-02,  6.7351e-03, -7.9038e-01,  4.9791e-02, -4.3896e-01,
        -3.2473e-01, -2.9875e-01, -3.1348e-03, -4.8676e-03,  4.0755e-02,
        -7.9778e-03,  2.4404e-01, -5.4111e-02, -1.1398e-01,  1.1369e-03,
         3.8762e-02,  9.8141e-03, -3.7269e-01, -1.4726e-02,  5.2647e-01,
        -4.4866e-01,  2.7330e-01, -1.6093e-01, -1.5819e-01, -2.0994e-01,
         1.9685e-02, -2.4199e-02, -8.2345e-02, -3.9722e-01, -1.6611e-02,
         4.0969e-02,  3.9075e-01, -5.4413e-01, -1.2593e-01, -1.4784e-01,
        -3.4171e-01, -6.1622e-03, -2.4370e-01, -2.2418e-01,  3.0437e-04,
        -2.3542e-01, -6.4280e-02,  1.3205e-02, -1.1394e-01, -4.1008e-02,
        -8.9198e-02, -5.1332e-02, -3.2771e-01,  5.0279e-03,  2.6738e-01,
         6.9735e-02,  6.9241e-01,  4.3881e-01, -2.2326e-01,  2.3691e-02,
        -3.1278e-01, -9.1258e-02, -2.7652e-01,  1.0137e-01,  1.0067e+00,
        -3.0610e-02, -3.0768e-02, -1.6984e-01,  6.5684e-01,  8.3777e-02,
         4.4153e-01,  2.3669e-01, -1.1397e-01,  3.7617e-03, -2.0286e-02,
        -2.9738e-01,  5.2122e-02, -1.5838e-01, -1.8251e-01,  8.7092e-02,
        -9.9948e-03, -4.6142e-02, -4.2110e-01, -9.8055e-02, -1.8508e-01,
        -6.2270e-03,  1.6868e-02, -1.9718e-01, -2.3422e-01, -3.4677e-01,
         1.6644e-01,  1.2507e-01,  3.9420e-01,  7.4626e-02, -3.1263e-02,
        -3.1774e-01,  8.2826e-02,  1.5916e-02,  9.8656e-02,  1.1931e-02,
        -3.0593e-01, -3.5126e-02,  2.9627e-01,  2.0167e-01,  1.0441e-01,
        -1.0012e-01,  5.5526e-01, -1.0113e-01,  1.1197e-01, -5.4777e-02,
         5.3432e-01,  1.8931e-01,  1.2888e-01, -9.9682e-01, -3.9092e-02,
        -1.6113e-01,  1.7402e-02,  1.7736e-02,  1.6028e-01, -3.4079e-01,
         3.0156e-01,  7.4539e-02, -2.5540e-01, -3.4748e-01,  2.8852e-01,
        -2.7768e-01, -7.4830e-02,  1.7404e-01, -6.9480e-02, -2.7810e-01,
        -1.2865e-01,  2.2681e-01, -2.0875e-01, -4.3857e-01, -1.3635e-01,
        -3.7374e-01, -6.9348e-04,  2.8005e-01,  1.3245e-04, -1.2098e-01,
        -3.6941e-01, -1.2099e-01,  3.8067e-02, -3.8953e-01, -3.6714e-01,
        -4.5712e-02, -3.1230e-02, -1.0634e-01,  1.4169e-01,  2.3006e-01,
        -1.8546e-01, -2.0267e-01, -6.4678e-02, -2.3959e-01,  3.1085e-01,
         3.6057e-01,  1.6338e-02, -2.4542e-01, -8.0525e-02, -2.3345e-01,
        -1.0109e-02, -2.5681e-02,  9.0185e-01,  2.6805e-01,  3.4582e-01,
        -1.8347e-02, -1.3388e-01, -2.4006e-01,  1.4226e-02, -4.0939e-02,
        -1.7018e-01, -1.4158e-01, -2.0831e-01, -1.6937e-01, -8.4634e-02,
        -3.2971e-01, -2.7501e-01,  1.6288e-02, -4.0977e-02, -1.1737e-01,
         1.2762e-02, -1.3446e-01, -1.0033e-01, -1.4785e-01,  1.6940e-01,
        -6.3066e-02, -1.2878e-01,  6.4633e-01, -5.3337e-01,  1.4794e-02,
        -9.2401e-02, -4.7321e-01,  4.4711e-02, -3.0021e-01,  1.7768e-01,
        -4.5306e-01, -1.2879e-01, -3.4056e-02, -1.7092e-01, -3.2663e-01,
        -4.7844e-02, -3.4172e-01,  3.4814e-01, -1.8827e-01, -1.6557e-01,
        -5.7711e-01, -1.1870e-01,  2.7405e-01,  2.3554e-01, -2.6390e-01,
         2.1475e-01, -3.4904e-01,  1.3482e-01, -1.8987e-01, -2.4477e-02,
        -3.1930e-01,  9.0383e-02,  6.3579e-01, -1.4432e-01, -2.4493e-01,
         2.1646e-01,  4.9190e-01,  1.1630e-02,  7.9975e-02,  2.4348e-01,
         1.2597e-02, -1.4821e-01, -7.4587e-02,  1.5592e-01,  1.3076e-01,
         3.0585e-01, -3.6773e-01,  1.8266e-02,  9.1949e-02,  3.1869e-01,
        -2.1595e-01,  3.7490e-01, -2.6143e-02, -3.6379e-01,  8.8123e-03,
         2.6170e-02,  2.5108e-02,  2.6420e-02, -9.9201e-02,  3.0538e-01,
        -1.0716e-02, -1.9231e-01, -2.7256e-01,  1.1161e+00,  1.0307e-02,
        -9.5664e-02, -7.0595e-04, -3.1032e-01, -7.5438e-02,  2.4541e-01,
        -9.1378e-02, -5.9279e-01,  3.0521e-03,  1.4869e-02, -4.7875e-01,
         6.7284e-02, -1.8228e-01,  4.9474e-02,  3.0890e-02,  1.5924e-01,
         1.5409e-02,  3.8060e-02, -2.0830e-01, -1.9951e-01, -4.6216e-02,
        -5.7944e-01, -4.0634e-02,  1.8278e-01, -1.0761e-01, -5.3346e-01,
        -9.1332e-03, -3.6206e-01, -5.0549e-02,  2.9751e-01, -2.0689e-02,
         6.0334e-01,  2.5752e-01,  9.7461e-03,  6.7221e-03, -1.2128e-01,
        -8.0106e-02, -4.5751e-02,  6.7042e-02, -1.8902e-02, -2.1782e-01,
        -3.6457e-01, -2.6533e-02,  6.3350e-01, -3.4595e-01, -3.7133e-02,
        -9.5447e-02, -3.0462e-01, -3.0521e-01, -6.8317e-02, -5.2826e-01,
         1.4542e-01, -1.9183e-01,  1.9127e-03, -5.3533e-03, -1.5697e-01,
         2.8604e-02,  2.2384e-01, -4.2827e-02,  3.7193e-01, -1.0113e-01,
        -7.1846e-02, -1.7502e-01,  3.7556e-02, -6.9689e-01, -3.6151e-01,
        -3.2398e-02, -2.4085e-02, -3.1030e-01,  9.2289e-02, -4.0313e-01,
        -1.1534e-01,  1.2941e-01,  3.9191e-01,  6.1184e-02, -1.3612e-01,
        -2.1756e-02,  9.9644e-02,  2.4690e-01, -1.5004e-03,  1.3127e-01,
        -4.5444e-01,  3.8564e-01, -4.4021e-01,  4.3855e-01, -1.5638e-01,
         2.3229e-01,  4.4088e-02, -5.8860e-02, -1.5687e-03, -1.2277e-01,
        -8.8027e-02, -1.9164e-01, -6.1247e-02,  4.0479e-01, -3.7728e-01,
        -1.1528e-01,  1.1578e-01,  7.6795e-01, -7.4226e-02,  2.1551e-01,
         1.1526e-01, -2.0986e-03,  1.7941e-01, -7.2154e-01,  3.0800e-01,
        -3.7801e-02, -1.0173e-01,  2.5063e-01, -9.7411e-03, -1.2966e-01,
        -9.2895e-03,  5.0409e-02, -1.3581e-01,  2.7527e-01, -1.5140e-01,
         3.9171e-02,  5.3645e-02,  7.7754e-02,  2.6264e-02,  3.7058e-02,
         4.2296e-01, -4.2493e-02, -4.7810e-01, -2.3012e-01,  1.5902e-01,
         1.3807e-01, -1.8588e-01, -2.5382e-01,  1.1852e-02, -2.7152e-01,
        -2.3341e-01,  9.9333e-01], device='cuda:0')}
INFO:root:==> Evaluating the model at: 1
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:10.2249025345, MAE: 101.208069897, MSE: 101.208069566
INFO:root:(Meta-testing) test MAE: 101.541421127, MSE: 101.541422107
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.92773497105, MAE: 3.70236587524, MSE: 3.70236584572
INFO:root:(Meta-training) post train loss: 2.13366699219, MAE: 37.6027603149, MSE: 37.6027595968
INFO:root:(Meta-training) pre-training test MAE: 6.88640213013, MSE: 6.88640217694
INFO:root:(Meta-training) post-training test MAE: 40.4782524109, MSE: 40.4782520818
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-43.9209, device='cuda:0'), 'backend.0.bias': tensor(0.0013, device='cuda:0'), 'backend.10.weight': tensor(-2.8210, device='cuda:0'), 'backend.8.bias': tensor(-0.1662, device='cuda:0'), 'backend.6.weight': tensor(-52.1225, device='cuda:0'), 'backend.2.bias': tensor(-0.0119, device='cuda:0'), 'backend.10.bias': tensor(0.1539, device='cuda:0'), 'output_layer.bias': tensor(-30.3483, device='cuda:0'), 'backend.2.weight': tensor(-93.3568, device='cuda:0'), 'backend.6.bias': tensor(-0.0265, device='cuda:0'), 'backend.0.weight': tensor(-21.5632, device='cuda:0'), 'output_layer.weight': tensor(-5.2881, device='cuda:0'), 'backend.4.weight': tensor(-96.7638, device='cuda:0'), 'backend.4.bias': tensor(-0.0339, device='cuda:0')}
INFO:root:==> Training scene: 2
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.4576377869, MAE: 14.0155792236, MSE: 14.0155792746
INFO:root:(Meta-training) post train loss: 28.2439689636, MAE: 246.063415527, MSE: 246.063412813
INFO:root:(Meta-training) pre-training test MAE: 8.87585067749, MSE: 8.875850583
INFO:root:(Meta-training) post-training test MAE: 235.911209106, MSE: 235.911207144
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-1020.3319, device='cuda:0'), 'backend.0.bias': tensor(-0.1067, device='cuda:0'), 'backend.10.weight': tensor(-2049.0684, device='cuda:0'), 'backend.8.bias': tensor(-5.0614, device='cuda:0'), 'backend.6.weight': tensor(-1269.1729, device='cuda:0'), 'backend.2.bias': tensor(-0.5702, device='cuda:0'), 'backend.10.bias': tensor(-49.0953, device='cuda:0'), 'output_layer.bias': tensor(-201.3323, device='cuda:0'), 'backend.2.weight': tensor(-2259.6045, device='cuda:0'), 'backend.6.bias': tensor(-1.0513, device='cuda:0'), 'backend.0.weight': tensor(-684.9938, device='cuda:0'), 'output_layer.weight': tensor(-48.6113, device='cuda:0'), 'backend.4.weight': tensor(-2496.2798, device='cuda:0'), 'backend.4.bias': tensor(-1.3280, device='cuda:0')}
INFO:root:==> Training scene: 3
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.215716362, MAE: 12.3267059326, MSE: 12.3267058703
INFO:root:(Meta-training) post train loss: 13.1575832367, MAE: 155.954437256, MSE: 155.95443921
INFO:root:(Meta-training) pre-training test MAE: 17.9829978943, MSE: 17.9829979178
INFO:root:(Meta-training) post-training test MAE: 149.803665161, MSE: 149.803667084
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-411.3149, device='cuda:0'), 'backend.0.bias': tensor(-0.1084, device='cuda:0'), 'backend.10.weight': tensor(-577.3656, device='cuda:0'), 'backend.8.bias': tensor(-1.6774, device='cuda:0'), 'backend.6.weight': tensor(-752.4695, device='cuda:0'), 'backend.2.bias': tensor(-0.3535, device='cuda:0'), 'backend.10.bias': tensor(-13.2628, device='cuda:0'), 'output_layer.bias': tensor(-113.9397, device='cuda:0'), 'backend.2.weight': tensor(-1495.3254, device='cuda:0'), 'backend.6.bias': tensor(-0.6486, device='cuda:0'), 'backend.0.weight': tensor(-532.8889, device='cuda:0'), 'output_layer.weight': tensor(-24.8956, device='cuda:0'), 'backend.4.weight': tensor(-1443.4937, device='cuda:0'), 'backend.4.bias': tensor(-0.7667, device='cuda:0')}
INFO:root:==> Training scene: 4
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.40858054161, MAE: 3.46781778336, MSE: 3.46781785142
INFO:root:(Meta-training) post train loss: 1.24631130695, MAE: 40.1663703918, MSE: 40.1663700161
INFO:root:(Meta-training) pre-training test MAE: 5.10420227051, MSE: 5.1042023119
INFO:root:(Meta-training) post-training test MAE: 38.2077407837, MSE: 38.207740327
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-22.4932, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(-6.9668, device='cuda:0'), 'backend.8.bias': tensor(-0.0887, device='cuda:0'), 'backend.6.weight': tensor(1.9747, device='cuda:0'), 'backend.2.bias': tensor(-0.0034, device='cuda:0'), 'backend.10.bias': tensor(-0.2023, device='cuda:0'), 'output_layer.bias': tensor(-28.7350, device='cuda:0'), 'backend.2.weight': tensor(-43.8065, device='cuda:0'), 'backend.6.bias': tensor(0.0327, device='cuda:0'), 'backend.0.weight': tensor(-7.9347, device='cuda:0'), 'output_layer.weight': tensor(-4.6944, device='cuda:0'), 'backend.4.weight': tensor(-74.9707, device='cuda:0'), 'backend.4.bias': tensor(-0.0318, device='cuda:0')}
INFO:root:==> Training scene: 5
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.464849472, MAE: 11.5086917877, MSE: 11.5086915716
INFO:root:(Meta-training) post train loss: 12.0098371506, MAE: 157.504074097, MSE: 157.504073608
INFO:root:(Meta-training) pre-training test MAE: 6.65334415436, MSE: 6.65334403491
INFO:root:(Meta-training) post-training test MAE: 148.859954834, MSE: 148.859958046
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-168.4951, device='cuda:0'), 'backend.0.bias': tensor(-0.0335, device='cuda:0'), 'backend.10.weight': tensor(-512.0421, device='cuda:0'), 'backend.8.bias': tensor(-0.8689, device='cuda:0'), 'backend.6.weight': tensor(-290.6689, device='cuda:0'), 'backend.2.bias': tensor(-0.2067, device='cuda:0'), 'backend.10.bias': tensor(-12.1426, device='cuda:0'), 'output_layer.bias': tensor(-113.5457, device='cuda:0'), 'backend.2.weight': tensor(-810.5502, device='cuda:0'), 'backend.6.bias': tensor(-0.2528, device='cuda:0'), 'backend.0.weight': tensor(-189.6144, device='cuda:0'), 'output_layer.weight': tensor(-21.5855, device='cuda:0'), 'backend.4.weight': tensor(-870.6675, device='cuda:0'), 'backend.4.bias': tensor(-0.5180, device='cuda:0')}
INFO:root:==> Training scene: 6
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.31700372696, MAE: 4.50811004639, MSE: 4.50810994402
INFO:root:(Meta-training) post train loss: 2.54581308365, MAE: 56.9175300598, MSE: 56.9175300291
INFO:root:(Meta-training) pre-training test MAE: 3.33308029175, MSE: 3.33308034573
INFO:root:(Meta-training) post-training test MAE: 57.6218566895, MSE: 57.6218562727
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-37.6213, device='cuda:0'), 'backend.0.bias': tensor(0.0053, device='cuda:0'), 'backend.10.weight': tensor(-48.7510, device='cuda:0'), 'backend.8.bias': tensor(-0.1999, device='cuda:0'), 'backend.6.weight': tensor(-3.2662, device='cuda:0'), 'backend.2.bias': tensor(-0.0192, device='cuda:0'), 'backend.10.bias': tensor(-1.0821, device='cuda:0'), 'output_layer.bias': tensor(-43.8108, device='cuda:0'), 'backend.2.weight': tensor(-99.3718, device='cuda:0'), 'backend.6.bias': tensor(0.0174, device='cuda:0'), 'backend.0.weight': tensor(-8.4586, device='cuda:0'), 'output_layer.weight': tensor(-7.1186, device='cuda:0'), 'backend.4.weight': tensor(-117.8177, device='cuda:0'), 'backend.4.bias': tensor(-0.0676, device='cuda:0')}
INFO:root:==> Training scene: 7
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.56835842133, MAE: 9.11410331726, MSE: 9.11410331697
INFO:root:(Meta-training) post train loss: 8.68908500671, MAE: 118.70375061, MSE: 118.703749217
INFO:root:(Meta-training) pre-training test MAE: 7.59414863586, MSE: 7.59414860186
INFO:root:(Meta-training) post-training test MAE: 119.183746338, MSE: 119.183747319
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-183.1738, device='cuda:0'), 'backend.0.bias': tensor(-0.0085, device='cuda:0'), 'backend.10.weight': tensor(-210.6387, device='cuda:0'), 'backend.8.bias': tensor(-0.9138, device='cuda:0'), 'backend.6.weight': tensor(-301.4147, device='cuda:0'), 'backend.2.bias': tensor(-0.1017, device='cuda:0'), 'backend.10.bias': tensor(-4.8148, device='cuda:0'), 'output_layer.bias': tensor(-90.9324, device='cuda:0'), 'backend.2.weight': tensor(-551.6275, device='cuda:0'), 'backend.6.bias': tensor(-0.2307, device='cuda:0'), 'backend.0.weight': tensor(-168.9219, device='cuda:0'), 'output_layer.weight': tensor(-16.1698, device='cuda:0'), 'backend.4.weight': tensor(-548.3022, device='cuda:0'), 'backend.4.bias': tensor(-0.2530, device='cuda:0')}
INFO:root:==> Training scene: 8
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.70169210434, MAE: 4.29832458496, MSE: 4.29832450693
INFO:root:(Meta-training) post train loss: 3.96286082268, MAE: 41.1326255798, MSE: 41.1326262757
INFO:root:(Meta-training) pre-training test MAE: 0.344522476196, MSE: 0.34452247522
INFO:root:(Meta-training) post-training test MAE: 45.7303619385, MSE: 45.730363144
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-90.5592, device='cuda:0'), 'backend.0.bias': tensor(-0.0234, device='cuda:0'), 'backend.10.weight': tensor(-131.2070, device='cuda:0'), 'backend.8.bias': tensor(-0.3804, device='cuda:0'), 'backend.6.weight': tensor(-169.8558, device='cuda:0'), 'backend.2.bias': tensor(-0.0816, device='cuda:0'), 'backend.10.bias': tensor(-2.6672, device='cuda:0'), 'output_layer.bias': tensor(-34.8099, device='cuda:0'), 'backend.2.weight': tensor(-365.8163, device='cuda:0'), 'backend.6.bias': tensor(-0.1439, device='cuda:0'), 'backend.0.weight': tensor(-121.5346, device='cuda:0'), 'output_layer.weight': tensor(-7.2147, device='cuda:0'), 'backend.4.weight': tensor(-379.3095, device='cuda:0'), 'backend.4.bias': tensor(-0.1953, device='cuda:0')}
INFO:root:==> Training scene: 9
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.31722784042, MAE: 1.57554912567, MSE: 1.57554914801
INFO:root:(Meta-training) post train loss: 4.04796695709, MAE: 13.7908353806, MSE: 13.7908351375
INFO:root:(Meta-training) pre-training test MAE: 5.13178634644, MSE: 5.13178641226
INFO:root:(Meta-training) post-training test MAE: 10.5187931061, MSE: 10.5187932721
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(12.7440, device='cuda:0'), 'backend.0.bias': tensor(0.0095, device='cuda:0'), 'backend.10.weight': tensor(-5.2699, device='cuda:0'), 'backend.8.bias': tensor(0.0464, device='cuda:0'), 'backend.6.weight': tensor(44.8930, device='cuda:0'), 'backend.2.bias': tensor(0.0177, device='cuda:0'), 'backend.10.bias': tensor(-0.2285, device='cuda:0'), 'output_layer.bias': tensor(-7.7328, device='cuda:0'), 'backend.2.weight': tensor(82.0600, device='cuda:0'), 'backend.6.bias': tensor(0.0495, device='cuda:0'), 'backend.0.weight': tensor(42.8591, device='cuda:0'), 'output_layer.weight': tensor(-1.1357, device='cuda:0'), 'backend.4.weight': tensor(46.6682, device='cuda:0'), 'backend.4.bias': tensor(0.0206, device='cuda:0')}
INFO:root:==> Training scene: 10
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 2.62649679184, MAE: 0.140889167786, MSE: 0.14088916471
INFO:root:(Meta-training) post train loss: 1.72036874294, MAE: 8.40645599365, MSE: 8.40645601949
INFO:root:(Meta-training) pre-training test MAE: 2.28190612793, MSE: 2.28190613808
INFO:root:(Meta-training) post-training test MAE: 9.2960319519, MSE: 9.29603175338
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(29.3622, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(14.4824, device='cuda:0'), 'backend.8.bias': tensor(0.1243, device='cuda:0'), 'backend.6.weight': tensor(20.2014, device='cuda:0'), 'backend.2.bias': tensor(0.0180, device='cuda:0'), 'backend.10.bias': tensor(0.5394, device='cuda:0'), 'output_layer.bias': tensor(7.4570, device='cuda:0'), 'backend.2.weight': tensor(65.5935, device='cuda:0'), 'backend.6.bias': tensor(0.0065, device='cuda:0'), 'backend.0.weight': tensor(18.4875, device='cuda:0'), 'output_layer.weight': tensor(1.3642, device='cuda:0'), 'backend.4.weight': tensor(55.7639, device='cuda:0'), 'backend.4.bias': tensor(0.0333, device='cuda:0')}
INFO:root:==> Training scene: 11
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 20.0581626892, MAE: 3.79273986816, MSE: 3.79273981411
INFO:root:(Meta-training) post train loss: 15.4374341965, MAE: 60.0539627075, MSE: 60.0539633632
INFO:root:(Meta-training) pre-training test MAE: 1.65007305145, MSE: 1.65007306717
INFO:root:(Meta-training) post-training test MAE: 46.8975715637, MSE: 46.8975726901
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-285.1153, device='cuda:0'), 'backend.0.bias': tensor(-0.0562, device='cuda:0'), 'backend.10.weight': tensor(-397.6520, device='cuda:0'), 'backend.8.bias': tensor(-1.2813, device='cuda:0'), 'backend.6.weight': tensor(-501.0741, device='cuda:0'), 'backend.2.bias': tensor(-0.1695, device='cuda:0'), 'backend.10.bias': tensor(-8.2408, device='cuda:0'), 'output_layer.bias': tensor(-36.3815, device='cuda:0'), 'backend.2.weight': tensor(-722.0635, device='cuda:0'), 'backend.6.bias': tensor(-0.4861, device='cuda:0'), 'backend.0.weight': tensor(-277.7652, device='cuda:0'), 'output_layer.weight': tensor(-10.3747, device='cuda:0'), 'backend.4.weight': tensor(-798.2844, device='cuda:0'), 'backend.4.bias': tensor(-0.4068, device='cuda:0')}
INFO:root:==> Training scene: 12
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.26931238174, MAE: 9.15769100189, MSE: 9.15769098289
INFO:root:(Meta-training) post train loss: 5.25304222107, MAE: 128.482192993, MSE: 128.48219265
INFO:root:(Meta-training) pre-training test MAE: 4.61597824097, MSE: 4.61597820524
INFO:root:(Meta-training) post-training test MAE: 141.958709717, MSE: 141.958710161
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(260.6507, device='cuda:0'), 'backend.0.bias': tensor(0.0241, device='cuda:0'), 'backend.10.weight': tensor(468.7808, device='cuda:0'), 'backend.8.bias': tensor(1.2948, device='cuda:0'), 'backend.6.weight': tensor(381.9536, device='cuda:0'), 'backend.2.bias': tensor(0.2002, device='cuda:0'), 'backend.10.bias': tensor(12.5315, device='cuda:0'), 'output_layer.bias': tensor(110.0442, device='cuda:0'), 'backend.2.weight': tensor(951.6746, device='cuda:0'), 'backend.6.bias': tensor(0.2520, device='cuda:0'), 'backend.0.weight': tensor(256.8109, device='cuda:0'), 'output_layer.weight': tensor(24.2919, device='cuda:0'), 'backend.4.weight': tensor(1108.7393, device='cuda:0'), 'backend.4.bias': tensor(0.5716, device='cuda:0')}
INFO:root:==> Training scene: 13
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.15585327148, MAE: 0.122278213501, MSE: 0.122278211939
INFO:root:(Meta-training) post train loss: 6.03297472, MAE: 16.0758647919, MSE: 16.0758651762
INFO:root:(Meta-training) pre-training test MAE: 6.88552856445, MSE: 6.88552854815
INFO:root:(Meta-training) post-training test MAE: 24.3776397705, MSE: 24.3776403318
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(63.4827, device='cuda:0'), 'backend.0.bias': tensor(0.0233, device='cuda:0'), 'backend.10.weight': tensor(82.2645, device='cuda:0'), 'backend.8.bias': tensor(0.2575, device='cuda:0'), 'backend.6.weight': tensor(116.4496, device='cuda:0'), 'backend.2.bias': tensor(0.0472, device='cuda:0'), 'backend.10.bias': tensor(1.7026, device='cuda:0'), 'output_layer.bias': tensor(19.4743, device='cuda:0'), 'backend.2.weight': tensor(230.1284, device='cuda:0'), 'backend.6.bias': tensor(0.0803, device='cuda:0'), 'backend.0.weight': tensor(113.2029, device='cuda:0'), 'output_layer.weight': tensor(4.3419, device='cuda:0'), 'backend.4.weight': tensor(236.4451, device='cuda:0'), 'backend.4.bias': tensor(0.1142, device='cuda:0')}
INFO:root:==> Training scene: 14
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.2247161865, MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post train loss: 11.210111618, MAE: 134.058197021, MSE: 134.058194861
INFO:root:(Meta-training) pre-training test MAE: 9.19702339172, MSE: 9.19702319208
INFO:root:(Meta-training) post-training test MAE: 132.98664856, MSE: 132.986650528
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-412.4737, device='cuda:0'), 'backend.0.bias': tensor(-0.0713, device='cuda:0'), 'backend.10.weight': tensor(-431.9995, device='cuda:0'), 'backend.8.bias': tensor(-1.9927, device='cuda:0'), 'backend.6.weight': tensor(-607.5551, device='cuda:0'), 'backend.2.bias': tensor(-0.2443, device='cuda:0'), 'backend.10.bias': tensor(-9.6425, device='cuda:0'), 'output_layer.bias': tensor(-102.2852, device='cuda:0'), 'backend.2.weight': tensor(-871.2731, device='cuda:0'), 'backend.6.bias': tensor(-0.6839, device='cuda:0'), 'backend.0.weight': tensor(-302.5356, device='cuda:0'), 'output_layer.weight': tensor(-20.8222, device='cuda:0'), 'backend.4.weight': tensor(-984.5646, device='cuda:0'), 'backend.4.bias': tensor(-0.5933, device='cuda:0')}
INFO:root:==> Training scene: 15
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.0185213089, MAE: 6.06261253357, MSE: 6.06261263084
INFO:root:(Meta-training) post train loss: 5.02552700043, MAE: 89.3602752686, MSE: 89.3602752293
INFO:root:(Meta-training) pre-training test MAE: 2.2882976532, MSE: 2.28829766213
INFO:root:(Meta-training) post-training test MAE: 88.706703186, MSE: 88.7067043381
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(73.9416, device='cuda:0'), 'backend.0.bias': tensor(-0.0452, device='cuda:0'), 'backend.10.weight': tensor(228.9542, device='cuda:0'), 'backend.8.bias': tensor(0.1953, device='cuda:0'), 'backend.6.weight': tensor(-42.0229, device='cuda:0'), 'backend.2.bias': tensor(-0.0187, device='cuda:0'), 'backend.10.bias': tensor(7.8502, device='cuda:0'), 'output_layer.bias': tensor(67.6426, device='cuda:0'), 'backend.2.weight': tensor(47.4639, device='cuda:0'), 'backend.6.bias': tensor(-0.2108, device='cuda:0'), 'backend.0.weight': tensor(-75.9561, device='cuda:0'), 'output_layer.weight': tensor(11.4994, device='cuda:0'), 'backend.4.weight': tensor(242.4803, device='cuda:0'), 'backend.4.bias': tensor(0.1128, device='cuda:0')}
INFO:root:==> Training scene: 16
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.7963008881, MAE: 16.1687660217, MSE: 16.1687657413
INFO:root:(Meta-training) post train loss: 22.4242420197, MAE: 229.407485962, MSE: 229.407482373
INFO:root:(Meta-training) pre-training test MAE: 6.00388336182, MSE: 6.00388337666
INFO:root:(Meta-training) post-training test MAE: 239.257141113, MSE: 239.257142984
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-988.6005, device='cuda:0'), 'backend.0.bias': tensor(-0.2824, device='cuda:0'), 'backend.10.weight': tensor(-1988.3595, device='cuda:0'), 'backend.8.bias': tensor(-5.0329, device='cuda:0'), 'backend.6.weight': tensor(-2082.1543, device='cuda:0'), 'backend.2.bias': tensor(-1.0028, device='cuda:0'), 'backend.10.bias': tensor(-44.8206, device='cuda:0'), 'output_layer.bias': tensor(-201.1472, device='cuda:0'), 'backend.2.weight': tensor(-3871.7910, device='cuda:0'), 'backend.6.bias': tensor(-2.2654, device='cuda:0'), 'backend.0.weight': tensor(-1286.4838, device='cuda:0'), 'output_layer.weight': tensor(-56.6222, device='cuda:0'), 'backend.4.weight': tensor(-4343.2554, device='cuda:0'), 'backend.4.bias': tensor(-2.4096, device='cuda:0')}
INFO:root:==> Training scene: 17
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 32.0257339478, MAE: 15.1991195679, MSE: 15.1991193617
INFO:root:(Meta-training) post train loss: 48.2651062012, MAE: 335.650817871, MSE: 335.650813719
INFO:root:(Meta-training) pre-training test MAE: 11.0977325439, MSE: 11.0977325598
INFO:root:(Meta-training) post-training test MAE: 336.292419434, MSE: 336.292422974
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-7079.0312, device='cuda:0'), 'backend.0.bias': tensor(-1.0678, device='cuda:0'), 'backend.10.weight': tensor(-9176.1611, device='cuda:0'), 'backend.8.bias': tensor(-32.7449, device='cuda:0'), 'backend.6.weight': tensor(-9999.3828, device='cuda:0'), 'backend.2.bias': tensor(-3.5476, device='cuda:0'), 'backend.10.bias': tensor(-201.9896, device='cuda:0'), 'output_layer.bias': tensor(-380.1562, device='cuda:0'), 'backend.2.weight': tensor(-13915.4082, device='cuda:0'), 'backend.6.bias': tensor(-10.0968, device='cuda:0'), 'backend.0.weight': tensor(-4359.9946, device='cuda:0'), 'output_layer.weight': tensor(-154.6839, device='cuda:0'), 'backend.4.weight': tensor(-14321.7207, device='cuda:0'), 'backend.4.bias': tensor(-7.5350, device='cuda:0')}
INFO:root:==> Training scene: 18
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.19173002243, MAE: 9.96483707428, MSE: 9.96483724213
INFO:root:(Meta-training) post train loss: 8.31143093109, MAE: 108.922950745, MSE: 108.92294976
INFO:root:(Meta-training) pre-training test MAE: 26.310459137, MSE: 26.31045865
INFO:root:(Meta-training) post-training test MAE: 94.4987640381, MSE: 94.4987650796
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-88.2477, device='cuda:0'), 'backend.0.bias': tensor(0.0020, device='cuda:0'), 'backend.10.weight': tensor(-150.8411, device='cuda:0'), 'backend.8.bias': tensor(-0.5698, device='cuda:0'), 'backend.6.weight': tensor(-90.5708, device='cuda:0'), 'backend.2.bias': tensor(-0.0589, device='cuda:0'), 'backend.10.bias': tensor(-4.4715, device='cuda:0'), 'output_layer.bias': tensor(-71.4431, device='cuda:0'), 'backend.2.weight': tensor(-212.6744, device='cuda:0'), 'backend.6.bias': tensor(-0.1036, device='cuda:0'), 'backend.0.weight': tensor(-35.0562, device='cuda:0'), 'output_layer.weight': tensor(-12.1312, device='cuda:0'), 'backend.4.weight': tensor(-304.2588, device='cuda:0'), 'backend.4.bias': tensor(-0.2161, device='cuda:0')}
INFO:root:==> Training scene: 19
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.85736942291, MAE: 15.1381454468, MSE: 15.1381455981
INFO:root:(Meta-training) post train loss: 11.7894163132, MAE: 200.715942383, MSE: 200.715945119
INFO:root:(Meta-training) pre-training test MAE: 19.7869281769, MSE: 19.786928058
INFO:root:(Meta-training) post-training test MAE: 196.792785645, MSE: 196.792790375
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-82.1093, device='cuda:0'), 'backend.0.bias': tensor(0.0720, device='cuda:0'), 'backend.10.weight': tensor(-106.0497, device='cuda:0'), 'backend.8.bias': tensor(-0.6434, device='cuda:0'), 'backend.6.weight': tensor(60.6098, device='cuda:0'), 'backend.2.bias': tensor(0.0389, device='cuda:0'), 'backend.10.bias': tensor(-4.0570, device='cuda:0'), 'output_layer.bias': tensor(-149.3103, device='cuda:0'), 'backend.2.weight': tensor(-19.7755, device='cuda:0'), 'backend.6.bias': tensor(0.1884, device='cuda:0'), 'backend.0.weight': tensor(94.8992, device='cuda:0'), 'output_layer.weight': tensor(-21.7000, device='cuda:0'), 'backend.4.weight': tensor(-218.3605, device='cuda:0'), 'backend.4.bias': tensor(-0.1340, device='cuda:0')}
INFO:root:==> Training scene: 20
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.6179828644, MAE: 19.8658561707, MSE: 19.8658564426
INFO:root:(Meta-training) post train loss: 23.2383213043, MAE: 305.630065918, MSE: 305.630061308
INFO:root:(Meta-training) pre-training test MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post-training test MAE: 309.446746826, MSE: 309.446746731
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(58.7687, device='cuda:0'), 'backend.0.bias': tensor(0.1086, device='cuda:0'), 'backend.10.weight': tensor(-648.2240, device='cuda:0'), 'backend.8.bias': tensor(0.4562, device='cuda:0'), 'backend.6.weight': tensor(345.6557, device='cuda:0'), 'backend.2.bias': tensor(-0.1202, device='cuda:0'), 'backend.10.bias': tensor(-15.2989, device='cuda:0'), 'output_layer.bias': tensor(-243.9008, device='cuda:0'), 'backend.2.weight': tensor(-578.7977, device='cuda:0'), 'backend.6.bias': tensor(0.6730, device='cuda:0'), 'backend.0.weight': tensor(372.4923, device='cuda:0'), 'output_layer.weight': tensor(-42.9096, device='cuda:0'), 'backend.4.weight': tensor(-832.2753, device='cuda:0'), 'backend.4.bias': tensor(-0.4173, device='cuda:0')}
INFO:root:==> Training scene: 21
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.92966938019, MAE: 7.99254989624, MSE: 7.99255000362
INFO:root:(Meta-training) post train loss: 7.9303984642, MAE: 103.157691956, MSE: 103.157693681
INFO:root:(Meta-training) pre-training test MAE: 17.2073936462, MSE: 17.2073934943
INFO:root:(Meta-training) post-training test MAE: 94.2486724854, MSE: 94.2486737307
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-110.2388, device='cuda:0'), 'backend.0.bias': tensor(-0.0146, device='cuda:0'), 'backend.10.weight': tensor(-230.1305, device='cuda:0'), 'backend.8.bias': tensor(-0.4253, device='cuda:0'), 'backend.6.weight': tensor(-117.1571, device='cuda:0'), 'backend.2.bias': tensor(-0.0757, device='cuda:0'), 'backend.10.bias': tensor(-5.3008, device='cuda:0'), 'output_layer.bias': tensor(-71.6464, device='cuda:0'), 'backend.2.weight': tensor(-347.9861, device='cuda:0'), 'backend.6.bias': tensor(-0.0327, device='cuda:0'), 'backend.0.weight': tensor(-114.7507, device='cuda:0'), 'output_layer.weight': tensor(-14.5011, device='cuda:0'), 'backend.4.weight': tensor(-442.1410, device='cuda:0'), 'backend.4.bias': tensor(-0.2187, device='cuda:0')}
INFO:root:==> Training scene: 22
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.6123580933, MAE: 10.1582298279, MSE: 10.1582299753
INFO:root:(Meta-training) post train loss: 13.2736635208, MAE: 153.450256348, MSE: 153.450254052
INFO:root:(Meta-training) pre-training test MAE: 16.6812591553, MSE: 16.6812590741
INFO:root:(Meta-training) post-training test MAE: 142.571716309, MSE: 142.571713041
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-348.8337, device='cuda:0'), 'backend.0.bias': tensor(-0.1027, device='cuda:0'), 'backend.10.weight': tensor(-844.5209, device='cuda:0'), 'backend.8.bias': tensor(-1.7194, device='cuda:0'), 'backend.6.weight': tensor(-814.8105, device='cuda:0'), 'backend.2.bias': tensor(-0.4311, device='cuda:0'), 'backend.10.bias': tensor(-20.1072, device='cuda:0'), 'output_layer.bias': tensor(-113.4044, device='cuda:0'), 'backend.2.weight': tensor(-1628.4746, device='cuda:0'), 'backend.6.bias': tensor(-0.7616, device='cuda:0'), 'backend.0.weight': tensor(-452.7469, device='cuda:0'), 'output_layer.weight': tensor(-25.8738, device='cuda:0'), 'backend.4.weight': tensor(-1727.8400, device='cuda:0'), 'backend.4.bias': tensor(-1.0229, device='cuda:0')}
INFO:root:==> Training scene: 23
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 21.1111278534, MAE: 0.63020324707, MSE: 0.630203236541
INFO:root:(Meta-training) post train loss: 22.0809364319, MAE: 13.3689956665, MSE: 13.3689955309
INFO:root:(Meta-training) pre-training test MAE: 6.70138835907, MSE: 6.70138847426
INFO:root:(Meta-training) post-training test MAE: 37.1159133911, MSE: 37.1159138976
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(16.0151, device='cuda:0'), 'backend.0.bias': tensor(0.0425, device='cuda:0'), 'backend.10.weight': tensor(-114.7229, device='cuda:0'), 'backend.8.bias': tensor(-0.0450, device='cuda:0'), 'backend.6.weight': tensor(201.0754, device='cuda:0'), 'backend.2.bias': tensor(0.0558, device='cuda:0'), 'backend.10.bias': tensor(-2.8131, device='cuda:0'), 'output_layer.bias': tensor(-25.3123, device='cuda:0'), 'backend.2.weight': tensor(294.5615, device='cuda:0'), 'backend.6.bias': tensor(0.1817, device='cuda:0'), 'backend.0.weight': tensor(233.2776, device='cuda:0'), 'output_layer.weight': tensor(-4.9482, device='cuda:0'), 'backend.4.weight': tensor(177.3442, device='cuda:0'), 'backend.4.bias': tensor(0.0573, device='cuda:0')}
INFO:root:==> Training scene: 24
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.3689892292, MAE: 3.61751317978, MSE: 3.61751322588
INFO:root:(Meta-training) post train loss: 1.41690564156, MAE: 57.1678237915, MSE: 57.1678244841
INFO:root:(Meta-training) pre-training test MAE: 3.67163085938, MSE: 3.67163085126
INFO:root:(Meta-training) post-training test MAE: 62.9182128906, MSE: 62.9182121171
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(67.4449, device='cuda:0'), 'backend.0.bias': tensor(-0.0376, device='cuda:0'), 'backend.10.weight': tensor(95.9710, device='cuda:0'), 'backend.8.bias': tensor(0.2977, device='cuda:0'), 'backend.6.weight': tensor(-43.1883, device='cuda:0'), 'backend.2.bias': tensor(-0.0293, device='cuda:0'), 'backend.10.bias': tensor(3.6065, device='cuda:0'), 'output_layer.bias': tensor(48.0856, device='cuda:0'), 'backend.2.weight': tensor(-23.3053, device='cuda:0'), 'backend.6.bias': tensor(-0.1360, device='cuda:0'), 'backend.0.weight': tensor(-73.2256, device='cuda:0'), 'output_layer.weight': tensor(7.2894, device='cuda:0'), 'backend.4.weight': tensor(94.5628, device='cuda:0'), 'backend.4.bias': tensor(0.0419, device='cuda:0')}
INFO:root:==> Training scene: 25
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.78185081482, MAE: 3.64704179764, MSE: 3.647041789
INFO:root:(Meta-training) post train loss: 1.53377187252, MAE: 41.5643882751, MSE: 41.5643884674
INFO:root:(Meta-training) pre-training test MAE: 7.03860282898, MSE: 7.03860292617
INFO:root:(Meta-training) post-training test MAE: 38.4184913635, MSE: 38.4184912347
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(6.1834, device='cuda:0'), 'backend.0.bias': tensor(0.0124, device='cuda:0'), 'backend.10.weight': tensor(-7.2555, device='cuda:0'), 'backend.8.bias': tensor(0.0298, device='cuda:0'), 'backend.6.weight': tensor(31.5153, device='cuda:0'), 'backend.2.bias': tensor(0.0100, device='cuda:0'), 'backend.10.bias': tensor(-0.1930, device='cuda:0'), 'output_layer.bias': tensor(-28.9806, device='cuda:0'), 'backend.2.weight': tensor(31.5567, device='cuda:0'), 'backend.6.bias': tensor(0.0482, device='cuda:0'), 'backend.0.weight': tensor(44.4503, device='cuda:0'), 'output_layer.weight': tensor(-4.4127, device='cuda:0'), 'backend.4.weight': tensor(9.8322, device='cuda:0'), 'backend.4.bias': tensor(0.0038, device='cuda:0')}
INFO:root:==> Training scene: 26
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.51275110245, MAE: 4.93081665039, MSE: 4.93081656946
INFO:root:(Meta-training) post train loss: 6.66961288452, MAE: 63.5387802124, MSE: 63.5387796048
INFO:root:(Meta-training) pre-training test MAE: 1.70257949829, MSE: 1.70257951593
INFO:root:(Meta-training) post-training test MAE: 74.05909729, MSE: 74.0590980231
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-64.9163, device='cuda:0'), 'backend.0.bias': tensor(0.0207, device='cuda:0'), 'backend.10.weight': tensor(-215.7396, device='cuda:0'), 'backend.8.bias': tensor(-0.2159, device='cuda:0'), 'backend.6.weight': tensor(-53.6763, device='cuda:0'), 'backend.2.bias': tensor(0.0031, device='cuda:0'), 'backend.10.bias': tensor(-5.1249, device='cuda:0'), 'output_layer.bias': tensor(-58.9641, device='cuda:0'), 'backend.2.weight': tensor(-154.8738, device='cuda:0'), 'backend.6.bias': tensor(0.1189, device='cuda:0'), 'backend.0.weight': tensor(-51.5998, device='cuda:0'), 'output_layer.weight': tensor(-9.6605, device='cuda:0'), 'backend.4.weight': tensor(-269.6783, device='cuda:0'), 'backend.4.bias': tensor(-0.1026, device='cuda:0')}
INFO:root:==> Training scene: 27
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.81052994728, MAE: 3.4300737381, MSE: 3.43007370984
INFO:root:(Meta-training) post train loss: 1.85474956036, MAE: 49.2230949402, MSE: 49.2230950463
INFO:root:(Meta-training) pre-training test MAE: 0.405708312988, MSE: 0.405708318655
INFO:root:(Meta-training) post-training test MAE: 53.5645370483, MSE: 53.5645374102
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(21.7239, device='cuda:0'), 'backend.0.bias': tensor(-0.0415, device='cuda:0'), 'backend.10.weight': tensor(88.3675, device='cuda:0'), 'backend.8.bias': tensor(0.0254, device='cuda:0'), 'backend.6.weight': tensor(-91.4464, device='cuda:0'), 'backend.2.bias': tensor(-0.0413, device='cuda:0'), 'backend.10.bias': tensor(3.2484, device='cuda:0'), 'output_layer.bias': tensor(40.5884, device='cuda:0'), 'backend.2.weight': tensor(-47.4420, device='cuda:0'), 'backend.6.bias': tensor(-0.2370, device='cuda:0'), 'backend.0.weight': tensor(-68.5267, device='cuda:0'), 'output_layer.weight': tensor(6.0570, device='cuda:0'), 'backend.4.weight': tensor(54.8532, device='cuda:0'), 'backend.4.bias': tensor(-0.0010, device='cuda:0')}
INFO:root:==> Training scene: 28
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.91805839539, MAE: 16.495388031, MSE: 16.4953884269
INFO:root:(Meta-training) post train loss: 16.5992259979, MAE: 248.975204468, MSE: 248.975204275
INFO:root:(Meta-training) pre-training test MAE: 5.10612487793, MSE: 5.10612491749
INFO:root:(Meta-training) post-training test MAE: 254.839996338, MSE: 254.839992691
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-218.2436, device='cuda:0'), 'backend.0.bias': tensor(0.0600, device='cuda:0'), 'backend.10.weight': tensor(-483.3945, device='cuda:0'), 'backend.8.bias': tensor(-0.9689, device='cuda:0'), 'backend.6.weight': tensor(58.4665, device='cuda:0'), 'backend.2.bias': tensor(-0.1581, device='cuda:0'), 'backend.10.bias': tensor(-8.8787, device='cuda:0'), 'output_layer.bias': tensor(-200.1620, device='cuda:0'), 'backend.2.weight': tensor(-680.3275, device='cuda:0'), 'backend.6.bias': tensor(0.2169, device='cuda:0'), 'backend.0.weight': tensor(194.6782, device='cuda:0'), 'output_layer.weight': tensor(-33.2362, device='cuda:0'), 'backend.4.weight': tensor(-900.4709, device='cuda:0'), 'backend.4.bias': tensor(-0.4924, device='cuda:0')}
INFO:root:==> Training scene: 29
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.79754734039, MAE: 17.5090179443, MSE: 17.5090178007
INFO:root:(Meta-training) post train loss: 19.8869838715, MAE: 259.828735352, MSE: 259.828729647
INFO:root:(Meta-training) pre-training test MAE: 19.3920478821, MSE: 19.3920476916
INFO:root:(Meta-training) post-training test MAE: 262.822540283, MSE: 262.822539939
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-562.1874, device='cuda:0'), 'backend.0.bias': tensor(-0.0445, device='cuda:0'), 'backend.10.weight': tensor(-752.2290, device='cuda:0'), 'backend.8.bias': tensor(-2.6582, device='cuda:0'), 'backend.6.weight': tensor(-1082.9219, device='cuda:0'), 'backend.2.bias': tensor(-0.3633, device='cuda:0'), 'backend.10.bias': tensor(-19.6488, device='cuda:0'), 'output_layer.bias': tensor(-208.3302, device='cuda:0'), 'backend.2.weight': tensor(-1791.1676, device='cuda:0'), 'backend.6.bias': tensor(-0.9017, device='cuda:0'), 'backend.0.weight': tensor(-419.6157, device='cuda:0'), 'output_layer.weight': tensor(-41.2734, device='cuda:0'), 'backend.4.weight': tensor(-1991.5449, device='cuda:0'), 'backend.4.bias': tensor(-0.9737, device='cuda:0')}
INFO:root:==> Training scene: 30
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.79670476913, MAE: 2.56892776489, MSE: 2.56892779772
INFO:root:(Meta-training) post train loss: 5.1647310257, MAE: 24.4140777588, MSE: 24.4140775
INFO:root:(Meta-training) pre-training test MAE: 1.84230804443, MSE: 1.84230806249
INFO:root:(Meta-training) post-training test MAE: 22.7580795288, MSE: 22.7580793518
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-46.0849, device='cuda:0'), 'backend.0.bias': tensor(-0.0036, device='cuda:0'), 'backend.10.weight': tensor(-73.4196, device='cuda:0'), 'backend.8.bias': tensor(-0.1900, device='cuda:0'), 'backend.6.weight': tensor(-62.4277, device='cuda:0'), 'backend.2.bias': tensor(-0.0266, device='cuda:0'), 'backend.10.bias': tensor(-1.6552, device='cuda:0'), 'output_layer.bias': tensor(-17.0427, device='cuda:0'), 'backend.2.weight': tensor(-127.3635, device='cuda:0'), 'backend.6.bias': tensor(-0.0366, device='cuda:0'), 'backend.0.weight': tensor(-25.0330, device='cuda:0'), 'output_layer.weight': tensor(-3.4376, device='cuda:0'), 'backend.4.weight': tensor(-128.4553, device='cuda:0'), 'backend.4.bias': tensor(-0.0640, device='cuda:0')}
INFO:root:==> Training scene: 31
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.92816901207, MAE: 6.54268741608, MSE: 6.54268743565
INFO:root:(Meta-training) post train loss: 3.94747567177, MAE: 79.0179595947, MSE: 79.0179592917
INFO:root:(Meta-training) pre-training test MAE: 2.77071666718, MSE: 2.77071666233
INFO:root:(Meta-training) post-training test MAE: 81.9200592041, MSE: 81.9200585699
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-42.4969, device='cuda:0'), 'backend.0.bias': tensor(0.0191, device='cuda:0'), 'backend.10.weight': tensor(-89.6895, device='cuda:0'), 'backend.8.bias': tensor(-0.1760, device='cuda:0'), 'backend.6.weight': tensor(25.6620, device='cuda:0'), 'backend.2.bias': tensor(-0.0125, device='cuda:0'), 'backend.10.bias': tensor(-2.3425, device='cuda:0'), 'output_layer.bias': tensor(-62.3058, device='cuda:0'), 'backend.2.weight': tensor(-101.7161, device='cuda:0'), 'backend.6.bias': tensor(0.0798, device='cuda:0'), 'backend.0.weight': tensor(28.3379, device='cuda:0'), 'output_layer.weight': tensor(-10.7214, device='cuda:0'), 'backend.4.weight': tensor(-192.2546, device='cuda:0'), 'backend.4.bias': tensor(-0.0999, device='cuda:0')}
INFO:root:==> Training scene: 32
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.5723743439, MAE: 3.49564743042, MSE: 3.49564744882
INFO:root:(Meta-training) post train loss: 8.17095565796, MAE: 36.8633842468, MSE: 36.8633836973
INFO:root:(Meta-training) pre-training test MAE: 3.27803039551, MSE: 3.27803041451
INFO:root:(Meta-training) post-training test MAE: 33.7333984375, MSE: 33.733397971
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-57.7780, device='cuda:0'), 'backend.0.bias': tensor(-0.0101, device='cuda:0'), 'backend.10.weight': tensor(-168.3473, device='cuda:0'), 'backend.8.bias': tensor(-0.3028, device='cuda:0'), 'backend.6.weight': tensor(-124.3880, device='cuda:0'), 'backend.2.bias': tensor(-0.0514, device='cuda:0'), 'backend.10.bias': tensor(-3.7849, device='cuda:0'), 'output_layer.bias': tensor(-26.0395, device='cuda:0'), 'backend.2.weight': tensor(-202.7419, device='cuda:0'), 'backend.6.bias': tensor(-0.1365, device='cuda:0'), 'backend.0.weight': tensor(-33.2555, device='cuda:0'), 'output_layer.weight': tensor(-5.5097, device='cuda:0'), 'backend.4.weight': tensor(-261.7993, device='cuda:0'), 'backend.4.bias': tensor(-0.1488, device='cuda:0')}
INFO:root:===> Updating meta network
INFO:root:===> Gradients updated: {'backend.8.weight': tensor([[[[ 7.7916e-01,  8.5607e-01,  7.9229e-01],
          [ 9.0868e-01,  7.7736e-01,  6.4876e-01],
          [ 9.0064e-01,  9.4987e-01,  7.5753e-01]],

         [[ 1.1307e-01,  1.0704e-01,  9.0648e-02],
          [ 1.2795e-01,  1.0473e-01,  1.2942e-01],
          [ 1.3047e-01,  1.6048e-01,  1.4018e-01]],

         [[ 7.5768e-01,  7.1184e-01,  8.0713e-01],
          [ 7.5325e-01,  7.6828e-01,  8.4883e-01],
          [ 6.4983e-01,  8.1942e-01,  6.6784e-01]],

         ...,

         [[ 4.8735e-03,  5.3943e-03,  5.6951e-03],
          [ 4.0221e-03,  5.7924e-03,  2.3920e-03],
          [ 5.1351e-03,  6.9411e-03,  1.8353e-03]],

         [[ 2.1338e-02,  1.4164e-02,  1.3132e-02],
          [ 1.4678e-02,  1.8111e-02,  1.2113e-02],
          [ 1.1622e-02,  1.0919e-02,  8.9135e-03]],

         [[ 8.8305e-01,  8.2144e-01,  7.5310e-01],
          [ 8.2313e-01,  8.4059e-01,  7.4162e-01],
          [ 8.5086e-01,  7.3575e-01,  7.3748e-01]]],


        [[[-4.9812e-01, -5.0378e-01, -5.1191e-01],
          [-4.0563e-01, -2.9149e-01, -3.7377e-01],
          [-2.8067e-01, -3.3813e-01, -3.9142e-01]],

         [[-3.6184e-02, -4.4533e-02, -3.7252e-02],
          [-3.7537e-02, -2.0505e-02, -3.5804e-02],
          [-3.6210e-02, -6.8324e-02, -4.4339e-02]],

         [[-3.7382e-01, -3.9211e-01, -4.3686e-01],
          [-4.6847e-01, -4.9453e-01, -5.1677e-01],
          [-5.1365e-01, -5.5016e-01, -3.8768e-01]],

         ...,

         [[-5.0242e-03, -1.1526e-03, -2.1686e-03],
          [-3.8029e-03, -3.3367e-03, -1.4324e-03],
          [-3.0780e-03, -4.2156e-03, -4.6184e-03]],

         [[-5.8552e-03, -1.7621e-02, -2.0924e-02],
          [-2.2585e-02, -2.9422e-02, -2.1775e-02],
          [-1.7520e-02, -1.5502e-02, -9.9939e-03]],

         [[-3.5619e-01, -4.2216e-01, -4.5200e-01],
          [-4.1187e-01, -5.1697e-01, -4.8196e-01],
          [-2.5478e-01, -2.9195e-01, -3.7740e-01]]],


        [[[-5.0192e-01, -1.6550e-01, -3.0481e-01],
          [-4.3925e-01, -2.2387e-01, -4.2957e-01],
          [-2.3618e-01, -4.3159e-01, -5.8229e-01]],

         [[-1.4857e-02, -4.3006e-02, -5.9084e-02],
          [-6.6490e-03, -6.0455e-02, -7.7892e-02],
          [-2.2638e-02, -5.3768e-02, -7.4316e-02]],

         [[ 8.3277e-02,  2.6159e-02, -2.1678e-01],
          [-1.3345e-01, -2.8881e-01, -1.2474e-01],
          [-3.7338e-01, -2.9140e-01, -1.1983e-01]],

         ...,

         [[-8.1380e-03, -4.9586e-03, -2.1028e-03],
          [-4.4010e-03, -1.6209e-03,  3.1506e-03],
          [-6.1093e-04,  1.2553e-03, -5.3142e-03]],

         [[ 1.1792e-02, -2.7060e-03, -3.8840e-03],
          [-1.7547e-03, -1.5361e-02, -9.7132e-03],
          [-3.5432e-03, -5.4997e-03, -2.7220e-03]],

         [[-7.8806e-03, -2.6094e-01, -2.7988e-01],
          [-1.4145e-01, -1.4226e-01, -3.1542e-01],
          [ 2.1230e-02, -2.0337e-01, -2.4090e-01]]],


        ...,


        [[[-2.9929e-01, -3.0268e-01, -2.6287e-01],
          [-2.9783e-01, -3.2070e-01, -2.3949e-01],
          [-3.1233e-01, -3.2161e-01, -2.6809e-01]],

         [[-3.4950e-02, -4.1251e-02, -3.6930e-02],
          [-3.8473e-02, -3.4362e-02, -3.8018e-02],
          [-3.6614e-02, -3.9380e-02, -3.5096e-02]],

         [[-1.7141e-01, -1.5779e-01, -1.4476e-01],
          [-1.7421e-01, -1.4054e-01, -1.5374e-01],
          [-1.1284e-01, -1.3553e-01, -1.4858e-01]],

         ...,

         [[-3.5638e-03, -2.7827e-03, -2.7394e-03],
          [-3.8444e-03, -3.7023e-03, -1.9840e-03],
          [-5.2670e-03, -4.6121e-03, -2.3858e-03]],

         [[-4.0673e-03, -2.9856e-03, -2.4182e-03],
          [-3.0785e-03, -2.0582e-03, -2.0237e-03],
          [-1.1365e-03, -2.0668e-03, -1.9191e-03]],

         [[-2.2178e-01, -2.4374e-01, -2.2302e-01],
          [-2.0329e-01, -2.1494e-01, -2.0253e-01],
          [-2.2834e-01, -2.2162e-01, -2.1170e-01]]],


        [[[-1.9047e-01, -5.0808e-01, -6.5153e-01],
          [-5.2507e-01, -5.0222e-01, -7.7457e-01],
          [-2.1515e-01,  8.5311e-02, -3.5444e-01]],

         [[ 3.1730e-02, -1.1143e-01,  1.3258e-02],
          [-6.2913e-02,  5.6851e-02, -3.5361e-02],
          [-4.4692e-02, -6.0705e-02, -1.5646e-02]],

         [[-2.1753e-01, -4.0753e-01,  1.6298e-01],
          [-2.4689e-01,  2.1465e-01, -1.9746e-01],
          [-3.6736e-01, -3.6167e-01, -3.7535e-01]],

         ...,

         [[-1.1183e-02, -9.8645e-03, -4.9526e-03],
          [-1.2929e-02, -9.7746e-03, -1.4052e-02],
          [-9.3558e-03, -6.5620e-03, -3.3315e-03]],

         [[ 8.0944e-03,  1.3655e-02,  8.0051e-03],
          [-5.6982e-03,  1.6566e-03, -4.8271e-03],
          [-4.1137e-03,  1.1966e-03,  4.5941e-03]],

         [[ 1.2224e-01,  3.1816e-01, -1.0587e-02],
          [-2.2470e-02, -3.1922e-01, -2.2589e-01],
          [ 2.7739e-03,  5.2612e-03,  1.2988e-02]]],


        [[[-4.9065e-01, -5.2073e-01, -5.2142e-01],
          [-6.1824e-01, -4.1892e-01, -5.3042e-01],
          [-7.6838e-01, -4.8344e-01, -6.1932e-01]],

         [[-1.0348e-01, -5.7851e-02, -8.9387e-02],
          [-8.2591e-02, -8.9406e-02, -8.5119e-02],
          [-9.8153e-02, -1.1333e-01, -1.1592e-01]],

         [[-5.3413e-01, -5.2772e-01, -4.8901e-01],
          [-3.7988e-01, -3.6942e-01, -5.1767e-01],
          [-4.2634e-01, -3.9946e-01, -4.8190e-01]],

         ...,

         [[-1.6937e-03, -4.2673e-03, -6.6555e-03],
          [-3.8203e-03, -4.7556e-03, -4.0911e-03],
          [-4.4072e-03, -1.1244e-03, -1.3580e-03]],

         [[-1.8637e-02, -5.6253e-03, -1.0104e-02],
          [-2.4474e-04, -1.3704e-03, -3.9372e-03],
          [-5.8169e-03, -9.9687e-03, -7.9205e-03]],

         [[-6.9425e-01, -5.7233e-01, -5.7277e-01],
          [-5.3208e-01, -6.1464e-01, -5.7705e-01],
          [-6.7009e-01, -4.8128e-01, -5.7393e-01]]]], device='cuda:0'), 'backend.0.bias': tensor([ 3.7435e-02,  8.6871e-03,  2.9686e-02,  9.5617e-02, -7.9367e-03,
        -2.2906e-01,  2.1799e-02,  1.2916e-01, -1.1742e-01,  5.3096e-02,
         6.5154e-02, -3.3858e-02, -1.8881e-01,  6.5476e-02,  1.1124e-01,
        -1.6869e-02, -9.0779e-02, -5.9170e-02, -1.5688e-02, -6.3597e-03,
        -1.0433e-01,  1.4870e-02,  2.4667e-01,  3.6994e-02, -5.4464e-02,
         1.1374e-02, -1.7108e-01, -2.9400e-02, -1.2781e-01, -2.2294e-02,
         5.0196e-02, -4.6587e-02, -4.9303e-02, -6.8110e-02, -1.1202e-01,
         1.1110e-01,  4.5687e-02,  1.5133e-01,  3.5386e-02, -2.8245e-02,
         4.8510e-02, -1.7623e-01,  1.0987e-01, -1.7990e-01,  3.6821e-02,
         6.6116e-03,  8.1240e-03,  1.3467e-01,  2.1310e-02, -2.2370e-02,
        -3.5821e-02,  1.0288e-01, -2.3761e-01,  1.0829e-01, -1.2286e-01,
         4.3771e-02,  9.0972e-02,  5.4289e-03,  6.3612e-03,  6.7665e-02,
        -8.3068e-03,  2.5766e-02,  1.2529e-01,  9.5696e-02, -3.2554e-02,
         1.1471e-03,  4.7836e-02, -1.0141e-01, -5.9006e-02,  1.1059e-01,
         1.9443e-03,  3.8479e-02,  1.3207e-02, -2.1735e-02, -5.8060e-03,
         5.6675e-02,  6.5929e-02,  2.8957e-02,  1.0560e-01,  8.2576e-03,
        -4.4969e-02,  1.1855e-03, -1.6334e-01,  3.3129e-02,  1.4978e-02,
        -5.1273e-02,  1.3312e-02, -1.1537e-01,  1.1990e-01, -2.9756e-03,
         2.5821e-02, -1.2387e-01,  3.3274e-02,  1.4201e-01, -1.8099e-02,
        -8.3502e-02, -1.2276e-01, -1.7765e-01, -1.7965e-01,  1.4993e-01,
        -2.8551e-04, -9.3298e-03,  1.3635e-01,  3.1088e-03,  3.3440e-02,
        -1.6650e-02, -3.7137e-02,  1.8647e-02, -1.6222e-02, -1.3726e-01,
        -2.6881e-02,  1.3328e-01, -2.0468e-02, -1.7346e-02,  1.0685e-01,
        -9.4515e-03, -3.3735e-02,  5.2324e-02, -6.5748e-02,  5.0565e-02,
         6.0393e-02, -2.3554e-02, -1.8967e-01,  6.2572e-03,  7.2337e-02,
        -1.7122e-02, -2.7186e-03, -9.6275e-02,  4.6953e-04, -2.2710e-01,
         6.5836e-03,  3.1450e-02, -7.9211e-03, -1.7999e-01,  1.5686e-01,
        -1.3606e-02, -3.6704e-02, -1.8343e-01,  1.3468e-01,  1.1925e-02,
        -1.4944e-02, -9.2971e-03,  3.1527e-02, -3.5561e-02,  8.4170e-03,
        -7.3547e-02,  6.9652e-02,  1.4172e-01, -5.6149e-02,  8.2017e-02,
         5.3280e-02,  9.1900e-02,  2.8365e-03, -1.3483e-02,  7.4776e-02,
         6.9655e-03, -2.7512e-02, -3.0704e-02, -2.0543e-01,  1.8875e-01,
         6.9805e-02,  3.3832e-02, -2.7313e-02, -2.0109e-01, -5.1880e-02,
         2.3723e-03,  1.0829e-01, -3.6843e-02, -8.6512e-02, -2.1700e-01,
        -7.0291e-02,  6.8957e-02,  3.1385e-02,  1.3123e-02, -3.2298e-02,
        -1.0123e-01,  8.2451e-02, -1.8406e-02,  2.7769e-02, -1.5899e-01,
         4.5782e-03,  1.1976e-02,  7.1423e-03,  4.3336e-03, -1.7068e-01,
        -3.9195e-02,  4.2247e-02,  8.9103e-02, -5.1268e-03, -5.4139e-02,
         1.3960e-03, -8.0118e-02, -5.2302e-02,  8.1240e-03,  1.2798e-01,
         8.6178e-02,  5.2952e-02,  7.4546e-02, -3.3940e-03,  1.7204e-01,
        -1.1362e-01,  1.4207e-01,  2.1858e-01,  9.2226e-02, -1.9899e-01,
         3.6390e-02, -1.1806e-01, -8.2607e-02,  9.6324e-02,  3.8893e-02,
        -4.3599e-03, -1.4082e-01,  8.5450e-02,  7.8837e-02,  4.1851e-02,
         1.1332e-02,  7.4670e-02,  6.7291e-02, -7.1615e-02, -1.5780e-01,
        -9.5901e-03, -2.2307e-02, -6.0844e-02,  9.7201e-02, -1.1720e-01,
         1.0030e-01, -1.0908e-02, -3.6493e-02, -2.5854e-04, -7.7158e-02,
        -1.7274e-01,  2.3191e-02, -1.9714e-02,  3.5282e-02, -1.4302e-01,
         1.2823e-02,  4.7919e-02, -1.6809e-01,  5.6044e-02,  7.4026e-02,
         2.2771e-02, -1.4494e-01, -4.2029e-02, -6.3801e-02,  1.2181e-02,
         4.3359e-02,  5.3710e-02,  4.2697e-02, -2.8497e-02,  1.4108e-01,
        -5.5331e-03,  9.1693e-02,  6.3695e-02, -3.4251e-02, -2.8300e-02,
        -5.3445e-02,  2.9543e-03, -5.0378e-02,  1.6559e-02,  1.2318e-01,
        -4.0892e-04, -9.3539e-02, -6.3956e-02, -1.3604e-02, -5.2656e-02,
         3.6483e-02, -9.6794e-02, -8.6377e-02,  4.8810e-04,  8.6021e-03,
        -1.0094e-01, -5.5458e-02, -6.2282e-03,  2.4521e-02,  1.6359e-01,
        -3.3315e-02,  4.5278e-02,  5.1334e-02, -1.2520e-01,  9.1645e-02,
        -5.9487e-02, -1.1458e-01, -6.1015e-02, -2.1344e-01,  2.6370e-02,
         1.8459e-02, -8.5138e-04,  3.9910e-01,  2.6680e-02, -1.6055e-01,
        -6.4647e-02, -5.6140e-02,  1.0158e-02, -1.4173e-02,  7.4237e-02,
         3.7756e-02, -7.6092e-02, -5.3069e-02,  4.9687e-02, -2.6026e-01,
        -1.8112e-01,  1.3090e-01,  2.7320e-02,  2.0812e-02,  3.8818e-02,
         4.0497e-02, -4.4816e-02, -3.4689e-02, -6.9139e-02,  1.2729e-01,
        -1.7978e-01,  3.2796e-02, -4.3860e-02,  9.0156e-02,  3.4747e-02,
        -5.8768e-02, -2.9963e-02, -2.5520e-03, -2.6110e-03, -3.0463e-02,
         4.8107e-02, -1.5035e-01,  4.0941e-02, -8.9532e-02, -2.2504e-02,
         2.5582e-02,  9.0480e-02,  6.8586e-02,  1.1664e-01, -1.2780e-02,
         1.4531e-02,  2.3292e-02, -8.2613e-02,  7.2054e-02,  6.5946e-03,
         5.9477e-02,  2.1407e-02, -1.0625e-01, -1.0625e-01, -8.5957e-02,
         8.7438e-02,  6.5845e-02,  1.9993e-02, -2.2160e-02, -7.1829e-02,
        -1.4767e-03, -2.1725e-02,  4.5513e-02,  4.6463e-02, -5.6595e-02,
         7.0408e-02, -7.1068e-02,  8.3108e-02,  7.8467e-02,  9.3381e-02,
         6.4279e-04,  4.0035e-02, -3.3876e-03,  4.2069e-02, -1.4598e-01,
         7.9622e-02,  1.4402e-01, -4.1292e-02,  4.3087e-02, -1.2322e-01,
        -1.4230e-01, -1.5479e-02, -1.5638e-01,  7.6902e-02, -1.8433e-02,
        -3.0860e-02, -7.7828e-02,  4.6240e-02,  1.0648e-01,  6.2954e-02,
         3.3869e-02,  5.2017e-02,  7.5417e-02, -1.0650e-01, -8.4434e-04,
        -1.1416e-01,  5.3097e-02,  1.0518e-01,  1.0734e-01, -8.4019e-02,
         1.3562e-01, -1.2335e-01, -4.9152e-02,  1.2402e-01, -8.0860e-02,
         1.4998e-01, -2.3119e-02,  1.0668e-01, -5.9596e-02, -1.0735e-02,
         4.4335e-02,  2.6922e-02, -5.7335e-02,  1.0289e-01,  2.2908e-01,
        -6.2296e-02,  4.3519e-02,  3.5142e-02, -3.7512e-02, -1.5319e-01,
        -1.7330e-01, -1.7242e-01,  1.1273e-01,  8.8121e-02,  1.7928e-02,
         1.5912e-01, -8.8503e-03,  3.6250e-03, -1.5004e-02, -9.1842e-02,
         2.3674e-02,  2.8330e-02,  2.2836e-02,  4.4368e-02, -6.7739e-02,
        -5.3700e-02, -3.3513e-03, -1.7342e-02, -9.4061e-03,  5.4576e-02,
        -5.9962e-02, -4.1889e-03, -5.1600e-02, -1.4493e-02, -7.0578e-02,
        -1.0849e-01,  1.7600e-01, -9.0257e-02,  1.1788e-01, -3.2405e-03,
         5.9320e-02, -6.7924e-02, -6.7785e-02,  3.3781e-02,  3.1116e-02,
        -1.1967e-01,  1.1624e-01, -6.5046e-02,  6.9480e-02,  3.6162e-02,
         1.8169e-02, -1.1414e-02, -2.2335e-02, -5.7600e-02,  4.2444e-02,
         1.4756e-02,  2.9848e-02,  9.0882e-02, -1.8334e-02, -1.7758e-01,
         6.6599e-02, -4.1335e-02, -5.6227e-02, -2.5876e-02, -1.4190e-01,
         2.3720e-03,  1.5120e-02,  8.3824e-03,  1.7196e-02,  4.8926e-02,
        -1.8419e-01,  1.6426e-04, -5.8988e-03, -2.3125e-01, -1.4528e-01,
         2.8597e-02,  4.2600e-02, -3.7204e-02,  1.2312e-02,  1.3099e-01,
        -3.3445e-02, -1.1550e-01, -3.2145e-02, -5.2977e-02,  3.4272e-02,
        -1.4026e-02, -7.2395e-03,  5.4506e-03, -2.1931e-02, -1.5544e-02,
         5.1915e-02,  6.7205e-03, -2.1290e-01,  8.3985e-02,  9.0955e-02,
        -1.9859e-02,  5.5643e-02,  7.0865e-02, -6.5067e-02, -1.8820e-02,
        -2.6492e-03, -1.0377e-02, -2.6327e-02,  1.3805e-01,  7.2932e-03,
         6.3785e-02, -1.9616e-02,  5.1569e-03, -6.8187e-02,  2.9798e-02,
         9.7753e-02,  1.3504e-01, -1.2660e-01,  6.2470e-04,  6.9422e-02,
         2.6582e-02,  5.3618e-02], device='cuda:0'), 'backend.10.weight': tensor([[[[-2.1959e-01, -3.3617e-01, -3.1556e-01],
          [-4.1270e-01, -3.4179e-01, -3.8507e-01],
          [-5.4396e-01, -5.1190e-01, -5.2420e-01]],

         [[-1.8068e-01, -1.1518e-01, -9.5162e-02],
          [-5.3012e-02, -3.9710e-02, -3.9326e-02],
          [-1.9610e-02, -1.2150e-02, -1.1782e-02]],

         [[-5.8630e-01, -4.5302e-01, -3.9153e-01],
          [-5.4708e-01, -2.9469e-01, -3.2340e-01],
          [-3.8501e-01, -3.9807e-01, -5.7451e-01]],

         ...,

         [[-9.7577e-02, -7.3513e-02, -7.1505e-02],
          [-5.3139e-02, -8.2465e-02, -6.4261e-02],
          [-5.2220e-02, -5.2126e-02, -5.7822e-02]],

         [[-7.6080e-01, -6.6571e-01, -8.5296e-01],
          [-6.0264e-01, -6.6787e-01, -6.7292e-01],
          [-1.1411e+00, -6.8185e-01, -6.6706e-01]],

         [[-1.8829e-01, -1.7584e-01, -2.0558e-01],
          [-1.6771e-01, -2.0710e-01, -3.6579e-01],
          [-1.1624e-01, -1.1664e-01, -1.4307e-01]]],


        [[[-2.3476e+00, -2.6140e+00, -2.5955e+00],
          [-3.0088e+00, -2.9354e+00, -2.9637e+00],
          [-3.3367e+00, -3.2346e+00, -3.2560e+00]],

         [[-3.5227e-01, -3.1430e-01, -2.8929e-01],
          [-3.8315e-01, -3.6267e-01, -3.4866e-01],
          [-1.9386e-01, -1.8508e-01, -1.6998e-01]],

         [[-2.3411e+00, -2.0769e+00, -1.9700e+00],
          [-2.4370e+00, -2.0338e+00, -2.0448e+00],
          [-1.9506e+00, -1.8898e+00, -2.0975e+00]],

         ...,

         [[-7.2566e-01, -7.4311e-01, -7.0555e-01],
          [-6.7706e-01, -7.6847e-01, -7.2329e-01],
          [-6.1617e-01, -6.6311e-01, -6.7480e-01]],

         [[-4.6668e+00, -4.4965e+00, -4.7603e+00],
          [-4.8601e+00, -4.4961e+00, -4.5276e+00],
          [-5.5612e+00, -4.5514e+00, -4.3601e+00]],

         [[-5.4382e-01, -5.9398e-01, -6.5607e-01],
          [-5.7637e-01, -6.7748e-01, -8.0152e-01],
          [-4.7273e-01, -5.1591e-01, -6.0473e-01]]],


        [[[ 5.0461e-01,  5.0912e-01,  5.1985e-01],
          [ 5.1670e-01,  5.3388e-01,  5.4456e-01],
          [ 5.2959e-01,  5.4138e-01,  5.4454e-01]],

         [[ 8.5475e-03,  1.2207e-02,  1.2803e-02],
          [ 2.4507e-02,  2.6864e-02,  2.6616e-02],
          [ 2.4521e-02,  2.6697e-02,  2.7364e-02]],

         [[ 1.6012e-01,  1.9595e-01,  1.9410e-01],
          [ 1.9142e-01,  2.1182e-01,  1.9630e-01],
          [ 1.9157e-01,  2.1010e-01,  2.0856e-01]],

         ...,

         [[ 1.0573e-01,  1.0355e-01,  1.0533e-01],
          [ 1.1294e-01,  1.1248e-01,  1.1330e-01],
          [ 1.1578e-01,  1.1593e-01,  1.1540e-01]],

         [[ 5.8944e-01,  6.1057e-01,  6.0976e-01],
          [ 5.8719e-01,  6.4044e-01,  6.4838e-01],
          [ 6.2204e-01,  6.5195e-01,  6.4490e-01]],

         [[ 3.2154e-02,  3.4026e-02,  2.0880e-02],
          [ 3.2994e-02,  4.0004e-02,  2.7592e-02],
          [ 3.6006e-02,  4.3411e-02,  3.7159e-02]]],


        ...,


        [[[ 1.8190e-01,  1.7046e-01,  1.6139e-01],
          [ 1.8184e-01,  1.8455e-01,  1.6810e-01],
          [ 1.5529e-01,  1.4892e-01,  1.3226e-01]],

         [[ 6.4873e-03,  1.1624e-02,  1.2358e-02],
          [ 5.4277e-02,  5.7847e-02,  5.7604e-02],
          [ 2.9974e-02,  3.2117e-02,  3.0282e-02]],

         [[ 7.2629e-02,  8.3997e-02,  7.7993e-02],
          [ 1.4803e-01,  1.6411e-01,  1.4653e-01],
          [ 1.2448e-01,  1.1466e-01,  9.5875e-02]],

         ...,

         [[ 2.1645e-02,  2.1378e-02,  2.0795e-02],
          [ 2.4206e-02,  2.2717e-02,  2.0400e-02],
          [ 1.9733e-02,  1.8385e-02,  1.5471e-02]],

         [[ 2.3900e-01,  2.4282e-01,  2.2168e-01],
          [ 2.5852e-01,  2.4316e-01,  2.4233e-01],
          [ 1.6479e-01,  1.7964e-01,  1.5443e-01]],

         [[ 1.5493e-02,  1.5617e-02,  2.1987e-02],
          [ 3.8231e-02,  3.1676e-02,  3.4201e-02],
          [ 3.2448e-02,  4.2885e-02,  4.5704e-02]]],


        [[[-1.1759e+00, -1.6960e+00, -1.5655e+00],
          [-2.0424e+00, -1.9111e+00, -1.9262e+00],
          [-2.5530e+00, -2.4313e+00, -2.4598e+00]],

         [[-5.2375e-01, -3.9010e-01, -3.5612e-01],
          [-1.7797e-01, -1.4278e-01, -1.5336e-01],
          [-5.4150e-02, -3.4322e-02, -4.5135e-02]],

         [[-2.4280e+00, -2.0517e+00, -1.8042e+00],
          [-2.3026e+00, -1.3931e+00, -1.5063e+00],
          [-1.5431e+00, -1.5189e+00, -2.2005e+00]],

         ...,

         [[-3.9746e-01, -3.2304e-01, -2.6708e-01],
          [-2.9420e-01, -3.7322e-01, -3.1304e-01],
          [-2.4681e-01, -2.3344e-01, -2.4592e-01]],

         [[-3.1743e+00, -3.0652e+00, -3.6059e+00],
          [-2.6640e+00, -2.7461e+00, -2.8847e+00],
          [-4.6844e+00, -3.0260e+00, -2.9310e+00]],

         [[-6.6746e-01, -6.5959e-01, -6.4882e-01],
          [-5.9409e-01, -7.4414e-01, -1.1450e+00],
          [-3.8093e-01, -3.7266e-01, -4.6022e-01]]],


        [[[-2.0956e-02, -2.0874e-02, -1.9518e-02],
          [-2.7313e-02, -2.4516e-02, -2.2938e-02],
          [-3.3471e-02, -3.3802e-02, -3.1649e-02]],

         [[-7.0705e-03, -8.3364e-03, -8.0707e-03],
          [-1.5045e-03, -2.1105e-03, -1.4246e-03],
          [-2.9154e-04, -2.5145e-04, -2.7530e-04]],

         [[-2.9277e-02, -2.6434e-02, -2.3441e-02],
          [-2.4026e-02, -2.1748e-02, -2.1338e-02],
          [-1.7061e-02, -2.5575e-02, -2.2425e-02]],

         ...,

         [[-3.2052e-03, -2.6869e-03, -1.9415e-03],
          [-1.3244e-03, -1.4512e-03, -1.2490e-03],
          [-1.7377e-03, -2.1666e-03, -1.5998e-03]],

         [[-3.7680e-02, -3.7452e-02, -3.5263e-02],
          [-3.3036e-02, -3.4708e-02, -2.4630e-02],
          [-4.1510e-02, -3.3301e-02, -3.4321e-02]],

         [[-1.6050e-02, -1.3616e-02, -1.1221e-02],
          [-9.7573e-03, -1.1921e-02, -1.2731e-02],
          [-5.4952e-03, -6.2394e-03, -4.1736e-03]]]], device='cuda:0'), 'backend.8.bias': tensor([ 4.9737e+00, -3.2972e+00, -1.2807e+00,  7.2607e-01, -1.5039e+00,
         1.6829e-01,  4.9959e-01, -2.1996e+00, -8.1899e-01, -1.3867e+00,
        -2.9949e-01, -4.3840e+00,  3.9718e-01, -3.1363e+00, -3.8491e+00,
        -2.6649e+00, -4.2858e-03, -5.9884e-01,  2.8110e+00, -2.2734e+00,
        -3.7313e-01,  7.8965e+00, -2.7427e-01, -4.5185e+00, -4.7506e-01,
         6.7307e+00,  2.4345e+00,  7.2646e+00, -3.2969e+00, -2.1476e+00,
        -1.9279e+00, -1.8337e+00, -1.6325e+00, -6.2015e-01, -9.9722e-01,
        -4.8325e+00,  2.9649e+00, -1.7396e+00, -1.6582e+00, -2.2803e+00,
         8.5869e-01,  3.3220e+00, -1.2001e+00,  9.5225e-02, -6.5972e-01,
         2.6132e+00, -3.0081e+00,  2.7432e+00, -2.9369e+00, -5.7038e-01,
        -4.1127e+00, -5.6515e+00, -3.8666e-01, -3.7298e+00,  7.6422e-01,
        -2.0456e+00, -2.0734e+00,  2.8771e-01, -2.2529e+00,  3.3025e+00,
         3.9578e+00, -2.1992e+00, -7.6605e-01, -1.0977e+00,  1.1327e-01,
        -3.4376e+00, -6.3099e-01, -7.0960e+00,  2.1510e+00,  1.8661e+00,
         2.0419e-01, -8.1414e-01,  4.6508e+00, -2.5497e+00, -4.1238e-01,
        -3.9497e+00,  2.1542e+00, -1.6452e+00, -1.1187e+00,  2.3748e+00,
        -5.8479e+00,  1.0999e+00,  9.7701e-02,  1.6046e+01, -1.4923e-01,
         3.7003e+00,  8.8302e-01, -4.3128e+00, -3.0774e+00,  5.0140e+00,
        -3.2504e+00,  2.5758e+00,  8.8291e-01, -1.0728e-01, -4.5346e-01,
        -2.7930e+00, -5.8308e+00, -1.6652e+00, -3.4447e-01, -4.6627e+00,
        -3.4878e+00, -2.0511e+00, -6.1618e-03,  5.6120e+00, -1.7158e-01,
        -5.2394e-01, -4.4822e-01,  1.6986e+00, -1.6533e+00, -2.3031e+00,
         2.8576e+00, -3.0470e+00, -5.3538e+00, -1.7170e+00,  8.7231e-01,
        -6.4554e+00, -1.1155e+00, -1.7039e+00,  9.7583e+00,  4.5824e-02,
         6.5802e+00, -2.2104e+00,  1.9929e+00, -5.2730e-02, -1.6266e+00,
        -1.3862e+00, -1.2762e+00, -3.9050e+00], device='cuda:0'), 'backend.6.weight': tensor([[[[ 1.7659e-02, -2.6832e-02,  1.1385e-02],
          [-9.5987e-03, -6.9889e-02, -7.4894e-02],
          [-5.2249e-02, -5.5227e-02, -7.9817e-02]],

         [[ 3.0971e-02,  5.7662e-02, -3.3497e-03],
          [-1.8451e-02, -1.3400e-02, -2.8495e-02],
          [-3.6402e-02, -7.0431e-02, -3.7302e-02]],

         [[-8.8065e-02, -1.2215e-01, -9.8338e-02],
          [-8.9382e-02, -4.0194e-02, -8.8762e-02],
          [-6.7900e-02, -6.4822e-02, -2.2597e-02]],

         ...,

         [[ 7.3210e-02, -2.9444e-02,  3.3526e-02],
          [ 1.1094e-02, -1.5081e-02, -2.0852e-02],
          [-5.2141e-02, -7.4994e-02, -8.7375e-02]],

         [[ 6.4951e-02,  5.9654e-02, -4.4959e-03],
          [-3.5679e-02,  6.1586e-02, -3.2397e-02],
          [-2.3371e-02, -6.1787e-02, -2.3975e-02]],

         [[-4.3150e-02, -2.9796e-02, -3.8649e-03],
          [-2.6559e-02, -1.7023e-02,  2.6667e-02],
          [ 4.5345e-02,  5.3840e-02,  8.0433e-02]]],


        [[[-1.8931e-02, -1.3767e-02, -2.2328e-02],
          [-1.8000e-02, -1.7059e-02, -1.7738e-02],
          [-1.7193e-03,  2.6560e-03, -3.2754e-03]],

         [[-4.8773e-03, -9.9158e-03, -1.8203e-02],
          [-9.3296e-03, -3.3826e-03, -1.0877e-02],
          [ 3.6880e-03, -3.0342e-03,  1.1093e-03]],

         [[-1.9347e-02, -1.9374e-02, -7.3067e-03],
          [ 1.2831e-02,  5.7045e-05, -5.6080e-03],
          [-1.6918e-02, -1.6682e-02, -2.7384e-02]],

         ...,

         [[-3.2147e-02, -5.1278e-02, -5.4455e-02],
          [-2.2433e-02, -6.8818e-03, -2.5640e-02],
          [-2.3895e-02, -3.1762e-02, -3.6114e-02]],

         [[-2.0606e-02, -3.0017e-02, -4.2409e-02],
          [-3.8846e-02, -2.1023e-02, -2.3158e-02],
          [-1.8858e-02, -2.0132e-02, -2.1347e-02]],

         [[ 3.0966e-02,  2.2453e-02,  2.1628e-02],
          [-1.4633e-02,  3.5284e-03,  8.0403e-04],
          [ 3.7989e-03, -2.6809e-03,  6.2535e-03]]],


        [[[ 1.6406e-01,  1.0967e-01,  1.5278e-01],
          [ 1.9659e-01,  1.5155e-01,  1.5199e-01],
          [ 1.1946e-01,  1.4954e-01,  1.1909e-01]],

         [[ 6.7720e-02,  1.4779e-01,  1.6977e-01],
          [ 1.0759e-01,  1.5109e-01,  1.3400e-01],
          [ 1.4679e-01,  1.1283e-01,  7.9237e-02]],

         [[ 4.3010e-01,  4.1349e-01,  3.3435e-01],
          [ 3.3523e-01,  3.7894e-01,  3.6660e-01],
          [ 3.4610e-01,  3.0348e-01,  3.2541e-01]],

         ...,

         [[ 1.7422e-01,  1.2319e-01,  1.7807e-01],
          [ 1.3168e-01,  1.4664e-01,  7.5703e-02],
          [ 8.7482e-02,  1.2710e-01,  1.0617e-01]],

         [[ 2.8918e-01,  2.1335e-01,  3.0835e-01],
          [ 2.9417e-01,  2.6610e-01,  3.8148e-01],
          [ 3.5822e-01,  1.8312e-01,  2.4299e-01]],

         [[ 6.2543e-01,  6.9266e-01,  6.6342e-01],
          [ 6.4601e-01,  6.5722e-01,  6.6194e-01],
          [ 7.1699e-01,  7.2908e-01,  6.5543e-01]]],


        ...,


        [[[-3.0835e-03, -5.4564e-03, -4.0023e-03],
          [-4.0692e-03, -5.8402e-03, -5.1373e-03],
          [-3.0648e-03, -2.8590e-03, -4.6755e-03]],

         [[-3.8954e-03, -4.8944e-03, -5.4124e-03],
          [-1.1260e-02, -8.1189e-03, -8.4610e-03],
          [-7.5158e-03, -1.0222e-02, -8.0837e-03]],

         [[-1.4891e-02, -1.4623e-02, -2.0755e-02],
          [-2.3570e-02, -1.8869e-02, -2.5201e-02],
          [-2.3054e-02, -2.1368e-02, -1.9387e-02]],

         ...,

         [[-7.3070e-03, -1.0875e-02, -7.4364e-03],
          [-6.0823e-03, -5.9057e-03, -9.7995e-03],
          [-5.6779e-03, -4.5553e-03, -5.1283e-03]],

         [[-6.7615e-03, -8.6668e-03, -1.2406e-02],
          [-1.7809e-02, -1.6932e-02, -1.4824e-02],
          [-1.3919e-02, -1.8692e-02, -1.7843e-02]],

         [[-1.1690e-02, -1.2990e-02, -9.4363e-03],
          [-3.4773e-02, -3.4121e-02, -3.0164e-02],
          [-3.9312e-02, -4.2817e-02, -4.0379e-02]]],


        [[[-1.1916e-02, -8.5963e-03, -1.0027e-02],
          [-9.8618e-03, -1.3041e-02, -9.8268e-03],
          [-1.3514e-02, -1.5581e-02, -1.3258e-02]],

         [[-4.4534e-03, -6.6128e-03, -5.6979e-03],
          [-4.0484e-03, -4.0086e-03, -5.0110e-03],
          [-4.2607e-03, -4.7118e-03, -7.7490e-03]],

         [[-2.5376e-02, -2.8867e-02, -3.2323e-02],
          [-1.9552e-02, -2.3627e-02, -2.7003e-02],
          [-1.9886e-02, -1.9896e-02, -2.6292e-02]],

         ...,

         [[-8.8458e-03, -8.3307e-03, -7.5917e-03],
          [-1.1403e-02, -1.1842e-02, -1.1067e-02],
          [-1.5496e-02, -1.6875e-02, -1.5704e-02]],

         [[-1.7235e-02, -2.2534e-02, -1.8845e-02],
          [-1.8398e-02, -1.8702e-02, -1.9821e-02],
          [-2.2294e-02, -1.8882e-02, -2.1458e-02]],

         [[-2.3912e-02, -3.0531e-02, -3.6398e-02],
          [-2.0194e-02, -2.3741e-02, -3.0163e-02],
          [-1.7457e-02, -1.2982e-02, -2.0532e-02]]],


        [[[-3.1058e-02,  1.6961e-02, -5.0719e-02],
          [-2.3574e-02,  2.1136e-02, -5.6161e-04],
          [-7.0931e-02, -4.7651e-02, -1.5538e-02]],

         [[ 4.7572e-02, -7.3376e-03,  3.1953e-02],
          [ 1.1158e-01,  5.7627e-02, -1.6535e-04],
          [ 1.5485e-03, -5.2597e-03, -5.0023e-03]],

         [[ 5.3417e-02,  2.0064e-01,  1.3220e-01],
          [-1.2124e-01, -1.6742e-01, -8.4609e-02],
          [-2.1417e-01, -2.5808e-01, -3.0919e-01]],

         ...,

         [[ 2.0335e-02,  1.1659e-01, -2.2835e-02],
          [ 1.9424e-01,  2.3623e-01,  1.9429e-01],
          [ 8.7263e-03,  4.6950e-02,  3.9763e-02]],

         [[-2.1546e-02,  4.8327e-02,  2.2328e-02],
          [ 1.4283e-01,  4.5180e-02, -4.6277e-02],
          [ 1.0123e-01,  2.4752e-01,  1.2154e-01]],

         [[-3.1303e-01, -2.8268e-01, -2.1845e-01],
          [-1.3687e-01, -1.7780e-01, -2.2222e-01],
          [-6.3109e-03,  3.5331e-02,  1.3386e-01]]]], device='cuda:0'), 'backend.2.bias': tensor([-9.5444e-02,  1.2119e-01, -7.2407e-03, -1.1388e-01, -1.4564e-01,
        -1.3560e-02,  3.4899e-03,  7.2915e-02,  7.2378e-02, -8.7557e-02,
        -2.1074e-01, -4.4167e-02, -1.4108e-04, -2.8610e-02, -7.1423e-02,
        -1.7638e-01,  7.6595e-02, -9.6582e-02, -3.9317e-02,  1.0934e-02,
        -9.4698e-03, -5.9575e-03, -1.8186e-01,  6.3055e-02, -9.9821e-02,
         6.5251e-02, -1.8788e-01, -2.5884e-02, -7.8024e-02, -1.6218e-01,
         2.9943e-02,  2.5168e-02, -1.4130e-01, -1.0984e-02,  1.9060e-01,
        -6.5443e-02,  2.4095e-01,  2.0356e-01,  5.0611e-02,  3.8263e-01,
         8.4442e-02,  5.4964e-04,  5.1976e-03, -5.1447e-03, -1.3074e-01,
        -9.0037e-02, -1.0445e-01, -7.5577e-02, -4.8599e-02, -1.1293e-01,
         1.2864e-02, -6.1114e-02,  3.9259e-02,  2.2158e-02, -1.2546e-01,
         5.5565e-02, -8.7546e-02, -4.8289e-01,  2.3837e-02,  2.4683e-04,
         1.9772e-02,  3.4710e-02, -1.0664e-01, -8.6263e-03, -3.3262e-02,
        -2.8562e-02,  1.6657e-02, -3.4660e-02, -2.5922e-01,  1.1552e-01,
         1.8184e-02, -1.5381e-01, -5.6102e-02, -5.9995e-02, -2.5072e-01,
        -1.1116e-01,  1.4272e-01, -2.8126e-02,  2.4978e-01,  1.3900e-01,
        -2.2722e-01,  1.6405e-02,  1.9514e-02, -1.4806e-02,  2.3785e-02,
        -2.5480e-02, -9.9123e-02,  5.5204e-03,  9.6752e-03,  9.0120e-04,
         1.0361e-01, -8.6627e-02,  8.5515e-02,  8.5152e-02,  4.3013e-01,
        -1.7292e-01,  2.5248e-01, -2.4305e-02, -1.4437e-01, -9.8618e-02,
        -2.0639e-02, -2.6136e-02, -3.1095e-01,  2.7444e-01,  1.5304e-02,
        -5.0389e-02, -7.4309e-02,  6.4031e-02,  1.5671e-02,  1.0776e-01,
         5.7239e-02, -6.2661e-02, -6.3628e-02, -1.7401e-01, -1.7384e-01,
        -2.9030e-02, -3.5191e-02, -1.0351e-01,  5.5874e-02, -3.7032e-02,
        -9.5960e-02, -8.1393e-02, -1.5220e-01,  1.9719e-01, -1.1948e-01,
        -1.6690e-01, -9.5103e-02,  1.5894e-01, -4.6987e-02,  8.7201e-03,
        -4.3616e-02,  1.1448e-01, -2.8034e-02,  1.1368e-01, -6.3129e-02,
         2.6932e-03,  2.8195e-02, -7.3617e-02, -1.2490e-01, -6.5041e-04,
         3.3711e-01, -2.7533e-02, -1.2788e-01, -1.1739e-01, -1.4322e-01,
        -6.4528e-02,  4.3952e-02,  4.8670e-02,  1.0127e-01, -5.3155e-02,
         1.9053e-02,  5.7656e-03, -2.0637e-01,  4.9391e-02,  1.0601e-01,
         2.6321e-01,  9.8347e-03, -4.2333e-02,  4.7637e-02,  4.1250e-02,
        -4.3121e-02,  4.6516e-02, -1.8736e-02, -1.7739e-01,  1.6252e-01,
         5.0901e-02,  5.9270e-02, -7.1254e-02, -1.3990e-01, -1.2609e-02,
         1.3635e-01, -1.9156e-02,  9.9167e-02,  9.7901e-03, -7.9730e-03,
         9.6064e-02, -1.1978e-02, -2.6992e-02,  5.5695e-02, -2.0711e-02,
        -7.5227e-03,  9.6908e-02, -2.6946e-02,  1.9297e-02, -1.2362e-01,
        -2.1191e-01,  2.5298e-02, -4.3558e-02,  5.8504e-02,  2.8252e-03,
         3.3447e-03, -2.0438e-01, -1.5362e-01, -7.2067e-02, -1.3362e-01,
        -6.9235e-02,  7.7507e-03, -2.2435e-01, -5.0222e-02, -6.3786e-02,
         1.4209e-01, -1.0317e-01, -4.3364e-02,  2.3452e-01, -1.0269e-02,
        -2.0785e-01, -1.0589e-01, -1.0867e-01,  7.9163e-02,  2.6168e-02,
        -3.6233e-02,  2.0472e-01, -4.7378e-02, -2.2673e-01,  8.8924e-02,
        -1.1418e-01, -3.3485e-02,  1.1014e-01,  5.6061e-02, -5.1884e-03,
         5.2243e-02,  4.1363e-01,  1.6679e-01, -2.8167e-02, -1.5872e-01,
         1.9175e-01, -2.1024e-03,  2.7883e-01,  1.0203e-01, -3.1564e-03,
        -1.3493e-01,  2.3950e-02,  6.8332e-03, -2.6369e-02, -1.9124e-03,
        -2.4801e-02, -9.5863e-02,  3.1373e-01,  1.0827e-01, -3.9025e-01,
         1.2343e-02,  1.6870e-01, -1.3238e-02,  9.2255e-02, -1.0211e-01,
        -2.7446e-01, -1.4298e-01,  4.5026e-03,  9.2050e-02, -9.7811e-03,
        -1.4301e-01, -5.0959e-02,  1.0820e-01,  7.1858e-02, -1.1097e-01,
        -2.3027e-02, -1.9033e-01, -3.1622e-01, -1.0966e-01,  2.0770e-02,
        -1.2985e-01,  7.2911e-02, -6.8903e-03,  2.2239e-02,  4.5560e-02,
         4.6646e-02,  1.0876e-01,  1.8415e-01,  2.5826e-02, -3.4767e-03,
        -3.4906e-02, -1.1110e-01, -7.4293e-05, -5.3389e-02, -2.1667e-01,
         2.3660e-01,  8.3035e-02,  1.6274e-01, -6.9703e-02, -2.4589e-03,
         3.3348e-01, -5.4762e-02,  2.8821e-02, -5.8684e-02,  3.8901e-02,
        -2.1664e-01,  2.5282e-03,  1.5021e-01, -1.5283e-02,  5.2182e-03,
         3.5758e-02,  9.5710e-02,  2.2947e-01, -8.4501e-03,  1.3985e-01,
         3.1626e-02,  2.7621e-01,  1.1268e-01,  7.1204e-03,  6.4728e-02,
         5.0483e-02, -1.1644e-01, -1.0756e-01,  7.3279e-02,  2.8580e-01,
        -1.7353e-01,  2.0274e-01, -5.0729e-01, -2.1405e-01, -1.3283e-01,
        -1.5440e-02, -9.0186e-02,  1.2485e-01,  7.0710e-03,  5.6440e-02,
        -2.2062e-02, -3.1489e-01,  7.7756e-02, -2.7833e-02, -3.0603e-02,
         6.8869e-02, -7.9890e-02, -2.6295e-02,  1.7892e-02,  1.6964e-01,
         8.7095e-02,  1.7398e-02, -2.1467e-01,  2.5736e-02,  1.3860e-02,
         8.3725e-03, -2.8858e-01,  1.6839e-03,  5.3385e-02,  9.3108e-02,
         6.1977e-03, -5.2588e-02,  1.9725e-01, -3.6481e-01, -1.1734e-01,
         2.1406e-01, -1.0737e-02, -3.6181e-01,  5.7253e-01, -5.5063e-02,
         3.8287e-02, -5.8543e-01,  2.0143e-01,  5.1507e-03,  1.5529e-01,
        -5.8387e-02,  9.6522e-02,  3.9092e-03,  1.5408e-01, -6.9661e-04,
         3.3011e-01,  8.9382e-02,  1.8885e-01, -1.6545e-02,  1.7791e-03,
        -6.3066e-02, -2.0381e-02, -7.3932e-02,  5.7189e-02, -2.2169e-01,
        -1.7594e-01,  7.2579e-02,  8.9699e-02,  1.4016e-01,  1.4531e-01,
        -4.8203e-02, -7.4432e-02, -1.2661e-01,  2.2443e-02, -1.7195e-01,
         5.1155e-02, -1.6276e-02, -8.0198e-02,  1.0578e-01, -3.3089e-02,
         1.2326e-01,  1.1279e-01,  1.3939e-02, -2.6169e-01, -4.8321e-02,
         1.8079e-01, -8.4013e-02,  4.3008e-02, -2.0496e-01, -4.6512e-02,
         2.2161e-01,  2.0267e-02, -2.6134e-01, -6.8644e-02,  1.0455e-02,
        -1.6853e-02, -4.4687e-01, -2.6737e-01, -5.5871e-02, -7.4339e-02,
        -4.4164e-01, -6.0504e-02, -4.2871e-02,  2.1000e-01, -3.5374e-02,
         1.9708e-01,  8.2763e-03, -6.6385e-03,  9.9982e-03, -1.5929e-01,
        -9.6029e-02, -8.3696e-02, -2.3543e-01, -3.2169e-02,  2.4580e-02,
        -4.3336e-01, -1.3247e-01,  3.6893e-02, -1.4186e-01,  5.9492e-03,
        -9.1728e-02, -1.2927e-01,  8.5177e-02, -1.1441e-03,  4.2594e-02,
         5.3824e-02, -1.4818e-01, -7.7129e-02, -2.5509e-02,  2.2265e-01,
        -6.6041e-02, -1.0948e-01, -4.1537e-01, -2.4047e-02,  2.0213e-01,
        -1.0381e-01,  3.8255e-02, -2.7223e-02, -4.7806e-02, -1.2563e-02,
        -1.4074e-02, -1.2187e-01,  1.6063e-01, -1.7875e-01, -1.2772e-03,
         1.0068e-01,  3.8112e-02, -1.4348e-01,  1.2196e-01,  1.3997e-03,
        -1.0433e-02,  6.5087e-02,  1.1839e-02, -7.3006e-02, -2.5583e-01,
         2.6136e-03,  1.5689e-01,  1.7598e-01,  6.9529e-02, -6.1462e-02,
        -9.7275e-02,  3.5660e-02,  4.7909e-02,  8.2740e-02,  1.4097e-02,
         4.9414e-02,  4.2052e-02,  1.4344e-01, -6.2792e-02,  4.0596e-04,
         1.5250e-01, -1.7522e-01, -5.9427e-02, -1.0787e-01, -2.6620e-03,
         4.5772e-02, -1.4194e-01,  3.6366e-01,  1.7674e-01,  3.2443e-01,
        -2.4558e-01,  1.8082e-02, -3.6560e-01,  2.6439e-03,  9.1669e-02,
         7.1562e-03, -9.6866e-02, -6.1576e-02, -3.0196e-01, -1.1254e-01,
        -5.5088e-02, -5.7569e-02,  1.0761e-01, -2.8558e-02, -4.1266e-01,
         4.0287e-02,  2.9997e-02, -6.0387e-02,  3.4556e-02, -2.6565e-01,
        -3.9135e-02, -5.7811e-02,  1.2102e-01,  5.8584e-02, -1.1471e-02,
         4.9081e-02, -1.0090e-01, -8.9323e-02, -9.7825e-02,  7.6052e-02,
        -2.5763e-01,  1.2562e-02], device='cuda:0'), 'backend.10.bias': tensor([-5.8029e+00, -5.3878e+01,  1.0696e+01,  2.2877e+01, -1.1114e+01,
         2.1028e-01, -3.5056e+00, -4.7255e+00, -1.8161e+00,  5.6120e-01,
        -4.5989e+00, -1.4484e+01, -2.5311e+01, -2.5464e-01, -1.0811e+01,
        -1.0108e+01,  2.4036e+00,  7.8466e-01, -1.4855e+01, -3.5416e+01,
         3.4983e+00, -1.6306e+01, -2.6800e-01, -1.6920e-02,  1.0981e+00,
         2.8397e+01,  8.6920e-01, -1.3417e+00, -4.1239e-01, -3.3987e+01,
        -1.3303e+01, -3.8404e+00, -7.8278e-01,  4.7887e-02, -2.9392e-01,
        -4.3888e+01,  3.2917e-01, -5.0268e+01, -4.0567e-01,  8.4493e-01,
         5.0143e+00, -5.7116e+01,  7.1828e-02,  1.0728e+00,  4.6707e-01,
        -3.4152e+01, -7.9422e+00,  4.3289e-01,  1.0090e+01, -6.5736e-01,
        -2.2008e+01,  1.0102e+00, -2.4218e-01, -1.8479e+01, -2.5554e-02,
         7.1699e+00,  1.1377e+00,  1.8071e+00,  4.5674e+00,  8.1736e+00,
         1.3086e+00,  2.5759e+00, -2.7065e+01, -2.6927e-01], device='cuda:0'), 'output_layer.bias': tensor([-2368.7073], device='cuda:0'), 'backend.2.weight': tensor([[[[-2.6743e-02, -3.9613e-02, -8.0125e-03],
          [-1.7406e-02, -5.3059e-02, -2.6566e-02],
          [-3.5892e-02, -4.0332e-02, -1.3288e-02]],

         [[-8.8571e-03, -7.8051e-03, -8.0927e-03],
          [-1.2177e-02, -8.5556e-03, -4.6050e-03],
          [-1.0736e-02, -2.2353e-03, -2.1007e-03]],

         [[-5.4203e-02, -2.8204e-02, -6.6149e-02],
          [-9.3613e-02, -8.7684e-02, -1.0216e-01],
          [-8.6319e-02, -6.5349e-02, -6.5383e-02]],

         ...,

         [[-6.8695e-02, -1.2343e-01, -6.7855e-02],
          [-5.2467e-02, -1.2090e-01, -9.2997e-02],
          [-1.5116e-01, -1.8670e-01, -1.7145e-01]],

         [[-3.5143e-02, -2.8826e-02, -2.5545e-02],
          [-4.4439e-02, -3.8221e-02, -3.8729e-02],
          [-2.2132e-02, -2.8051e-02, -2.6021e-02]],

         [[-2.7207e-02, -1.4604e-02, -2.6464e-02],
          [-1.3161e-02, -1.7328e-02, -2.3120e-02],
          [-3.2824e-02, -1.9330e-02, -3.9086e-02]]],


        [[[ 7.7715e-02,  3.7031e-02,  5.9199e-02],
          [ 6.9623e-02,  3.8972e-02,  3.4251e-02],
          [ 5.2239e-02,  4.0355e-02,  4.5524e-02]],

         [[ 8.7287e-03,  1.0781e-02,  1.1893e-02],
          [ 7.5952e-03,  7.7004e-03,  8.8367e-03],
          [ 1.1768e-02,  6.2630e-03,  1.1725e-02]],

         [[ 7.2417e-02,  8.9045e-02,  8.2415e-02],
          [ 8.0393e-02,  7.5211e-02,  6.3762e-02],
          [ 7.1169e-02,  1.0387e-01,  9.9011e-02]],

         ...,

         [[ 1.4388e-01,  1.0236e-01,  1.3851e-01],
          [ 1.2052e-01,  1.1338e-01,  1.7003e-01],
          [ 1.5285e-01,  1.2835e-01,  1.4204e-01]],

         [[ 6.6305e-02,  5.3928e-02,  5.6094e-02],
          [ 4.6762e-02,  4.0123e-02,  2.8895e-02],
          [ 3.1198e-02,  4.4879e-02,  4.0969e-02]],

         [[ 2.8076e-02,  3.7205e-02,  3.6337e-02],
          [ 1.5341e-02,  4.2387e-02,  3.7633e-02],
          [ 1.9189e-02,  3.1697e-02,  4.1698e-02]]],


        [[[-9.8590e-03, -5.9415e-04, -1.5896e-03],
          [-1.4482e-03,  7.3030e-03, -3.8602e-03],
          [-8.3031e-03, -4.1849e-05, -1.1306e-02]],

         [[-6.2674e-04, -3.3450e-04,  7.6562e-05],
          [ 4.1101e-03,  6.4968e-04, -1.6109e-03],
          [ 1.8856e-03,  1.6983e-03, -2.0550e-03]],

         [[-1.1351e-02, -4.0540e-03, -9.0501e-03],
          [-2.9626e-03, -7.6368e-03, -1.2746e-02],
          [-1.6146e-02, -2.2904e-02, -9.9337e-03]],

         ...,

         [[-1.6460e-02, -2.5880e-02, -7.2919e-03],
          [-3.2705e-02,  8.7722e-03, -2.2338e-02],
          [-3.5240e-03,  5.4252e-03, -9.8817e-03]],

         [[ 5.0207e-03, -4.1996e-03,  3.6658e-03],
          [ 7.6037e-03, -2.2851e-03,  6.1383e-03],
          [-9.2010e-03, -6.9947e-03, -5.7209e-03]],

         [[-4.1634e-03, -5.1096e-03,  1.0458e-03],
          [-7.3520e-03, -3.9129e-03,  8.5424e-03],
          [-5.4502e-03, -4.1668e-03, -1.1901e-02]]],


        ...,


        [[[-8.8293e-03,  4.3770e-03,  6.6473e-02],
          [-8.1426e-03,  2.4337e-02,  4.2202e-02],
          [-1.7271e-02,  3.1402e-02,  6.8163e-02]],

         [[-4.0399e-03,  5.5715e-03,  1.0041e-02],
          [ 2.1243e-03,  7.6127e-03,  1.1767e-03],
          [ 6.4538e-04,  9.1157e-03,  6.0502e-03]],

         [[-2.5099e-02,  1.5327e-02, -1.1128e-03],
          [ 1.4341e-03,  2.7357e-02, -5.7301e-03],
          [-1.0064e-02,  1.4987e-03, -1.9910e-03]],

         ...,

         [[ 2.0682e-01,  1.0093e-01,  1.4818e-01],
          [ 6.5353e-02,  1.9605e-01,  2.1523e-01],
          [ 1.7583e-01,  1.0937e-01,  1.1586e-01]],

         [[-1.5126e-02, -9.0456e-03,  1.3631e-03],
          [-2.0700e-02, -1.1767e-02, -4.5529e-03],
          [-1.5402e-02, -1.9581e-02, -1.5352e-02]],

         [[ 8.9623e-03,  4.3922e-02,  3.4448e-02],
          [ 3.6678e-02,  5.0561e-02,  1.8873e-02],
          [ 3.5364e-02,  5.3386e-02,  2.4553e-02]]],


        [[[-6.4073e-02, -7.1424e-02, -1.3557e-01],
          [-1.0439e-01, -1.0575e-01, -1.1695e-01],
          [-1.1025e-01, -1.1215e-01, -1.0477e-01]],

         [[-1.5107e-02, -2.1762e-02, -2.7486e-02],
          [-2.0304e-02, -1.2360e-02, -2.1811e-02],
          [-2.3954e-02, -1.2941e-02, -1.2730e-02]],

         [[-1.3944e-01, -1.1372e-01, -1.1283e-01],
          [-1.5474e-01, -1.2211e-01, -1.1001e-01],
          [-1.8234e-01, -1.5628e-01, -1.4351e-01]],

         ...,

         [[-4.4711e-01, -4.0074e-01, -4.7918e-01],
          [-3.8266e-01, -4.4923e-01, -4.4080e-01],
          [-4.6186e-01, -4.5300e-01, -4.6996e-01]],

         [[-2.4721e-02, -3.4568e-02, -2.5146e-02],
          [-3.2767e-02, -3.5458e-02, -3.5848e-02],
          [-2.8946e-02, -3.0527e-02, -3.7150e-02]],

         [[-6.7310e-02, -7.3472e-02, -8.8186e-02],
          [-9.3798e-02, -9.4707e-02, -9.7847e-02],
          [-9.2637e-02, -8.5534e-02, -7.9306e-02]]],


        [[[-3.6618e-02, -1.3964e-02, -1.0298e-02],
          [-8.8741e-02, -4.4203e-02, -1.8938e-02],
          [-7.0730e-02, -3.1267e-02,  2.7327e-02]],

         [[-9.3141e-03,  8.7460e-04, -9.4223e-03],
          [-5.9765e-03, -2.6659e-03, -8.2794e-03],
          [ 3.5149e-03,  4.4635e-03, -7.3948e-04]],

         [[ 7.3819e-02,  4.9795e-02,  1.5395e-02],
          [ 1.2660e-01,  1.1228e-01,  9.8425e-02],
          [ 4.8682e-02,  5.5705e-02,  1.0727e-01]],

         ...,

         [[-8.3064e-02, -1.9624e-02,  9.4107e-02],
          [-1.6090e-02,  5.3197e-02,  5.2262e-02],
          [ 5.3617e-02,  5.5293e-02,  4.2047e-02]],

         [[-3.1702e-02, -4.6874e-02, -5.6751e-02],
          [-1.4009e-02, -1.7437e-02,  8.5361e-03],
          [-3.1719e-03, -1.3172e-02, -6.2182e-03]],

         [[-1.9244e-03,  1.0770e-02,  9.0751e-03],
          [-1.2532e-02, -1.8902e-04, -3.9581e-03],
          [-4.5671e-03, -1.1593e-02,  7.9191e-03]]]], device='cuda:0'), 'backend.6.bias': tensor([-8.3899e-02, -1.6171e-02,  1.1420e+00, -5.7551e-02,  5.3863e-01,
        -8.3389e-01,  1.1408e-01,  3.1573e-02, -1.6201e-01, -2.2798e-01,
        -1.0613e+00,  1.7285e-02, -1.9214e+00, -1.1184e-01, -6.8129e-01,
         2.2950e-02, -1.4048e+00, -2.4419e-01,  9.4105e-01,  2.4619e-01,
         3.1538e-01, -3.4581e-01,  4.3028e-01,  2.8217e-03, -6.5242e-01,
         1.2156e+00, -1.1701e+00,  9.7104e-02,  1.8542e-01, -8.4765e-01,
        -8.2549e-02,  8.8012e-01,  1.3529e+00,  1.4453e-01, -1.8760e-01,
         2.3450e-01, -5.5987e-02,  4.2681e-01, -3.5006e-01,  5.4508e-01,
        -8.3722e-01,  6.0964e-02,  8.9371e-03, -6.9755e-03,  2.5819e-01,
        -8.1418e-01, -1.1959e+00,  7.2191e-01, -1.3467e-01, -9.9605e-01,
         2.0732e+00,  7.9013e-01,  1.2127e+00, -1.5427e-01,  2.0351e-01,
        -5.0857e-01, -2.5497e-01, -2.5927e-01, -5.9111e-03, -1.0637e-01,
        -7.7560e-01, -3.9563e-01, -5.0864e-01, -4.2363e-01, -1.1203e-01,
         1.5607e+00,  1.1222e+00, -2.8460e-01, -5.2958e-01,  4.4043e-01,
        -2.0771e+00,  1.1595e+00,  5.9845e-01,  6.1730e-02,  3.3175e-02,
        -4.1539e-01,  5.6374e-01, -1.5174e+00, -9.2519e-01, -7.4753e-01,
         2.4032e-03, -7.1820e-02, -3.7930e-01, -1.2810e+00,  1.7283e+00,
        -1.5666e-02, -1.0817e-01,  4.1596e-01, -5.1974e-01, -2.8065e-01,
         4.1466e-01, -2.6418e-01, -9.3956e-01,  1.0207e+00,  2.1993e-01,
         7.7891e-01, -1.2826e-02, -9.0745e-01,  5.0318e-01, -1.2849e+00,
        -1.3128e+00,  1.6148e-02,  1.0761e-01,  1.2552e-02, -7.9037e-01,
        -4.6911e-01, -1.1417e+00, -7.8195e-02,  2.5988e-03,  1.5220e-02,
         5.2964e-02, -5.6886e-01,  2.0896e-01, -2.1517e-02,  4.7351e-01,
        -1.4713e+00, -3.6948e-01,  2.1909e-02,  1.2982e+00,  1.3832e+00,
        -4.6231e-01, -2.0406e-02,  2.7874e-02, -1.9149e+00,  1.5788e+00,
        -8.4886e-01,  1.3790e+00,  3.3353e+00, -1.1661e+00, -4.0027e-01,
         1.9986e-01,  1.0771e+00,  9.1898e-01, -6.6466e-01,  4.5549e-01,
         1.8903e+00, -7.6614e-01,  2.3348e-02, -1.0125e+00, -2.0532e+00,
        -8.9911e-01,  1.2650e+00, -1.0543e+00,  8.2443e-01, -8.1073e-01,
        -4.6521e-02, -4.7334e-04, -3.0504e-01, -9.6903e-03, -5.8532e-01,
        -5.4516e-01, -6.6429e-01, -2.3238e-02,  2.0377e+00,  1.8188e+00,
        -7.2864e-01, -2.5927e-02,  4.8815e-02, -2.2780e-04, -5.5808e-01,
        -3.7023e-01, -1.1683e-01, -1.0920e+00, -8.0476e-03,  8.5099e-02,
         1.4044e+00, -1.8894e-02, -1.2077e-01, -2.6243e-01, -4.0546e-01,
         2.1495e-02,  9.4085e-02, -6.4142e-01, -1.6538e+00, -8.9192e-01,
        -4.8411e-01,  1.4857e-02,  5.2869e-01,  1.6901e-01, -2.0868e-01,
         1.7790e-02,  4.9152e-01,  4.9781e-01, -7.0547e-01,  1.7543e-01,
        -7.4892e-01, -5.0036e-01, -6.2179e-02,  3.3094e-02,  1.9181e+00,
         4.4188e-01,  2.4910e-01, -3.7713e-01,  1.5005e+00,  3.7024e-01,
        -1.5421e-01, -2.9336e-01, -2.8169e-01, -1.0113e-01, -1.9074e+00,
        -6.8935e-01, -6.8837e-01,  1.9108e-01, -6.8252e-01, -6.3966e-01,
         1.6775e-01,  8.4237e-01, -4.1269e-01,  1.0999e+00,  1.0861e+00,
         5.0101e-01,  2.0691e-02, -7.4593e-01, -4.0649e-01,  3.1674e-01,
         4.7350e-02, -1.3425e-02,  4.4528e-01, -1.0489e+00, -1.3415e+00,
         3.2184e-01,  8.5183e-01, -3.3267e-01, -2.9079e-01, -4.9677e-01,
        -1.3985e-01,  4.5514e-02,  6.9376e-01, -1.9076e+00,  1.0484e+00,
        -5.9901e-01,  1.0391e+00, -3.5584e-01, -1.5562e-01, -7.4192e-01,
         1.9428e+00, -1.1659e+00, -4.8475e-02, -9.1319e-02, -1.1107e+00,
        -7.8743e-01, -1.0142e+00,  1.9766e-02,  6.6773e-02, -1.4531e-01,
        -2.2162e-01,  3.6885e-01, -3.8783e-01,  3.8288e-01, -7.1044e-01,
        -2.3415e-01, -3.7066e-01,  5.3615e-01, -6.6176e-02, -6.9476e-02,
         9.0193e-04], device='cuda:0'), 'backend.0.weight': tensor([[[[-1.0965e-02, -1.7621e-02, -1.1160e-02],
          [-3.1529e-03, -5.4654e-03, -6.9497e-03],
          [ 4.9167e-03,  6.9457e-03,  1.3815e-03]],

         [[-9.4745e-02, -8.2677e-02, -6.6368e-02],
          [ 5.5757e-03, -1.3242e-02, -4.1414e-02],
          [ 9.9203e-02,  7.3023e-02, -2.9837e-03]],

         [[ 5.2261e-02,  5.8763e-02,  5.5729e-02],
          [ 6.1537e-02,  8.4553e-02,  3.7036e-02],
          [ 1.0334e-01,  9.4032e-02,  6.6058e-02]],

         ...,

         [[ 4.8520e-04,  4.6799e-04,  3.1705e-03],
          [ 1.0355e-04, -2.0711e-03, -2.6303e-03],
          [ 7.7474e-04, -3.3154e-03, -2.7112e-03]],

         [[ 2.9971e-03, -6.2087e-03,  2.7157e-02],
          [-5.4836e-03, -1.4382e-02,  8.4063e-04],
          [-1.3320e-03,  7.5198e-03, -1.0118e-02]],

         [[ 7.4050e-02,  9.7492e-02,  1.3282e-01],
          [ 8.5057e-02,  8.1243e-02,  8.0770e-02],
          [ 7.5954e-02,  9.3831e-02,  8.4564e-02]]],


        [[[ 3.3563e-03,  5.4455e-03,  3.4572e-03],
          [ 7.2756e-03,  8.1888e-03,  2.1705e-03],
          [ 5.1402e-04,  5.7355e-03,  8.8269e-03]],

         [[ 1.1157e-01,  1.0452e-01,  8.9040e-02],
          [ 9.8320e-02,  1.2030e-01,  8.4504e-02],
          [ 8.3782e-02,  8.3955e-02,  6.3719e-02]],

         [[ 1.8970e-02,  2.2374e-02,  1.1430e-02],
          [ 1.7493e-02,  1.1410e-02,  1.2682e-02],
          [ 4.9710e-04, -3.6673e-03, -6.4815e-03]],

         ...,

         [[ 4.9068e-03,  4.3096e-03,  2.7919e-04],
          [ 3.1393e-03,  2.7693e-03,  4.3251e-03],
          [-1.0944e-03,  2.5520e-03,  2.1074e-03]],

         [[ 1.2171e-02,  1.2222e-02,  7.5670e-03],
          [ 1.7481e-02,  2.1930e-02,  1.4793e-02],
          [ 1.9990e-02,  2.3993e-02,  2.8636e-02]],

         [[ 9.6595e-03, -4.9512e-03,  1.7026e-02],
          [ 5.5919e-03, -9.2158e-03,  2.0788e-02],
          [-8.4710e-03, -1.2853e-04,  8.8651e-03]]],


        [[[ 1.0118e-02,  1.2774e-02,  7.2156e-03],
          [ 1.0304e-02,  1.2340e-02,  4.9388e-03],
          [ 1.7319e-02,  2.1505e-02,  1.9966e-03]],

         [[ 2.1414e-01,  1.4136e-01,  1.1734e-01],
          [ 2.9939e-01,  2.4250e-01,  1.0767e-01],
          [ 2.0077e-01,  2.0030e-01,  4.3080e-02]],

         [[ 4.6795e-02,  5.1594e-02,  4.4767e-02],
          [ 3.4120e-02,  5.9090e-02,  4.1478e-02],
          [ 7.0841e-02,  7.7754e-02,  7.5425e-02]],

         ...,

         [[-6.3573e-04, -4.8427e-04, -4.7803e-03],
          [ 1.0010e-02,  5.5797e-03,  5.0048e-03],
          [ 8.7089e-03,  4.7926e-03,  6.8315e-03]],

         [[ 5.1334e-02,  2.5493e-02,  5.5958e-03],
          [ 4.4769e-02,  3.4323e-02,  7.7109e-03],
          [ 3.5576e-02,  4.2393e-02,  2.2568e-02]],

         [[ 5.0627e-02,  2.1957e-02,  8.0027e-02],
          [-2.6768e-02,  7.8537e-03,  5.7528e-02],
          [ 7.2560e-02,  8.3124e-02,  7.9691e-02]]],


        ...,


        [[[ 2.0045e-02,  6.3761e-03,  5.0251e-04],
          [ 2.1295e-02,  8.4854e-03, -6.0189e-03],
          [ 1.8921e-02,  1.4829e-02,  8.0010e-03]],

         [[ 2.1407e-01,  1.7944e-01,  2.6115e-02],
          [ 2.9567e-01,  2.6751e-01,  9.5501e-02],
          [ 2.9139e-01,  2.5383e-01,  8.2905e-02]],

         [[ 1.7746e-01,  1.9658e-01,  1.8618e-01],
          [ 7.2051e-02,  4.3125e-02,  1.0901e-01],
          [ 1.5234e-01,  1.9395e-01,  1.6791e-01]],

         ...,

         [[ 3.3874e-03, -5.1800e-04,  1.4071e-03],
          [ 3.2952e-03,  6.6845e-04, -3.8086e-03],
          [ 9.4261e-03,  8.2751e-03,  4.3092e-03]],

         [[ 6.2549e-02,  3.2151e-02, -9.1807e-03],
          [ 6.9782e-02,  1.9211e-02, -1.8662e-02],
          [ 7.1129e-02,  4.4202e-02,  1.8734e-03]],

         [[ 2.4898e-01,  2.3219e-01,  3.5021e-01],
          [ 3.2861e-02,  3.7562e-02,  1.8472e-01],
          [ 1.1136e-01,  1.3887e-01,  1.8594e-01]]],


        [[[ 4.4693e-02,  4.3510e-02,  3.1192e-02],
          [ 4.5764e-02,  4.5040e-02,  4.3091e-02],
          [ 5.0477e-02,  5.0647e-02,  4.6610e-02]],

         [[ 4.8130e-01,  4.9007e-01,  4.3751e-01],
          [ 4.3486e-01,  4.5149e-01,  4.4865e-01],
          [ 3.1297e-01,  3.5288e-01,  3.5299e-01]],

         [[ 4.8869e-02,  5.6782e-02,  6.4833e-02],
          [ 3.0822e-02,  3.8095e-02,  4.7184e-02],
          [ 6.1477e-02,  5.3461e-02,  4.0249e-02]],

         ...,

         [[ 1.1525e-02,  1.3004e-02,  1.0198e-02],
          [ 5.2148e-03,  1.3582e-03,  8.1860e-03],
          [ 6.3621e-03,  2.3229e-03,  4.0532e-03]],

         [[ 6.6032e-02,  5.6164e-02,  2.7974e-02],
          [ 5.5586e-02,  5.5609e-02,  3.7571e-02],
          [ 2.7228e-02,  1.7298e-02, -1.6124e-03]],

         [[ 4.3123e-02,  2.8379e-02,  3.5880e-02],
          [ 1.2766e-02,  2.6669e-02,  2.7427e-02],
          [ 5.3280e-02,  7.6970e-02,  1.1788e-02]]],


        [[[ 9.0564e-03,  9.5050e-03,  1.0587e-02],
          [ 1.3180e-02,  1.0427e-02,  1.5775e-02],
          [ 1.5143e-02,  1.6777e-02,  1.7506e-02]],

         [[ 1.0941e-01,  1.0080e-01,  1.7831e-01],
          [ 1.3935e-01,  1.4261e-01,  2.3914e-01],
          [ 1.8722e-01,  1.9382e-01,  2.4268e-01]],

         [[ 5.9845e-02,  6.3960e-02,  5.8496e-02],
          [ 9.4833e-02,  1.2498e-01,  1.2457e-01],
          [ 9.6724e-02,  1.0555e-01,  9.4719e-02]],

         ...,

         [[ 4.8428e-04,  2.5726e-03,  1.3078e-03],
          [ 3.2865e-03,  2.4151e-03,  3.0787e-03],
          [ 3.2823e-03,  2.0312e-03,  1.3947e-03]],

         [[ 1.3699e-02,  7.8325e-03,  2.1781e-02],
          [ 1.6425e-02,  1.2316e-02,  2.7761e-02],
          [ 1.4946e-02,  1.5759e-02,  1.8320e-02]],

         [[ 8.6319e-02,  1.5244e-01,  1.0609e-01],
          [ 1.5536e-01,  1.3366e-01,  1.5492e-01],
          [ 1.0859e-01,  8.9653e-02,  6.4167e-02]]]], device='cuda:0'), 'output_layer.weight': tensor([[[[-1.6358e+00]],

         [[-2.5940e+01]],

         [[-2.2885e+01]],

         [[-4.2481e+01]],

         [[-8.9195e+00]],

         [[-4.3450e-01]],

         [[-4.4648e+00]],

         [[-8.7988e+00]],

         [[-9.7922e+00]],

         [[-6.4884e+00]],

         [[-1.6077e+00]],

         [[-9.1065e+00]],

         [[-9.2577e+00]],

         [[-8.4950e+00]],

         [[-3.1119e+00]],

         [[-4.4014e+00]],

         [[-1.1049e+00]],

         [[-9.0646e+00]],

         [[-1.0693e+01]],

         [[-1.3028e+01]],

         [[-1.9226e+01]],

         [[-5.4063e+00]],

         [[-1.7429e+00]],

         [[-4.2664e-01]],

         [[-1.4460e+00]],

         [[-6.2714e+01]],

         [[-1.6194e+00]],

         [[-1.6695e+00]],

         [[-1.2076e+00]],

         [[-1.8779e+01]],

         [[-4.6703e+00]],

         [[-1.2733e+01]],

         [[-1.3408e+00]],

         [[ 4.5206e-02]],

         [[-4.8045e+00]],

         [[-1.6932e+01]],

         [[-6.8475e-01]],

         [[-2.4269e+01]],

         [[-4.6628e-01]],

         [[-6.4551e+00]],

         [[-3.5551e+00]],

         [[-2.7895e+01]],

         [[-2.5401e-01]],

         [[-4.7532e-01]],

         [[-1.3100e-01]],

         [[-1.7155e+01]],

         [[-2.8089e+00]],

         [[-2.4248e-01]],

         [[-1.8241e+01]],

         [[-4.4687e-01]],

         [[-5.6391e+00]],

         [[-2.1812e+00]],

         [[-1.2111e-01]],

         [[-4.8903e+00]],

         [[-4.5772e-03]],

         [[-2.9828e+01]],

         [[-1.2588e+00]],

         [[-2.7432e+00]],

         [[-3.9311e+00]],

         [[-2.8007e+01]],

         [[-3.5534e+00]],

         [[-2.1570e+00]],

         [[-1.0613e+01]],

         [[-2.9810e-01]]]], device='cuda:0'), 'backend.4.weight': tensor([[[[-1.2048e-02, -6.0804e-02, -5.4469e-02],
          [-8.9128e-03, -8.2508e-02, -6.2418e-02],
          [-1.1260e-02, -5.8706e-02, -4.9833e-04]],

         [[-3.8528e-02, -2.3249e-02,  2.3059e-02],
          [-6.0004e-02,  3.9834e-02,  4.6437e-02],
          [-1.0442e-01, -3.2645e-02, -1.4246e-04]],

         [[-1.3503e-02, -2.6101e-02, -1.9275e-02],
          [-1.5314e-02, -2.7579e-02, -7.4561e-03],
          [-3.1707e-02, -1.0187e-02, -1.2931e-02]],

         ...,

         [[ 4.6745e-03, -5.3108e-02, -8.8508e-02],
          [ 4.9763e-02, -9.0174e-02, -3.2583e-02],
          [-4.8892e-02,  1.3480e-02,  3.9005e-02]],

         [[-5.9419e-02, -1.0136e-01, -1.1546e-01],
          [-7.5363e-02, -4.8470e-02, -2.4965e-02],
          [-4.4913e-02, -1.8796e-02, -1.4597e-02]],

         [[-8.9494e-02, -3.5856e-02, -1.2368e-02],
          [-2.1256e-02, -2.2860e-02, -6.7882e-02],
          [-1.1565e-01, -7.2962e-02, -5.9713e-02]]],


        [[[-6.1420e-02, -7.4409e-02, -5.5025e-02],
          [-8.4431e-02, -5.0342e-02, -1.7649e-02],
          [-4.9211e-02, -2.8632e-02, -3.9524e-02]],

         [[-1.1809e-01, -1.2985e-01, -1.3566e-01],
          [-1.5668e-01, -1.1771e-01, -1.3297e-01],
          [-1.5706e-01, -1.5218e-01, -1.7541e-01]],

         [[-3.7269e-02, -3.6366e-02, -3.9533e-02],
          [-3.3907e-02, -2.5395e-02, -3.3013e-02],
          [-2.8684e-02, -1.9192e-02, -1.9853e-02]],

         ...,

         [[-1.4428e-01, -1.3440e-01, -4.8934e-02],
          [-8.5696e-02, -9.6212e-02, -5.4566e-02],
          [-1.2662e-01, -7.0622e-02, -9.3470e-02]],

         [[-1.1058e-01, -7.2284e-02, -7.5916e-02],
          [-9.1712e-02, -5.9536e-02, -8.4217e-02],
          [-6.3676e-02, -6.2908e-02, -1.0002e-01]],

         [[-2.0823e-01, -2.0906e-01, -2.1805e-01],
          [-1.7231e-01, -2.0222e-01, -2.3789e-01],
          [-2.6540e-01, -2.6746e-01, -2.9672e-01]]],


        [[[ 2.7792e-03,  2.2988e-03, -5.3761e-02],
          [-2.6932e-02,  4.3406e-02, -7.2001e-02],
          [ 1.5608e-03,  1.1809e-02, -7.6258e-02]],

         [[-1.1995e-02,  1.6806e-02,  6.0270e-02],
          [ 7.1743e-02, -4.5483e-03,  5.1581e-02],
          [ 8.9463e-02,  8.7169e-02,  1.6582e-01]],

         [[-3.9849e-03,  9.4197e-03,  2.3183e-02],
          [ 3.4039e-02, -1.6622e-03,  2.0194e-02],
          [ 1.2939e-02, -1.6664e-03,  1.1720e-02]],

         ...,

         [[-5.3542e-02,  1.3020e-01, -1.4320e-01],
          [-8.9343e-02,  8.4100e-02, -1.5566e-01],
          [ 6.7427e-02, -2.3242e-02, -2.0595e-01]],

         [[ 3.7305e-02, -9.8499e-03,  4.2857e-02],
          [ 6.3236e-02, -4.5389e-02, -6.4480e-02],
          [ 6.6958e-03, -1.4844e-01, -1.3273e-02]],

         [[ 6.5942e-02,  8.1113e-04,  5.4290e-02],
          [ 7.0968e-03, -9.7524e-02,  9.8904e-02],
          [ 1.2407e-01,  7.0395e-02,  1.2213e-01]]],


        ...,


        [[[-9.2294e-02, -3.1216e-02, -7.2767e-02],
          [-9.2674e-02, -9.8752e-02, -1.3588e-01],
          [-1.0899e-01, -1.5502e-01, -7.5264e-02]],

         [[-1.1606e-01, -1.4396e-01, -5.8016e-02],
          [-3.7690e-02, -6.5498e-02, -8.3960e-02],
          [-6.8773e-02, -8.4260e-02, -5.5586e-02]],

         [[-3.3650e-02, -2.5016e-02, -3.0571e-02],
          [-2.4607e-02, -3.8932e-02, -3.2553e-02],
          [-2.4547e-02, -2.5013e-02, -2.2982e-02]],

         ...,

         [[-1.4992e-01, -1.0191e-01, -1.7541e-01],
          [-2.3860e-01, -2.6577e-01, -1.5842e-01],
          [-1.5260e-01, -1.9920e-01, -1.9439e-01]],

         [[-2.2625e-01, -2.1584e-01, -1.7163e-01],
          [-1.7381e-01, -1.5323e-01, -1.7070e-01],
          [-1.4792e-01, -1.9673e-01, -1.1021e-01]],

         [[-1.4642e-01, -8.4645e-02, -1.1511e-01],
          [-2.1538e-01, -2.6934e-01, -2.4112e-01],
          [-1.4448e-01, -8.2776e-02, -1.1832e-01]]],


        [[[-1.5638e-01, -1.4835e-01, -1.9036e-01],
          [-1.7547e-01, -8.7566e-02, -1.1183e-01],
          [-8.2429e-02,  2.9826e-02,  2.9444e-02]],

         [[-3.5364e-03,  7.8474e-02,  3.5788e-02],
          [ 2.8734e-02, -8.3441e-02, -3.0322e-02],
          [-1.1562e-01, -1.6252e-01, -1.9590e-01]],

         [[-5.9862e-02, -6.6110e-02, -3.8213e-02],
          [-5.4671e-02, -3.5382e-02, -2.5554e-02],
          [ 9.8652e-03, -6.5195e-03, -9.3011e-03]],

         ...,

         [[-3.2161e-01, -2.8489e-01, -2.5918e-01],
          [-3.2716e-01, -4.6102e-02, -1.2386e-01],
          [-6.2740e-02, -1.9311e-01, -9.9467e-02]],

         [[-2.3160e-01, -2.2290e-01, -1.7311e-01],
          [-1.2878e-01, -1.0607e-01, -1.8933e-01],
          [-1.3857e-01, -1.7024e-01, -8.4571e-02]],

         [[-9.7382e-02, -1.5025e-01, -2.1385e-01],
          [-1.5372e-01, -1.2470e-01, -9.2417e-02],
          [-1.2051e-01, -2.0160e-01, -1.7870e-01]]],


        [[[ 1.4705e-01,  2.1214e-01,  1.3026e-01],
          [ 1.5705e-01,  2.3031e-01,  1.4932e-01],
          [ 2.4698e-01,  3.2268e-01,  2.5551e-01]],

         [[ 4.3678e-01,  4.6324e-01,  4.4893e-01],
          [ 4.4244e-01,  3.3968e-01,  4.9461e-01],
          [ 3.9638e-01,  3.2134e-01,  2.9273e-01]],

         [[ 8.4497e-02,  7.1968e-02,  5.6404e-02],
          [ 5.4276e-02,  3.5380e-02,  4.2073e-02],
          [ 1.0959e-01,  7.9675e-02,  6.8024e-02]],

         ...,

         [[ 2.5636e-01,  3.1694e-01,  2.9748e-01],
          [ 3.4446e-01,  5.3526e-01,  3.9326e-01],
          [ 4.9409e-01,  4.1774e-01,  5.3854e-01]],

         [[ 4.0206e-01,  3.6071e-01,  3.3972e-01],
          [ 4.3792e-01,  3.8572e-01,  3.7576e-01],
          [ 4.6684e-01,  4.0982e-01,  4.3654e-01]],

         [[ 5.7194e-01,  5.3078e-01,  4.8957e-01],
          [ 6.5429e-01,  7.0739e-01,  6.6911e-01],
          [ 6.2929e-01,  4.8608e-01,  4.9186e-01]]]], device='cuda:0'), 'backend.4.bias': tensor([-1.0811e-01, -3.6617e-01,  1.2843e-01, -4.9062e-02, -2.9246e-01,
        -3.0937e-02, -2.1622e-01,  5.0674e-02,  7.6933e-02, -3.7847e-01,
         3.8315e-01,  6.9405e-02,  3.7675e-01,  3.4870e-02, -2.4371e-01,
        -6.7990e-02, -1.8840e-01,  9.8034e-02,  2.0505e-02,  1.9701e-03,
        -1.7969e-01,  3.6393e-01, -1.7572e-01, -4.2377e-01, -7.6813e-02,
        -5.1208e-01,  1.6247e-01,  1.3582e-01, -1.0090e-01, -6.3032e-01,
         2.1797e-01, -3.1502e-02,  2.5710e-02, -1.9573e-01,  4.0428e-02,
        -1.9214e-01, -1.6725e-01,  7.8190e-03,  1.1864e-01, -1.0260e-02,
        -5.1140e-05,  1.6475e-01,  4.8805e-02, -2.7859e-01, -2.8268e-01,
        -2.4050e-02, -1.5400e-03,  5.9488e-02, -3.5742e-01,  8.5504e-02,
        -3.2695e-01, -2.1993e-01, -4.9916e-01, -4.0068e-02, -2.6698e-02,
         3.2183e-01, -3.9358e-01, -1.2468e-02, -5.5512e-01, -3.7874e-01,
        -1.0882e-01, -8.0760e-03, -4.0328e-02, -2.3989e-01,  4.2836e-01,
         1.1270e-01,  5.2402e-03, -4.4078e-02, -1.1977e-01, -5.8301e-01,
        -4.5836e-01, -3.2117e-02, -4.3982e-01, -1.7271e-01, -1.0471e-01,
        -9.2244e-02, -2.5922e-01, -4.8508e-02, -1.3433e-01,  4.9866e-01,
         4.0625e-03,  4.7469e-01,  1.2651e-01,  2.1825e-01,  4.0003e-01,
         5.3297e-02, -4.8195e-02, -7.7326e-03,  3.1431e-02, -2.9858e-01,
         9.6683e-02,  5.9274e-03, -3.5871e-01, -1.8527e-01, -2.1074e-01,
        -2.4775e-02, -4.3069e-03, -4.8011e-01, -2.3097e-02, -4.8732e-01,
        -2.3378e-01,  1.2443e-02,  1.9692e-01,  6.4457e-01, -3.0372e-02,
        -7.6160e-02, -1.2318e-01,  1.7330e-01, -1.0179e-01,  4.4202e-02,
        -1.2982e-01, -1.8453e-01,  2.1299e-01, -5.0389e-02, -2.0802e-01,
         2.6357e-02, -5.6352e-01,  5.0608e-01,  1.8495e-01,  8.3415e-03,
        -3.2192e-02,  5.1196e-01, -1.3434e-02, -5.2051e-02,  1.4465e-01,
         3.7586e-02,  3.4294e-01,  6.9532e-03,  2.2646e-01,  5.1074e-01,
         3.4326e-02, -7.9605e-03,  3.3118e-01, -1.0774e-01, -4.2533e-02,
         3.0071e-02,  6.7271e-03, -7.9038e-01,  4.9789e-02, -4.3896e-01,
        -3.2473e-01, -2.9875e-01, -3.1284e-03, -4.8676e-03,  4.0755e-02,
        -7.9779e-03,  2.4403e-01, -5.4111e-02, -1.1398e-01,  1.1381e-03,
         3.8762e-02,  9.8144e-03, -3.7268e-01, -1.4725e-02,  5.2647e-01,
        -4.4866e-01,  2.7330e-01, -1.6092e-01, -1.5819e-01, -2.0994e-01,
         1.9687e-02, -2.4195e-02, -8.2346e-02, -3.9722e-01, -1.6621e-02,
         4.0971e-02,  3.9076e-01, -5.4414e-01, -1.2593e-01, -1.4784e-01,
        -3.4171e-01, -6.1622e-03, -2.4369e-01, -2.2419e-01,  3.1194e-04,
        -2.3541e-01, -6.4281e-02,  1.3214e-02, -1.1394e-01, -4.1008e-02,
        -8.9198e-02, -5.1327e-02, -3.2771e-01,  5.0167e-03,  2.6738e-01,
         6.9739e-02,  6.9241e-01,  4.3881e-01, -2.2326e-01,  2.3687e-02,
        -3.1278e-01, -9.1269e-02, -2.7651e-01,  1.0137e-01,  1.0068e+00,
        -3.0621e-02, -3.0768e-02, -1.6984e-01,  6.5683e-01,  8.3775e-02,
         4.4154e-01,  2.3669e-01, -1.1397e-01,  3.7616e-03, -2.0287e-02,
        -2.9737e-01,  5.2128e-02, -1.5838e-01, -1.8251e-01,  8.7094e-02,
        -9.9949e-03, -4.6141e-02, -4.2110e-01, -9.8060e-02, -1.8507e-01,
        -6.2266e-03,  1.6868e-02, -1.9719e-01, -2.3422e-01, -3.4677e-01,
         1.6644e-01,  1.2508e-01,  3.9419e-01,  7.4623e-02, -3.1263e-02,
        -3.1772e-01,  8.2826e-02,  1.5916e-02,  9.8656e-02,  1.1933e-02,
        -3.0592e-01, -3.5128e-02,  2.9627e-01,  2.0167e-01,  1.0441e-01,
        -1.0012e-01,  5.5527e-01, -1.0113e-01,  1.1197e-01, -5.4782e-02,
         5.3432e-01,  1.8933e-01,  1.2889e-01, -9.9683e-01, -3.9095e-02,
        -1.6115e-01,  1.7402e-02,  1.7735e-02,  1.6028e-01, -3.4079e-01,
         3.0157e-01,  7.4536e-02, -2.5539e-01, -3.4748e-01,  2.8850e-01,
        -2.7769e-01, -7.4830e-02,  1.7404e-01, -6.9485e-02, -2.7810e-01,
        -1.2865e-01,  2.2681e-01, -2.0876e-01, -4.3858e-01, -1.3636e-01,
        -3.7374e-01, -6.9845e-04,  2.8005e-01,  1.3781e-04, -1.2098e-01,
        -3.6941e-01, -1.2099e-01,  3.8068e-02, -3.8953e-01, -3.6715e-01,
        -4.5713e-02, -3.1230e-02, -1.0634e-01,  1.4168e-01,  2.3006e-01,
        -1.8545e-01, -2.0268e-01, -6.4673e-02, -2.3959e-01,  3.1085e-01,
         3.6060e-01,  1.6343e-02, -2.4542e-01, -8.0532e-02, -2.3345e-01,
        -1.0109e-02, -2.5677e-02,  9.0185e-01,  2.6805e-01,  3.4583e-01,
        -1.8345e-02, -1.3387e-01, -2.4006e-01,  1.4222e-02, -4.0942e-02,
        -1.7019e-01, -1.4158e-01, -2.0830e-01, -1.6937e-01, -8.4634e-02,
        -3.2971e-01, -2.7501e-01,  1.6297e-02, -4.0977e-02, -1.1737e-01,
         1.2762e-02, -1.3446e-01, -1.0032e-01, -1.4785e-01,  1.6940e-01,
        -6.3065e-02, -1.2878e-01,  6.4634e-01, -5.3337e-01,  1.4796e-02,
        -9.2406e-02, -4.7322e-01,  4.4713e-02, -3.0021e-01,  1.7769e-01,
        -4.5306e-01, -1.2880e-01, -3.4058e-02, -1.7092e-01, -3.2663e-01,
        -4.7847e-02, -3.4171e-01,  3.4814e-01, -1.8828e-01, -1.6558e-01,
        -5.7710e-01, -1.1870e-01,  2.7406e-01,  2.3553e-01, -2.6389e-01,
         2.1475e-01, -3.4905e-01,  1.3481e-01, -1.8988e-01, -2.4476e-02,
        -3.1931e-01,  9.0385e-02,  6.3579e-01, -1.4432e-01, -2.4492e-01,
         2.1646e-01,  4.9189e-01,  1.1619e-02,  7.9975e-02,  2.4348e-01,
         1.2597e-02, -1.4821e-01, -7.4586e-02,  1.5593e-01,  1.3075e-01,
         3.0585e-01, -3.6773e-01,  1.8266e-02,  9.1950e-02,  3.1870e-01,
        -2.1595e-01,  3.7490e-01, -2.6143e-02, -3.6379e-01,  8.8123e-03,
         2.6170e-02,  2.5109e-02,  2.6418e-02, -9.9203e-02,  3.0538e-01,
        -1.0716e-02, -1.9231e-01, -2.7256e-01,  1.1161e+00,  1.0306e-02,
        -9.5664e-02, -7.0387e-04, -3.1032e-01, -7.5437e-02,  2.4540e-01,
        -9.1371e-02, -5.9279e-01,  3.0519e-03,  1.4869e-02, -4.7875e-01,
         6.7282e-02, -1.8228e-01,  4.9477e-02,  3.0897e-02,  1.5924e-01,
         1.5401e-02,  3.8059e-02, -2.0829e-01, -1.9951e-01, -4.6217e-02,
        -5.7943e-01, -4.0632e-02,  1.8277e-01, -1.0761e-01, -5.3346e-01,
        -9.1331e-03, -3.6206e-01, -5.0542e-02,  2.9751e-01, -2.0687e-02,
         6.0333e-01,  2.5752e-01,  9.7420e-03,  6.7221e-03, -1.2128e-01,
        -8.0107e-02, -4.5753e-02,  6.7041e-02, -1.8902e-02, -2.1782e-01,
        -3.6457e-01, -2.6520e-02,  6.3351e-01, -3.4595e-01, -3.7133e-02,
        -9.5453e-02, -3.0462e-01, -3.0522e-01, -6.8319e-02, -5.2827e-01,
         1.4542e-01, -1.9183e-01,  1.9126e-03, -5.3526e-03, -1.5697e-01,
         2.8615e-02,  2.2385e-01, -4.2827e-02,  3.7193e-01, -1.0112e-01,
        -7.1846e-02, -1.7502e-01,  3.7556e-02, -6.9689e-01, -3.6152e-01,
        -3.2400e-02, -2.4076e-02, -3.1030e-01,  9.2280e-02, -4.0314e-01,
        -1.1533e-01,  1.2941e-01,  3.9190e-01,  6.1193e-02, -1.3612e-01,
        -2.1752e-02,  9.9641e-02,  2.4689e-01, -1.4833e-03,  1.3127e-01,
        -4.5445e-01,  3.8565e-01, -4.4021e-01,  4.3853e-01, -1.5639e-01,
         2.3228e-01,  4.4088e-02, -5.8860e-02, -1.5630e-03, -1.2278e-01,
        -8.8028e-02, -1.9164e-01, -6.1237e-02,  4.0478e-01, -3.7728e-01,
        -1.1528e-01,  1.1578e-01,  7.6797e-01, -7.4221e-02,  2.1551e-01,
         1.1526e-01, -2.0986e-03,  1.7941e-01, -7.2154e-01,  3.0799e-01,
        -3.7808e-02, -1.0175e-01,  2.5063e-01, -9.7411e-03, -1.2966e-01,
        -9.2820e-03,  5.0411e-02, -1.3581e-01,  2.7527e-01, -1.5140e-01,
         3.9171e-02,  5.3645e-02,  7.7759e-02,  2.6279e-02,  3.7055e-02,
         4.2298e-01, -4.2495e-02, -4.7810e-01, -2.3013e-01,  1.5903e-01,
         1.3805e-01, -1.8588e-01, -2.5382e-01,  1.1852e-02, -2.7152e-01,
        -2.3342e-01,  9.9333e-01], device='cuda:0')}
INFO:root:==> Evaluating the model at: 1
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:10.2249022007, MAE: 101.208069611, MSE: 101.208069314
INFO:root:(Meta-testing) test MAE: 101.541418076, MSE: 101.541418281
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.92773497105, MAE: 3.70236587524, MSE: 3.70236584572
INFO:root:(Meta-training) post train loss: 2.13366699219, MAE: 37.6027603149, MSE: 37.6027595968
INFO:root:(Meta-training) pre-training test MAE: 6.88640213013, MSE: 6.88640217694
INFO:root:(Meta-training) post-training test MAE: 40.4782524109, MSE: 40.4782520818
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-43.9209, device='cuda:0'), 'backend.0.bias': tensor(0.0013, device='cuda:0'), 'backend.10.weight': tensor(-2.8210, device='cuda:0'), 'backend.8.bias': tensor(-0.1662, device='cuda:0'), 'backend.6.weight': tensor(-52.1225, device='cuda:0'), 'backend.2.bias': tensor(-0.0119, device='cuda:0'), 'backend.10.bias': tensor(0.1539, device='cuda:0'), 'output_layer.bias': tensor(-30.3483, device='cuda:0'), 'backend.2.weight': tensor(-93.3568, device='cuda:0'), 'backend.6.bias': tensor(-0.0265, device='cuda:0'), 'backend.0.weight': tensor(-21.5632, device='cuda:0'), 'output_layer.weight': tensor(-5.2881, device='cuda:0'), 'backend.4.weight': tensor(-96.7638, device='cuda:0'), 'backend.4.bias': tensor(-0.0339, device='cuda:0')}
INFO:root:==> Training scene: 2
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.4576377869, MAE: 14.0155792236, MSE: 14.0155792746
INFO:root:(Meta-training) post train loss: 28.2439670563, MAE: 246.063415527, MSE: 246.063412813
INFO:root:(Meta-training) pre-training test MAE: 8.87585067749, MSE: 8.875850583
INFO:root:(Meta-training) post-training test MAE: 235.911239624, MSE: 235.911240261
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-1020.3319, device='cuda:0'), 'backend.0.bias': tensor(-0.1067, device='cuda:0'), 'backend.10.weight': tensor(-2049.0684, device='cuda:0'), 'backend.8.bias': tensor(-5.0614, device='cuda:0'), 'backend.6.weight': tensor(-1269.1729, device='cuda:0'), 'backend.2.bias': tensor(-0.5702, device='cuda:0'), 'backend.10.bias': tensor(-49.0953, device='cuda:0'), 'output_layer.bias': tensor(-201.3323, device='cuda:0'), 'backend.2.weight': tensor(-2259.6045, device='cuda:0'), 'backend.6.bias': tensor(-1.0513, device='cuda:0'), 'backend.0.weight': tensor(-684.9938, device='cuda:0'), 'output_layer.weight': tensor(-48.6113, device='cuda:0'), 'backend.4.weight': tensor(-2496.2798, device='cuda:0'), 'backend.4.bias': tensor(-1.3280, device='cuda:0')}
INFO:root:==> Training scene: 3
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.215716362, MAE: 12.3267059326, MSE: 12.3267058703
INFO:root:(Meta-training) post train loss: 13.1575832367, MAE: 155.954437256, MSE: 155.95443921
INFO:root:(Meta-training) pre-training test MAE: 17.9829978943, MSE: 17.9829979178
INFO:root:(Meta-training) post-training test MAE: 149.803665161, MSE: 149.803667084
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-411.3109, device='cuda:0'), 'backend.0.bias': tensor(-0.1084, device='cuda:0'), 'backend.10.weight': tensor(-577.3654, device='cuda:0'), 'backend.8.bias': tensor(-1.6774, device='cuda:0'), 'backend.6.weight': tensor(-752.4692, device='cuda:0'), 'backend.2.bias': tensor(-0.3535, device='cuda:0'), 'backend.10.bias': tensor(-13.2628, device='cuda:0'), 'output_layer.bias': tensor(-113.9397, device='cuda:0'), 'backend.2.weight': tensor(-1495.3286, device='cuda:0'), 'backend.6.bias': tensor(-0.6486, device='cuda:0'), 'backend.0.weight': tensor(-532.8908, device='cuda:0'), 'output_layer.weight': tensor(-24.8956, device='cuda:0'), 'backend.4.weight': tensor(-1443.4918, device='cuda:0'), 'backend.4.bias': tensor(-0.7667, device='cuda:0')}
INFO:root:==> Training scene: 4
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.40858054161, MAE: 3.46781778336, MSE: 3.46781785142
INFO:root:(Meta-training) post train loss: 1.24631130695, MAE: 40.1663703918, MSE: 40.1663700161
INFO:root:(Meta-training) pre-training test MAE: 5.10420227051, MSE: 5.1042023119
INFO:root:(Meta-training) post-training test MAE: 38.2077407837, MSE: 38.207740327
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-22.4932, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(-6.9668, device='cuda:0'), 'backend.8.bias': tensor(-0.0887, device='cuda:0'), 'backend.6.weight': tensor(1.9747, device='cuda:0'), 'backend.2.bias': tensor(-0.0034, device='cuda:0'), 'backend.10.bias': tensor(-0.2023, device='cuda:0'), 'output_layer.bias': tensor(-28.7350, device='cuda:0'), 'backend.2.weight': tensor(-43.8065, device='cuda:0'), 'backend.6.bias': tensor(0.0327, device='cuda:0'), 'backend.0.weight': tensor(-7.9347, device='cuda:0'), 'output_layer.weight': tensor(-4.6944, device='cuda:0'), 'backend.4.weight': tensor(-74.9707, device='cuda:0'), 'backend.4.bias': tensor(-0.0318, device='cuda:0')}
INFO:root:==> Training scene: 5
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.464849472, MAE: 11.5086917877, MSE: 11.5086915716
INFO:root:(Meta-training) post train loss: 12.0098371506, MAE: 157.504074097, MSE: 157.504073608
INFO:root:(Meta-training) pre-training test MAE: 6.65334415436, MSE: 6.65334403491
INFO:root:(Meta-training) post-training test MAE: 148.859954834, MSE: 148.859958046
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-168.4951, device='cuda:0'), 'backend.0.bias': tensor(-0.0335, device='cuda:0'), 'backend.10.weight': tensor(-512.0417, device='cuda:0'), 'backend.8.bias': tensor(-0.8689, device='cuda:0'), 'backend.6.weight': tensor(-290.6689, device='cuda:0'), 'backend.2.bias': tensor(-0.2067, device='cuda:0'), 'backend.10.bias': tensor(-12.1426, device='cuda:0'), 'output_layer.bias': tensor(-113.5457, device='cuda:0'), 'backend.2.weight': tensor(-810.5500, device='cuda:0'), 'backend.6.bias': tensor(-0.2528, device='cuda:0'), 'backend.0.weight': tensor(-189.6143, device='cuda:0'), 'output_layer.weight': tensor(-21.5855, device='cuda:0'), 'backend.4.weight': tensor(-870.6674, device='cuda:0'), 'backend.4.bias': tensor(-0.5180, device='cuda:0')}
INFO:root:==> Training scene: 6
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.31700372696, MAE: 4.50811004639, MSE: 4.50810994402
INFO:root:(Meta-training) post train loss: 2.54581308365, MAE: 56.9175300598, MSE: 56.9175300291
INFO:root:(Meta-training) pre-training test MAE: 3.33308029175, MSE: 3.33308034573
INFO:root:(Meta-training) post-training test MAE: 57.6218643188, MSE: 57.6218647466
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-37.6213, device='cuda:0'), 'backend.0.bias': tensor(0.0053, device='cuda:0'), 'backend.10.weight': tensor(-48.7510, device='cuda:0'), 'backend.8.bias': tensor(-0.1999, device='cuda:0'), 'backend.6.weight': tensor(-3.2662, device='cuda:0'), 'backend.2.bias': tensor(-0.0192, device='cuda:0'), 'backend.10.bias': tensor(-1.0821, device='cuda:0'), 'output_layer.bias': tensor(-43.8108, device='cuda:0'), 'backend.2.weight': tensor(-99.3718, device='cuda:0'), 'backend.6.bias': tensor(0.0174, device='cuda:0'), 'backend.0.weight': tensor(-8.4586, device='cuda:0'), 'output_layer.weight': tensor(-7.1186, device='cuda:0'), 'backend.4.weight': tensor(-117.8177, device='cuda:0'), 'backend.4.bias': tensor(-0.0676, device='cuda:0')}
INFO:root:==> Training scene: 7
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.56835842133, MAE: 9.11410331726, MSE: 9.11410331697
INFO:root:(Meta-training) post train loss: 8.68908500671, MAE: 118.70375061, MSE: 118.703749217
INFO:root:(Meta-training) pre-training test MAE: 7.59414863586, MSE: 7.59414860186
INFO:root:(Meta-training) post-training test MAE: 119.183746338, MSE: 119.183747319
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-183.1739, device='cuda:0'), 'backend.0.bias': tensor(-0.0085, device='cuda:0'), 'backend.10.weight': tensor(-210.6387, device='cuda:0'), 'backend.8.bias': tensor(-0.9138, device='cuda:0'), 'backend.6.weight': tensor(-301.4147, device='cuda:0'), 'backend.2.bias': tensor(-0.1017, device='cuda:0'), 'backend.10.bias': tensor(-4.8148, device='cuda:0'), 'output_layer.bias': tensor(-90.9324, device='cuda:0'), 'backend.2.weight': tensor(-551.6276, device='cuda:0'), 'backend.6.bias': tensor(-0.2307, device='cuda:0'), 'backend.0.weight': tensor(-168.9219, device='cuda:0'), 'output_layer.weight': tensor(-16.1698, device='cuda:0'), 'backend.4.weight': tensor(-548.3023, device='cuda:0'), 'backend.4.bias': tensor(-0.2530, device='cuda:0')}
INFO:root:==> Training scene: 8
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.70169210434, MAE: 4.29832458496, MSE: 4.29832450693
INFO:root:(Meta-training) post train loss: 3.96286129951, MAE: 41.1326179504, MSE: 41.1326173725
INFO:root:(Meta-training) pre-training test MAE: 0.344522476196, MSE: 0.34452247522
INFO:root:(Meta-training) post-training test MAE: 45.7303619385, MSE: 45.730363144
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-90.5592, device='cuda:0'), 'backend.0.bias': tensor(-0.0234, device='cuda:0'), 'backend.10.weight': tensor(-131.2070, device='cuda:0'), 'backend.8.bias': tensor(-0.3804, device='cuda:0'), 'backend.6.weight': tensor(-169.8558, device='cuda:0'), 'backend.2.bias': tensor(-0.0816, device='cuda:0'), 'backend.10.bias': tensor(-2.6672, device='cuda:0'), 'output_layer.bias': tensor(-34.8099, device='cuda:0'), 'backend.2.weight': tensor(-365.8163, device='cuda:0'), 'backend.6.bias': tensor(-0.1439, device='cuda:0'), 'backend.0.weight': tensor(-121.5345, device='cuda:0'), 'output_layer.weight': tensor(-7.2147, device='cuda:0'), 'backend.4.weight': tensor(-379.3094, device='cuda:0'), 'backend.4.bias': tensor(-0.1953, device='cuda:0')}
INFO:root:==> Training scene: 9
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.31722784042, MAE: 1.57554912567, MSE: 1.57554914801
INFO:root:(Meta-training) post train loss: 4.04796648026, MAE: 13.7908353806, MSE: 13.7908351375
INFO:root:(Meta-training) pre-training test MAE: 5.13178634644, MSE: 5.13178641226
INFO:root:(Meta-training) post-training test MAE: 10.5187931061, MSE: 10.5187932721
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(12.7440, device='cuda:0'), 'backend.0.bias': tensor(0.0095, device='cuda:0'), 'backend.10.weight': tensor(-5.2699, device='cuda:0'), 'backend.8.bias': tensor(0.0464, device='cuda:0'), 'backend.6.weight': tensor(44.8930, device='cuda:0'), 'backend.2.bias': tensor(0.0177, device='cuda:0'), 'backend.10.bias': tensor(-0.2285, device='cuda:0'), 'output_layer.bias': tensor(-7.7328, device='cuda:0'), 'backend.2.weight': tensor(82.0600, device='cuda:0'), 'backend.6.bias': tensor(0.0495, device='cuda:0'), 'backend.0.weight': tensor(42.8591, device='cuda:0'), 'output_layer.weight': tensor(-1.1357, device='cuda:0'), 'backend.4.weight': tensor(46.6682, device='cuda:0'), 'backend.4.bias': tensor(0.0206, device='cuda:0')}
INFO:root:==> Training scene: 10
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 2.62649679184, MAE: 0.140889167786, MSE: 0.14088916471
INFO:root:(Meta-training) post train loss: 1.72036862373, MAE: 8.40645599365, MSE: 8.40645601949
INFO:root:(Meta-training) pre-training test MAE: 2.28190612793, MSE: 2.28190613808
INFO:root:(Meta-training) post-training test MAE: 9.2960319519, MSE: 9.29603175338
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(29.3622, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(14.4824, device='cuda:0'), 'backend.8.bias': tensor(0.1243, device='cuda:0'), 'backend.6.weight': tensor(20.2014, device='cuda:0'), 'backend.2.bias': tensor(0.0180, device='cuda:0'), 'backend.10.bias': tensor(0.5394, device='cuda:0'), 'output_layer.bias': tensor(7.4570, device='cuda:0'), 'backend.2.weight': tensor(65.5934, device='cuda:0'), 'backend.6.bias': tensor(0.0065, device='cuda:0'), 'backend.0.weight': tensor(18.4875, device='cuda:0'), 'output_layer.weight': tensor(1.3642, device='cuda:0'), 'backend.4.weight': tensor(55.7639, device='cuda:0'), 'backend.4.bias': tensor(0.0333, device='cuda:0')}
INFO:root:==> Training scene: 11
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 20.0581626892, MAE: 3.79273986816, MSE: 3.79273981411
INFO:root:(Meta-training) post train loss: 15.4374341965, MAE: 60.0539779663, MSE: 60.0539775919
INFO:root:(Meta-training) pre-training test MAE: 1.65007305145, MSE: 1.65007306717
INFO:root:(Meta-training) post-training test MAE: 46.8975715637, MSE: 46.8975726901
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-285.1148, device='cuda:0'), 'backend.0.bias': tensor(-0.0562, device='cuda:0'), 'backend.10.weight': tensor(-397.6510, device='cuda:0'), 'backend.8.bias': tensor(-1.2813, device='cuda:0'), 'backend.6.weight': tensor(-501.0728, device='cuda:0'), 'backend.2.bias': tensor(-0.1695, device='cuda:0'), 'backend.10.bias': tensor(-8.2408, device='cuda:0'), 'output_layer.bias': tensor(-36.3815, device='cuda:0'), 'backend.2.weight': tensor(-722.0421, device='cuda:0'), 'backend.6.bias': tensor(-0.4861, device='cuda:0'), 'backend.0.weight': tensor(-277.7679, device='cuda:0'), 'output_layer.weight': tensor(-10.3747, device='cuda:0'), 'backend.4.weight': tensor(-798.2821, device='cuda:0'), 'backend.4.bias': tensor(-0.4068, device='cuda:0')}
INFO:root:==> Training scene: 12
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.26931238174, MAE: 9.15769100189, MSE: 9.15769098289
INFO:root:(Meta-training) post train loss: 5.25304222107, MAE: 128.482192993, MSE: 128.48219265
INFO:root:(Meta-training) pre-training test MAE: 4.61597824097, MSE: 4.61597820524
INFO:root:(Meta-training) post-training test MAE: 141.958694458, MSE: 141.958696403
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(260.6506, device='cuda:0'), 'backend.0.bias': tensor(0.0241, device='cuda:0'), 'backend.10.weight': tensor(468.7807, device='cuda:0'), 'backend.8.bias': tensor(1.2948, device='cuda:0'), 'backend.6.weight': tensor(381.9536, device='cuda:0'), 'backend.2.bias': tensor(0.2002, device='cuda:0'), 'backend.10.bias': tensor(12.5315, device='cuda:0'), 'output_layer.bias': tensor(110.0442, device='cuda:0'), 'backend.2.weight': tensor(951.6744, device='cuda:0'), 'backend.6.bias': tensor(0.2520, device='cuda:0'), 'backend.0.weight': tensor(256.8109, device='cuda:0'), 'output_layer.weight': tensor(24.2919, device='cuda:0'), 'backend.4.weight': tensor(1108.7393, device='cuda:0'), 'backend.4.bias': tensor(0.5716, device='cuda:0')}
INFO:root:==> Training scene: 13
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.15585327148, MAE: 0.122278213501, MSE: 0.122278211939
INFO:root:(Meta-training) post train loss: 6.03297472, MAE: 16.0758647919, MSE: 16.0758651762
INFO:root:(Meta-training) pre-training test MAE: 6.88552856445, MSE: 6.88552854815
INFO:root:(Meta-training) post-training test MAE: 24.3776416779, MSE: 24.3776415836
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(63.4808, device='cuda:0'), 'backend.0.bias': tensor(0.0233, device='cuda:0'), 'backend.10.weight': tensor(82.2610, device='cuda:0'), 'backend.8.bias': tensor(0.2575, device='cuda:0'), 'backend.6.weight': tensor(116.4730, device='cuda:0'), 'backend.2.bias': tensor(0.0472, device='cuda:0'), 'backend.10.bias': tensor(1.7025, device='cuda:0'), 'output_layer.bias': tensor(19.4742, device='cuda:0'), 'backend.2.weight': tensor(230.1301, device='cuda:0'), 'backend.6.bias': tensor(0.0803, device='cuda:0'), 'backend.0.weight': tensor(113.1909, device='cuda:0'), 'output_layer.weight': tensor(4.3418, device='cuda:0'), 'backend.4.weight': tensor(236.4320, device='cuda:0'), 'backend.4.bias': tensor(0.1142, device='cuda:0')}
INFO:root:==> Training scene: 14
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.2247161865, MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post train loss: 11.2101106644, MAE: 134.058197021, MSE: 134.058194861
INFO:root:(Meta-training) pre-training test MAE: 9.19702339172, MSE: 9.19702319208
INFO:root:(Meta-training) post-training test MAE: 132.986633301, MSE: 132.986635842
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-412.4737, device='cuda:0'), 'backend.0.bias': tensor(-0.0713, device='cuda:0'), 'backend.10.weight': tensor(-431.9995, device='cuda:0'), 'backend.8.bias': tensor(-1.9927, device='cuda:0'), 'backend.6.weight': tensor(-607.5549, device='cuda:0'), 'backend.2.bias': tensor(-0.2443, device='cuda:0'), 'backend.10.bias': tensor(-9.6425, device='cuda:0'), 'output_layer.bias': tensor(-102.2852, device='cuda:0'), 'backend.2.weight': tensor(-871.2729, device='cuda:0'), 'backend.6.bias': tensor(-0.6839, device='cuda:0'), 'backend.0.weight': tensor(-302.5356, device='cuda:0'), 'output_layer.weight': tensor(-20.8222, device='cuda:0'), 'backend.4.weight': tensor(-984.5647, device='cuda:0'), 'backend.4.bias': tensor(-0.5933, device='cuda:0')}
INFO:root:==> Training scene: 15
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.0185213089, MAE: 6.06261253357, MSE: 6.06261263084
INFO:root:(Meta-training) post train loss: 5.02552700043, MAE: 89.3602752686, MSE: 89.3602752293
INFO:root:(Meta-training) pre-training test MAE: 2.2882976532, MSE: 2.28829766213
INFO:root:(Meta-training) post-training test MAE: 88.706703186, MSE: 88.7067043381
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(73.9416, device='cuda:0'), 'backend.0.bias': tensor(-0.0452, device='cuda:0'), 'backend.10.weight': tensor(228.9542, device='cuda:0'), 'backend.8.bias': tensor(0.1953, device='cuda:0'), 'backend.6.weight': tensor(-42.0229, device='cuda:0'), 'backend.2.bias': tensor(-0.0187, device='cuda:0'), 'backend.10.bias': tensor(7.8502, device='cuda:0'), 'output_layer.bias': tensor(67.6426, device='cuda:0'), 'backend.2.weight': tensor(47.4640, device='cuda:0'), 'backend.6.bias': tensor(-0.2108, device='cuda:0'), 'backend.0.weight': tensor(-75.9561, device='cuda:0'), 'output_layer.weight': tensor(11.4994, device='cuda:0'), 'backend.4.weight': tensor(242.4803, device='cuda:0'), 'backend.4.bias': tensor(0.1128, device='cuda:0')}
INFO:root:==> Training scene: 16
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.7963008881, MAE: 16.1687660217, MSE: 16.1687657413
INFO:root:(Meta-training) post train loss: 22.4242458344, MAE: 229.407485962, MSE: 229.407482373
INFO:root:(Meta-training) pre-training test MAE: 6.00388336182, MSE: 6.00388337666
INFO:root:(Meta-training) post-training test MAE: 239.257141113, MSE: 239.257142984
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-988.6003, device='cuda:0'), 'backend.0.bias': tensor(-0.2824, device='cuda:0'), 'backend.10.weight': tensor(-1988.3594, device='cuda:0'), 'backend.8.bias': tensor(-5.0329, device='cuda:0'), 'backend.6.weight': tensor(-2082.1543, device='cuda:0'), 'backend.2.bias': tensor(-1.0028, device='cuda:0'), 'backend.10.bias': tensor(-44.8206, device='cuda:0'), 'output_layer.bias': tensor(-201.1472, device='cuda:0'), 'backend.2.weight': tensor(-3871.7905, device='cuda:0'), 'backend.6.bias': tensor(-2.2654, device='cuda:0'), 'backend.0.weight': tensor(-1286.4838, device='cuda:0'), 'output_layer.weight': tensor(-56.6222, device='cuda:0'), 'backend.4.weight': tensor(-4343.2554, device='cuda:0'), 'backend.4.bias': tensor(-2.4096, device='cuda:0')}
INFO:root:==> Training scene: 17
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 32.0257339478, MAE: 15.1991195679, MSE: 15.1991193617
INFO:root:(Meta-training) post train loss: 48.2651062012, MAE: 335.650817871, MSE: 335.650813719
INFO:root:(Meta-training) pre-training test MAE: 11.0977325439, MSE: 11.0977325598
INFO:root:(Meta-training) post-training test MAE: 336.292419434, MSE: 336.292422974
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-7079.0317, device='cuda:0'), 'backend.0.bias': tensor(-1.0678, device='cuda:0'), 'backend.10.weight': tensor(-9176.1621, device='cuda:0'), 'backend.8.bias': tensor(-32.7449, device='cuda:0'), 'backend.6.weight': tensor(-9999.3828, device='cuda:0'), 'backend.2.bias': tensor(-3.5476, device='cuda:0'), 'backend.10.bias': tensor(-201.9896, device='cuda:0'), 'output_layer.bias': tensor(-380.1562, device='cuda:0'), 'backend.2.weight': tensor(-13915.4082, device='cuda:0'), 'backend.6.bias': tensor(-10.0968, device='cuda:0'), 'backend.0.weight': tensor(-4359.9946, device='cuda:0'), 'output_layer.weight': tensor(-154.6839, device='cuda:0'), 'backend.4.weight': tensor(-14321.7227, device='cuda:0'), 'backend.4.bias': tensor(-7.5350, device='cuda:0')}
INFO:root:==> Training scene: 18
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.19173002243, MAE: 9.96483707428, MSE: 9.96483724213
INFO:root:(Meta-training) post train loss: 8.31143093109, MAE: 108.922950745, MSE: 108.92294976
INFO:root:(Meta-training) pre-training test MAE: 26.310459137, MSE: 26.31045865
INFO:root:(Meta-training) post-training test MAE: 94.4987640381, MSE: 94.4987650796
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-88.2477, device='cuda:0'), 'backend.0.bias': tensor(0.0020, device='cuda:0'), 'backend.10.weight': tensor(-150.8411, device='cuda:0'), 'backend.8.bias': tensor(-0.5698, device='cuda:0'), 'backend.6.weight': tensor(-90.5708, device='cuda:0'), 'backend.2.bias': tensor(-0.0589, device='cuda:0'), 'backend.10.bias': tensor(-4.4715, device='cuda:0'), 'output_layer.bias': tensor(-71.4431, device='cuda:0'), 'backend.2.weight': tensor(-212.6744, device='cuda:0'), 'backend.6.bias': tensor(-0.1036, device='cuda:0'), 'backend.0.weight': tensor(-35.0562, device='cuda:0'), 'output_layer.weight': tensor(-12.1312, device='cuda:0'), 'backend.4.weight': tensor(-304.2588, device='cuda:0'), 'backend.4.bias': tensor(-0.2161, device='cuda:0')}
INFO:root:==> Training scene: 19
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.85736942291, MAE: 15.1381454468, MSE: 15.1381455981
INFO:root:(Meta-training) post train loss: 11.7894144058, MAE: 200.715957642, MSE: 200.71595485
INFO:root:(Meta-training) pre-training test MAE: 19.7869281769, MSE: 19.786928058
INFO:root:(Meta-training) post-training test MAE: 196.792785645, MSE: 196.792790375
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-82.1093, device='cuda:0'), 'backend.0.bias': tensor(0.0720, device='cuda:0'), 'backend.10.weight': tensor(-106.0497, device='cuda:0'), 'backend.8.bias': tensor(-0.6434, device='cuda:0'), 'backend.6.weight': tensor(60.6098, device='cuda:0'), 'backend.2.bias': tensor(0.0389, device='cuda:0'), 'backend.10.bias': tensor(-4.0570, device='cuda:0'), 'output_layer.bias': tensor(-149.3103, device='cuda:0'), 'backend.2.weight': tensor(-19.7755, device='cuda:0'), 'backend.6.bias': tensor(0.1884, device='cuda:0'), 'backend.0.weight': tensor(94.8992, device='cuda:0'), 'output_layer.weight': tensor(-21.7000, device='cuda:0'), 'backend.4.weight': tensor(-218.3605, device='cuda:0'), 'backend.4.bias': tensor(-0.1340, device='cuda:0')}
INFO:root:==> Training scene: 20
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.6179828644, MAE: 19.8658561707, MSE: 19.8658564426
INFO:root:(Meta-training) post train loss: 23.2383213043, MAE: 305.630065918, MSE: 305.630061308
INFO:root:(Meta-training) pre-training test MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post-training test MAE: 309.446746826, MSE: 309.446746731
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(58.7687, device='cuda:0'), 'backend.0.bias': tensor(0.1086, device='cuda:0'), 'backend.10.weight': tensor(-648.2240, device='cuda:0'), 'backend.8.bias': tensor(0.4562, device='cuda:0'), 'backend.6.weight': tensor(345.6557, device='cuda:0'), 'backend.2.bias': tensor(-0.1202, device='cuda:0'), 'backend.10.bias': tensor(-15.2989, device='cuda:0'), 'output_layer.bias': tensor(-243.9008, device='cuda:0'), 'backend.2.weight': tensor(-578.7977, device='cuda:0'), 'backend.6.bias': tensor(0.6730, device='cuda:0'), 'backend.0.weight': tensor(372.4923, device='cuda:0'), 'output_layer.weight': tensor(-42.9096, device='cuda:0'), 'backend.4.weight': tensor(-832.2753, device='cuda:0'), 'backend.4.bias': tensor(-0.4173, device='cuda:0')}
INFO:root:==> Training scene: 21
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.92966938019, MAE: 7.99254989624, MSE: 7.99255000362
INFO:root:(Meta-training) post train loss: 7.93039751053, MAE: 103.157691956, MSE: 103.157693681
INFO:root:(Meta-training) pre-training test MAE: 17.2073936462, MSE: 17.2073934943
INFO:root:(Meta-training) post-training test MAE: 94.2486724854, MSE: 94.2486737307
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-110.2387, device='cuda:0'), 'backend.0.bias': tensor(-0.0146, device='cuda:0'), 'backend.10.weight': tensor(-230.1305, device='cuda:0'), 'backend.8.bias': tensor(-0.4253, device='cuda:0'), 'backend.6.weight': tensor(-117.1571, device='cuda:0'), 'backend.2.bias': tensor(-0.0757, device='cuda:0'), 'backend.10.bias': tensor(-5.3008, device='cuda:0'), 'output_layer.bias': tensor(-71.6464, device='cuda:0'), 'backend.2.weight': tensor(-347.9861, device='cuda:0'), 'backend.6.bias': tensor(-0.0327, device='cuda:0'), 'backend.0.weight': tensor(-114.7507, device='cuda:0'), 'output_layer.weight': tensor(-14.5011, device='cuda:0'), 'backend.4.weight': tensor(-442.1409, device='cuda:0'), 'backend.4.bias': tensor(-0.2187, device='cuda:0')}
INFO:root:==> Training scene: 22
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.6123580933, MAE: 10.1582298279, MSE: 10.1582299753
INFO:root:(Meta-training) post train loss: 13.2736635208, MAE: 153.450241089, MSE: 153.450241324
INFO:root:(Meta-training) pre-training test MAE: 16.6812591553, MSE: 16.6812590741
INFO:root:(Meta-training) post-training test MAE: 142.571716309, MSE: 142.571713041
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-348.8337, device='cuda:0'), 'backend.0.bias': tensor(-0.1027, device='cuda:0'), 'backend.10.weight': tensor(-844.5209, device='cuda:0'), 'backend.8.bias': tensor(-1.7194, device='cuda:0'), 'backend.6.weight': tensor(-814.8105, device='cuda:0'), 'backend.2.bias': tensor(-0.4311, device='cuda:0'), 'backend.10.bias': tensor(-20.1072, device='cuda:0'), 'output_layer.bias': tensor(-113.4044, device='cuda:0'), 'backend.2.weight': tensor(-1628.4746, device='cuda:0'), 'backend.6.bias': tensor(-0.7616, device='cuda:0'), 'backend.0.weight': tensor(-452.7468, device='cuda:0'), 'output_layer.weight': tensor(-25.8738, device='cuda:0'), 'backend.4.weight': tensor(-1727.8400, device='cuda:0'), 'backend.4.bias': tensor(-1.0229, device='cuda:0')}
INFO:root:==> Training scene: 23
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 21.1111278534, MAE: 0.63020324707, MSE: 0.630203236541
INFO:root:(Meta-training) post train loss: 22.0809364319, MAE: 13.3689956665, MSE: 13.3689955309
INFO:root:(Meta-training) pre-training test MAE: 6.70138835907, MSE: 6.70138847426
INFO:root:(Meta-training) post-training test MAE: 37.1159133911, MSE: 37.1159138976
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(16.0151, device='cuda:0'), 'backend.0.bias': tensor(0.0425, device='cuda:0'), 'backend.10.weight': tensor(-114.7230, device='cuda:0'), 'backend.8.bias': tensor(-0.0450, device='cuda:0'), 'backend.6.weight': tensor(201.0753, device='cuda:0'), 'backend.2.bias': tensor(0.0558, device='cuda:0'), 'backend.10.bias': tensor(-2.8131, device='cuda:0'), 'output_layer.bias': tensor(-25.3123, device='cuda:0'), 'backend.2.weight': tensor(294.5614, device='cuda:0'), 'backend.6.bias': tensor(0.1817, device='cuda:0'), 'backend.0.weight': tensor(233.2775, device='cuda:0'), 'output_layer.weight': tensor(-4.9482, device='cuda:0'), 'backend.4.weight': tensor(177.3441, device='cuda:0'), 'backend.4.bias': tensor(0.0573, device='cuda:0')}
INFO:root:==> Training scene: 24
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.3689892292, MAE: 3.61751317978, MSE: 3.61751322588
INFO:root:(Meta-training) post train loss: 1.41690564156, MAE: 57.1678237915, MSE: 57.1678244841
INFO:root:(Meta-training) pre-training test MAE: 3.67163085938, MSE: 3.67163085126
INFO:root:(Meta-training) post-training test MAE: 62.91822052, MSE: 62.9182198777
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(67.4449, device='cuda:0'), 'backend.0.bias': tensor(-0.0376, device='cuda:0'), 'backend.10.weight': tensor(95.9710, device='cuda:0'), 'backend.8.bias': tensor(0.2977, device='cuda:0'), 'backend.6.weight': tensor(-43.1883, device='cuda:0'), 'backend.2.bias': tensor(-0.0293, device='cuda:0'), 'backend.10.bias': tensor(3.6065, device='cuda:0'), 'output_layer.bias': tensor(48.0856, device='cuda:0'), 'backend.2.weight': tensor(-23.3053, device='cuda:0'), 'backend.6.bias': tensor(-0.1360, device='cuda:0'), 'backend.0.weight': tensor(-73.2256, device='cuda:0'), 'output_layer.weight': tensor(7.2894, device='cuda:0'), 'backend.4.weight': tensor(94.5628, device='cuda:0'), 'backend.4.bias': tensor(0.0419, device='cuda:0')}
INFO:root:==> Training scene: 25
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.78185081482, MAE: 3.64704179764, MSE: 3.647041789
INFO:root:(Meta-training) post train loss: 1.53377187252, MAE: 41.5643882751, MSE: 41.5643884674
INFO:root:(Meta-training) pre-training test MAE: 7.03860282898, MSE: 7.03860292617
INFO:root:(Meta-training) post-training test MAE: 38.4184913635, MSE: 38.4184912347
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(6.1834, device='cuda:0'), 'backend.0.bias': tensor(0.0124, device='cuda:0'), 'backend.10.weight': tensor(-7.2555, device='cuda:0'), 'backend.8.bias': tensor(0.0298, device='cuda:0'), 'backend.6.weight': tensor(31.5153, device='cuda:0'), 'backend.2.bias': tensor(0.0100, device='cuda:0'), 'backend.10.bias': tensor(-0.1930, device='cuda:0'), 'output_layer.bias': tensor(-28.9806, device='cuda:0'), 'backend.2.weight': tensor(31.5566, device='cuda:0'), 'backend.6.bias': tensor(0.0482, device='cuda:0'), 'backend.0.weight': tensor(44.4503, device='cuda:0'), 'output_layer.weight': tensor(-4.4127, device='cuda:0'), 'backend.4.weight': tensor(9.8322, device='cuda:0'), 'backend.4.bias': tensor(0.0038, device='cuda:0')}
INFO:root:==> Training scene: 26
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.51275110245, MAE: 4.93081665039, MSE: 4.93081656946
INFO:root:(Meta-training) post train loss: 6.66961288452, MAE: 63.5387802124, MSE: 63.5387796048
INFO:root:(Meta-training) pre-training test MAE: 1.70257949829, MSE: 1.70257951593
INFO:root:(Meta-training) post-training test MAE: 74.05909729, MSE: 74.0590980231
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-64.9146, device='cuda:0'), 'backend.0.bias': tensor(0.0207, device='cuda:0'), 'backend.10.weight': tensor(-215.7396, device='cuda:0'), 'backend.8.bias': tensor(-0.2159, device='cuda:0'), 'backend.6.weight': tensor(-53.6725, device='cuda:0'), 'backend.2.bias': tensor(0.0031, device='cuda:0'), 'backend.10.bias': tensor(-5.1249, device='cuda:0'), 'output_layer.bias': tensor(-58.9641, device='cuda:0'), 'backend.2.weight': tensor(-154.8737, device='cuda:0'), 'backend.6.bias': tensor(0.1189, device='cuda:0'), 'backend.0.weight': tensor(-51.5991, device='cuda:0'), 'output_layer.weight': tensor(-9.6605, device='cuda:0'), 'backend.4.weight': tensor(-269.6791, device='cuda:0'), 'backend.4.bias': tensor(-0.1026, device='cuda:0')}
INFO:root:==> Training scene: 27
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.81052994728, MAE: 3.4300737381, MSE: 3.43007370984
INFO:root:(Meta-training) post train loss: 1.85474956036, MAE: 49.2230949402, MSE: 49.2230950463
INFO:root:(Meta-training) pre-training test MAE: 0.405708312988, MSE: 0.405708318655
INFO:root:(Meta-training) post-training test MAE: 53.5645370483, MSE: 53.5645374102
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(21.7239, device='cuda:0'), 'backend.0.bias': tensor(-0.0415, device='cuda:0'), 'backend.10.weight': tensor(88.3675, device='cuda:0'), 'backend.8.bias': tensor(0.0254, device='cuda:0'), 'backend.6.weight': tensor(-91.4464, device='cuda:0'), 'backend.2.bias': tensor(-0.0413, device='cuda:0'), 'backend.10.bias': tensor(3.2484, device='cuda:0'), 'output_layer.bias': tensor(40.5884, device='cuda:0'), 'backend.2.weight': tensor(-47.4420, device='cuda:0'), 'backend.6.bias': tensor(-0.2370, device='cuda:0'), 'backend.0.weight': tensor(-68.5267, device='cuda:0'), 'output_layer.weight': tensor(6.0570, device='cuda:0'), 'backend.4.weight': tensor(54.8532, device='cuda:0'), 'backend.4.bias': tensor(-0.0010, device='cuda:0')}
INFO:root:==> Training scene: 28
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.91805839539, MAE: 16.495388031, MSE: 16.4953884269
INFO:root:(Meta-training) post train loss: 16.5992298126, MAE: 248.975234985, MSE: 248.975235654
INFO:root:(Meta-training) pre-training test MAE: 5.10612487793, MSE: 5.10612491749
INFO:root:(Meta-training) post-training test MAE: 254.839996338, MSE: 254.839992691
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-218.2436, device='cuda:0'), 'backend.0.bias': tensor(0.0600, device='cuda:0'), 'backend.10.weight': tensor(-483.3945, device='cuda:0'), 'backend.8.bias': tensor(-0.9689, device='cuda:0'), 'backend.6.weight': tensor(58.4666, device='cuda:0'), 'backend.2.bias': tensor(-0.1581, device='cuda:0'), 'backend.10.bias': tensor(-8.8787, device='cuda:0'), 'output_layer.bias': tensor(-200.1620, device='cuda:0'), 'backend.2.weight': tensor(-680.3275, device='cuda:0'), 'backend.6.bias': tensor(0.2169, device='cuda:0'), 'backend.0.weight': tensor(194.6782, device='cuda:0'), 'output_layer.weight': tensor(-33.2362, device='cuda:0'), 'backend.4.weight': tensor(-900.4709, device='cuda:0'), 'backend.4.bias': tensor(-0.4924, device='cuda:0')}
INFO:root:==> Training scene: 29
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.79754734039, MAE: 17.5090179443, MSE: 17.5090178007
INFO:root:(Meta-training) post train loss: 19.8869819641, MAE: 259.828735352, MSE: 259.828729647
INFO:root:(Meta-training) pre-training test MAE: 19.3920478821, MSE: 19.3920476916
INFO:root:(Meta-training) post-training test MAE: 262.822509766, MSE: 262.822510214
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-562.1880, device='cuda:0'), 'backend.0.bias': tensor(-0.0445, device='cuda:0'), 'backend.10.weight': tensor(-752.2289, device='cuda:0'), 'backend.8.bias': tensor(-2.6582, device='cuda:0'), 'backend.6.weight': tensor(-1082.9235, device='cuda:0'), 'backend.2.bias': tensor(-0.3633, device='cuda:0'), 'backend.10.bias': tensor(-19.6488, device='cuda:0'), 'output_layer.bias': tensor(-208.3303, device='cuda:0'), 'backend.2.weight': tensor(-1791.1687, device='cuda:0'), 'backend.6.bias': tensor(-0.9017, device='cuda:0'), 'backend.0.weight': tensor(-419.6126, device='cuda:0'), 'output_layer.weight': tensor(-41.2734, device='cuda:0'), 'backend.4.weight': tensor(-1991.5342, device='cuda:0'), 'backend.4.bias': tensor(-0.9737, device='cuda:0')}
INFO:root:==> Training scene: 30
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.79670476913, MAE: 2.56892776489, MSE: 2.56892779772
INFO:root:(Meta-training) post train loss: 5.16473054886, MAE: 24.4140777588, MSE: 24.4140775
INFO:root:(Meta-training) pre-training test MAE: 1.84230804443, MSE: 1.84230806249
INFO:root:(Meta-training) post-training test MAE: 22.7580795288, MSE: 22.7580793518
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-46.0849, device='cuda:0'), 'backend.0.bias': tensor(-0.0036, device='cuda:0'), 'backend.10.weight': tensor(-73.4196, device='cuda:0'), 'backend.8.bias': tensor(-0.1900, device='cuda:0'), 'backend.6.weight': tensor(-62.4307, device='cuda:0'), 'backend.2.bias': tensor(-0.0266, device='cuda:0'), 'backend.10.bias': tensor(-1.6552, device='cuda:0'), 'output_layer.bias': tensor(-17.0427, device='cuda:0'), 'backend.2.weight': tensor(-127.3670, device='cuda:0'), 'backend.6.bias': tensor(-0.0366, device='cuda:0'), 'backend.0.weight': tensor(-25.0341, device='cuda:0'), 'output_layer.weight': tensor(-3.4376, device='cuda:0'), 'backend.4.weight': tensor(-128.4538, device='cuda:0'), 'backend.4.bias': tensor(-0.0640, device='cuda:0')}
INFO:root:==> Training scene: 31
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.92816901207, MAE: 6.54268741608, MSE: 6.54268743565
INFO:root:(Meta-training) post train loss: 3.94747567177, MAE: 79.0179595947, MSE: 79.0179592917
INFO:root:(Meta-training) pre-training test MAE: 2.77071666718, MSE: 2.77071666233
INFO:root:(Meta-training) post-training test MAE: 81.9200592041, MSE: 81.9200585699
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-42.4969, device='cuda:0'), 'backend.0.bias': tensor(0.0191, device='cuda:0'), 'backend.10.weight': tensor(-89.6895, device='cuda:0'), 'backend.8.bias': tensor(-0.1760, device='cuda:0'), 'backend.6.weight': tensor(25.6620, device='cuda:0'), 'backend.2.bias': tensor(-0.0125, device='cuda:0'), 'backend.10.bias': tensor(-2.3425, device='cuda:0'), 'output_layer.bias': tensor(-62.3058, device='cuda:0'), 'backend.2.weight': tensor(-101.7161, device='cuda:0'), 'backend.6.bias': tensor(0.0798, device='cuda:0'), 'backend.0.weight': tensor(28.3379, device='cuda:0'), 'output_layer.weight': tensor(-10.7214, device='cuda:0'), 'backend.4.weight': tensor(-192.2546, device='cuda:0'), 'backend.4.bias': tensor(-0.0999, device='cuda:0')}
INFO:root:==> Training scene: 32
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.5723743439, MAE: 3.49564743042, MSE: 3.49564744882
INFO:root:(Meta-training) post train loss: 8.17095756531, MAE: 36.8633918762, MSE: 36.8633919759
INFO:root:(Meta-training) pre-training test MAE: 3.27803039551, MSE: 3.27803041451
INFO:root:(Meta-training) post-training test MAE: 33.7333984375, MSE: 33.733397971
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-57.7771, device='cuda:0'), 'backend.0.bias': tensor(-0.0101, device='cuda:0'), 'backend.10.weight': tensor(-168.3690, device='cuda:0'), 'backend.8.bias': tensor(-0.3028, device='cuda:0'), 'backend.6.weight': tensor(-124.5657, device='cuda:0'), 'backend.2.bias': tensor(-0.0514, device='cuda:0'), 'backend.10.bias': tensor(-3.7853, device='cuda:0'), 'output_layer.bias': tensor(-26.0408, device='cuda:0'), 'backend.2.weight': tensor(-202.7009, device='cuda:0'), 'backend.6.bias': tensor(-0.1367, device='cuda:0'), 'backend.0.weight': tensor(-33.2378, device='cuda:0'), 'output_layer.weight': tensor(-5.5101, device='cuda:0'), 'backend.4.weight': tensor(-261.8320, device='cuda:0'), 'backend.4.bias': tensor(-0.1489, device='cuda:0')}
INFO:root:===> Updating meta network
INFO:root:===> Gradients updated: {'backend.8.weight': tensor([[[[ 7.7916e-01,  8.5607e-01,  7.9229e-01],
          [ 9.0868e-01,  7.7736e-01,  6.4876e-01],
          [ 9.0064e-01,  9.4987e-01,  7.5753e-01]],

         [[ 1.1307e-01,  1.0704e-01,  9.0649e-02],
          [ 1.2796e-01,  1.0473e-01,  1.2942e-01],
          [ 1.3047e-01,  1.6048e-01,  1.4018e-01]],

         [[ 7.5768e-01,  7.1184e-01,  8.0713e-01],
          [ 7.5325e-01,  7.6828e-01,  8.4883e-01],
          [ 6.4983e-01,  8.1942e-01,  6.6784e-01]],

         ...,

         [[ 4.8735e-03,  5.3943e-03,  5.6951e-03],
          [ 4.0223e-03,  5.7926e-03,  2.3920e-03],
          [ 5.1352e-03,  6.9413e-03,  1.8356e-03]],

         [[ 2.1338e-02,  1.4164e-02,  1.3132e-02],
          [ 1.4678e-02,  1.8111e-02,  1.2113e-02],
          [ 1.1622e-02,  1.0919e-02,  8.9136e-03]],

         [[ 8.8305e-01,  8.2144e-01,  7.5310e-01],
          [ 8.2313e-01,  8.4059e-01,  7.4162e-01],
          [ 8.5086e-01,  7.3575e-01,  7.3748e-01]]],


        [[[-4.9812e-01, -5.0378e-01, -5.1191e-01],
          [-4.0563e-01, -2.9149e-01, -3.7377e-01],
          [-2.8067e-01, -3.3813e-01, -3.9142e-01]],

         [[-3.6185e-02, -4.4534e-02, -3.7252e-02],
          [-3.7536e-02, -2.0504e-02, -3.5803e-02],
          [-3.6210e-02, -6.8325e-02, -4.4340e-02]],

         [[-3.7382e-01, -3.9211e-01, -4.3686e-01],
          [-4.6847e-01, -4.9453e-01, -5.1677e-01],
          [-5.1365e-01, -5.5016e-01, -3.8768e-01]],

         ...,

         [[-5.0242e-03, -1.1525e-03, -2.1685e-03],
          [-3.8029e-03, -3.3366e-03, -1.4325e-03],
          [-3.0780e-03, -4.2158e-03, -4.6185e-03]],

         [[-5.8557e-03, -1.7622e-02, -2.0925e-02],
          [-2.2585e-02, -2.9423e-02, -2.1775e-02],
          [-1.7520e-02, -1.5502e-02, -9.9940e-03]],

         [[-3.5619e-01, -4.2216e-01, -4.5200e-01],
          [-4.1187e-01, -5.1698e-01, -4.8196e-01],
          [-2.5478e-01, -2.9195e-01, -3.7740e-01]]],


        [[[-5.0192e-01, -1.6550e-01, -3.0481e-01],
          [-4.3925e-01, -2.2387e-01, -4.2957e-01],
          [-2.3618e-01, -4.3159e-01, -5.8229e-01]],

         [[-1.4857e-02, -4.3006e-02, -5.9084e-02],
          [-6.6487e-03, -6.0455e-02, -7.7892e-02],
          [-2.2638e-02, -5.3768e-02, -7.4317e-02]],

         [[ 8.3276e-02,  2.6158e-02, -2.1678e-01],
          [-1.3345e-01, -2.8881e-01, -1.2474e-01],
          [-3.7338e-01, -2.9140e-01, -1.1983e-01]],

         ...,

         [[-8.1383e-03, -4.9587e-03, -2.1028e-03],
          [-4.4009e-03, -1.6209e-03,  3.1504e-03],
          [-6.1091e-04,  1.2553e-03, -5.3144e-03]],

         [[ 1.1792e-02, -2.7062e-03, -3.8844e-03],
          [-1.7547e-03, -1.5361e-02, -9.7133e-03],
          [-3.5433e-03, -5.4995e-03, -2.7218e-03]],

         [[-7.8813e-03, -2.6094e-01, -2.7988e-01],
          [-1.4145e-01, -1.4226e-01, -3.1542e-01],
          [ 2.1230e-02, -2.0337e-01, -2.4090e-01]]],


        ...,


        [[[-2.9929e-01, -3.0268e-01, -2.6287e-01],
          [-2.9783e-01, -3.2071e-01, -2.3949e-01],
          [-3.1233e-01, -3.2161e-01, -2.6809e-01]],

         [[-3.4950e-02, -4.1251e-02, -3.6930e-02],
          [-3.8473e-02, -3.4362e-02, -3.8018e-02],
          [-3.6614e-02, -3.9380e-02, -3.5096e-02]],

         [[-1.7141e-01, -1.5779e-01, -1.4476e-01],
          [-1.7421e-01, -1.4054e-01, -1.5374e-01],
          [-1.1284e-01, -1.3553e-01, -1.4858e-01]],

         ...,

         [[-3.5639e-03, -2.7827e-03, -2.7394e-03],
          [-3.8445e-03, -3.7023e-03, -1.9841e-03],
          [-5.2670e-03, -4.6121e-03, -2.3858e-03]],

         [[-4.0673e-03, -2.9856e-03, -2.4181e-03],
          [-3.0785e-03, -2.0582e-03, -2.0237e-03],
          [-1.1365e-03, -2.0668e-03, -1.9191e-03]],

         [[-2.2178e-01, -2.4374e-01, -2.2302e-01],
          [-2.0329e-01, -2.1494e-01, -2.0253e-01],
          [-2.2835e-01, -2.2162e-01, -2.1170e-01]]],


        [[[-1.9047e-01, -5.0808e-01, -6.5154e-01],
          [-5.2507e-01, -5.0222e-01, -7.7457e-01],
          [-2.1515e-01,  8.5308e-02, -3.5444e-01]],

         [[ 3.1730e-02, -1.1143e-01,  1.3258e-02],
          [-6.2912e-02,  5.6852e-02, -3.5360e-02],
          [-4.4693e-02, -6.0705e-02, -1.5646e-02]],

         [[-2.1752e-01, -4.0752e-01,  1.6297e-01],
          [-2.4690e-01,  2.1465e-01, -1.9746e-01],
          [-3.6736e-01, -3.6167e-01, -3.7535e-01]],

         ...,

         [[-1.1183e-02, -9.8649e-03, -4.9530e-03],
          [-1.2929e-02, -9.7740e-03, -1.4051e-02],
          [-9.3559e-03, -6.5622e-03, -3.3315e-03]],

         [[ 8.0945e-03,  1.3654e-02,  8.0040e-03],
          [-5.6982e-03,  1.6568e-03, -4.8265e-03],
          [-4.1134e-03,  1.1965e-03,  4.5939e-03]],

         [[ 1.2224e-01,  3.1816e-01, -1.0589e-02],
          [-2.2472e-02, -3.1923e-01, -2.2589e-01],
          [ 2.7719e-03,  5.2610e-03,  1.2988e-02]]],


        [[[-4.9065e-01, -5.2073e-01, -5.2142e-01],
          [-6.1824e-01, -4.1892e-01, -5.3042e-01],
          [-7.6838e-01, -4.8344e-01, -6.1932e-01]],

         [[-1.0348e-01, -5.7851e-02, -8.9387e-02],
          [-8.2592e-02, -8.9407e-02, -8.5119e-02],
          [-9.8153e-02, -1.1333e-01, -1.1592e-01]],

         [[-5.3413e-01, -5.2772e-01, -4.8901e-01],
          [-3.7988e-01, -3.6942e-01, -5.1767e-01],
          [-4.2634e-01, -3.9946e-01, -4.8190e-01]],

         ...,

         [[-1.6937e-03, -4.2673e-03, -6.6555e-03],
          [-3.8203e-03, -4.7557e-03, -4.0910e-03],
          [-4.4072e-03, -1.1244e-03, -1.3581e-03]],

         [[-1.8637e-02, -5.6245e-03, -1.0102e-02],
          [-2.4483e-04, -1.3707e-03, -3.9374e-03],
          [-5.8170e-03, -9.9687e-03, -7.9207e-03]],

         [[-6.9425e-01, -5.7233e-01, -5.7277e-01],
          [-5.3208e-01, -6.1464e-01, -5.7705e-01],
          [-6.7009e-01, -4.8128e-01, -5.7393e-01]]]], device='cuda:0'), 'backend.0.bias': tensor([ 3.7435e-02,  8.6870e-03,  2.9687e-02,  9.5615e-02, -7.9366e-03,
        -2.2906e-01,  2.1799e-02,  1.2916e-01, -1.1742e-01,  5.3095e-02,
         6.5154e-02, -3.3857e-02, -1.8881e-01,  6.5476e-02,  1.1124e-01,
        -1.6869e-02, -9.0779e-02, -5.9171e-02, -1.5687e-02, -6.3601e-03,
        -1.0433e-01,  1.4868e-02,  2.4667e-01,  3.6994e-02, -5.4466e-02,
         1.1374e-02, -1.7108e-01, -2.9399e-02, -1.2781e-01, -2.2293e-02,
         5.0197e-02, -4.6588e-02, -4.9303e-02, -6.8111e-02, -1.1202e-01,
         1.1110e-01,  4.5685e-02,  1.5133e-01,  3.5386e-02, -2.8244e-02,
         4.8509e-02, -1.7623e-01,  1.0986e-01, -1.7990e-01,  3.6821e-02,
         6.6092e-03,  8.1261e-03,  1.3467e-01,  2.1311e-02, -2.2371e-02,
        -3.5822e-02,  1.0288e-01, -2.3761e-01,  1.0828e-01, -1.2286e-01,
         4.3771e-02,  9.0976e-02,  5.4291e-03,  6.3594e-03,  6.7665e-02,
        -8.3080e-03,  2.5766e-02,  1.2529e-01,  9.5696e-02, -3.2555e-02,
         1.1471e-03,  4.7835e-02, -1.0141e-01, -5.9007e-02,  1.1059e-01,
         1.9459e-03,  3.8479e-02,  1.3206e-02, -2.1734e-02, -5.8063e-03,
         5.6675e-02,  6.5930e-02,  2.8954e-02,  1.0560e-01,  8.2580e-03,
        -4.4967e-02,  1.1845e-03, -1.6334e-01,  3.3130e-02,  1.4980e-02,
        -5.1273e-02,  1.3311e-02, -1.1537e-01,  1.1990e-01, -2.9766e-03,
         2.5823e-02, -1.2387e-01,  3.3274e-02,  1.4201e-01, -1.8099e-02,
        -8.3500e-02, -1.2276e-01, -1.7765e-01, -1.7965e-01,  1.4993e-01,
        -2.8363e-04, -9.3303e-03,  1.3635e-01,  3.1081e-03,  3.3438e-02,
        -1.6648e-02, -3.7137e-02,  1.8647e-02, -1.6222e-02, -1.3726e-01,
        -2.6879e-02,  1.3328e-01, -2.0468e-02, -1.7346e-02,  1.0685e-01,
        -9.4513e-03, -3.3734e-02,  5.2324e-02, -6.5748e-02,  5.0566e-02,
         6.0393e-02, -2.3553e-02, -1.8967e-01,  6.2576e-03,  7.2336e-02,
        -1.7122e-02, -2.7196e-03, -9.6275e-02,  4.6943e-04, -2.2710e-01,
         6.5826e-03,  3.1450e-02, -7.9220e-03, -1.7999e-01,  1.5686e-01,
        -1.3607e-02, -3.6705e-02, -1.8343e-01,  1.3468e-01,  1.1924e-02,
        -1.4944e-02, -9.2972e-03,  3.1526e-02, -3.5560e-02,  8.4172e-03,
        -7.3547e-02,  6.9649e-02,  1.4172e-01, -5.6148e-02,  8.2017e-02,
         5.3280e-02,  9.1900e-02,  2.8378e-03, -1.3483e-02,  7.4777e-02,
         6.9646e-03, -2.7512e-02, -3.0703e-02, -2.0543e-01,  1.8875e-01,
         6.9804e-02,  3.3834e-02, -2.7313e-02, -2.0109e-01, -5.1881e-02,
         2.3692e-03,  1.0829e-01, -3.6844e-02, -8.6512e-02, -2.1700e-01,
        -7.0292e-02,  6.8957e-02,  3.1386e-02,  1.3123e-02, -3.2300e-02,
        -1.0123e-01,  8.2451e-02, -1.8405e-02,  2.7770e-02, -1.5899e-01,
         4.5789e-03,  1.1975e-02,  7.1424e-03,  4.3332e-03, -1.7068e-01,
        -3.9195e-02,  4.2247e-02,  8.9102e-02, -5.1279e-03, -5.4139e-02,
         1.3974e-03, -8.0118e-02, -5.2303e-02,  8.1216e-03,  1.2798e-01,
         8.6179e-02,  5.2950e-02,  7.4546e-02, -3.3942e-03,  1.7204e-01,
        -1.1362e-01,  1.4206e-01,  2.1858e-01,  9.2226e-02, -1.9899e-01,
         3.6390e-02, -1.1806e-01, -8.2607e-02,  9.6324e-02,  3.8894e-02,
        -4.3596e-03, -1.4082e-01,  8.5449e-02,  7.8836e-02,  4.1850e-02,
         1.1328e-02,  7.4670e-02,  6.7290e-02, -7.1616e-02, -1.5780e-01,
        -9.5885e-03, -2.2306e-02, -6.0844e-02,  9.7202e-02, -1.1720e-01,
         1.0030e-01, -1.0907e-02, -3.6494e-02, -2.5864e-04, -7.7159e-02,
        -1.7274e-01,  2.3191e-02, -1.9711e-02,  3.5280e-02, -1.4302e-01,
         1.2825e-02,  4.7919e-02, -1.6809e-01,  5.6044e-02,  7.4026e-02,
         2.2772e-02, -1.4494e-01, -4.2030e-02, -6.3803e-02,  1.2182e-02,
         4.3357e-02,  5.3708e-02,  4.2698e-02, -2.8498e-02,  1.4108e-01,
        -5.5319e-03,  9.1692e-02,  6.3695e-02, -3.4250e-02, -2.8302e-02,
        -5.3445e-02,  2.9549e-03, -5.0377e-02,  1.6559e-02,  1.2318e-01,
        -4.0769e-04, -9.3539e-02, -6.3956e-02, -1.3604e-02, -5.2657e-02,
         3.6483e-02, -9.6793e-02, -8.6376e-02,  4.8673e-04,  8.6022e-03,
        -1.0094e-01, -5.5459e-02, -6.2277e-03,  2.4522e-02,  1.6359e-01,
        -3.3313e-02,  4.5278e-02,  5.1332e-02, -1.2520e-01,  9.1645e-02,
        -5.9487e-02, -1.1458e-01, -6.1016e-02, -2.1344e-01,  2.6369e-02,
         1.8460e-02, -8.5283e-04,  3.9910e-01,  2.6680e-02, -1.6055e-01,
        -6.4645e-02, -5.6140e-02,  1.0158e-02, -1.4174e-02,  7.4238e-02,
         3.7757e-02, -7.6092e-02, -5.3069e-02,  4.9685e-02, -2.6026e-01,
        -1.8112e-01,  1.3090e-01,  2.7321e-02,  2.0812e-02,  3.8819e-02,
         4.0497e-02, -4.4817e-02, -3.4690e-02, -6.9138e-02,  1.2728e-01,
        -1.7978e-01,  3.2796e-02, -4.3860e-02,  9.0157e-02,  3.4749e-02,
        -5.8771e-02, -2.9962e-02, -2.5504e-03, -2.6110e-03, -3.0463e-02,
         4.8108e-02, -1.5034e-01,  4.0939e-02, -8.9531e-02, -2.2503e-02,
         2.5583e-02,  9.0480e-02,  6.8584e-02,  1.1664e-01, -1.2778e-02,
         1.4530e-02,  2.3291e-02, -8.2612e-02,  7.2054e-02,  6.5943e-03,
         5.9477e-02,  2.1409e-02, -1.0625e-01, -1.0625e-01, -8.5955e-02,
         8.7440e-02,  6.5846e-02,  1.9994e-02, -2.2160e-02, -7.1827e-02,
        -1.4755e-03, -2.1725e-02,  4.5513e-02,  4.6463e-02, -5.6594e-02,
         7.0406e-02, -7.1067e-02,  8.3108e-02,  7.8468e-02,  9.3381e-02,
         6.4196e-04,  4.0035e-02, -3.3856e-03,  4.2069e-02, -1.4598e-01,
         7.9621e-02,  1.4402e-01, -4.1291e-02,  4.3087e-02, -1.2321e-01,
        -1.4229e-01, -1.5477e-02, -1.5638e-01,  7.6902e-02, -1.8433e-02,
        -3.0861e-02, -7.7829e-02,  4.6241e-02,  1.0649e-01,  6.2955e-02,
         3.3869e-02,  5.2016e-02,  7.5418e-02, -1.0650e-01, -8.4462e-04,
        -1.1416e-01,  5.3096e-02,  1.0518e-01,  1.0734e-01, -8.4019e-02,
         1.3562e-01, -1.2334e-01, -4.9151e-02,  1.2403e-01, -8.0861e-02,
         1.4998e-01, -2.3119e-02,  1.0668e-01, -5.9597e-02, -1.0736e-02,
         4.4334e-02,  2.6921e-02, -5.7334e-02,  1.0289e-01,  2.2908e-01,
        -6.2295e-02,  4.3519e-02,  3.5141e-02, -3.7513e-02, -1.5320e-01,
        -1.7330e-01, -1.7242e-01,  1.1273e-01,  8.8121e-02,  1.7925e-02,
         1.5912e-01, -8.8515e-03,  3.6228e-03, -1.5002e-02, -9.1840e-02,
         2.3673e-02,  2.8329e-02,  2.2835e-02,  4.4367e-02, -6.7741e-02,
        -5.3699e-02, -3.3518e-03, -1.7343e-02, -9.4084e-03,  5.4577e-02,
        -5.9961e-02, -4.1878e-03, -5.1599e-02, -1.4495e-02, -7.0580e-02,
        -1.0849e-01,  1.7600e-01, -9.0257e-02,  1.1788e-01, -3.2402e-03,
         5.9322e-02, -6.7923e-02, -6.7786e-02,  3.3781e-02,  3.1117e-02,
        -1.1967e-01,  1.1624e-01, -6.5048e-02,  6.9480e-02,  3.6160e-02,
         1.8169e-02, -1.1414e-02, -2.2333e-02, -5.7602e-02,  4.2443e-02,
         1.4755e-02,  2.9847e-02,  9.0883e-02, -1.8335e-02, -1.7758e-01,
         6.6599e-02, -4.1333e-02, -5.6229e-02, -2.5875e-02, -1.4190e-01,
         2.3748e-03,  1.5121e-02,  8.3825e-03,  1.7196e-02,  4.8924e-02,
        -1.8419e-01,  1.6579e-04, -5.8995e-03, -2.3125e-01, -1.4528e-01,
         2.8597e-02,  4.2600e-02, -3.7203e-02,  1.2312e-02,  1.3099e-01,
        -3.3446e-02, -1.1550e-01, -3.2146e-02, -5.2976e-02,  3.4270e-02,
        -1.4025e-02, -7.2390e-03,  5.4484e-03, -2.1931e-02, -1.5543e-02,
         5.1916e-02,  6.7207e-03, -2.1290e-01,  8.3986e-02,  9.0955e-02,
        -1.9859e-02,  5.5643e-02,  7.0865e-02, -6.5067e-02, -1.8819e-02,
        -2.6504e-03, -1.0377e-02, -2.6327e-02,  1.3805e-01,  7.2935e-03,
         6.3787e-02, -1.9616e-02,  5.1553e-03, -6.8186e-02,  2.9798e-02,
         9.7751e-02,  1.3504e-01, -1.2660e-01,  6.2476e-04,  6.9422e-02,
         2.6582e-02,  5.3619e-02], device='cuda:0'), 'backend.10.weight': tensor([[[[-2.1959e-01, -3.3617e-01, -3.1556e-01],
          [-4.1270e-01, -3.4180e-01, -3.8507e-01],
          [-5.4396e-01, -5.1190e-01, -5.2420e-01]],

         [[-1.8068e-01, -1.1519e-01, -9.5161e-02],
          [-5.3012e-02, -3.9709e-02, -3.9325e-02],
          [-1.9610e-02, -1.2149e-02, -1.1782e-02]],

         [[-5.8630e-01, -4.5302e-01, -3.9153e-01],
          [-5.4708e-01, -2.9469e-01, -3.2340e-01],
          [-3.8501e-01, -3.9807e-01, -5.7451e-01]],

         ...,

         [[-9.7577e-02, -7.3513e-02, -7.1505e-02],
          [-5.3139e-02, -8.2465e-02, -6.4261e-02],
          [-5.2220e-02, -5.2127e-02, -5.7822e-02]],

         [[-7.6080e-01, -6.6571e-01, -8.5296e-01],
          [-6.0264e-01, -6.6787e-01, -6.7292e-01],
          [-1.1411e+00, -6.8185e-01, -6.6706e-01]],

         [[-1.8829e-01, -1.7583e-01, -2.0558e-01],
          [-1.6771e-01, -2.0710e-01, -3.6578e-01],
          [-1.1624e-01, -1.1664e-01, -1.4306e-01]]],


        [[[-2.3476e+00, -2.6140e+00, -2.5955e+00],
          [-3.0088e+00, -2.9354e+00, -2.9637e+00],
          [-3.3367e+00, -3.2346e+00, -3.2560e+00]],

         [[-3.5227e-01, -3.1430e-01, -2.8929e-01],
          [-3.8315e-01, -3.6267e-01, -3.4866e-01],
          [-1.9386e-01, -1.8508e-01, -1.6998e-01]],

         [[-2.3411e+00, -2.0769e+00, -1.9700e+00],
          [-2.4370e+00, -2.0338e+00, -2.0448e+00],
          [-1.9506e+00, -1.8898e+00, -2.0975e+00]],

         ...,

         [[-7.2566e-01, -7.4311e-01, -7.0555e-01],
          [-6.7706e-01, -7.6847e-01, -7.2329e-01],
          [-6.1618e-01, -6.6311e-01, -6.7481e-01]],

         [[-4.6668e+00, -4.4965e+00, -4.7603e+00],
          [-4.8601e+00, -4.4961e+00, -4.5276e+00],
          [-5.5612e+00, -4.5514e+00, -4.3601e+00]],

         [[-5.4382e-01, -5.9398e-01, -6.5607e-01],
          [-5.7637e-01, -6.7748e-01, -8.0152e-01],
          [-4.7273e-01, -5.1591e-01, -6.0473e-01]]],


        [[[ 5.0461e-01,  5.0912e-01,  5.1986e-01],
          [ 5.1670e-01,  5.3388e-01,  5.4456e-01],
          [ 5.2959e-01,  5.4138e-01,  5.4454e-01]],

         [[ 8.5475e-03,  1.2207e-02,  1.2803e-02],
          [ 2.4507e-02,  2.6864e-02,  2.6616e-02],
          [ 2.4521e-02,  2.6697e-02,  2.7364e-02]],

         [[ 1.6012e-01,  1.9595e-01,  1.9410e-01],
          [ 1.9142e-01,  2.1182e-01,  1.9630e-01],
          [ 1.9157e-01,  2.1010e-01,  2.0856e-01]],

         ...,

         [[ 1.0573e-01,  1.0355e-01,  1.0533e-01],
          [ 1.1294e-01,  1.1248e-01,  1.1330e-01],
          [ 1.1578e-01,  1.1593e-01,  1.1540e-01]],

         [[ 5.8945e-01,  6.1057e-01,  6.0976e-01],
          [ 5.8720e-01,  6.4044e-01,  6.4838e-01],
          [ 6.2204e-01,  6.5195e-01,  6.4490e-01]],

         [[ 3.2154e-02,  3.4026e-02,  2.0880e-02],
          [ 3.2994e-02,  4.0004e-02,  2.7592e-02],
          [ 3.6006e-02,  4.3411e-02,  3.7158e-02]]],


        ...,


        [[[ 1.8190e-01,  1.7046e-01,  1.6139e-01],
          [ 1.8184e-01,  1.8455e-01,  1.6810e-01],
          [ 1.5529e-01,  1.4892e-01,  1.3226e-01]],

         [[ 6.4871e-03,  1.1624e-02,  1.2358e-02],
          [ 5.4277e-02,  5.7847e-02,  5.7604e-02],
          [ 2.9974e-02,  3.2117e-02,  3.0282e-02]],

         [[ 7.2629e-02,  8.3997e-02,  7.7993e-02],
          [ 1.4803e-01,  1.6411e-01,  1.4653e-01],
          [ 1.2448e-01,  1.1466e-01,  9.5875e-02]],

         ...,

         [[ 2.1645e-02,  2.1378e-02,  2.0795e-02],
          [ 2.4206e-02,  2.2717e-02,  2.0400e-02],
          [ 1.9733e-02,  1.8385e-02,  1.5471e-02]],

         [[ 2.3900e-01,  2.4282e-01,  2.2168e-01],
          [ 2.5852e-01,  2.4316e-01,  2.4233e-01],
          [ 1.6480e-01,  1.7964e-01,  1.5443e-01]],

         [[ 1.5493e-02,  1.5617e-02,  2.1987e-02],
          [ 3.8231e-02,  3.1676e-02,  3.4201e-02],
          [ 3.2447e-02,  4.2885e-02,  4.5704e-02]]],


        [[[-1.1759e+00, -1.6960e+00, -1.5655e+00],
          [-2.0424e+00, -1.9111e+00, -1.9262e+00],
          [-2.5530e+00, -2.4314e+00, -2.4598e+00]],

         [[-5.2375e-01, -3.9010e-01, -3.5612e-01],
          [-1.7797e-01, -1.4278e-01, -1.5335e-01],
          [-5.4149e-02, -3.4321e-02, -4.5134e-02]],

         [[-2.4280e+00, -2.0517e+00, -1.8042e+00],
          [-2.3026e+00, -1.3931e+00, -1.5063e+00],
          [-1.5431e+00, -1.5189e+00, -2.2006e+00]],

         ...,

         [[-3.9746e-01, -3.2304e-01, -2.6708e-01],
          [-2.9420e-01, -3.7322e-01, -3.1305e-01],
          [-2.4681e-01, -2.3345e-01, -2.4592e-01]],

         [[-3.1743e+00, -3.0652e+00, -3.6059e+00],
          [-2.6640e+00, -2.7461e+00, -2.8847e+00],
          [-4.6844e+00, -3.0260e+00, -2.9310e+00]],

         [[-6.6746e-01, -6.5959e-01, -6.4882e-01],
          [-5.9409e-01, -7.4414e-01, -1.1450e+00],
          [-3.8093e-01, -3.7266e-01, -4.6022e-01]]],


        [[[-2.0956e-02, -2.0874e-02, -1.9518e-02],
          [-2.7313e-02, -2.4516e-02, -2.2938e-02],
          [-3.3471e-02, -3.3802e-02, -3.1649e-02]],

         [[-7.0705e-03, -8.3364e-03, -8.0707e-03],
          [-1.5045e-03, -2.1105e-03, -1.4246e-03],
          [-2.9152e-04, -2.5143e-04, -2.7530e-04]],

         [[-2.9277e-02, -2.6434e-02, -2.3441e-02],
          [-2.4026e-02, -2.1748e-02, -2.1338e-02],
          [-1.7061e-02, -2.5575e-02, -2.2425e-02]],

         ...,

         [[-3.2052e-03, -2.6869e-03, -1.9415e-03],
          [-1.3244e-03, -1.4512e-03, -1.2490e-03],
          [-1.7377e-03, -2.1666e-03, -1.5999e-03]],

         [[-3.7681e-02, -3.7452e-02, -3.5264e-02],
          [-3.3036e-02, -3.4708e-02, -2.4630e-02],
          [-4.1510e-02, -3.3301e-02, -3.4321e-02]],

         [[-1.6050e-02, -1.3616e-02, -1.1221e-02],
          [-9.7573e-03, -1.1921e-02, -1.2731e-02],
          [-5.4952e-03, -6.2393e-03, -4.1736e-03]]]], device='cuda:0'), 'backend.8.bias': tensor([ 4.9737e+00, -3.2972e+00, -1.2807e+00,  7.2608e-01, -1.5039e+00,
         1.6829e-01,  4.9959e-01, -2.1996e+00, -8.1899e-01, -1.3867e+00,
        -2.9949e-01, -4.3840e+00,  3.9718e-01, -3.1363e+00, -3.8491e+00,
        -2.6649e+00, -4.2858e-03, -5.9884e-01,  2.8110e+00, -2.2734e+00,
        -3.7313e-01,  7.8966e+00, -2.7427e-01, -4.5185e+00, -4.7506e-01,
         6.7307e+00,  2.4345e+00,  7.2646e+00, -3.2969e+00, -2.1476e+00,
        -1.9279e+00, -1.8337e+00, -1.6325e+00, -6.2015e-01, -9.9722e-01,
        -4.8325e+00,  2.9649e+00, -1.7396e+00, -1.6582e+00, -2.2803e+00,
         8.5869e-01,  3.3221e+00, -1.2001e+00,  9.5225e-02, -6.5972e-01,
         2.6132e+00, -3.0081e+00,  2.7432e+00, -2.9369e+00, -5.7038e-01,
        -4.1127e+00, -5.6516e+00, -3.8666e-01, -3.7298e+00,  7.6422e-01,
        -2.0456e+00, -2.0734e+00,  2.8771e-01, -2.2529e+00,  3.3025e+00,
         3.9578e+00, -2.1992e+00, -7.6605e-01, -1.0977e+00,  1.1327e-01,
        -3.4376e+00, -6.3099e-01, -7.0960e+00,  2.1510e+00,  1.8661e+00,
         2.0419e-01, -8.1415e-01,  4.6508e+00, -2.5497e+00, -4.1238e-01,
        -3.9497e+00,  2.1542e+00, -1.6452e+00, -1.1187e+00,  2.3748e+00,
        -5.8479e+00,  1.0999e+00,  9.7701e-02,  1.6046e+01, -1.4923e-01,
         3.7003e+00,  8.8302e-01, -4.3128e+00, -3.0774e+00,  5.0141e+00,
        -3.2504e+00,  2.5759e+00,  8.8290e-01, -1.0728e-01, -4.5346e-01,
        -2.7930e+00, -5.8308e+00, -1.6652e+00, -3.4447e-01, -4.6627e+00,
        -3.4878e+00, -2.0511e+00, -6.1618e-03,  5.6120e+00, -1.7159e-01,
        -5.2394e-01, -4.4822e-01,  1.6986e+00, -1.6533e+00, -2.3031e+00,
         2.8576e+00, -3.0470e+00, -5.3538e+00, -1.7170e+00,  8.7231e-01,
        -6.4554e+00, -1.1156e+00, -1.7039e+00,  9.7583e+00,  4.5824e-02,
         6.5802e+00, -2.2104e+00,  1.9929e+00, -5.2730e-02, -1.6266e+00,
        -1.3862e+00, -1.2762e+00, -3.9050e+00], device='cuda:0'), 'backend.6.weight': tensor([[[[ 1.7659e-02, -2.6832e-02,  1.1385e-02],
          [-9.5984e-03, -6.9888e-02, -7.4893e-02],
          [-5.2248e-02, -5.5227e-02, -7.9817e-02]],

         [[ 3.0972e-02,  5.7662e-02, -3.3489e-03],
          [-1.8451e-02, -1.3400e-02, -2.8494e-02],
          [-3.6402e-02, -7.0431e-02, -3.7302e-02]],

         [[-8.8065e-02, -1.2215e-01, -9.8338e-02],
          [-8.9382e-02, -4.0194e-02, -8.8762e-02],
          [-6.7900e-02, -6.4822e-02, -2.2596e-02]],

         ...,

         [[ 7.3210e-02, -2.9444e-02,  3.3527e-02],
          [ 1.1094e-02, -1.5081e-02, -2.0852e-02],
          [-5.2141e-02, -7.4994e-02, -8.7375e-02]],

         [[ 6.4951e-02,  5.9654e-02, -4.4958e-03],
          [-3.5679e-02,  6.1587e-02, -3.2398e-02],
          [-2.3371e-02, -6.1786e-02, -2.3975e-02]],

         [[-4.3150e-02, -2.9796e-02, -3.8643e-03],
          [-2.6559e-02, -1.7023e-02,  2.6667e-02],
          [ 4.5345e-02,  5.3840e-02,  8.0433e-02]]],


        [[[-1.8931e-02, -1.3767e-02, -2.2328e-02],
          [-1.7999e-02, -1.7059e-02, -1.7739e-02],
          [-1.7193e-03,  2.6561e-03, -3.2753e-03]],

         [[-4.8770e-03, -9.9159e-03, -1.8203e-02],
          [-9.3299e-03, -3.3823e-03, -1.0877e-02],
          [ 3.6882e-03, -3.0340e-03,  1.1092e-03]],

         [[-1.9346e-02, -1.9373e-02, -7.3060e-03],
          [ 1.2832e-02,  5.7328e-05, -5.6076e-03],
          [-1.6917e-02, -1.6682e-02, -2.7383e-02]],

         ...,

         [[-3.2147e-02, -5.1278e-02, -5.4454e-02],
          [-2.2433e-02, -6.8817e-03, -2.5640e-02],
          [-2.3895e-02, -3.1762e-02, -3.6114e-02]],

         [[-2.0607e-02, -3.0017e-02, -4.2409e-02],
          [-3.8847e-02, -2.1023e-02, -2.3158e-02],
          [-1.8858e-02, -2.0132e-02, -2.1347e-02]],

         [[ 3.0966e-02,  2.2453e-02,  2.1628e-02],
          [-1.4634e-02,  3.5282e-03,  8.0388e-04],
          [ 3.7986e-03, -2.6813e-03,  6.2535e-03]]],


        [[[ 1.6407e-01,  1.0967e-01,  1.5278e-01],
          [ 1.9659e-01,  1.5155e-01,  1.5199e-01],
          [ 1.1947e-01,  1.4954e-01,  1.1909e-01]],

         [[ 6.7720e-02,  1.4779e-01,  1.6977e-01],
          [ 1.0759e-01,  1.5109e-01,  1.3400e-01],
          [ 1.4679e-01,  1.1283e-01,  7.9238e-02]],

         [[ 4.3010e-01,  4.1349e-01,  3.3435e-01],
          [ 3.3523e-01,  3.7894e-01,  3.6660e-01],
          [ 3.4610e-01,  3.0348e-01,  3.2541e-01]],

         ...,

         [[ 1.7422e-01,  1.2319e-01,  1.7807e-01],
          [ 1.3168e-01,  1.4664e-01,  7.5703e-02],
          [ 8.7482e-02,  1.2710e-01,  1.0617e-01]],

         [[ 2.8918e-01,  2.1335e-01,  3.0835e-01],
          [ 2.9417e-01,  2.6610e-01,  3.8148e-01],
          [ 3.5822e-01,  1.8312e-01,  2.4299e-01]],

         [[ 6.2543e-01,  6.9266e-01,  6.6342e-01],
          [ 6.4601e-01,  6.5722e-01,  6.6194e-01],
          [ 7.1699e-01,  7.2908e-01,  6.5544e-01]]],


        ...,


        [[[-3.0835e-03, -5.4564e-03, -4.0023e-03],
          [-4.0692e-03, -5.8402e-03, -5.1373e-03],
          [-3.0648e-03, -2.8590e-03, -4.6755e-03]],

         [[-3.8954e-03, -4.8944e-03, -5.4124e-03],
          [-1.1260e-02, -8.1189e-03, -8.4610e-03],
          [-7.5158e-03, -1.0222e-02, -8.0836e-03]],

         [[-1.4891e-02, -1.4623e-02, -2.0755e-02],
          [-2.3570e-02, -1.8869e-02, -2.5201e-02],
          [-2.3054e-02, -2.1368e-02, -1.9387e-02]],

         ...,

         [[-7.3070e-03, -1.0875e-02, -7.4364e-03],
          [-6.0824e-03, -5.9057e-03, -9.7995e-03],
          [-5.6780e-03, -4.5554e-03, -5.1283e-03]],

         [[-6.7616e-03, -8.6668e-03, -1.2406e-02],
          [-1.7809e-02, -1.6932e-02, -1.4825e-02],
          [-1.3919e-02, -1.8692e-02, -1.7844e-02]],

         [[-1.1690e-02, -1.2990e-02, -9.4364e-03],
          [-3.4773e-02, -3.4121e-02, -3.0164e-02],
          [-3.9313e-02, -4.2817e-02, -4.0379e-02]]],


        [[[-1.1916e-02, -8.5964e-03, -1.0027e-02],
          [-9.8618e-03, -1.3041e-02, -9.8269e-03],
          [-1.3514e-02, -1.5581e-02, -1.3258e-02]],

         [[-4.4533e-03, -6.6127e-03, -5.6980e-03],
          [-4.0484e-03, -4.0086e-03, -5.0111e-03],
          [-4.2605e-03, -4.7118e-03, -7.7490e-03]],

         [[-2.5376e-02, -2.8867e-02, -3.2323e-02],
          [-1.9552e-02, -2.3627e-02, -2.7003e-02],
          [-1.9886e-02, -1.9896e-02, -2.6292e-02]],

         ...,

         [[-8.8458e-03, -8.3307e-03, -7.5918e-03],
          [-1.1403e-02, -1.1842e-02, -1.1067e-02],
          [-1.5496e-02, -1.6875e-02, -1.5704e-02]],

         [[-1.7235e-02, -2.2534e-02, -1.8846e-02],
          [-1.8398e-02, -1.8702e-02, -1.9821e-02],
          [-2.2294e-02, -1.8882e-02, -2.1458e-02]],

         [[-2.3913e-02, -3.0531e-02, -3.6398e-02],
          [-2.0194e-02, -2.3742e-02, -3.0163e-02],
          [-1.7456e-02, -1.2982e-02, -2.0532e-02]]],


        [[[-3.1058e-02,  1.6961e-02, -5.0719e-02],
          [-2.3574e-02,  2.1136e-02, -5.6126e-04],
          [-7.0931e-02, -4.7651e-02, -1.5537e-02]],

         [[ 4.7571e-02, -7.3377e-03,  3.1953e-02],
          [ 1.1158e-01,  5.7628e-02, -1.6454e-04],
          [ 1.5482e-03, -5.2598e-03, -5.0021e-03]],

         [[ 5.3417e-02,  2.0064e-01,  1.3220e-01],
          [-1.2124e-01, -1.6742e-01, -8.4608e-02],
          [-2.1417e-01, -2.5808e-01, -3.0919e-01]],

         ...,

         [[ 2.0335e-02,  1.1659e-01, -2.2834e-02],
          [ 1.9424e-01,  2.3623e-01,  1.9429e-01],
          [ 8.7266e-03,  4.6949e-02,  3.9763e-02]],

         [[-2.1546e-02,  4.8327e-02,  2.2329e-02],
          [ 1.4284e-01,  4.5180e-02, -4.6276e-02],
          [ 1.0123e-01,  2.4752e-01,  1.2154e-01]],

         [[-3.1303e-01, -2.8268e-01, -2.1845e-01],
          [-1.3687e-01, -1.7780e-01, -2.2222e-01],
          [-6.3111e-03,  3.5331e-02,  1.3386e-01]]]], device='cuda:0'), 'backend.2.bias': tensor([-9.5445e-02,  1.2118e-01, -7.2391e-03, -1.1388e-01, -1.4564e-01,
        -1.3560e-02,  3.4898e-03,  7.2919e-02,  7.2377e-02, -8.7557e-02,
        -2.1074e-01, -4.4167e-02, -1.4490e-04, -2.8609e-02, -7.1421e-02,
        -1.7638e-01,  7.6595e-02, -9.6583e-02, -3.9318e-02,  1.0934e-02,
        -9.4726e-03, -5.9582e-03, -1.8186e-01,  6.3051e-02, -9.9821e-02,
         6.5248e-02, -1.8788e-01, -2.5883e-02, -7.8021e-02, -1.6218e-01,
         2.9943e-02,  2.5170e-02, -1.4130e-01, -1.0984e-02,  1.9060e-01,
        -6.5443e-02,  2.4095e-01,  2.0355e-01,  5.0608e-02,  3.8263e-01,
         8.4443e-02,  5.4905e-04,  5.1955e-03, -5.1459e-03, -1.3074e-01,
        -9.0038e-02, -1.0445e-01, -7.5575e-02, -4.8597e-02, -1.1293e-01,
         1.2865e-02, -6.1113e-02,  3.9259e-02,  2.2154e-02, -1.2546e-01,
         5.5565e-02, -8.7545e-02, -4.8289e-01,  2.3833e-02,  2.4542e-04,
         1.9773e-02,  3.4710e-02, -1.0664e-01, -8.6273e-03, -3.3260e-02,
        -2.8559e-02,  1.6657e-02, -3.4660e-02, -2.5922e-01,  1.1552e-01,
         1.8184e-02, -1.5381e-01, -5.6098e-02, -5.9998e-02, -2.5072e-01,
        -1.1116e-01,  1.4272e-01, -2.8125e-02,  2.4978e-01,  1.3899e-01,
        -2.2722e-01,  1.6405e-02,  1.9514e-02, -1.4806e-02,  2.3784e-02,
        -2.5480e-02, -9.9125e-02,  5.5195e-03,  9.6779e-03,  9.0118e-04,
         1.0361e-01, -8.6631e-02,  8.5515e-02,  8.5150e-02,  4.3013e-01,
        -1.7292e-01,  2.5248e-01, -2.4305e-02, -1.4437e-01, -9.8615e-02,
        -2.0638e-02, -2.6137e-02, -3.1094e-01,  2.7443e-01,  1.5303e-02,
        -5.0389e-02, -7.4305e-02,  6.4033e-02,  1.5671e-02,  1.0776e-01,
         5.7240e-02, -6.2665e-02, -6.3629e-02, -1.7401e-01, -1.7384e-01,
        -2.9029e-02, -3.5188e-02, -1.0351e-01,  5.5873e-02, -3.7031e-02,
        -9.5961e-02, -8.1390e-02, -1.5220e-01,  1.9719e-01, -1.1948e-01,
        -1.6690e-01, -9.5103e-02,  1.5895e-01, -4.6991e-02,  8.7203e-03,
        -4.3617e-02,  1.1448e-01, -2.8034e-02,  1.1368e-01, -6.3128e-02,
         2.6903e-03,  2.8196e-02, -7.3620e-02, -1.2489e-01, -6.4804e-04,
         3.3710e-01, -2.7533e-02, -1.2788e-01, -1.1739e-01, -1.4322e-01,
        -6.4528e-02,  4.3952e-02,  4.8671e-02,  1.0128e-01, -5.3157e-02,
         1.9053e-02,  5.7650e-03, -2.0636e-01,  4.9392e-02,  1.0601e-01,
         2.6320e-01,  9.8345e-03, -4.2334e-02,  4.7638e-02,  4.1247e-02,
        -4.3123e-02,  4.6514e-02, -1.8737e-02, -1.7739e-01,  1.6252e-01,
         5.0900e-02,  5.9270e-02, -7.1250e-02, -1.3990e-01, -1.2608e-02,
         1.3636e-01, -1.9153e-02,  9.9166e-02,  9.7903e-03, -7.9706e-03,
         9.6061e-02, -1.1978e-02, -2.6987e-02,  5.5693e-02, -2.0706e-02,
        -7.5234e-03,  9.6907e-02, -2.6948e-02,  1.9295e-02, -1.2362e-01,
        -2.1191e-01,  2.5300e-02, -4.3556e-02,  5.8500e-02,  2.8267e-03,
         3.3448e-03, -2.0438e-01, -1.5362e-01, -7.2068e-02, -1.3362e-01,
        -6.9234e-02,  7.7569e-03, -2.2435e-01, -5.0221e-02, -6.3790e-02,
         1.4208e-01, -1.0317e-01, -4.3362e-02,  2.3451e-01, -1.0269e-02,
        -2.0785e-01, -1.0589e-01, -1.0867e-01,  7.9162e-02,  2.6165e-02,
        -3.6232e-02,  2.0472e-01, -4.7377e-02, -2.2673e-01,  8.8925e-02,
        -1.1418e-01, -3.3485e-02,  1.1014e-01,  5.6062e-02, -5.1889e-03,
         5.2242e-02,  4.1363e-01,  1.6679e-01, -2.8168e-02, -1.5872e-01,
         1.9176e-01, -2.0997e-03,  2.7883e-01,  1.0203e-01, -3.1555e-03,
        -1.3493e-01,  2.3950e-02,  6.8330e-03, -2.6369e-02, -1.9133e-03,
        -2.4798e-02, -9.5862e-02,  3.1373e-01,  1.0827e-01, -3.9025e-01,
         1.2347e-02,  1.6870e-01, -1.3239e-02,  9.2257e-02, -1.0211e-01,
        -2.7446e-01, -1.4298e-01,  4.5025e-03,  9.2050e-02, -9.7836e-03,
        -1.4301e-01, -5.0958e-02,  1.0820e-01,  7.1856e-02, -1.1097e-01,
        -2.3028e-02, -1.9033e-01, -3.1622e-01, -1.0966e-01,  2.0771e-02,
        -1.2985e-01,  7.2917e-02, -6.8903e-03,  2.2240e-02,  4.5559e-02,
         4.6641e-02,  1.0876e-01,  1.8415e-01,  2.5828e-02, -3.4739e-03,
        -3.4905e-02, -1.1110e-01, -7.4906e-05, -5.3387e-02, -2.1667e-01,
         2.3660e-01,  8.3035e-02,  1.6275e-01, -6.9704e-02, -2.4589e-03,
         3.3348e-01, -5.4760e-02,  2.8822e-02, -5.8684e-02,  3.8901e-02,
        -2.1664e-01,  2.5281e-03,  1.5021e-01, -1.5284e-02,  5.2177e-03,
         3.5757e-02,  9.5711e-02,  2.2947e-01, -8.4518e-03,  1.3986e-01,
         3.1626e-02,  2.7621e-01,  1.1267e-01,  7.1202e-03,  6.4725e-02,
         5.0482e-02, -1.1644e-01, -1.0756e-01,  7.3278e-02,  2.8580e-01,
        -1.7353e-01,  2.0274e-01, -5.0729e-01, -2.1406e-01, -1.3283e-01,
        -1.5439e-02, -9.0185e-02,  1.2485e-01,  7.0718e-03,  5.6438e-02,
        -2.2060e-02, -3.1489e-01,  7.7756e-02, -2.7833e-02, -3.0607e-02,
         6.8867e-02, -7.9889e-02, -2.6296e-02,  1.7895e-02,  1.6963e-01,
         8.7094e-02,  1.7396e-02, -2.1467e-01,  2.5737e-02,  1.3856e-02,
         8.3725e-03, -2.8858e-01,  1.6862e-03,  5.3386e-02,  9.3108e-02,
         6.1977e-03, -5.2589e-02,  1.9725e-01, -3.6482e-01, -1.1734e-01,
         2.1406e-01, -1.0737e-02, -3.6181e-01,  5.7253e-01, -5.5064e-02,
         3.8287e-02, -5.8543e-01,  2.0143e-01,  5.1477e-03,  1.5529e-01,
        -5.8388e-02,  9.6525e-02,  3.9118e-03,  1.5408e-01, -6.9739e-04,
         3.3011e-01,  8.9390e-02,  1.8885e-01, -1.6545e-02,  1.7813e-03,
        -6.3065e-02, -2.0381e-02, -7.3931e-02,  5.7186e-02, -2.2169e-01,
        -1.7594e-01,  7.2577e-02,  8.9697e-02,  1.4016e-01,  1.4531e-01,
        -4.8203e-02, -7.4430e-02, -1.2660e-01,  2.2440e-02, -1.7194e-01,
         5.1154e-02, -1.6276e-02, -8.0199e-02,  1.0578e-01, -3.3091e-02,
         1.2326e-01,  1.1280e-01,  1.3938e-02, -2.6170e-01, -4.8323e-02,
         1.8080e-01, -8.4015e-02,  4.3010e-02, -2.0496e-01, -4.6512e-02,
         2.2161e-01,  2.0267e-02, -2.6133e-01, -6.8644e-02,  1.0455e-02,
        -1.6855e-02, -4.4688e-01, -2.6737e-01, -5.5871e-02, -7.4338e-02,
        -4.4163e-01, -6.0503e-02, -4.2865e-02,  2.1001e-01, -3.5372e-02,
         1.9708e-01,  8.2752e-03, -6.6393e-03,  9.9982e-03, -1.5928e-01,
        -9.6029e-02, -8.3696e-02, -2.3542e-01, -3.2169e-02,  2.4577e-02,
        -4.3335e-01, -1.3247e-01,  3.6884e-02, -1.4186e-01,  5.9453e-03,
        -9.1733e-02, -1.2927e-01,  8.5177e-02, -1.1441e-03,  4.2598e-02,
         5.3823e-02, -1.4818e-01, -7.7130e-02, -2.5510e-02,  2.2265e-01,
        -6.6041e-02, -1.0947e-01, -4.1537e-01, -2.4050e-02,  2.0213e-01,
        -1.0381e-01,  3.8251e-02, -2.7223e-02, -4.7806e-02, -1.2561e-02,
        -1.4074e-02, -1.2187e-01,  1.6062e-01, -1.7874e-01, -1.2774e-03,
         1.0068e-01,  3.8112e-02, -1.4348e-01,  1.2197e-01,  1.3996e-03,
        -1.0438e-02,  6.5086e-02,  1.1839e-02, -7.3008e-02, -2.5583e-01,
         2.6138e-03,  1.5690e-01,  1.7598e-01,  6.9526e-02, -6.1461e-02,
        -9.7276e-02,  3.5660e-02,  4.7912e-02,  8.2739e-02,  1.4097e-02,
         4.9413e-02,  4.2053e-02,  1.4344e-01, -6.2792e-02,  4.0205e-04,
         1.5250e-01, -1.7522e-01, -5.9424e-02, -1.0787e-01, -2.6675e-03,
         4.5776e-02, -1.4194e-01,  3.6366e-01,  1.7674e-01,  3.2443e-01,
        -2.4558e-01,  1.8080e-02, -3.6560e-01,  2.6439e-03,  9.1668e-02,
         7.1584e-03, -9.6864e-02, -6.1576e-02, -3.0196e-01, -1.1254e-01,
        -5.5086e-02, -5.7570e-02,  1.0761e-01, -2.8561e-02, -4.1266e-01,
         4.0287e-02,  3.0000e-02, -6.0385e-02,  3.4558e-02, -2.6565e-01,
        -3.9134e-02, -5.7808e-02,  1.2102e-01,  5.8583e-02, -1.1470e-02,
         4.9078e-02, -1.0090e-01, -8.9321e-02, -9.7825e-02,  7.6055e-02,
        -2.5764e-01,  1.2564e-02], device='cuda:0'), 'backend.10.bias': tensor([-5.8029e+00, -5.3878e+01,  1.0696e+01,  2.2877e+01, -1.1115e+01,
         2.1028e-01, -3.5056e+00, -4.7255e+00, -1.8161e+00,  5.6121e-01,
        -4.5989e+00, -1.4484e+01, -2.5311e+01, -2.5464e-01, -1.0811e+01,
        -1.0108e+01,  2.4036e+00,  7.8466e-01, -1.4855e+01, -3.5416e+01,
         3.4983e+00, -1.6306e+01, -2.6800e-01, -1.6920e-02,  1.0981e+00,
         2.8397e+01,  8.6920e-01, -1.3417e+00, -4.1239e-01, -3.3987e+01,
        -1.3303e+01, -3.8404e+00, -7.8278e-01,  4.7887e-02, -2.9392e-01,
        -4.3888e+01,  3.2917e-01, -5.0268e+01, -4.0567e-01,  8.4493e-01,
         5.0143e+00, -5.7116e+01,  7.1828e-02,  1.0728e+00,  4.6707e-01,
        -3.4152e+01, -7.9422e+00,  4.3289e-01,  1.0090e+01, -6.5736e-01,
        -2.2008e+01,  1.0102e+00, -2.4218e-01, -1.8479e+01, -2.5554e-02,
         7.1699e+00,  1.1377e+00,  1.8071e+00,  4.5674e+00,  8.1736e+00,
         1.3086e+00,  2.5759e+00, -2.7065e+01, -2.6927e-01], device='cuda:0'), 'output_layer.bias': tensor([-2368.7085], device='cuda:0'), 'backend.2.weight': tensor([[[[-2.6743e-02, -3.9614e-02, -8.0125e-03],
          [-1.7407e-02, -5.3059e-02, -2.6566e-02],
          [-3.5894e-02, -4.0332e-02, -1.3288e-02]],

         [[-8.8571e-03, -7.8051e-03, -8.0927e-03],
          [-1.2177e-02, -8.5555e-03, -4.6050e-03],
          [-1.0736e-02, -2.2354e-03, -2.1007e-03]],

         [[-5.4201e-02, -2.8204e-02, -6.6149e-02],
          [-9.3613e-02, -8.7685e-02, -1.0216e-01],
          [-8.6319e-02, -6.5350e-02, -6.5383e-02]],

         ...,

         [[-6.8695e-02, -1.2343e-01, -6.7855e-02],
          [-5.2468e-02, -1.2090e-01, -9.2997e-02],
          [-1.5116e-01, -1.8670e-01, -1.7145e-01]],

         [[-3.5145e-02, -2.8826e-02, -2.5547e-02],
          [-4.4438e-02, -3.8223e-02, -3.8730e-02],
          [-2.2132e-02, -2.8051e-02, -2.6023e-02]],

         [[-2.7207e-02, -1.4604e-02, -2.6464e-02],
          [-1.3161e-02, -1.7328e-02, -2.3120e-02],
          [-3.2824e-02, -1.9330e-02, -3.9086e-02]]],


        [[[ 7.7712e-02,  3.7037e-02,  5.9199e-02],
          [ 6.9622e-02,  3.8969e-02,  3.4251e-02],
          [ 5.2236e-02,  4.0354e-02,  4.5525e-02]],

         [[ 8.7282e-03,  1.0780e-02,  1.1893e-02],
          [ 7.5951e-03,  7.7005e-03,  8.8367e-03],
          [ 1.1768e-02,  6.2631e-03,  1.1724e-02]],

         [[ 7.2417e-02,  8.9040e-02,  8.2410e-02],
          [ 8.0392e-02,  7.5214e-02,  6.3760e-02],
          [ 7.1169e-02,  1.0386e-01,  9.9016e-02]],

         ...,

         [[ 1.4388e-01,  1.0236e-01,  1.3851e-01],
          [ 1.2052e-01,  1.1337e-01,  1.7002e-01],
          [ 1.5284e-01,  1.2835e-01,  1.4204e-01]],

         [[ 6.6291e-02,  5.3915e-02,  5.6079e-02],
          [ 4.6756e-02,  4.0121e-02,  2.8891e-02],
          [ 3.1187e-02,  4.4871e-02,  4.0962e-02]],

         [[ 2.8077e-02,  3.7205e-02,  3.6338e-02],
          [ 1.5340e-02,  4.2387e-02,  3.7633e-02],
          [ 1.9189e-02,  3.1697e-02,  4.1698e-02]]],


        [[[-9.8588e-03, -5.9472e-04, -1.5901e-03],
          [-1.4477e-03,  7.3029e-03, -3.8603e-03],
          [-8.3022e-03, -4.2083e-05, -1.1306e-02]],

         [[-6.2676e-04, -3.3455e-04,  7.6447e-05],
          [ 4.1101e-03,  6.4965e-04, -1.6110e-03],
          [ 1.8855e-03,  1.6981e-03, -2.0552e-03]],

         [[-1.1348e-02, -4.0541e-03, -9.0501e-03],
          [-2.9625e-03, -7.6348e-03, -1.2746e-02],
          [-1.6145e-02, -2.2904e-02, -9.9332e-03]],

         ...,

         [[-1.6459e-02, -2.5879e-02, -7.2916e-03],
          [-3.2705e-02,  8.7726e-03, -2.2338e-02],
          [-3.5231e-03,  5.4278e-03, -9.8810e-03]],

         [[ 5.0235e-03, -4.1964e-03,  3.6696e-03],
          [ 7.6089e-03, -2.2837e-03,  6.1412e-03],
          [-9.2003e-03, -6.9908e-03, -5.7213e-03]],

         [[-4.1632e-03, -5.1097e-03,  1.0458e-03],
          [-7.3520e-03, -3.9127e-03,  8.5425e-03],
          [-5.4493e-03, -4.1669e-03, -1.1901e-02]]],


        ...,


        [[[-8.8276e-03,  4.3765e-03,  6.6472e-02],
          [-8.1391e-03,  2.4337e-02,  4.2203e-02],
          [-1.7271e-02,  3.1401e-02,  6.8163e-02]],

         [[-4.0400e-03,  5.5717e-03,  1.0041e-02],
          [ 2.1243e-03,  7.6132e-03,  1.1768e-03],
          [ 6.4584e-04,  9.1161e-03,  6.0503e-03]],

         [[-2.5099e-02,  1.5327e-02, -1.1101e-03],
          [ 1.4321e-03,  2.7358e-02, -5.7295e-03],
          [-1.0060e-02,  1.4983e-03, -1.9909e-03]],

         ...,

         [[ 2.0682e-01,  1.0093e-01,  1.4818e-01],
          [ 6.5353e-02,  1.9606e-01,  2.1523e-01],
          [ 1.7583e-01,  1.0937e-01,  1.1587e-01]],

         [[-1.5121e-02, -9.0392e-03,  1.3652e-03],
          [-2.0699e-02, -1.1765e-02, -4.5473e-03],
          [-1.5399e-02, -1.9579e-02, -1.5345e-02]],

         [[ 8.9640e-03,  4.3921e-02,  3.4448e-02],
          [ 3.6678e-02,  5.0559e-02,  1.8872e-02],
          [ 3.5363e-02,  5.3386e-02,  2.4553e-02]]],


        [[[-6.4073e-02, -7.1425e-02, -1.3557e-01],
          [-1.0439e-01, -1.0575e-01, -1.1695e-01],
          [-1.1025e-01, -1.1215e-01, -1.0477e-01]],

         [[-1.5107e-02, -2.1762e-02, -2.7486e-02],
          [-2.0305e-02, -1.2360e-02, -2.1811e-02],
          [-2.3954e-02, -1.2941e-02, -1.2730e-02]],

         [[-1.3945e-01, -1.1372e-01, -1.1283e-01],
          [-1.5474e-01, -1.2211e-01, -1.1001e-01],
          [-1.8234e-01, -1.5628e-01, -1.4351e-01]],

         ...,

         [[-4.4711e-01, -4.0074e-01, -4.7918e-01],
          [-3.8266e-01, -4.4923e-01, -4.4080e-01],
          [-4.6187e-01, -4.5300e-01, -4.6997e-01]],

         [[-2.4722e-02, -3.4569e-02, -2.5149e-02],
          [-3.2767e-02, -3.5458e-02, -3.5848e-02],
          [-2.8946e-02, -3.0527e-02, -3.7151e-02]],

         [[-6.7310e-02, -7.3472e-02, -8.8186e-02],
          [-9.3798e-02, -9.4707e-02, -9.7847e-02],
          [-9.2636e-02, -8.5534e-02, -7.9306e-02]]],


        [[[-3.6619e-02, -1.3962e-02, -1.0299e-02],
          [-8.8740e-02, -4.4200e-02, -1.8938e-02],
          [-7.0731e-02, -3.1265e-02,  2.7327e-02]],

         [[-9.3137e-03,  8.7424e-04, -9.4219e-03],
          [-5.9767e-03, -2.6660e-03, -8.2795e-03],
          [ 3.5147e-03,  4.4632e-03, -7.3969e-04]],

         [[ 7.3821e-02,  4.9793e-02,  1.5396e-02],
          [ 1.2660e-01,  1.1229e-01,  9.8424e-02],
          [ 4.8685e-02,  5.5704e-02,  1.0727e-01]],

         ...,

         [[-8.3063e-02, -1.9622e-02,  9.4111e-02],
          [-1.6090e-02,  5.3198e-02,  5.2264e-02],
          [ 5.3613e-02,  5.5289e-02,  4.2043e-02]],

         [[-3.1701e-02, -4.6874e-02, -5.6747e-02],
          [-1.4007e-02, -1.7434e-02,  8.5384e-03],
          [-3.1725e-03, -1.3171e-02, -6.2189e-03]],

         [[-1.9241e-03,  1.0770e-02,  9.0750e-03],
          [-1.2533e-02, -1.8902e-04, -3.9585e-03],
          [-4.5669e-03, -1.1593e-02,  7.9190e-03]]]], device='cuda:0'), 'backend.6.bias': tensor([-8.3898e-02, -1.6171e-02,  1.1420e+00, -5.7550e-02,  5.3863e-01,
        -8.3389e-01,  1.1408e-01,  3.1572e-02, -1.6201e-01, -2.2798e-01,
        -1.0613e+00,  1.7285e-02, -1.9214e+00, -1.1183e-01, -6.8129e-01,
         2.2950e-02, -1.4048e+00, -2.4419e-01,  9.4105e-01,  2.4619e-01,
         3.1539e-01, -3.4581e-01,  4.3028e-01,  2.8217e-03, -6.5242e-01,
         1.2156e+00, -1.1701e+00,  9.7104e-02,  1.8542e-01, -8.4766e-01,
        -8.2549e-02,  8.8012e-01,  1.3529e+00,  1.4453e-01, -1.8760e-01,
         2.3450e-01, -5.5987e-02,  4.2681e-01, -3.5007e-01,  5.4509e-01,
        -8.3722e-01,  6.0962e-02,  8.9387e-03, -6.9753e-03,  2.5819e-01,
        -8.1418e-01, -1.1959e+00,  7.2166e-01, -1.3468e-01, -9.9605e-01,
         2.0732e+00,  7.9013e-01,  1.2127e+00, -1.5427e-01,  2.0351e-01,
        -5.0857e-01, -2.5497e-01, -2.5927e-01, -5.9099e-03, -1.0637e-01,
        -7.7560e-01, -3.9563e-01, -5.0864e-01, -4.2363e-01, -1.1203e-01,
         1.5607e+00,  1.1222e+00, -2.8460e-01, -5.2958e-01,  4.4043e-01,
        -2.0771e+00,  1.1595e+00,  5.9845e-01,  6.1728e-02,  3.3175e-02,
        -4.1539e-01,  5.6375e-01, -1.5174e+00, -9.2519e-01, -7.4753e-01,
         2.4033e-03, -7.1819e-02, -3.7930e-01, -1.2810e+00,  1.7283e+00,
        -1.5666e-02, -1.0817e-01,  4.1597e-01, -5.1974e-01, -2.8064e-01,
         4.1466e-01, -2.6418e-01, -9.3957e-01,  1.0207e+00,  2.1993e-01,
         7.7892e-01, -1.2826e-02, -9.0745e-01,  5.0318e-01, -1.2849e+00,
        -1.3128e+00,  1.6148e-02,  1.0761e-01,  1.2552e-02, -7.9037e-01,
        -4.6911e-01, -1.1418e+00, -7.8196e-02,  2.5991e-03,  1.5220e-02,
         5.2965e-02, -5.6886e-01,  2.0896e-01, -2.1517e-02,  4.7351e-01,
        -1.4713e+00, -3.6948e-01,  2.1909e-02,  1.2982e+00,  1.3832e+00,
        -4.6231e-01, -2.0406e-02,  2.7874e-02, -1.9149e+00,  1.5788e+00,
        -8.4886e-01,  1.3790e+00,  3.3353e+00, -1.1661e+00, -4.0027e-01,
         1.9986e-01,  1.0772e+00,  9.1899e-01, -6.6467e-01,  4.5549e-01,
         1.8903e+00, -7.6614e-01,  2.3348e-02, -1.0125e+00, -2.0532e+00,
        -8.9911e-01,  1.2650e+00, -1.0543e+00,  8.2443e-01, -8.1073e-01,
        -4.6521e-02, -4.7322e-04, -3.0504e-01, -9.6905e-03, -5.8533e-01,
        -5.4517e-01, -6.6429e-01, -2.3237e-02,  2.0377e+00,  1.8188e+00,
        -7.2864e-01, -2.5928e-02,  4.8815e-02, -2.2779e-04, -5.5808e-01,
        -3.7023e-01, -1.1683e-01, -1.0920e+00, -8.0476e-03,  8.5100e-02,
         1.4044e+00, -1.8894e-02, -1.2077e-01, -2.6243e-01, -4.0546e-01,
         2.1496e-02,  9.4086e-02, -6.4143e-01, -1.6538e+00, -8.9192e-01,
        -4.8411e-01,  1.4858e-02,  5.2869e-01,  1.6901e-01, -2.0868e-01,
         1.7790e-02,  4.9152e-01,  4.9781e-01, -7.0547e-01,  1.7543e-01,
        -7.4892e-01, -5.0036e-01, -6.2179e-02,  3.3095e-02,  1.9181e+00,
         4.4188e-01,  2.4910e-01, -3.7713e-01,  1.5005e+00,  3.7024e-01,
        -1.5421e-01, -2.9336e-01, -2.8169e-01, -1.0113e-01, -1.9074e+00,
        -6.8935e-01, -6.8837e-01,  1.9108e-01, -6.8252e-01, -6.3966e-01,
         1.6775e-01,  8.4237e-01, -4.1269e-01,  1.0999e+00,  1.0861e+00,
         5.0100e-01,  2.0692e-02, -7.4591e-01, -4.0649e-01,  3.1674e-01,
         4.7350e-02, -1.3426e-02,  4.4528e-01, -1.0489e+00, -1.3415e+00,
         3.2184e-01,  8.5183e-01, -3.3267e-01, -2.9079e-01, -4.9677e-01,
        -1.3985e-01,  4.5515e-02,  6.9376e-01, -1.9076e+00,  1.0485e+00,
        -5.9901e-01,  1.0391e+00, -3.5584e-01, -1.5562e-01, -7.4192e-01,
         1.9428e+00, -1.1659e+00, -4.8476e-02, -9.1319e-02, -1.1107e+00,
        -7.8743e-01, -1.0142e+00,  1.9766e-02,  6.6773e-02, -1.4531e-01,
        -2.2162e-01,  3.6885e-01, -3.8783e-01,  3.8288e-01, -7.1044e-01,
        -2.3415e-01, -3.7066e-01,  5.3615e-01, -6.6176e-02, -6.9477e-02,
         9.0316e-04], device='cuda:0'), 'backend.0.weight': tensor([[[[-1.0966e-02, -1.7620e-02, -1.1161e-02],
          [-3.1534e-03, -5.4648e-03, -6.9499e-03],
          [ 4.9162e-03,  6.9466e-03,  1.3813e-03]],

         [[-9.4746e-02, -8.2678e-02, -6.6370e-02],
          [ 5.5762e-03, -1.3240e-02, -4.1414e-02],
          [ 9.9205e-02,  7.3027e-02, -2.9842e-03]],

         [[ 5.2260e-02,  5.8763e-02,  5.5730e-02],
          [ 6.1536e-02,  8.4552e-02,  3.7031e-02],
          [ 1.0334e-01,  9.4034e-02,  6.6054e-02]],

         ...,

         [[ 4.8529e-04,  4.6797e-04,  3.1704e-03],
          [ 1.0338e-04, -2.0709e-03, -2.6304e-03],
          [ 7.7474e-04, -3.3152e-03, -2.7113e-03]],

         [[ 2.9967e-03, -6.2076e-03,  2.7156e-02],
          [-5.4862e-03, -1.4380e-02,  8.3834e-04],
          [-1.3340e-03,  7.5223e-03, -1.0119e-02]],

         [[ 7.4049e-02,  9.7493e-02,  1.3282e-01],
          [ 8.5056e-02,  8.1243e-02,  8.0770e-02],
          [ 7.5957e-02,  9.3831e-02,  8.4564e-02]]],


        [[[ 3.3562e-03,  5.4455e-03,  3.4571e-03],
          [ 7.2755e-03,  8.1888e-03,  2.1705e-03],
          [ 5.1376e-04,  5.7354e-03,  8.8267e-03]],

         [[ 1.1156e-01,  1.0452e-01,  8.9039e-02],
          [ 9.8319e-02,  1.2030e-01,  8.4499e-02],
          [ 8.3782e-02,  8.3954e-02,  6.3717e-02]],

         [[ 1.8970e-02,  2.2375e-02,  1.1430e-02],
          [ 1.7493e-02,  1.1410e-02,  1.2681e-02],
          [ 4.9676e-04, -3.6679e-03, -6.4820e-03]],

         ...,

         [[ 4.9066e-03,  4.3095e-03,  2.7887e-04],
          [ 3.1390e-03,  2.7697e-03,  4.3249e-03],
          [-1.0944e-03,  2.5523e-03,  2.1074e-03]],

         [[ 1.2171e-02,  1.2222e-02,  7.5668e-03],
          [ 1.7480e-02,  2.1930e-02,  1.4792e-02],
          [ 1.9990e-02,  2.3994e-02,  2.8636e-02]],

         [[ 9.6596e-03, -4.9511e-03,  1.7026e-02],
          [ 5.5919e-03, -9.2158e-03,  2.0788e-02],
          [-8.4710e-03, -1.2845e-04,  8.8652e-03]]],


        [[[ 1.0118e-02,  1.2772e-02,  7.2155e-03],
          [ 1.0304e-02,  1.2340e-02,  4.9393e-03],
          [ 1.7318e-02,  2.1505e-02,  1.9967e-03]],

         [[ 2.1414e-01,  1.4136e-01,  1.1734e-01],
          [ 2.9938e-01,  2.4250e-01,  1.0766e-01],
          [ 2.0077e-01,  2.0030e-01,  4.3075e-02]],

         [[ 4.6796e-02,  5.1595e-02,  4.4769e-02],
          [ 3.4122e-02,  5.9094e-02,  4.1480e-02],
          [ 7.0839e-02,  7.7758e-02,  7.5428e-02]],

         ...,

         [[-6.3569e-04, -4.8502e-04, -4.7803e-03],
          [ 1.0010e-02,  5.5793e-03,  5.0049e-03],
          [ 8.7090e-03,  4.7928e-03,  6.8313e-03]],

         [[ 5.1332e-02,  2.5491e-02,  5.5946e-03],
          [ 4.4768e-02,  3.4322e-02,  7.7115e-03],
          [ 3.5574e-02,  4.2392e-02,  2.2568e-02]],

         [[ 5.0628e-02,  2.1956e-02,  8.0028e-02],
          [-2.6765e-02,  7.8551e-03,  5.7528e-02],
          [ 7.2559e-02,  8.3124e-02,  7.9690e-02]]],


        ...,


        [[[ 2.0044e-02,  6.3766e-03,  5.0217e-04],
          [ 2.1295e-02,  8.4858e-03, -6.0190e-03],
          [ 1.8922e-02,  1.4829e-02,  8.0018e-03]],

         [[ 2.1408e-01,  1.7944e-01,  2.6113e-02],
          [ 2.9567e-01,  2.6751e-01,  9.5501e-02],
          [ 2.9139e-01,  2.5382e-01,  8.2907e-02]],

         [[ 1.7746e-01,  1.9658e-01,  1.8618e-01],
          [ 7.2045e-02,  4.3123e-02,  1.0901e-01],
          [ 1.5234e-01,  1.9394e-01,  1.6791e-01]],

         ...,

         [[ 3.3877e-03, -5.1779e-04,  1.4072e-03],
          [ 3.2954e-03,  6.6858e-04, -3.8084e-03],
          [ 9.4258e-03,  8.2752e-03,  4.3091e-03]],

         [[ 6.2550e-02,  3.2152e-02, -9.1818e-03],
          [ 6.9781e-02,  1.9211e-02, -1.8662e-02],
          [ 7.1130e-02,  4.4201e-02,  1.8714e-03]],

         [[ 2.4898e-01,  2.3219e-01,  3.5021e-01],
          [ 3.2859e-02,  3.7563e-02,  1.8472e-01],
          [ 1.1136e-01,  1.3887e-01,  1.8594e-01]]],


        [[[ 4.4694e-02,  4.3510e-02,  3.1191e-02],
          [ 4.5765e-02,  4.5040e-02,  4.3091e-02],
          [ 5.0478e-02,  5.0647e-02,  4.6610e-02]],

         [[ 4.8131e-01,  4.9007e-01,  4.3751e-01],
          [ 4.3487e-01,  4.5149e-01,  4.4866e-01],
          [ 3.1297e-01,  3.5288e-01,  3.5300e-01]],

         [[ 4.8868e-02,  5.6781e-02,  6.4834e-02],
          [ 3.0821e-02,  3.8099e-02,  4.7188e-02],
          [ 6.1475e-02,  5.3462e-02,  4.0252e-02]],

         ...,

         [[ 1.1525e-02,  1.3003e-02,  1.0197e-02],
          [ 5.2146e-03,  1.3580e-03,  8.1858e-03],
          [ 6.3619e-03,  2.3230e-03,  4.0533e-03]],

         [[ 6.6032e-02,  5.6164e-02,  2.7974e-02],
          [ 5.5589e-02,  5.5610e-02,  3.7570e-02],
          [ 2.7232e-02,  1.7300e-02, -1.6126e-03]],

         [[ 4.3123e-02,  2.8378e-02,  3.5879e-02],
          [ 1.2766e-02,  2.6669e-02,  2.7428e-02],
          [ 5.3280e-02,  7.6970e-02,  1.1786e-02]]],


        [[[ 9.0564e-03,  9.5053e-03,  1.0586e-02],
          [ 1.3179e-02,  1.0427e-02,  1.5775e-02],
          [ 1.5143e-02,  1.6777e-02,  1.7506e-02]],

         [[ 1.0941e-01,  1.0080e-01,  1.7831e-01],
          [ 1.3935e-01,  1.4260e-01,  2.3914e-01],
          [ 1.8721e-01,  1.9382e-01,  2.4268e-01]],

         [[ 5.9847e-02,  6.3961e-02,  5.8496e-02],
          [ 9.4831e-02,  1.2498e-01,  1.2457e-01],
          [ 9.6725e-02,  1.0555e-01,  9.4718e-02]],

         ...,

         [[ 4.8408e-04,  2.5726e-03,  1.3075e-03],
          [ 3.2864e-03,  2.4151e-03,  3.0786e-03],
          [ 3.2824e-03,  2.0312e-03,  1.3948e-03]],

         [[ 1.3699e-02,  7.8330e-03,  2.1781e-02],
          [ 1.6424e-02,  1.2317e-02,  2.7760e-02],
          [ 1.4945e-02,  1.5759e-02,  1.8318e-02]],

         [[ 8.6319e-02,  1.5244e-01,  1.0609e-01],
          [ 1.5536e-01,  1.3366e-01,  1.5492e-01],
          [ 1.0859e-01,  8.9654e-02,  6.4167e-02]]]], device='cuda:0'), 'output_layer.weight': tensor([[[[-1.6358e+00]],

         [[-2.5940e+01]],

         [[-2.2885e+01]],

         [[-4.2481e+01]],

         [[-8.9195e+00]],

         [[-4.3450e-01]],

         [[-4.4648e+00]],

         [[-8.7988e+00]],

         [[-9.7922e+00]],

         [[-6.4884e+00]],

         [[-1.6077e+00]],

         [[-9.1065e+00]],

         [[-9.2577e+00]],

         [[-8.4950e+00]],

         [[-3.1119e+00]],

         [[-4.4014e+00]],

         [[-1.1049e+00]],

         [[-9.0646e+00]],

         [[-1.0693e+01]],

         [[-1.3028e+01]],

         [[-1.9226e+01]],

         [[-5.4063e+00]],

         [[-1.7429e+00]],

         [[-4.2664e-01]],

         [[-1.4460e+00]],

         [[-6.2714e+01]],

         [[-1.6194e+00]],

         [[-1.6695e+00]],

         [[-1.2076e+00]],

         [[-1.8779e+01]],

         [[-4.6703e+00]],

         [[-1.2733e+01]],

         [[-1.3408e+00]],

         [[ 4.5206e-02]],

         [[-4.8045e+00]],

         [[-1.6932e+01]],

         [[-6.8475e-01]],

         [[-2.4269e+01]],

         [[-4.6628e-01]],

         [[-6.4551e+00]],

         [[-3.5551e+00]],

         [[-2.7895e+01]],

         [[-2.5401e-01]],

         [[-4.7532e-01]],

         [[-1.3100e-01]],

         [[-1.7155e+01]],

         [[-2.8089e+00]],

         [[-2.4248e-01]],

         [[-1.8241e+01]],

         [[-4.4687e-01]],

         [[-5.6391e+00]],

         [[-2.1812e+00]],

         [[-1.2111e-01]],

         [[-4.8903e+00]],

         [[-4.5773e-03]],

         [[-2.9828e+01]],

         [[-1.2588e+00]],

         [[-2.7432e+00]],

         [[-3.9311e+00]],

         [[-2.8007e+01]],

         [[-3.5534e+00]],

         [[-2.1570e+00]],

         [[-1.0613e+01]],

         [[-2.9810e-01]]]], device='cuda:0'), 'backend.4.weight': tensor([[[[-1.2049e-02, -6.0804e-02, -5.4470e-02],
          [-8.9146e-03, -8.2507e-02, -6.2419e-02],
          [-1.1260e-02, -5.8706e-02, -4.9905e-04]],

         [[-3.8529e-02, -2.3250e-02,  2.3058e-02],
          [-6.0005e-02,  3.9833e-02,  4.6436e-02],
          [-1.0442e-01, -3.2645e-02, -1.4321e-04]],

         [[-1.3504e-02, -2.6101e-02, -1.9275e-02],
          [-1.5315e-02, -2.7579e-02, -7.4564e-03],
          [-3.1707e-02, -1.0188e-02, -1.2930e-02]],

         ...,

         [[ 4.6737e-03, -5.3108e-02, -8.8509e-02],
          [ 4.9762e-02, -9.0174e-02, -3.2583e-02],
          [-4.8893e-02,  1.3479e-02,  3.9005e-02]],

         [[-5.9419e-02, -1.0137e-01, -1.1546e-01],
          [-7.5363e-02, -4.8470e-02, -2.4965e-02],
          [-4.4913e-02, -1.8796e-02, -1.4597e-02]],

         [[-8.9496e-02, -3.5857e-02, -1.2368e-02],
          [-2.1257e-02, -2.2860e-02, -6.7884e-02],
          [-1.1565e-01, -7.2963e-02, -5.9713e-02]]],


        [[[-6.1421e-02, -7.4409e-02, -5.5027e-02],
          [-8.4431e-02, -5.0343e-02, -1.7649e-02],
          [-4.9211e-02, -2.8633e-02, -3.9525e-02]],

         [[-1.1809e-01, -1.2985e-01, -1.3566e-01],
          [-1.5668e-01, -1.1772e-01, -1.3297e-01],
          [-1.5706e-01, -1.5218e-01, -1.7541e-01]],

         [[-3.7270e-02, -3.6366e-02, -3.9533e-02],
          [-3.3907e-02, -2.5396e-02, -3.3014e-02],
          [-2.8684e-02, -1.9192e-02, -1.9853e-02]],

         ...,

         [[-1.4428e-01, -1.3440e-01, -4.8935e-02],
          [-8.5695e-02, -9.6213e-02, -5.4565e-02],
          [-1.2662e-01, -7.0622e-02, -9.3470e-02]],

         [[-1.1058e-01, -7.2285e-02, -7.5917e-02],
          [-9.1712e-02, -5.9536e-02, -8.4218e-02],
          [-6.3677e-02, -6.2909e-02, -1.0002e-01]],

         [[-2.0823e-01, -2.0906e-01, -2.1805e-01],
          [-1.7231e-01, -2.0222e-01, -2.3789e-01],
          [-2.6540e-01, -2.6746e-01, -2.9672e-01]]],


        [[[ 2.7771e-03,  2.2999e-03, -5.3761e-02],
          [-2.6934e-02,  4.3403e-02, -7.2006e-02],
          [ 1.5620e-03,  1.1805e-02, -7.6259e-02]],

         [[-1.1999e-02,  1.6805e-02,  6.0268e-02],
          [ 7.1735e-02, -4.5540e-03,  5.1572e-02],
          [ 8.9457e-02,  8.7168e-02,  1.6582e-01]],

         [[-3.9870e-03,  9.4175e-03,  2.3183e-02],
          [ 3.4039e-02, -1.6632e-03,  2.0193e-02],
          [ 1.2939e-02, -1.6657e-03,  1.1720e-02]],

         ...,

         [[-5.3541e-02,  1.3020e-01, -1.4320e-01],
          [-8.9344e-02,  8.4100e-02, -1.5566e-01],
          [ 6.7427e-02, -2.3242e-02, -2.0595e-01]],

         [[ 3.7305e-02, -9.8502e-03,  4.2859e-02],
          [ 6.3234e-02, -4.5391e-02, -6.4480e-02],
          [ 6.6965e-03, -1.4844e-01, -1.3271e-02]],

         [[ 6.5943e-02,  8.0951e-04,  5.4286e-02],
          [ 7.0928e-03, -9.7528e-02,  9.8901e-02],
          [ 1.2406e-01,  7.0388e-02,  1.2213e-01]]],


        ...,


        [[[-9.2292e-02, -3.1216e-02, -7.2768e-02],
          [-9.2674e-02, -9.8753e-02, -1.3588e-01],
          [-1.0899e-01, -1.5503e-01, -7.5265e-02]],

         [[-1.1606e-01, -1.4396e-01, -5.8015e-02],
          [-3.7693e-02, -6.5500e-02, -8.3959e-02],
          [-6.8774e-02, -8.4262e-02, -5.5588e-02]],

         [[-3.3651e-02, -2.5016e-02, -3.0571e-02],
          [-2.4607e-02, -3.8932e-02, -3.2553e-02],
          [-2.4548e-02, -2.5013e-02, -2.2983e-02]],

         ...,

         [[-1.4992e-01, -1.0191e-01, -1.7542e-01],
          [-2.3860e-01, -2.6577e-01, -1.5842e-01],
          [-1.5260e-01, -1.9920e-01, -1.9439e-01]],

         [[-2.2625e-01, -2.1584e-01, -1.7163e-01],
          [-1.7381e-01, -1.5323e-01, -1.7070e-01],
          [-1.4793e-01, -1.9673e-01, -1.1021e-01]],

         [[-1.4642e-01, -8.4646e-02, -1.1512e-01],
          [-2.1538e-01, -2.6934e-01, -2.4112e-01],
          [-1.4448e-01, -8.2779e-02, -1.1832e-01]]],


        [[[-1.5638e-01, -1.4835e-01, -1.9036e-01],
          [-1.7547e-01, -8.7568e-02, -1.1182e-01],
          [-8.2418e-02,  2.9827e-02,  2.9444e-02]],

         [[-3.5353e-03,  7.8475e-02,  3.5789e-02],
          [ 2.8736e-02, -8.3443e-02, -3.0318e-02],
          [-1.1562e-01, -1.6252e-01, -1.9590e-01]],

         [[-5.9863e-02, -6.6110e-02, -3.8213e-02],
          [-5.4671e-02, -3.5383e-02, -2.5554e-02],
          [ 9.8642e-03, -6.5177e-03, -9.3011e-03]],

         ...,

         [[-3.2161e-01, -2.8489e-01, -2.5918e-01],
          [-3.2716e-01, -4.6101e-02, -1.2386e-01],
          [-6.2740e-02, -1.9311e-01, -9.9467e-02]],

         [[-2.3160e-01, -2.2290e-01, -1.7311e-01],
          [-1.2877e-01, -1.0607e-01, -1.8933e-01],
          [-1.3856e-01, -1.7023e-01, -8.4564e-02]],

         [[-9.7379e-02, -1.5025e-01, -2.1385e-01],
          [-1.5372e-01, -1.2470e-01, -9.2415e-02],
          [-1.2050e-01, -2.0160e-01, -1.7870e-01]]],


        [[[ 1.4705e-01,  2.1214e-01,  1.3027e-01],
          [ 1.5705e-01,  2.3031e-01,  1.4932e-01],
          [ 2.4698e-01,  3.2268e-01,  2.5551e-01]],

         [[ 4.3678e-01,  4.6324e-01,  4.4894e-01],
          [ 4.4244e-01,  3.3969e-01,  4.9461e-01],
          [ 3.9638e-01,  3.2134e-01,  2.9273e-01]],

         [[ 8.4497e-02,  7.1967e-02,  5.6404e-02],
          [ 5.4277e-02,  3.5380e-02,  4.2072e-02],
          [ 1.0959e-01,  7.9675e-02,  6.8024e-02]],

         ...,

         [[ 2.5636e-01,  3.1694e-01,  2.9748e-01],
          [ 3.4446e-01,  5.3526e-01,  3.9326e-01],
          [ 4.9409e-01,  4.1774e-01,  5.3854e-01]],

         [[ 4.0206e-01,  3.6071e-01,  3.3972e-01],
          [ 4.3792e-01,  3.8572e-01,  3.7576e-01],
          [ 4.6685e-01,  4.0983e-01,  4.3655e-01]],

         [[ 5.7194e-01,  5.3079e-01,  4.8957e-01],
          [ 6.5429e-01,  7.0739e-01,  6.6911e-01],
          [ 6.2929e-01,  4.8608e-01,  4.9187e-01]]]], device='cuda:0'), 'backend.4.bias': tensor([-1.0812e-01, -3.6618e-01,  1.2842e-01, -4.9060e-02, -2.9246e-01,
        -3.0940e-02, -2.1622e-01,  5.0669e-02,  7.6933e-02, -3.7847e-01,
         3.8316e-01,  6.9392e-02,  3.7674e-01,  3.4865e-02, -2.4371e-01,
        -6.7996e-02, -1.8840e-01,  9.8036e-02,  2.0499e-02,  1.9595e-03,
        -1.7969e-01,  3.6393e-01, -1.7573e-01, -4.2377e-01, -7.6807e-02,
        -5.1208e-01,  1.6246e-01,  1.3582e-01, -1.0089e-01, -6.3033e-01,
         2.1797e-01, -3.1502e-02,  2.5708e-02, -1.9572e-01,  4.0422e-02,
        -1.9214e-01, -1.6726e-01,  7.8275e-03,  1.1864e-01, -1.0253e-02,
        -5.1593e-05,  1.6473e-01,  4.8805e-02, -2.7859e-01, -2.8268e-01,
        -2.4050e-02, -1.5401e-03,  5.9487e-02, -3.5743e-01,  8.5501e-02,
        -3.2695e-01, -2.1991e-01, -4.9916e-01, -4.0062e-02, -2.6688e-02,
         3.2183e-01, -3.9357e-01, -1.2466e-02, -5.5511e-01, -3.7874e-01,
        -1.0882e-01, -8.0761e-03, -4.0334e-02, -2.3989e-01,  4.2835e-01,
         1.1270e-01,  5.2402e-03, -4.4078e-02, -1.1977e-01, -5.8301e-01,
        -4.5837e-01, -3.2117e-02, -4.3981e-01, -1.7271e-01, -1.0471e-01,
        -9.2244e-02, -2.5923e-01, -4.8508e-02, -1.3433e-01,  4.9865e-01,
         4.0563e-03,  4.7469e-01,  1.2650e-01,  2.1825e-01,  4.0002e-01,
         5.3300e-02, -4.8195e-02, -7.7325e-03,  3.1430e-02, -2.9858e-01,
         9.6678e-02,  5.9244e-03, -3.5871e-01, -1.8527e-01, -2.1074e-01,
        -2.4775e-02, -4.3054e-03, -4.8010e-01, -2.3097e-02, -4.8733e-01,
        -2.3378e-01,  1.2448e-02,  1.9692e-01,  6.4458e-01, -3.0372e-02,
        -7.6163e-02, -1.2317e-01,  1.7330e-01, -1.0179e-01,  4.4206e-02,
        -1.2982e-01, -1.8453e-01,  2.1300e-01, -5.0385e-02, -2.0801e-01,
         2.6361e-02, -5.6353e-01,  5.0608e-01,  1.8496e-01,  8.3391e-03,
        -3.2190e-02,  5.1195e-01, -1.3433e-02, -5.2053e-02,  1.4464e-01,
         3.7586e-02,  3.4294e-01,  6.9649e-03,  2.2647e-01,  5.1073e-01,
         3.4326e-02, -7.9606e-03,  3.3117e-01, -1.0774e-01, -4.2533e-02,
         3.0071e-02,  6.7355e-03, -7.9038e-01,  4.9791e-02, -4.3896e-01,
        -3.2473e-01, -2.9875e-01, -3.1350e-03, -4.8676e-03,  4.0755e-02,
        -7.9779e-03,  2.4404e-01, -5.4112e-02, -1.1398e-01,  1.1370e-03,
         3.8763e-02,  9.8141e-03, -3.7269e-01, -1.4725e-02,  5.2647e-01,
        -4.4866e-01,  2.7330e-01, -1.6093e-01, -1.5819e-01, -2.0994e-01,
         1.9685e-02, -2.4199e-02, -8.2345e-02, -3.9722e-01, -1.6619e-02,
         4.0969e-02,  3.9075e-01, -5.4413e-01, -1.2593e-01, -1.4784e-01,
        -3.4171e-01, -6.1622e-03, -2.4370e-01, -2.2418e-01,  3.0521e-04,
        -2.3542e-01, -6.4280e-02,  1.3203e-02, -1.1394e-01, -4.1009e-02,
        -8.9198e-02, -5.1333e-02, -3.2771e-01,  5.0279e-03,  2.6738e-01,
         6.9735e-02,  6.9241e-01,  4.3881e-01, -2.2326e-01,  2.3691e-02,
        -3.1278e-01, -9.1259e-02, -2.7652e-01,  1.0137e-01,  1.0067e+00,
        -3.0610e-02, -3.0768e-02, -1.6984e-01,  6.5684e-01,  8.3777e-02,
         4.4153e-01,  2.3669e-01, -1.1397e-01,  3.7618e-03, -2.0286e-02,
        -2.9738e-01,  5.2122e-02, -1.5838e-01, -1.8250e-01,  8.7092e-02,
        -9.9948e-03, -4.6142e-02, -4.2110e-01, -9.8054e-02, -1.8508e-01,
        -6.2269e-03,  1.6868e-02, -1.9718e-01, -2.3422e-01, -3.4677e-01,
         1.6644e-01,  1.2507e-01,  3.9420e-01,  7.4627e-02, -3.1263e-02,
        -3.1774e-01,  8.2827e-02,  1.5916e-02,  9.8656e-02,  1.1931e-02,
        -3.0593e-01, -3.5126e-02,  2.9627e-01,  2.0167e-01,  1.0441e-01,
        -1.0012e-01,  5.5526e-01, -1.0112e-01,  1.1197e-01, -5.4775e-02,
         5.3432e-01,  1.8932e-01,  1.2888e-01, -9.9682e-01, -3.9092e-02,
        -1.6113e-01,  1.7402e-02,  1.7735e-02,  1.6028e-01, -3.4079e-01,
         3.0156e-01,  7.4540e-02, -2.5540e-01, -3.4748e-01,  2.8851e-01,
        -2.7768e-01, -7.4829e-02,  1.7404e-01, -6.9480e-02, -2.7810e-01,
        -1.2865e-01,  2.2681e-01, -2.0875e-01, -4.3857e-01, -1.3635e-01,
        -3.7374e-01, -6.9215e-04,  2.8005e-01,  1.3246e-04, -1.2098e-01,
        -3.6941e-01, -1.2100e-01,  3.8067e-02, -3.8953e-01, -3.6714e-01,
        -4.5712e-02, -3.1230e-02, -1.0634e-01,  1.4169e-01,  2.3006e-01,
        -1.8546e-01, -2.0267e-01, -6.4678e-02, -2.3959e-01,  3.1085e-01,
         3.6061e-01,  1.6338e-02, -2.4542e-01, -8.0524e-02, -2.3345e-01,
        -1.0109e-02, -2.5681e-02,  9.0185e-01,  2.6805e-01,  3.4583e-01,
        -1.8347e-02, -1.3388e-01, -2.4006e-01,  1.4225e-02, -4.0939e-02,
        -1.7018e-01, -1.4158e-01, -2.0831e-01, -1.6937e-01, -8.4634e-02,
        -3.2971e-01, -2.7501e-01,  1.6288e-02, -4.0977e-02, -1.1737e-01,
         1.2762e-02, -1.3446e-01, -1.0033e-01, -1.4785e-01,  1.6940e-01,
        -6.3066e-02, -1.2878e-01,  6.4633e-01, -5.3337e-01,  1.4793e-02,
        -9.2401e-02, -4.7321e-01,  4.4709e-02, -3.0021e-01,  1.7768e-01,
        -4.5306e-01, -1.2879e-01, -3.4056e-02, -1.7092e-01, -3.2663e-01,
        -4.7844e-02, -3.4171e-01,  3.4814e-01, -1.8827e-01, -1.6557e-01,
        -5.7711e-01, -1.1870e-01,  2.7405e-01,  2.3554e-01, -2.6390e-01,
         2.1475e-01, -3.4903e-01,  1.3482e-01, -1.8987e-01, -2.4476e-02,
        -3.1930e-01,  9.0382e-02,  6.3579e-01, -1.4432e-01, -2.4493e-01,
         2.1646e-01,  4.9190e-01,  1.1630e-02,  7.9976e-02,  2.4348e-01,
         1.2597e-02, -1.4821e-01, -7.4587e-02,  1.5592e-01,  1.3076e-01,
         3.0585e-01, -3.6773e-01,  1.8266e-02,  9.1948e-02,  3.1869e-01,
        -2.1595e-01,  3.7490e-01, -2.6143e-02, -3.6379e-01,  8.8123e-03,
         2.6169e-02,  2.5108e-02,  2.6421e-02, -9.9199e-02,  3.0538e-01,
        -1.0716e-02, -1.9231e-01, -2.7256e-01,  1.1161e+00,  1.0307e-02,
        -9.5665e-02, -7.0562e-04, -3.1032e-01, -7.5437e-02,  2.4541e-01,
        -9.1378e-02, -5.9279e-01,  3.0515e-03,  1.4869e-02, -4.7875e-01,
         6.7284e-02, -1.8228e-01,  4.9475e-02,  3.0890e-02,  1.5924e-01,
         1.5409e-02,  3.8060e-02, -2.0830e-01, -1.9951e-01, -4.6217e-02,
        -5.7944e-01, -4.0634e-02,  1.8278e-01, -1.0762e-01, -5.3346e-01,
        -9.1331e-03, -3.6206e-01, -5.0549e-02,  2.9751e-01, -2.0689e-02,
         6.0334e-01,  2.5752e-01,  9.7462e-03,  6.7221e-03, -1.2128e-01,
        -8.0106e-02, -4.5752e-02,  6.7042e-02, -1.8903e-02, -2.1782e-01,
        -3.6457e-01, -2.6534e-02,  6.3350e-01, -3.4595e-01, -3.7133e-02,
        -9.5446e-02, -3.0462e-01, -3.0521e-01, -6.8317e-02, -5.2826e-01,
         1.4542e-01, -1.9183e-01,  1.9122e-03, -5.3528e-03, -1.5697e-01,
         2.8603e-02,  2.2384e-01, -4.2826e-02,  3.7193e-01, -1.0113e-01,
        -7.1846e-02, -1.7502e-01,  3.7556e-02, -6.9689e-01, -3.6151e-01,
        -3.2398e-02, -2.4085e-02, -3.1030e-01,  9.2290e-02, -4.0313e-01,
        -1.1534e-01,  1.2941e-01,  3.9191e-01,  6.1184e-02, -1.3613e-01,
        -2.1757e-02,  9.9645e-02,  2.4690e-01, -1.5013e-03,  1.3126e-01,
        -4.5444e-01,  3.8564e-01, -4.4021e-01,  4.3855e-01, -1.5638e-01,
         2.3229e-01,  4.4087e-02, -5.8859e-02, -1.5682e-03, -1.2277e-01,
        -8.8027e-02, -1.9164e-01, -6.1248e-02,  4.0479e-01, -3.7728e-01,
        -1.1528e-01,  1.1578e-01,  7.6795e-01, -7.4226e-02,  2.1551e-01,
         1.1526e-01, -2.0986e-03,  1.7941e-01, -7.2154e-01,  3.0800e-01,
        -3.7801e-02, -1.0173e-01,  2.5063e-01, -9.7411e-03, -1.2966e-01,
        -9.2895e-03,  5.0410e-02, -1.3581e-01,  2.7527e-01, -1.5140e-01,
         3.9171e-02,  5.3646e-02,  7.7754e-02,  2.6264e-02,  3.7058e-02,
         4.2296e-01, -4.2494e-02, -4.7810e-01, -2.3012e-01,  1.5902e-01,
         1.3807e-01, -1.8588e-01, -2.5382e-01,  1.1852e-02, -2.7152e-01,
        -2.3341e-01,  9.9333e-01], device='cuda:0')}
INFO:root:==> Evaluating the model at: 1
INFO:root:Started MAML Skip training
INFO:root:Loaded model: /mnt/creeper/grad/kumarkm/first_year/future_crowd/CSRNet/worldexpo_train_valmodel_best.pth.tar
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:10.2249028206, MAE: 101.208064651, MSE: 101.208065081
INFO:root:(Meta-testing) test MAE: 101.541421318, MSE: 101.541422349
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.92773497105, MAE: 3.70236587524, MSE: 3.70236584572
INFO:root:(Meta-training) post train loss: 2.13366699219, MAE: 37.6027603149, MSE: 37.6027595968
INFO:root:(Meta-training) pre-training test MAE: 6.88640213013, MSE: 6.88640217694
INFO:root:(Meta-training) post-training test MAE: 40.4782524109, MSE: 40.4782520818
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-43.9210, device='cuda:0'), 'backend.0.bias': tensor(0.0013, device='cuda:0'), 'backend.10.weight': tensor(-2.8210, device='cuda:0'), 'backend.8.bias': tensor(-0.1662, device='cuda:0'), 'backend.6.weight': tensor(-52.1225, device='cuda:0'), 'backend.2.bias': tensor(-0.0119, device='cuda:0'), 'backend.10.bias': tensor(0.1539, device='cuda:0'), 'output_layer.bias': tensor(-30.3483, device='cuda:0'), 'backend.2.weight': tensor(-93.3561, device='cuda:0'), 'backend.6.bias': tensor(-0.0265, device='cuda:0'), 'backend.0.weight': tensor(-21.5634, device='cuda:0'), 'output_layer.weight': tensor(-5.2881, device='cuda:0'), 'backend.4.weight': tensor(-96.7639, device='cuda:0'), 'backend.4.bias': tensor(-0.0339, device='cuda:0')}
INFO:root:==> Training scene: 2
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.4576377869, MAE: 14.0155792236, MSE: 14.0155792746
INFO:root:(Meta-training) post train loss: 28.2439689636, MAE: 246.063415527, MSE: 246.063412813
INFO:root:(Meta-training) pre-training test MAE: 8.87585067749, MSE: 8.875850583
INFO:root:(Meta-training) post-training test MAE: 235.911209106, MSE: 235.911207144
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-1020.3319, device='cuda:0'), 'backend.0.bias': tensor(-0.1067, device='cuda:0'), 'backend.10.weight': tensor(-2049.0684, device='cuda:0'), 'backend.8.bias': tensor(-5.0614, device='cuda:0'), 'backend.6.weight': tensor(-1269.1729, device='cuda:0'), 'backend.2.bias': tensor(-0.5702, device='cuda:0'), 'backend.10.bias': tensor(-49.0953, device='cuda:0'), 'output_layer.bias': tensor(-201.3323, device='cuda:0'), 'backend.2.weight': tensor(-2259.6045, device='cuda:0'), 'backend.6.bias': tensor(-1.0513, device='cuda:0'), 'backend.0.weight': tensor(-684.9938, device='cuda:0'), 'output_layer.weight': tensor(-48.6113, device='cuda:0'), 'backend.4.weight': tensor(-2496.2793, device='cuda:0'), 'backend.4.bias': tensor(-1.3280, device='cuda:0')}
INFO:root:==> Training scene: 3
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.215716362, MAE: 12.3267059326, MSE: 12.3267058703
INFO:root:(Meta-training) post train loss: 13.1575832367, MAE: 155.954437256, MSE: 155.95443921
INFO:root:(Meta-training) pre-training test MAE: 17.9829978943, MSE: 17.9829979178
INFO:root:(Meta-training) post-training test MAE: 149.803665161, MSE: 149.803667084
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-411.3130, device='cuda:0'), 'backend.0.bias': tensor(-0.1084, device='cuda:0'), 'backend.10.weight': tensor(-577.3652, device='cuda:0'), 'backend.8.bias': tensor(-1.6774, device='cuda:0'), 'backend.6.weight': tensor(-752.4664, device='cuda:0'), 'backend.2.bias': tensor(-0.3534, device='cuda:0'), 'backend.10.bias': tensor(-13.2628, device='cuda:0'), 'output_layer.bias': tensor(-113.9395, device='cuda:0'), 'backend.2.weight': tensor(-1495.3204, device='cuda:0'), 'backend.6.bias': tensor(-0.6486, device='cuda:0'), 'backend.0.weight': tensor(-532.8894, device='cuda:0'), 'output_layer.weight': tensor(-24.8956, device='cuda:0'), 'backend.4.weight': tensor(-1443.4893, device='cuda:0'), 'backend.4.bias': tensor(-0.7667, device='cuda:0')}
INFO:root:==> Training scene: 4
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.40858054161, MAE: 3.46781778336, MSE: 3.46781785142
INFO:root:(Meta-training) post train loss: 1.24631142616, MAE: 40.1663703918, MSE: 40.1663700161
INFO:root:(Meta-training) pre-training test MAE: 5.10420227051, MSE: 5.1042023119
INFO:root:(Meta-training) post-training test MAE: 38.207736969, MSE: 38.2077371321
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-22.4932, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(-6.9668, device='cuda:0'), 'backend.8.bias': tensor(-0.0887, device='cuda:0'), 'backend.6.weight': tensor(1.9747, device='cuda:0'), 'backend.2.bias': tensor(-0.0034, device='cuda:0'), 'backend.10.bias': tensor(-0.2023, device='cuda:0'), 'output_layer.bias': tensor(-28.7350, device='cuda:0'), 'backend.2.weight': tensor(-43.8065, device='cuda:0'), 'backend.6.bias': tensor(0.0327, device='cuda:0'), 'backend.0.weight': tensor(-7.9347, device='cuda:0'), 'output_layer.weight': tensor(-4.6944, device='cuda:0'), 'backend.4.weight': tensor(-74.9707, device='cuda:0'), 'backend.4.bias': tensor(-0.0318, device='cuda:0')}
INFO:root:==> Training scene: 5
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.464849472, MAE: 11.5086917877, MSE: 11.5086915716
INFO:root:(Meta-training) post train loss: 12.0098371506, MAE: 157.504074097, MSE: 157.504073608
INFO:root:(Meta-training) pre-training test MAE: 6.65334415436, MSE: 6.65334403491
INFO:root:(Meta-training) post-training test MAE: 148.859954834, MSE: 148.859958046
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-168.4951, device='cuda:0'), 'backend.0.bias': tensor(-0.0335, device='cuda:0'), 'backend.10.weight': tensor(-512.0421, device='cuda:0'), 'backend.8.bias': tensor(-0.8689, device='cuda:0'), 'backend.6.weight': tensor(-290.6689, device='cuda:0'), 'backend.2.bias': tensor(-0.2067, device='cuda:0'), 'backend.10.bias': tensor(-12.1426, device='cuda:0'), 'output_layer.bias': tensor(-113.5457, device='cuda:0'), 'backend.2.weight': tensor(-810.5502, device='cuda:0'), 'backend.6.bias': tensor(-0.2528, device='cuda:0'), 'backend.0.weight': tensor(-189.6144, device='cuda:0'), 'output_layer.weight': tensor(-21.5855, device='cuda:0'), 'backend.4.weight': tensor(-870.6675, device='cuda:0'), 'backend.4.bias': tensor(-0.5180, device='cuda:0')}
INFO:root:==> Training scene: 6
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.31700372696, MAE: 4.50811004639, MSE: 4.50810994402
INFO:root:(Meta-training) post train loss: 2.54581308365, MAE: 56.9175300598, MSE: 56.9175300291
INFO:root:(Meta-training) pre-training test MAE: 3.33308029175, MSE: 3.33308034573
INFO:root:(Meta-training) post-training test MAE: 57.6218643188, MSE: 57.6218647466
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-37.6213, device='cuda:0'), 'backend.0.bias': tensor(0.0053, device='cuda:0'), 'backend.10.weight': tensor(-48.7510, device='cuda:0'), 'backend.8.bias': tensor(-0.1999, device='cuda:0'), 'backend.6.weight': tensor(-3.2662, device='cuda:0'), 'backend.2.bias': tensor(-0.0192, device='cuda:0'), 'backend.10.bias': tensor(-1.0821, device='cuda:0'), 'output_layer.bias': tensor(-43.8108, device='cuda:0'), 'backend.2.weight': tensor(-99.3718, device='cuda:0'), 'backend.6.bias': tensor(0.0174, device='cuda:0'), 'backend.0.weight': tensor(-8.4586, device='cuda:0'), 'output_layer.weight': tensor(-7.1186, device='cuda:0'), 'backend.4.weight': tensor(-117.8177, device='cuda:0'), 'backend.4.bias': tensor(-0.0676, device='cuda:0')}
INFO:root:==> Training scene: 7
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.56835842133, MAE: 9.11410331726, MSE: 9.11410331697
INFO:root:(Meta-training) post train loss: 8.68908500671, MAE: 118.70375061, MSE: 118.703749217
INFO:root:(Meta-training) pre-training test MAE: 7.59414863586, MSE: 7.59414860186
INFO:root:(Meta-training) post-training test MAE: 119.183746338, MSE: 119.183747319
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-183.1739, device='cuda:0'), 'backend.0.bias': tensor(-0.0085, device='cuda:0'), 'backend.10.weight': tensor(-210.6387, device='cuda:0'), 'backend.8.bias': tensor(-0.9138, device='cuda:0'), 'backend.6.weight': tensor(-301.4147, device='cuda:0'), 'backend.2.bias': tensor(-0.1017, device='cuda:0'), 'backend.10.bias': tensor(-4.8148, device='cuda:0'), 'output_layer.bias': tensor(-90.9324, device='cuda:0'), 'backend.2.weight': tensor(-551.6276, device='cuda:0'), 'backend.6.bias': tensor(-0.2307, device='cuda:0'), 'backend.0.weight': tensor(-168.9219, device='cuda:0'), 'output_layer.weight': tensor(-16.1698, device='cuda:0'), 'backend.4.weight': tensor(-548.3022, device='cuda:0'), 'backend.4.bias': tensor(-0.2530, device='cuda:0')}
INFO:root:==> Training scene: 8
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.70169210434, MAE: 4.29832458496, MSE: 4.29832450693
INFO:root:(Meta-training) post train loss: 3.96286129951, MAE: 41.1326179504, MSE: 41.1326173725
INFO:root:(Meta-training) pre-training test MAE: 0.344522476196, MSE: 0.34452247522
INFO:root:(Meta-training) post-training test MAE: 45.7303619385, MSE: 45.730363144
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-90.5592, device='cuda:0'), 'backend.0.bias': tensor(-0.0234, device='cuda:0'), 'backend.10.weight': tensor(-131.2070, device='cuda:0'), 'backend.8.bias': tensor(-0.3804, device='cuda:0'), 'backend.6.weight': tensor(-169.8558, device='cuda:0'), 'backend.2.bias': tensor(-0.0816, device='cuda:0'), 'backend.10.bias': tensor(-2.6672, device='cuda:0'), 'output_layer.bias': tensor(-34.8099, device='cuda:0'), 'backend.2.weight': tensor(-365.8164, device='cuda:0'), 'backend.6.bias': tensor(-0.1439, device='cuda:0'), 'backend.0.weight': tensor(-121.5345, device='cuda:0'), 'output_layer.weight': tensor(-7.2147, device='cuda:0'), 'backend.4.weight': tensor(-379.3095, device='cuda:0'), 'backend.4.bias': tensor(-0.1953, device='cuda:0')}
INFO:root:==> Training scene: 9
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.31722784042, MAE: 1.57554912567, MSE: 1.57554914801
INFO:root:(Meta-training) post train loss: 4.04796648026, MAE: 13.7908353806, MSE: 13.7908351375
INFO:root:(Meta-training) pre-training test MAE: 5.13178634644, MSE: 5.13178641226
INFO:root:(Meta-training) post-training test MAE: 10.5187931061, MSE: 10.5187932721
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(12.7440, device='cuda:0'), 'backend.0.bias': tensor(0.0095, device='cuda:0'), 'backend.10.weight': tensor(-5.2699, device='cuda:0'), 'backend.8.bias': tensor(0.0464, device='cuda:0'), 'backend.6.weight': tensor(44.8930, device='cuda:0'), 'backend.2.bias': tensor(0.0177, device='cuda:0'), 'backend.10.bias': tensor(-0.2285, device='cuda:0'), 'output_layer.bias': tensor(-7.7328, device='cuda:0'), 'backend.2.weight': tensor(82.0600, device='cuda:0'), 'backend.6.bias': tensor(0.0495, device='cuda:0'), 'backend.0.weight': tensor(42.8591, device='cuda:0'), 'output_layer.weight': tensor(-1.1357, device='cuda:0'), 'backend.4.weight': tensor(46.6682, device='cuda:0'), 'backend.4.bias': tensor(0.0206, device='cuda:0')}
INFO:root:==> Training scene: 10
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 2.62649679184, MAE: 0.140889167786, MSE: 0.14088916471
INFO:root:(Meta-training) post train loss: 1.72036862373, MAE: 8.40645599365, MSE: 8.40645601949
INFO:root:(Meta-training) pre-training test MAE: 2.28190612793, MSE: 2.28190613808
INFO:root:(Meta-training) post-training test MAE: 9.29603385925, MSE: 9.29603380517
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(29.3622, device='cuda:0'), 'backend.0.bias': tensor(0.0022, device='cuda:0'), 'backend.10.weight': tensor(14.4824, device='cuda:0'), 'backend.8.bias': tensor(0.1243, device='cuda:0'), 'backend.6.weight': tensor(20.2014, device='cuda:0'), 'backend.2.bias': tensor(0.0180, device='cuda:0'), 'backend.10.bias': tensor(0.5394, device='cuda:0'), 'output_layer.bias': tensor(7.4570, device='cuda:0'), 'backend.2.weight': tensor(65.5934, device='cuda:0'), 'backend.6.bias': tensor(0.0065, device='cuda:0'), 'backend.0.weight': tensor(18.4875, device='cuda:0'), 'output_layer.weight': tensor(1.3642, device='cuda:0'), 'backend.4.weight': tensor(55.7639, device='cuda:0'), 'backend.4.bias': tensor(0.0333, device='cuda:0')}
INFO:root:==> Training scene: 11
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 20.0581626892, MAE: 3.79273986816, MSE: 3.79273981411
INFO:root:(Meta-training) post train loss: 15.4374332428, MAE: 60.0539627075, MSE: 60.0539633632
INFO:root:(Meta-training) pre-training test MAE: 1.65007305145, MSE: 1.65007306717
INFO:root:(Meta-training) post-training test MAE: 46.8975715637, MSE: 46.8975726901
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-285.1150, device='cuda:0'), 'backend.0.bias': tensor(-0.0562, device='cuda:0'), 'backend.10.weight': tensor(-397.6520, device='cuda:0'), 'backend.8.bias': tensor(-1.2813, device='cuda:0'), 'backend.6.weight': tensor(-501.0734, device='cuda:0'), 'backend.2.bias': tensor(-0.1695, device='cuda:0'), 'backend.10.bias': tensor(-8.2408, device='cuda:0'), 'output_layer.bias': tensor(-36.3815, device='cuda:0'), 'backend.2.weight': tensor(-722.0707, device='cuda:0'), 'backend.6.bias': tensor(-0.4861, device='cuda:0'), 'backend.0.weight': tensor(-277.7591, device='cuda:0'), 'output_layer.weight': tensor(-10.3747, device='cuda:0'), 'backend.4.weight': tensor(-798.2838, device='cuda:0'), 'backend.4.bias': tensor(-0.4068, device='cuda:0')}
INFO:root:==> Training scene: 12
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.26931238174, MAE: 9.15769100189, MSE: 9.15769098289
INFO:root:(Meta-training) post train loss: 5.25304222107, MAE: 128.482192993, MSE: 128.48219265
INFO:root:(Meta-training) pre-training test MAE: 4.61597824097, MSE: 4.61597820524
INFO:root:(Meta-training) post-training test MAE: 141.958709717, MSE: 141.958710161
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(260.6506, device='cuda:0'), 'backend.0.bias': tensor(0.0241, device='cuda:0'), 'backend.10.weight': tensor(468.7807, device='cuda:0'), 'backend.8.bias': tensor(1.2948, device='cuda:0'), 'backend.6.weight': tensor(381.9536, device='cuda:0'), 'backend.2.bias': tensor(0.2002, device='cuda:0'), 'backend.10.bias': tensor(12.5315, device='cuda:0'), 'output_layer.bias': tensor(110.0441, device='cuda:0'), 'backend.2.weight': tensor(951.6745, device='cuda:0'), 'backend.6.bias': tensor(0.2520, device='cuda:0'), 'backend.0.weight': tensor(256.8109, device='cuda:0'), 'output_layer.weight': tensor(24.2919, device='cuda:0'), 'backend.4.weight': tensor(1108.7393, device='cuda:0'), 'backend.4.bias': tensor(0.5716, device='cuda:0')}
INFO:root:==> Training scene: 13
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.15585327148, MAE: 0.122278213501, MSE: 0.122278211939
INFO:root:(Meta-training) post train loss: 6.03297519684, MAE: 16.0758628845, MSE: 16.0758632778
INFO:root:(Meta-training) pre-training test MAE: 6.88552856445, MSE: 6.88552854815
INFO:root:(Meta-training) post-training test MAE: 24.3776416779, MSE: 24.3776415836
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(63.4808, device='cuda:0'), 'backend.0.bias': tensor(0.0233, device='cuda:0'), 'backend.10.weight': tensor(82.2610, device='cuda:0'), 'backend.8.bias': tensor(0.2575, device='cuda:0'), 'backend.6.weight': tensor(116.4728, device='cuda:0'), 'backend.2.bias': tensor(0.0472, device='cuda:0'), 'backend.10.bias': tensor(1.7025, device='cuda:0'), 'output_layer.bias': tensor(19.4742, device='cuda:0'), 'backend.2.weight': tensor(230.1301, device='cuda:0'), 'backend.6.bias': tensor(0.0803, device='cuda:0'), 'backend.0.weight': tensor(113.1910, device='cuda:0'), 'output_layer.weight': tensor(4.3418, device='cuda:0'), 'backend.4.weight': tensor(236.4321, device='cuda:0'), 'backend.4.bias': tensor(0.1142, device='cuda:0')}
INFO:root:==> Training scene: 14
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.2247161865, MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post train loss: 11.2101097107, MAE: 134.058197021, MSE: 134.058194861
INFO:root:(Meta-training) pre-training test MAE: 9.19702339172, MSE: 9.19702319208
INFO:root:(Meta-training) post-training test MAE: 132.98664856, MSE: 132.986650528
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-412.4715, device='cuda:0'), 'backend.0.bias': tensor(-0.0713, device='cuda:0'), 'backend.10.weight': tensor(-431.9966, device='cuda:0'), 'backend.8.bias': tensor(-1.9927, device='cuda:0'), 'backend.6.weight': tensor(-607.5500, device='cuda:0'), 'backend.2.bias': tensor(-0.2443, device='cuda:0'), 'backend.10.bias': tensor(-9.6424, device='cuda:0'), 'output_layer.bias': tensor(-102.2852, device='cuda:0'), 'backend.2.weight': tensor(-871.2705, device='cuda:0'), 'backend.6.bias': tensor(-0.6839, device='cuda:0'), 'backend.0.weight': tensor(-302.5320, device='cuda:0'), 'output_layer.weight': tensor(-20.8222, device='cuda:0'), 'backend.4.weight': tensor(-984.5857, device='cuda:0'), 'backend.4.bias': tensor(-0.5933, device='cuda:0')}
INFO:root:==> Training scene: 15
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.0185213089, MAE: 6.06261253357, MSE: 6.06261263084
INFO:root:(Meta-training) post train loss: 5.02552700043, MAE: 89.3602752686, MSE: 89.3602752293
INFO:root:(Meta-training) pre-training test MAE: 2.2882976532, MSE: 2.28829766213
INFO:root:(Meta-training) post-training test MAE: 88.706703186, MSE: 88.7067043381
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(73.9416, device='cuda:0'), 'backend.0.bias': tensor(-0.0452, device='cuda:0'), 'backend.10.weight': tensor(228.9542, device='cuda:0'), 'backend.8.bias': tensor(0.1953, device='cuda:0'), 'backend.6.weight': tensor(-42.0229, device='cuda:0'), 'backend.2.bias': tensor(-0.0187, device='cuda:0'), 'backend.10.bias': tensor(7.8502, device='cuda:0'), 'output_layer.bias': tensor(67.6426, device='cuda:0'), 'backend.2.weight': tensor(47.4639, device='cuda:0'), 'backend.6.bias': tensor(-0.2108, device='cuda:0'), 'backend.0.weight': tensor(-75.9561, device='cuda:0'), 'output_layer.weight': tensor(11.4994, device='cuda:0'), 'backend.4.weight': tensor(242.4803, device='cuda:0'), 'backend.4.bias': tensor(0.1128, device='cuda:0')}
INFO:root:==> Training scene: 16
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 17.7963008881, MAE: 16.1687660217, MSE: 16.1687657413
INFO:root:(Meta-training) post train loss: 22.4242420197, MAE: 229.407485962, MSE: 229.407482373
INFO:root:(Meta-training) pre-training test MAE: 6.00388336182, MSE: 6.00388337666
INFO:root:(Meta-training) post-training test MAE: 239.257141113, MSE: 239.257142984
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-988.6003, device='cuda:0'), 'backend.0.bias': tensor(-0.2824, device='cuda:0'), 'backend.10.weight': tensor(-1988.3594, device='cuda:0'), 'backend.8.bias': tensor(-5.0329, device='cuda:0'), 'backend.6.weight': tensor(-2082.1543, device='cuda:0'), 'backend.2.bias': tensor(-1.0028, device='cuda:0'), 'backend.10.bias': tensor(-44.8206, device='cuda:0'), 'output_layer.bias': tensor(-201.1472, device='cuda:0'), 'backend.2.weight': tensor(-3871.7910, device='cuda:0'), 'backend.6.bias': tensor(-2.2654, device='cuda:0'), 'backend.0.weight': tensor(-1286.4836, device='cuda:0'), 'output_layer.weight': tensor(-56.6222, device='cuda:0'), 'backend.4.weight': tensor(-4343.2554, device='cuda:0'), 'backend.4.bias': tensor(-2.4096, device='cuda:0')}
INFO:root:==> Training scene: 17
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 32.0257339478, MAE: 15.1991195679, MSE: 15.1991193617
INFO:root:(Meta-training) post train loss: 48.2651100159, MAE: 335.650817871, MSE: 335.650813719
INFO:root:(Meta-training) pre-training test MAE: 11.0977325439, MSE: 11.0977325598
INFO:root:(Meta-training) post-training test MAE: 336.292419434, MSE: 336.292422974
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-7079.0312, device='cuda:0'), 'backend.0.bias': tensor(-1.0678, device='cuda:0'), 'backend.10.weight': tensor(-9176.1611, device='cuda:0'), 'backend.8.bias': tensor(-32.7449, device='cuda:0'), 'backend.6.weight': tensor(-9999.3828, device='cuda:0'), 'backend.2.bias': tensor(-3.5476, device='cuda:0'), 'backend.10.bias': tensor(-201.9896, device='cuda:0'), 'output_layer.bias': tensor(-380.1562, device='cuda:0'), 'backend.2.weight': tensor(-13915.4082, device='cuda:0'), 'backend.6.bias': tensor(-10.0968, device='cuda:0'), 'backend.0.weight': tensor(-4359.9951, device='cuda:0'), 'output_layer.weight': tensor(-154.6839, device='cuda:0'), 'backend.4.weight': tensor(-14321.7227, device='cuda:0'), 'backend.4.bias': tensor(-7.5350, device='cuda:0')}
INFO:root:==> Training scene: 18
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.19173002243, MAE: 9.96483707428, MSE: 9.96483724213
INFO:root:(Meta-training) post train loss: 8.31143093109, MAE: 108.922950745, MSE: 108.92294976
INFO:root:(Meta-training) pre-training test MAE: 26.310459137, MSE: 26.31045865
INFO:root:(Meta-training) post-training test MAE: 94.4987640381, MSE: 94.4987650796
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-88.2477, device='cuda:0'), 'backend.0.bias': tensor(0.0020, device='cuda:0'), 'backend.10.weight': tensor(-150.8411, device='cuda:0'), 'backend.8.bias': tensor(-0.5698, device='cuda:0'), 'backend.6.weight': tensor(-90.5708, device='cuda:0'), 'backend.2.bias': tensor(-0.0589, device='cuda:0'), 'backend.10.bias': tensor(-4.4715, device='cuda:0'), 'output_layer.bias': tensor(-71.4431, device='cuda:0'), 'backend.2.weight': tensor(-212.6744, device='cuda:0'), 'backend.6.bias': tensor(-0.1036, device='cuda:0'), 'backend.0.weight': tensor(-35.0562, device='cuda:0'), 'output_layer.weight': tensor(-12.1312, device='cuda:0'), 'backend.4.weight': tensor(-304.2589, device='cuda:0'), 'backend.4.bias': tensor(-0.2161, device='cuda:0')}
INFO:root:==> Training scene: 19
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.85736942291, MAE: 15.1381454468, MSE: 15.1381455981
INFO:root:(Meta-training) post train loss: 11.7894153595, MAE: 200.715957642, MSE: 200.71595485
INFO:root:(Meta-training) pre-training test MAE: 19.7869281769, MSE: 19.786928058
INFO:root:(Meta-training) post-training test MAE: 196.792785645, MSE: 196.792790375
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-82.1093, device='cuda:0'), 'backend.0.bias': tensor(0.0720, device='cuda:0'), 'backend.10.weight': tensor(-106.0497, device='cuda:0'), 'backend.8.bias': tensor(-0.6434, device='cuda:0'), 'backend.6.weight': tensor(60.6098, device='cuda:0'), 'backend.2.bias': tensor(0.0389, device='cuda:0'), 'backend.10.bias': tensor(-4.0570, device='cuda:0'), 'output_layer.bias': tensor(-149.3103, device='cuda:0'), 'backend.2.weight': tensor(-19.7755, device='cuda:0'), 'backend.6.bias': tensor(0.1884, device='cuda:0'), 'backend.0.weight': tensor(94.8992, device='cuda:0'), 'output_layer.weight': tensor(-21.7000, device='cuda:0'), 'backend.4.weight': tensor(-218.3605, device='cuda:0'), 'backend.4.bias': tensor(-0.1340, device='cuda:0')}
INFO:root:==> Training scene: 20
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.6179828644, MAE: 19.8658561707, MSE: 19.8658564426
INFO:root:(Meta-training) post train loss: 23.2383213043, MAE: 305.630065918, MSE: 305.630061308
INFO:root:(Meta-training) pre-training test MAE: 10.2544403076, MSE: 10.2544404623
INFO:root:(Meta-training) post-training test MAE: 309.446746826, MSE: 309.446746731
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(58.7686, device='cuda:0'), 'backend.0.bias': tensor(0.1086, device='cuda:0'), 'backend.10.weight': tensor(-648.2241, device='cuda:0'), 'backend.8.bias': tensor(0.4562, device='cuda:0'), 'backend.6.weight': tensor(345.6557, device='cuda:0'), 'backend.2.bias': tensor(-0.1202, device='cuda:0'), 'backend.10.bias': tensor(-15.2989, device='cuda:0'), 'output_layer.bias': tensor(-243.9008, device='cuda:0'), 'backend.2.weight': tensor(-578.7977, device='cuda:0'), 'backend.6.bias': tensor(0.6730, device='cuda:0'), 'backend.0.weight': tensor(372.4922, device='cuda:0'), 'output_layer.weight': tensor(-42.9096, device='cuda:0'), 'backend.4.weight': tensor(-832.2754, device='cuda:0'), 'backend.4.bias': tensor(-0.4173, device='cuda:0')}
INFO:root:==> Training scene: 21
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.92966938019, MAE: 7.99254989624, MSE: 7.99255000362
INFO:root:(Meta-training) post train loss: 7.9303984642, MAE: 103.157691956, MSE: 103.157693681
INFO:root:(Meta-training) pre-training test MAE: 17.2073936462, MSE: 17.2073934943
INFO:root:(Meta-training) post-training test MAE: 94.2486724854, MSE: 94.2486737307
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-110.2387, device='cuda:0'), 'backend.0.bias': tensor(-0.0146, device='cuda:0'), 'backend.10.weight': tensor(-230.1305, device='cuda:0'), 'backend.8.bias': tensor(-0.4253, device='cuda:0'), 'backend.6.weight': tensor(-117.1571, device='cuda:0'), 'backend.2.bias': tensor(-0.0757, device='cuda:0'), 'backend.10.bias': tensor(-5.3008, device='cuda:0'), 'output_layer.bias': tensor(-71.6464, device='cuda:0'), 'backend.2.weight': tensor(-347.9861, device='cuda:0'), 'backend.6.bias': tensor(-0.0327, device='cuda:0'), 'backend.0.weight': tensor(-114.7507, device='cuda:0'), 'output_layer.weight': tensor(-14.5011, device='cuda:0'), 'backend.4.weight': tensor(-442.1409, device='cuda:0'), 'backend.4.bias': tensor(-0.2187, device='cuda:0')}
INFO:root:==> Training scene: 22
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.6123580933, MAE: 10.1582298279, MSE: 10.1582299753
INFO:root:(Meta-training) post train loss: 13.2736635208, MAE: 153.450271606, MSE: 153.450273145
INFO:root:(Meta-training) pre-training test MAE: 16.6812591553, MSE: 16.6812590741
INFO:root:(Meta-training) post-training test MAE: 142.571716309, MSE: 142.571713041
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-348.8310, device='cuda:0'), 'backend.0.bias': tensor(-0.1027, device='cuda:0'), 'backend.10.weight': tensor(-844.5211, device='cuda:0'), 'backend.8.bias': tensor(-1.7194, device='cuda:0'), 'backend.6.weight': tensor(-814.8038, device='cuda:0'), 'backend.2.bias': tensor(-0.4312, device='cuda:0'), 'backend.10.bias': tensor(-20.1072, device='cuda:0'), 'output_layer.bias': tensor(-113.4044, device='cuda:0'), 'backend.2.weight': tensor(-1628.5049, device='cuda:0'), 'backend.6.bias': tensor(-0.7616, device='cuda:0'), 'backend.0.weight': tensor(-452.7623, device='cuda:0'), 'output_layer.weight': tensor(-25.8737, device='cuda:0'), 'backend.4.weight': tensor(-1727.8323, device='cuda:0'), 'backend.4.bias': tensor(-1.0229, device='cuda:0')}
INFO:root:==> Training scene: 23
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 21.1111278534, MAE: 0.63020324707, MSE: 0.630203236541
INFO:root:(Meta-training) post train loss: 22.0809345245, MAE: 13.3689956665, MSE: 13.3689955309
INFO:root:(Meta-training) pre-training test MAE: 6.70138835907, MSE: 6.70138847426
INFO:root:(Meta-training) post-training test MAE: 37.1159133911, MSE: 37.1159138976
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(16.0167, device='cuda:0'), 'backend.0.bias': tensor(0.0425, device='cuda:0'), 'backend.10.weight': tensor(-114.7200, device='cuda:0'), 'backend.8.bias': tensor(-0.0449, device='cuda:0'), 'backend.6.weight': tensor(201.0809, device='cuda:0'), 'backend.2.bias': tensor(0.0558, device='cuda:0'), 'backend.10.bias': tensor(-2.8130, device='cuda:0'), 'output_layer.bias': tensor(-25.3122, device='cuda:0'), 'backend.2.weight': tensor(294.5784, device='cuda:0'), 'backend.6.bias': tensor(0.1817, device='cuda:0'), 'backend.0.weight': tensor(233.2811, device='cuda:0'), 'output_layer.weight': tensor(-4.9482, device='cuda:0'), 'backend.4.weight': tensor(177.3403, device='cuda:0'), 'backend.4.bias': tensor(0.0573, device='cuda:0')}
INFO:root:==> Training scene: 24
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.3689892292, MAE: 3.61751317978, MSE: 3.61751322588
INFO:root:(Meta-training) post train loss: 1.41690576077, MAE: 57.1678237915, MSE: 57.1678244841
INFO:root:(Meta-training) pre-training test MAE: 3.67163085938, MSE: 3.67163085126
INFO:root:(Meta-training) post-training test MAE: 62.9182167053, MSE: 62.9182159974
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(67.4449, device='cuda:0'), 'backend.0.bias': tensor(-0.0376, device='cuda:0'), 'backend.10.weight': tensor(95.9710, device='cuda:0'), 'backend.8.bias': tensor(0.2977, device='cuda:0'), 'backend.6.weight': tensor(-43.1883, device='cuda:0'), 'backend.2.bias': tensor(-0.0293, device='cuda:0'), 'backend.10.bias': tensor(3.6065, device='cuda:0'), 'output_layer.bias': tensor(48.0856, device='cuda:0'), 'backend.2.weight': tensor(-23.3053, device='cuda:0'), 'backend.6.bias': tensor(-0.1360, device='cuda:0'), 'backend.0.weight': tensor(-73.2256, device='cuda:0'), 'output_layer.weight': tensor(7.2894, device='cuda:0'), 'backend.4.weight': tensor(94.5628, device='cuda:0'), 'backend.4.bias': tensor(0.0419, device='cuda:0')}
INFO:root:==> Training scene: 25
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.78185081482, MAE: 3.64704179764, MSE: 3.647041789
INFO:root:(Meta-training) post train loss: 1.53377175331, MAE: 41.5643920898, MSE: 41.5643914043
INFO:root:(Meta-training) pre-training test MAE: 7.03860282898, MSE: 7.03860292617
INFO:root:(Meta-training) post-training test MAE: 38.4184913635, MSE: 38.4184912347
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(6.1834, device='cuda:0'), 'backend.0.bias': tensor(0.0124, device='cuda:0'), 'backend.10.weight': tensor(-7.2555, device='cuda:0'), 'backend.8.bias': tensor(0.0298, device='cuda:0'), 'backend.6.weight': tensor(31.5153, device='cuda:0'), 'backend.2.bias': tensor(0.0100, device='cuda:0'), 'backend.10.bias': tensor(-0.1930, device='cuda:0'), 'output_layer.bias': tensor(-28.9806, device='cuda:0'), 'backend.2.weight': tensor(31.5567, device='cuda:0'), 'backend.6.bias': tensor(0.0482, device='cuda:0'), 'backend.0.weight': tensor(44.4503, device='cuda:0'), 'output_layer.weight': tensor(-4.4127, device='cuda:0'), 'backend.4.weight': tensor(9.8322, device='cuda:0'), 'backend.4.bias': tensor(0.0038, device='cuda:0')}
INFO:root:==> Training scene: 26
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.51275110245, MAE: 4.93081665039, MSE: 4.93081656946
INFO:root:(Meta-training) post train loss: 6.66961288452, MAE: 63.5387802124, MSE: 63.5387796048
INFO:root:(Meta-training) pre-training test MAE: 1.70257949829, MSE: 1.70257951593
INFO:root:(Meta-training) post-training test MAE: 74.05909729, MSE: 74.0590980231
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-64.9146, device='cuda:0'), 'backend.0.bias': tensor(0.0207, device='cuda:0'), 'backend.10.weight': tensor(-215.7396, device='cuda:0'), 'backend.8.bias': tensor(-0.2159, device='cuda:0'), 'backend.6.weight': tensor(-53.6725, device='cuda:0'), 'backend.2.bias': tensor(0.0031, device='cuda:0'), 'backend.10.bias': tensor(-5.1249, device='cuda:0'), 'output_layer.bias': tensor(-58.9641, device='cuda:0'), 'backend.2.weight': tensor(-154.8737, device='cuda:0'), 'backend.6.bias': tensor(0.1189, device='cuda:0'), 'backend.0.weight': tensor(-51.5992, device='cuda:0'), 'output_layer.weight': tensor(-9.6605, device='cuda:0'), 'backend.4.weight': tensor(-269.6791, device='cuda:0'), 'backend.4.bias': tensor(-0.1026, device='cuda:0')}
INFO:root:==> Training scene: 27
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.81052994728, MAE: 3.4300737381, MSE: 3.43007370984
INFO:root:(Meta-training) post train loss: 1.85474956036, MAE: 49.2230949402, MSE: 49.2230950463
INFO:root:(Meta-training) pre-training test MAE: 0.405708312988, MSE: 0.405708318655
INFO:root:(Meta-training) post-training test MAE: 53.5645370483, MSE: 53.5645374102
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(21.7239, device='cuda:0'), 'backend.0.bias': tensor(-0.0415, device='cuda:0'), 'backend.10.weight': tensor(88.3675, device='cuda:0'), 'backend.8.bias': tensor(0.0254, device='cuda:0'), 'backend.6.weight': tensor(-91.4464, device='cuda:0'), 'backend.2.bias': tensor(-0.0413, device='cuda:0'), 'backend.10.bias': tensor(3.2484, device='cuda:0'), 'output_layer.bias': tensor(40.5884, device='cuda:0'), 'backend.2.weight': tensor(-47.4420, device='cuda:0'), 'backend.6.bias': tensor(-0.2370, device='cuda:0'), 'backend.0.weight': tensor(-68.5267, device='cuda:0'), 'output_layer.weight': tensor(6.0570, device='cuda:0'), 'backend.4.weight': tensor(54.8532, device='cuda:0'), 'backend.4.bias': tensor(-0.0010, device='cuda:0')}
INFO:root:==> Training scene: 28
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.91805839539, MAE: 16.495388031, MSE: 16.4953884269
INFO:root:(Meta-training) post train loss: 16.5992279053, MAE: 248.975204468, MSE: 248.975204275
INFO:root:(Meta-training) pre-training test MAE: 5.10612487793, MSE: 5.10612491749
INFO:root:(Meta-training) post-training test MAE: 254.839996338, MSE: 254.839992691
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-218.2436, device='cuda:0'), 'backend.0.bias': tensor(0.0600, device='cuda:0'), 'backend.10.weight': tensor(-483.3945, device='cuda:0'), 'backend.8.bias': tensor(-0.9689, device='cuda:0'), 'backend.6.weight': tensor(58.4666, device='cuda:0'), 'backend.2.bias': tensor(-0.1581, device='cuda:0'), 'backend.10.bias': tensor(-8.8787, device='cuda:0'), 'output_layer.bias': tensor(-200.1620, device='cuda:0'), 'backend.2.weight': tensor(-680.3275, device='cuda:0'), 'backend.6.bias': tensor(0.2169, device='cuda:0'), 'backend.0.weight': tensor(194.6782, device='cuda:0'), 'output_layer.weight': tensor(-33.2362, device='cuda:0'), 'backend.4.weight': tensor(-900.4709, device='cuda:0'), 'backend.4.bias': tensor(-0.4924, device='cuda:0')}
INFO:root:==> Training scene: 29
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.79754734039, MAE: 17.5090179443, MSE: 17.5090178007
INFO:root:(Meta-training) post train loss: 19.8869838715, MAE: 259.828735352, MSE: 259.828729647
INFO:root:(Meta-training) pre-training test MAE: 19.3920478821, MSE: 19.3920476916
INFO:root:(Meta-training) post-training test MAE: 262.822540283, MSE: 262.822539939
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-562.1880, device='cuda:0'), 'backend.0.bias': tensor(-0.0445, device='cuda:0'), 'backend.10.weight': tensor(-752.2289, device='cuda:0'), 'backend.8.bias': tensor(-2.6582, device='cuda:0'), 'backend.6.weight': tensor(-1082.9235, device='cuda:0'), 'backend.2.bias': tensor(-0.3633, device='cuda:0'), 'backend.10.bias': tensor(-19.6488, device='cuda:0'), 'output_layer.bias': tensor(-208.3303, device='cuda:0'), 'backend.2.weight': tensor(-1791.1687, device='cuda:0'), 'backend.6.bias': tensor(-0.9017, device='cuda:0'), 'backend.0.weight': tensor(-419.6126, device='cuda:0'), 'output_layer.weight': tensor(-41.2734, device='cuda:0'), 'backend.4.weight': tensor(-1991.5342, device='cuda:0'), 'backend.4.bias': tensor(-0.9737, device='cuda:0')}
INFO:root:==> Training scene: 30
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.79670476913, MAE: 2.56892776489, MSE: 2.56892779772
INFO:root:(Meta-training) post train loss: 5.1647310257, MAE: 24.4140777588, MSE: 24.4140775
INFO:root:(Meta-training) pre-training test MAE: 1.84230804443, MSE: 1.84230806249
INFO:root:(Meta-training) post-training test MAE: 22.7580795288, MSE: 22.7580793518
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-46.0853, device='cuda:0'), 'backend.0.bias': tensor(-0.0036, device='cuda:0'), 'backend.10.weight': tensor(-73.4210, device='cuda:0'), 'backend.8.bias': tensor(-0.1900, device='cuda:0'), 'backend.6.weight': tensor(-62.4290, device='cuda:0'), 'backend.2.bias': tensor(-0.0266, device='cuda:0'), 'backend.10.bias': tensor(-1.6552, device='cuda:0'), 'output_layer.bias': tensor(-17.0427, device='cuda:0'), 'backend.2.weight': tensor(-127.3594, device='cuda:0'), 'backend.6.bias': tensor(-0.0366, device='cuda:0'), 'backend.0.weight': tensor(-25.0364, device='cuda:0'), 'output_layer.weight': tensor(-3.4376, device='cuda:0'), 'backend.4.weight': tensor(-128.4331, device='cuda:0'), 'backend.4.bias': tensor(-0.0640, device='cuda:0')}
INFO:root:==> Training scene: 31
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.92816901207, MAE: 6.54268741608, MSE: 6.54268743565
INFO:root:(Meta-training) post train loss: 3.94747591019, MAE: 79.0179672241, MSE: 79.0179685608
INFO:root:(Meta-training) pre-training test MAE: 2.77071666718, MSE: 2.77071666233
INFO:root:(Meta-training) post-training test MAE: 81.9200592041, MSE: 81.9200585699
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-42.4969, device='cuda:0'), 'backend.0.bias': tensor(0.0191, device='cuda:0'), 'backend.10.weight': tensor(-89.6895, device='cuda:0'), 'backend.8.bias': tensor(-0.1760, device='cuda:0'), 'backend.6.weight': tensor(25.6620, device='cuda:0'), 'backend.2.bias': tensor(-0.0125, device='cuda:0'), 'backend.10.bias': tensor(-2.3425, device='cuda:0'), 'output_layer.bias': tensor(-62.3058, device='cuda:0'), 'backend.2.weight': tensor(-101.7161, device='cuda:0'), 'backend.6.bias': tensor(0.0798, device='cuda:0'), 'backend.0.weight': tensor(28.3379, device='cuda:0'), 'output_layer.weight': tensor(-10.7214, device='cuda:0'), 'backend.4.weight': tensor(-192.2546, device='cuda:0'), 'backend.4.bias': tensor(-0.0999, device='cuda:0')}
INFO:root:==> Training scene: 32
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.5723743439, MAE: 3.49564743042, MSE: 3.49564744882
INFO:root:(Meta-training) post train loss: 8.17095756531, MAE: 36.8633918762, MSE: 36.8633919759
INFO:root:(Meta-training) pre-training test MAE: 3.27803039551, MSE: 3.27803041451
INFO:root:(Meta-training) post-training test MAE: 33.7333984375, MSE: 33.733397971
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.975341796875, '19.bias': 18.59708023071289, '17.bias': 2.3308541774749756, '14.bias': 5.615649223327637, '12.weight': -817.4696044921875, '10.weight': -366.64227294921875, '21.bias': 25.48503875732422, '5.weight': -132.0090789794922, '7.weight': -323.5810546875, '2.weight': -63.51335906982422, '21.weight': -5208.23095703125, '0.bias': -4.073812007904053, '14.weight': -1435.581298828125, '7.bias': 3.7745769023895264, '12.bias': 10.95762825012207, '5.bias': 7.1006760597229, '2.bias': 0.6054605841636658, '10.bias': 5.743321418762207, '19.weight': -3796.053955078125, '0.weight': -4.821667194366455}
INFO:root:Sum of gradients in backend: {'4.weight': -47.08636474609375, '6.bias': 0.3107316792011261, '10.weight': -16.68219757080078, '8.bias': 0.672062873840332, '4.bias': 0.17727279663085938, '2.weight': -85.5224380493164, '0.bias': 0.05404755473136902, '6.weight': -27.39265251159668, '8.weight': -5.205000400543213, '2.bias': 0.08785280585289001, '10.bias': 0.3817559480667114, '0.weight': -55.161659240722656}
INFO:root:Sum of gradients in output layer: {'bias': tensor(-6.1206e-06, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9383, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-57.7771, device='cuda:0'), 'backend.0.bias': tensor(-0.0101, device='cuda:0'), 'backend.10.weight': tensor(-168.3690, device='cuda:0'), 'backend.8.bias': tensor(-0.3028, device='cuda:0'), 'backend.6.weight': tensor(-124.5657, device='cuda:0'), 'backend.2.bias': tensor(-0.0514, device='cuda:0'), 'backend.10.bias': tensor(-3.7853, device='cuda:0'), 'output_layer.bias': tensor(-26.0408, device='cuda:0'), 'backend.2.weight': tensor(-202.7010, device='cuda:0'), 'backend.6.bias': tensor(-0.1367, device='cuda:0'), 'backend.0.weight': tensor(-33.2378, device='cuda:0'), 'output_layer.weight': tensor(-5.5101, device='cuda:0'), 'backend.4.weight': tensor(-261.8320, device='cuda:0'), 'backend.4.bias': tensor(-0.1489, device='cuda:0')}
INFO:root:===> Updating meta network
INFO:root:===> Gradients updated: {'backend.8.weight': tensor([[[[ 7.7916e-01,  8.5607e-01,  7.9229e-01],
          [ 9.0868e-01,  7.7736e-01,  6.4876e-01],
          [ 9.0064e-01,  9.4987e-01,  7.5753e-01]],

         [[ 1.1307e-01,  1.0704e-01,  9.0649e-02],
          [ 1.2796e-01,  1.0473e-01,  1.2942e-01],
          [ 1.3047e-01,  1.6048e-01,  1.4018e-01]],

         [[ 7.5768e-01,  7.1184e-01,  8.0713e-01],
          [ 7.5325e-01,  7.6828e-01,  8.4883e-01],
          [ 6.4983e-01,  8.1942e-01,  6.6784e-01]],

         ...,

         [[ 4.8735e-03,  5.3943e-03,  5.6951e-03],
          [ 4.0223e-03,  5.7926e-03,  2.3920e-03],
          [ 5.1352e-03,  6.9413e-03,  1.8356e-03]],

         [[ 2.1338e-02,  1.4164e-02,  1.3132e-02],
          [ 1.4678e-02,  1.8111e-02,  1.2113e-02],
          [ 1.1622e-02,  1.0919e-02,  8.9136e-03]],

         [[ 8.8305e-01,  8.2144e-01,  7.5310e-01],
          [ 8.2313e-01,  8.4059e-01,  7.4162e-01],
          [ 8.5086e-01,  7.3575e-01,  7.3748e-01]]],


        [[[-4.9812e-01, -5.0378e-01, -5.1191e-01],
          [-4.0563e-01, -2.9149e-01, -3.7377e-01],
          [-2.8067e-01, -3.3813e-01, -3.9142e-01]],

         [[-3.6185e-02, -4.4534e-02, -3.7252e-02],
          [-3.7536e-02, -2.0504e-02, -3.5803e-02],
          [-3.6210e-02, -6.8325e-02, -4.4340e-02]],

         [[-3.7382e-01, -3.9211e-01, -4.3686e-01],
          [-4.6847e-01, -4.9453e-01, -5.1677e-01],
          [-5.1365e-01, -5.5016e-01, -3.8768e-01]],

         ...,

         [[-5.0242e-03, -1.1525e-03, -2.1685e-03],
          [-3.8029e-03, -3.3366e-03, -1.4324e-03],
          [-3.0780e-03, -4.2158e-03, -4.6185e-03]],

         [[-5.8557e-03, -1.7622e-02, -2.0925e-02],
          [-2.2585e-02, -2.9422e-02, -2.1775e-02],
          [-1.7520e-02, -1.5502e-02, -9.9941e-03]],

         [[-3.5619e-01, -4.2216e-01, -4.5200e-01],
          [-4.1187e-01, -5.1698e-01, -4.8196e-01],
          [-2.5478e-01, -2.9195e-01, -3.7740e-01]]],


        [[[-5.0192e-01, -1.6550e-01, -3.0481e-01],
          [-4.3925e-01, -2.2387e-01, -4.2957e-01],
          [-2.3618e-01, -4.3159e-01, -5.8229e-01]],

         [[-1.4857e-02, -4.3006e-02, -5.9084e-02],
          [-6.6485e-03, -6.0455e-02, -7.7892e-02],
          [-2.2638e-02, -5.3768e-02, -7.4316e-02]],

         [[ 8.3276e-02,  2.6158e-02, -2.1678e-01],
          [-1.3345e-01, -2.8881e-01, -1.2474e-01],
          [-3.7338e-01, -2.9140e-01, -1.1983e-01]],

         ...,

         [[-8.1383e-03, -4.9587e-03, -2.1028e-03],
          [-4.4010e-03, -1.6209e-03,  3.1504e-03],
          [-6.1092e-04,  1.2552e-03, -5.3144e-03]],

         [[ 1.1792e-02, -2.7062e-03, -3.8844e-03],
          [-1.7546e-03, -1.5361e-02, -9.7134e-03],
          [-3.5433e-03, -5.4995e-03, -2.7219e-03]],

         [[-7.8811e-03, -2.6094e-01, -2.7988e-01],
          [-1.4145e-01, -1.4226e-01, -3.1542e-01],
          [ 2.1230e-02, -2.0338e-01, -2.4090e-01]]],


        ...,


        [[[-2.9929e-01, -3.0268e-01, -2.6287e-01],
          [-2.9783e-01, -3.2071e-01, -2.3949e-01],
          [-3.1233e-01, -3.2161e-01, -2.6809e-01]],

         [[-3.4950e-02, -4.1251e-02, -3.6930e-02],
          [-3.8473e-02, -3.4362e-02, -3.8018e-02],
          [-3.6614e-02, -3.9380e-02, -3.5096e-02]],

         [[-1.7141e-01, -1.5779e-01, -1.4476e-01],
          [-1.7421e-01, -1.4054e-01, -1.5374e-01],
          [-1.1284e-01, -1.3553e-01, -1.4858e-01]],

         ...,

         [[-3.5638e-03, -2.7827e-03, -2.7394e-03],
          [-3.8445e-03, -3.7023e-03, -1.9841e-03],
          [-5.2670e-03, -4.6121e-03, -2.3858e-03]],

         [[-4.0673e-03, -2.9856e-03, -2.4181e-03],
          [-3.0785e-03, -2.0582e-03, -2.0237e-03],
          [-1.1365e-03, -2.0668e-03, -1.9191e-03]],

         [[-2.2178e-01, -2.4374e-01, -2.2302e-01],
          [-2.0329e-01, -2.1494e-01, -2.0253e-01],
          [-2.2835e-01, -2.2162e-01, -2.1170e-01]]],


        [[[-1.9047e-01, -5.0808e-01, -6.5154e-01],
          [-5.2507e-01, -5.0222e-01, -7.7457e-01],
          [-2.1515e-01,  8.5309e-02, -3.5444e-01]],

         [[ 3.1730e-02, -1.1143e-01,  1.3258e-02],
          [-6.2912e-02,  5.6852e-02, -3.5360e-02],
          [-4.4693e-02, -6.0705e-02, -1.5647e-02]],

         [[-2.1752e-01, -4.0753e-01,  1.6297e-01],
          [-2.4690e-01,  2.1465e-01, -1.9746e-01],
          [-3.6736e-01, -3.6167e-01, -3.7535e-01]],

         ...,

         [[-1.1183e-02, -9.8649e-03, -4.9530e-03],
          [-1.2929e-02, -9.7740e-03, -1.4051e-02],
          [-9.3559e-03, -6.5621e-03, -3.3315e-03]],

         [[ 8.0945e-03,  1.3655e-02,  8.0041e-03],
          [-5.6982e-03,  1.6569e-03, -4.8264e-03],
          [-4.1135e-03,  1.1967e-03,  4.5939e-03]],

         [[ 1.2224e-01,  3.1816e-01, -1.0589e-02],
          [-2.2472e-02, -3.1923e-01, -2.2589e-01],
          [ 2.7725e-03,  5.2618e-03,  1.2988e-02]]],


        [[[-4.9065e-01, -5.2073e-01, -5.2142e-01],
          [-6.1824e-01, -4.1892e-01, -5.3042e-01],
          [-7.6838e-01, -4.8344e-01, -6.1932e-01]],

         [[-1.0348e-01, -5.7851e-02, -8.9387e-02],
          [-8.2592e-02, -8.9406e-02, -8.5119e-02],
          [-9.8153e-02, -1.1333e-01, -1.1592e-01]],

         [[-5.3413e-01, -5.2772e-01, -4.8901e-01],
          [-3.7988e-01, -3.6942e-01, -5.1767e-01],
          [-4.2634e-01, -3.9946e-01, -4.8190e-01]],

         ...,

         [[-1.6936e-03, -4.2673e-03, -6.6556e-03],
          [-3.8203e-03, -4.7557e-03, -4.0910e-03],
          [-4.4072e-03, -1.1244e-03, -1.3580e-03]],

         [[-1.8637e-02, -5.6244e-03, -1.0103e-02],
          [-2.4488e-04, -1.3707e-03, -3.9373e-03],
          [-5.8170e-03, -9.9687e-03, -7.9207e-03]],

         [[-6.9425e-01, -5.7233e-01, -5.7277e-01],
          [-5.3208e-01, -6.1464e-01, -5.7705e-01],
          [-6.7009e-01, -4.8128e-01, -5.7393e-01]]]], device='cuda:0'), 'backend.0.bias': tensor([ 3.7435e-02,  8.6868e-03,  2.9687e-02,  9.5615e-02, -7.9370e-03,
        -2.2906e-01,  2.1799e-02,  1.2916e-01, -1.1742e-01,  5.3095e-02,
         6.5154e-02, -3.3856e-02, -1.8881e-01,  6.5476e-02,  1.1124e-01,
        -1.6869e-02, -9.0779e-02, -5.9172e-02, -1.5687e-02, -6.3595e-03,
        -1.0433e-01,  1.4868e-02,  2.4667e-01,  3.6994e-02, -5.4466e-02,
         1.1374e-02, -1.7108e-01, -2.9399e-02, -1.2781e-01, -2.2293e-02,
         5.0197e-02, -4.6588e-02, -4.9304e-02, -6.8111e-02, -1.1202e-01,
         1.1110e-01,  4.5685e-02,  1.5133e-01,  3.5386e-02, -2.8244e-02,
         4.8509e-02, -1.7623e-01,  1.0986e-01, -1.7990e-01,  3.6821e-02,
         6.6091e-03,  8.1262e-03,  1.3467e-01,  2.1311e-02, -2.2371e-02,
        -3.5822e-02,  1.0288e-01, -2.3761e-01,  1.0828e-01, -1.2286e-01,
         4.3771e-02,  9.0975e-02,  5.4293e-03,  6.3596e-03,  6.7665e-02,
        -8.3081e-03,  2.5766e-02,  1.2529e-01,  9.5695e-02, -3.2555e-02,
         1.1471e-03,  4.7835e-02, -1.0141e-01, -5.9007e-02,  1.1059e-01,
         1.9455e-03,  3.8479e-02,  1.3206e-02, -2.1735e-02, -5.8061e-03,
         5.6675e-02,  6.5930e-02,  2.8954e-02,  1.0560e-01,  8.2582e-03,
        -4.4967e-02,  1.1846e-03, -1.6334e-01,  3.3130e-02,  1.4979e-02,
        -5.1272e-02,  1.3312e-02, -1.1537e-01,  1.1990e-01, -2.9765e-03,
         2.5823e-02, -1.2387e-01,  3.3274e-02,  1.4201e-01, -1.8099e-02,
        -8.3500e-02, -1.2276e-01, -1.7765e-01, -1.7965e-01,  1.4993e-01,
        -2.8374e-04, -9.3312e-03,  1.3635e-01,  3.1086e-03,  3.3439e-02,
        -1.6648e-02, -3.7136e-02,  1.8646e-02, -1.6222e-02, -1.3726e-01,
        -2.6878e-02,  1.3328e-01, -2.0468e-02, -1.7346e-02,  1.0685e-01,
        -9.4512e-03, -3.3734e-02,  5.2323e-02, -6.5747e-02,  5.0566e-02,
         6.0393e-02, -2.3553e-02, -1.8967e-01,  6.2574e-03,  7.2337e-02,
        -1.7122e-02, -2.7200e-03, -9.6275e-02,  4.6930e-04, -2.2710e-01,
         6.5826e-03,  3.1450e-02, -7.9221e-03, -1.7999e-01,  1.5686e-01,
        -1.3607e-02, -3.6705e-02, -1.8343e-01,  1.3468e-01,  1.1924e-02,
        -1.4944e-02, -9.2973e-03,  3.1527e-02, -3.5561e-02,  8.4171e-03,
        -7.3547e-02,  6.9649e-02,  1.4172e-01, -5.6148e-02,  8.2017e-02,
         5.3280e-02,  9.1899e-02,  2.8376e-03, -1.3483e-02,  7.4775e-02,
         6.9643e-03, -2.7512e-02, -3.0703e-02, -2.0543e-01,  1.8875e-01,
         6.9805e-02,  3.3834e-02, -2.7313e-02, -2.0109e-01, -5.1881e-02,
         2.3696e-03,  1.0829e-01, -3.6844e-02, -8.6512e-02, -2.1700e-01,
        -7.0292e-02,  6.8958e-02,  3.1386e-02,  1.3123e-02, -3.2299e-02,
        -1.0123e-01,  8.2451e-02, -1.8404e-02,  2.7769e-02, -1.5899e-01,
         4.5788e-03,  1.1975e-02,  7.1424e-03,  4.3330e-03, -1.7068e-01,
        -3.9194e-02,  4.2246e-02,  8.9103e-02, -5.1278e-03, -5.4139e-02,
         1.3974e-03, -8.0118e-02, -5.2303e-02,  8.1217e-03,  1.2798e-01,
         8.6179e-02,  5.2950e-02,  7.4546e-02, -3.3942e-03,  1.7204e-01,
        -1.1362e-01,  1.4206e-01,  2.1858e-01,  9.2226e-02, -1.9899e-01,
         3.6390e-02, -1.1806e-01, -8.2607e-02,  9.6324e-02,  3.8894e-02,
        -4.3602e-03, -1.4082e-01,  8.5450e-02,  7.8835e-02,  4.1850e-02,
         1.1328e-02,  7.4670e-02,  6.7290e-02, -7.1616e-02, -1.5780e-01,
        -9.5894e-03, -2.2307e-02, -6.0844e-02,  9.7202e-02, -1.1720e-01,
         1.0029e-01, -1.0907e-02, -3.6494e-02, -2.5825e-04, -7.7160e-02,
        -1.7274e-01,  2.3191e-02, -1.9710e-02,  3.5280e-02, -1.4302e-01,
         1.2824e-02,  4.7918e-02, -1.6809e-01,  5.6044e-02,  7.4026e-02,
         2.2772e-02, -1.4494e-01, -4.2030e-02, -6.3803e-02,  1.2182e-02,
         4.3357e-02,  5.3708e-02,  4.2698e-02, -2.8498e-02,  1.4108e-01,
        -5.5324e-03,  9.1692e-02,  6.3695e-02, -3.4250e-02, -2.8302e-02,
        -5.3446e-02,  2.9550e-03, -5.0376e-02,  1.6558e-02,  1.2318e-01,
        -4.0763e-04, -9.3539e-02, -6.3956e-02, -1.3604e-02, -5.2656e-02,
         3.6483e-02, -9.6794e-02, -8.6376e-02,  4.8663e-04,  8.6020e-03,
        -1.0094e-01, -5.5459e-02, -6.2277e-03,  2.4522e-02,  1.6359e-01,
        -3.3313e-02,  4.5278e-02,  5.1332e-02, -1.2520e-01,  9.1645e-02,
        -5.9487e-02, -1.1458e-01, -6.1016e-02, -2.1344e-01,  2.6370e-02,
         1.8459e-02, -8.5330e-04,  3.9910e-01,  2.6680e-02, -1.6055e-01,
        -6.4645e-02, -5.6139e-02,  1.0158e-02, -1.4173e-02,  7.4238e-02,
         3.7757e-02, -7.6092e-02, -5.3070e-02,  4.9686e-02, -2.6026e-01,
        -1.8112e-01,  1.3090e-01,  2.7321e-02,  2.0811e-02,  3.8819e-02,
         4.0497e-02, -4.4816e-02, -3.4690e-02, -6.9139e-02,  1.2729e-01,
        -1.7978e-01,  3.2796e-02, -4.3860e-02,  9.0157e-02,  3.4750e-02,
        -5.8772e-02, -2.9963e-02, -2.5508e-03, -2.6114e-03, -3.0463e-02,
         4.8108e-02, -1.5034e-01,  4.0939e-02, -8.9530e-02, -2.2503e-02,
         2.5582e-02,  9.0480e-02,  6.8584e-02,  1.1664e-01, -1.2778e-02,
         1.4531e-02,  2.3291e-02, -8.2612e-02,  7.2054e-02,  6.5944e-03,
         5.9477e-02,  2.1410e-02, -1.0625e-01, -1.0625e-01, -8.5954e-02,
         8.7440e-02,  6.5846e-02,  1.9994e-02, -2.2161e-02, -7.1826e-02,
        -1.4754e-03, -2.1725e-02,  4.5513e-02,  4.6463e-02, -5.6594e-02,
         7.0406e-02, -7.1067e-02,  8.3108e-02,  7.8467e-02,  9.3381e-02,
         6.4178e-04,  4.0035e-02, -3.3862e-03,  4.2069e-02, -1.4598e-01,
         7.9622e-02,  1.4402e-01, -4.1291e-02,  4.3087e-02, -1.2321e-01,
        -1.4229e-01, -1.5477e-02, -1.5638e-01,  7.6902e-02, -1.8434e-02,
        -3.0861e-02, -7.7829e-02,  4.6241e-02,  1.0648e-01,  6.2955e-02,
         3.3869e-02,  5.2016e-02,  7.5418e-02, -1.0650e-01, -8.4486e-04,
        -1.1416e-01,  5.3096e-02,  1.0518e-01,  1.0734e-01, -8.4019e-02,
         1.3562e-01, -1.2335e-01, -4.9151e-02,  1.2403e-01, -8.0861e-02,
         1.4998e-01, -2.3118e-02,  1.0668e-01, -5.9596e-02, -1.0736e-02,
         4.4334e-02,  2.6921e-02, -5.7335e-02,  1.0289e-01,  2.2908e-01,
        -6.2295e-02,  4.3519e-02,  3.5141e-02, -3.7513e-02, -1.5320e-01,
        -1.7330e-01, -1.7242e-01,  1.1273e-01,  8.8121e-02,  1.7926e-02,
         1.5912e-01, -8.8514e-03,  3.6227e-03, -1.5002e-02, -9.1840e-02,
         2.3673e-02,  2.8328e-02,  2.2834e-02,  4.4368e-02, -6.7740e-02,
        -5.3698e-02, -3.3517e-03, -1.7343e-02, -9.4082e-03,  5.4577e-02,
        -5.9962e-02, -4.1874e-03, -5.1599e-02, -1.4496e-02, -7.0580e-02,
        -1.0849e-01,  1.7600e-01, -9.0257e-02,  1.1788e-01, -3.2394e-03,
         5.9323e-02, -6.7923e-02, -6.7786e-02,  3.3780e-02,  3.1117e-02,
        -1.1967e-01,  1.1624e-01, -6.5048e-02,  6.9480e-02,  3.6160e-02,
         1.8170e-02, -1.1414e-02, -2.2333e-02, -5.7602e-02,  4.2444e-02,
         1.4755e-02,  2.9847e-02,  9.0883e-02, -1.8335e-02, -1.7758e-01,
         6.6599e-02, -4.1333e-02, -5.6229e-02, -2.5876e-02, -1.4190e-01,
         2.3748e-03,  1.5121e-02,  8.3822e-03,  1.7195e-02,  4.8925e-02,
        -1.8419e-01,  1.6619e-04, -5.8998e-03, -2.3125e-01, -1.4528e-01,
         2.8597e-02,  4.2600e-02, -3.7203e-02,  1.2312e-02,  1.3099e-01,
        -3.3446e-02, -1.1550e-01, -3.2146e-02, -5.2976e-02,  3.4270e-02,
        -1.4025e-02, -7.2390e-03,  5.4483e-03, -2.1931e-02, -1.5543e-02,
         5.1916e-02,  6.7203e-03, -2.1290e-01,  8.3986e-02,  9.0955e-02,
        -1.9859e-02,  5.5644e-02,  7.0865e-02, -6.5067e-02, -1.8819e-02,
        -2.6506e-03, -1.0377e-02, -2.6327e-02,  1.3805e-01,  7.2932e-03,
         6.3787e-02, -1.9616e-02,  5.1556e-03, -6.8185e-02,  2.9797e-02,
         9.7752e-02,  1.3504e-01, -1.2660e-01,  6.2430e-04,  6.9422e-02,
         2.6582e-02,  5.3619e-02], device='cuda:0'), 'backend.10.weight': tensor([[[[-2.1959e-01, -3.3617e-01, -3.1556e-01],
          [-4.1270e-01, -3.4179e-01, -3.8507e-01],
          [-5.4396e-01, -5.1189e-01, -5.2420e-01]],

         [[-1.8068e-01, -1.1519e-01, -9.5161e-02],
          [-5.3012e-02, -3.9709e-02, -3.9325e-02],
          [-1.9610e-02, -1.2149e-02, -1.1782e-02]],

         [[-5.8630e-01, -4.5302e-01, -3.9153e-01],
          [-5.4708e-01, -2.9469e-01, -3.2340e-01],
          [-3.8501e-01, -3.9807e-01, -5.7451e-01]],

         ...,

         [[-9.7576e-02, -7.3513e-02, -7.1505e-02],
          [-5.3139e-02, -8.2465e-02, -6.4261e-02],
          [-5.2220e-02, -5.2127e-02, -5.7822e-02]],

         [[-7.6080e-01, -6.6571e-01, -8.5296e-01],
          [-6.0264e-01, -6.6787e-01, -6.7292e-01],
          [-1.1411e+00, -6.8185e-01, -6.6706e-01]],

         [[-1.8829e-01, -1.7583e-01, -2.0558e-01],
          [-1.6771e-01, -2.0710e-01, -3.6578e-01],
          [-1.1624e-01, -1.1664e-01, -1.4306e-01]]],


        [[[-2.3476e+00, -2.6140e+00, -2.5955e+00],
          [-3.0088e+00, -2.9354e+00, -2.9637e+00],
          [-3.3367e+00, -3.2346e+00, -3.2560e+00]],

         [[-3.5227e-01, -3.1430e-01, -2.8929e-01],
          [-3.8315e-01, -3.6267e-01, -3.4866e-01],
          [-1.9386e-01, -1.8508e-01, -1.6998e-01]],

         [[-2.3411e+00, -2.0769e+00, -1.9700e+00],
          [-2.4370e+00, -2.0338e+00, -2.0448e+00],
          [-1.9506e+00, -1.8898e+00, -2.0975e+00]],

         ...,

         [[-7.2566e-01, -7.4311e-01, -7.0555e-01],
          [-6.7706e-01, -7.6847e-01, -7.2329e-01],
          [-6.1618e-01, -6.6311e-01, -6.7481e-01]],

         [[-4.6668e+00, -4.4965e+00, -4.7603e+00],
          [-4.8601e+00, -4.4961e+00, -4.5276e+00],
          [-5.5612e+00, -4.5514e+00, -4.3601e+00]],

         [[-5.4382e-01, -5.9398e-01, -6.5607e-01],
          [-5.7638e-01, -6.7748e-01, -8.0152e-01],
          [-4.7273e-01, -5.1591e-01, -6.0473e-01]]],


        [[[ 5.0461e-01,  5.0912e-01,  5.1985e-01],
          [ 5.1670e-01,  5.3388e-01,  5.4456e-01],
          [ 5.2959e-01,  5.4138e-01,  5.4454e-01]],

         [[ 8.5475e-03,  1.2207e-02,  1.2803e-02],
          [ 2.4507e-02,  2.6864e-02,  2.6616e-02],
          [ 2.4521e-02,  2.6697e-02,  2.7364e-02]],

         [[ 1.6012e-01,  1.9595e-01,  1.9410e-01],
          [ 1.9142e-01,  2.1182e-01,  1.9630e-01],
          [ 1.9157e-01,  2.1010e-01,  2.0856e-01]],

         ...,

         [[ 1.0573e-01,  1.0355e-01,  1.0533e-01],
          [ 1.1294e-01,  1.1248e-01,  1.1330e-01],
          [ 1.1578e-01,  1.1593e-01,  1.1540e-01]],

         [[ 5.8945e-01,  6.1057e-01,  6.0976e-01],
          [ 5.8720e-01,  6.4044e-01,  6.4838e-01],
          [ 6.2204e-01,  6.5195e-01,  6.4490e-01]],

         [[ 3.2154e-02,  3.4026e-02,  2.0880e-02],
          [ 3.2994e-02,  4.0004e-02,  2.7592e-02],
          [ 3.6006e-02,  4.3411e-02,  3.7158e-02]]],


        ...,


        [[[ 1.8190e-01,  1.7046e-01,  1.6139e-01],
          [ 1.8184e-01,  1.8455e-01,  1.6810e-01],
          [ 1.5529e-01,  1.4892e-01,  1.3226e-01]],

         [[ 6.4871e-03,  1.1624e-02,  1.2358e-02],
          [ 5.4277e-02,  5.7847e-02,  5.7604e-02],
          [ 2.9974e-02,  3.2117e-02,  3.0282e-02]],

         [[ 7.2629e-02,  8.3997e-02,  7.7993e-02],
          [ 1.4803e-01,  1.6411e-01,  1.4653e-01],
          [ 1.2448e-01,  1.1466e-01,  9.5875e-02]],

         ...,

         [[ 2.1645e-02,  2.1378e-02,  2.0795e-02],
          [ 2.4206e-02,  2.2717e-02,  2.0400e-02],
          [ 1.9733e-02,  1.8385e-02,  1.5471e-02]],

         [[ 2.3900e-01,  2.4282e-01,  2.2168e-01],
          [ 2.5852e-01,  2.4316e-01,  2.4233e-01],
          [ 1.6480e-01,  1.7964e-01,  1.5443e-01]],

         [[ 1.5493e-02,  1.5617e-02,  2.1987e-02],
          [ 3.8231e-02,  3.1676e-02,  3.4201e-02],
          [ 3.2447e-02,  4.2885e-02,  4.5704e-02]]],


        [[[-1.1759e+00, -1.6960e+00, -1.5655e+00],
          [-2.0424e+00, -1.9111e+00, -1.9262e+00],
          [-2.5530e+00, -2.4314e+00, -2.4598e+00]],

         [[-5.2375e-01, -3.9010e-01, -3.5612e-01],
          [-1.7797e-01, -1.4278e-01, -1.5335e-01],
          [-5.4149e-02, -3.4321e-02, -4.5134e-02]],

         [[-2.4280e+00, -2.0517e+00, -1.8042e+00],
          [-2.3026e+00, -1.3931e+00, -1.5063e+00],
          [-1.5431e+00, -1.5189e+00, -2.2006e+00]],

         ...,

         [[-3.9746e-01, -3.2304e-01, -2.6708e-01],
          [-2.9420e-01, -3.7322e-01, -3.1304e-01],
          [-2.4681e-01, -2.3345e-01, -2.4592e-01]],

         [[-3.1743e+00, -3.0652e+00, -3.6059e+00],
          [-2.6640e+00, -2.7461e+00, -2.8847e+00],
          [-4.6844e+00, -3.0260e+00, -2.9310e+00]],

         [[-6.6746e-01, -6.5959e-01, -6.4882e-01],
          [-5.9409e-01, -7.4414e-01, -1.1450e+00],
          [-3.8093e-01, -3.7266e-01, -4.6022e-01]]],


        [[[-2.0956e-02, -2.0874e-02, -1.9518e-02],
          [-2.7313e-02, -2.4516e-02, -2.2938e-02],
          [-3.3471e-02, -3.3802e-02, -3.1649e-02]],

         [[-7.0705e-03, -8.3364e-03, -8.0707e-03],
          [-1.5045e-03, -2.1105e-03, -1.4246e-03],
          [-2.9152e-04, -2.5143e-04, -2.7530e-04]],

         [[-2.9277e-02, -2.6434e-02, -2.3441e-02],
          [-2.4026e-02, -2.1748e-02, -2.1338e-02],
          [-1.7061e-02, -2.5575e-02, -2.2425e-02]],

         ...,

         [[-3.2052e-03, -2.6869e-03, -1.9415e-03],
          [-1.3244e-03, -1.4512e-03, -1.2490e-03],
          [-1.7377e-03, -2.1666e-03, -1.5999e-03]],

         [[-3.7681e-02, -3.7452e-02, -3.5264e-02],
          [-3.3036e-02, -3.4708e-02, -2.4630e-02],
          [-4.1510e-02, -3.3301e-02, -3.4321e-02]],

         [[-1.6050e-02, -1.3616e-02, -1.1221e-02],
          [-9.7572e-03, -1.1921e-02, -1.2731e-02],
          [-5.4952e-03, -6.2393e-03, -4.1736e-03]]]], device='cuda:0'), 'backend.8.bias': tensor([ 4.9737e+00, -3.2972e+00, -1.2807e+00,  7.2608e-01, -1.5039e+00,
         1.6829e-01,  4.9959e-01, -2.1996e+00, -8.1899e-01, -1.3866e+00,
        -2.9949e-01, -4.3840e+00,  3.9718e-01, -3.1363e+00, -3.8491e+00,
        -2.6649e+00, -4.2858e-03, -5.9884e-01,  2.8110e+00, -2.2734e+00,
        -3.7313e-01,  7.8966e+00, -2.7427e-01, -4.5185e+00, -4.7506e-01,
         6.7307e+00,  2.4345e+00,  7.2646e+00, -3.2969e+00, -2.1476e+00,
        -1.9279e+00, -1.8337e+00, -1.6325e+00, -6.2015e-01, -9.9722e-01,
        -4.8325e+00,  2.9649e+00, -1.7396e+00, -1.6582e+00, -2.2803e+00,
         8.5869e-01,  3.3221e+00, -1.2001e+00,  9.5225e-02, -6.5972e-01,
         2.6132e+00, -3.0081e+00,  2.7432e+00, -2.9369e+00, -5.7038e-01,
        -4.1127e+00, -5.6516e+00, -3.8666e-01, -3.7298e+00,  7.6422e-01,
        -2.0456e+00, -2.0734e+00,  2.8771e-01, -2.2529e+00,  3.3025e+00,
         3.9578e+00, -2.1992e+00, -7.6606e-01, -1.0977e+00,  1.1326e-01,
        -3.4376e+00, -6.3099e-01, -7.0960e+00,  2.1510e+00,  1.8661e+00,
         2.0419e-01, -8.1414e-01,  4.6508e+00, -2.5497e+00, -4.1238e-01,
        -3.9497e+00,  2.1542e+00, -1.6452e+00, -1.1187e+00,  2.3748e+00,
        -5.8479e+00,  1.0999e+00,  9.7701e-02,  1.6046e+01, -1.4923e-01,
         3.7003e+00,  8.8302e-01, -4.3128e+00, -3.0774e+00,  5.0141e+00,
        -3.2504e+00,  2.5759e+00,  8.8290e-01, -1.0728e-01, -4.5347e-01,
        -2.7930e+00, -5.8308e+00, -1.6652e+00, -3.4447e-01, -4.6627e+00,
        -3.4878e+00, -2.0511e+00, -6.1618e-03,  5.6120e+00, -1.7160e-01,
        -5.2394e-01, -4.4822e-01,  1.6986e+00, -1.6533e+00, -2.3031e+00,
         2.8576e+00, -3.0470e+00, -5.3538e+00, -1.7170e+00,  8.7231e-01,
        -6.4554e+00, -1.1156e+00, -1.7039e+00,  9.7583e+00,  4.5827e-02,
         6.5802e+00, -2.2104e+00,  1.9929e+00, -5.2730e-02, -1.6266e+00,
        -1.3862e+00, -1.2762e+00, -3.9050e+00], device='cuda:0'), 'backend.6.weight': tensor([[[[ 1.7659e-02, -2.6832e-02,  1.1385e-02],
          [-9.5985e-03, -6.9888e-02, -7.4893e-02],
          [-5.2248e-02, -5.5227e-02, -7.9817e-02]],

         [[ 3.0971e-02,  5.7662e-02, -3.3492e-03],
          [-1.8451e-02, -1.3400e-02, -2.8495e-02],
          [-3.6402e-02, -7.0431e-02, -3.7302e-02]],

         [[-8.8065e-02, -1.2215e-01, -9.8337e-02],
          [-8.9382e-02, -4.0194e-02, -8.8762e-02],
          [-6.7900e-02, -6.4822e-02, -2.2596e-02]],

         ...,

         [[ 7.3210e-02, -2.9444e-02,  3.3526e-02],
          [ 1.1094e-02, -1.5081e-02, -2.0852e-02],
          [-5.2141e-02, -7.4994e-02, -8.7375e-02]],

         [[ 6.4951e-02,  5.9654e-02, -4.4957e-03],
          [-3.5679e-02,  6.1587e-02, -3.2397e-02],
          [-2.3371e-02, -6.1786e-02, -2.3975e-02]],

         [[-4.3150e-02, -2.9796e-02, -3.8641e-03],
          [-2.6559e-02, -1.7022e-02,  2.6667e-02],
          [ 4.5345e-02,  5.3840e-02,  8.0433e-02]]],


        [[[-1.8931e-02, -1.3767e-02, -2.2328e-02],
          [-1.8000e-02, -1.7059e-02, -1.7738e-02],
          [-1.7194e-03,  2.6559e-03, -3.2753e-03]],

         [[-4.8771e-03, -9.9159e-03, -1.8203e-02],
          [-9.3296e-03, -3.3826e-03, -1.0877e-02],
          [ 3.6881e-03, -3.0342e-03,  1.1092e-03]],

         [[-1.9347e-02, -1.9374e-02, -7.3066e-03],
          [ 1.2832e-02,  5.7084e-05, -5.6079e-03],
          [-1.6918e-02, -1.6682e-02, -2.7384e-02]],

         ...,

         [[-3.2147e-02, -5.1278e-02, -5.4454e-02],
          [-2.2433e-02, -6.8818e-03, -2.5640e-02],
          [-2.3895e-02, -3.1762e-02, -3.6114e-02]],

         [[-2.0606e-02, -3.0017e-02, -4.2410e-02],
          [-3.8847e-02, -2.1024e-02, -2.3158e-02],
          [-1.8859e-02, -2.0132e-02, -2.1347e-02]],

         [[ 3.0966e-02,  2.2453e-02,  2.1628e-02],
          [-1.4634e-02,  3.5282e-03,  8.0361e-04],
          [ 3.7982e-03, -2.6815e-03,  6.2534e-03]]],


        [[[ 1.6407e-01,  1.0967e-01,  1.5278e-01],
          [ 1.9659e-01,  1.5155e-01,  1.5199e-01],
          [ 1.1947e-01,  1.4954e-01,  1.1909e-01]],

         [[ 6.7720e-02,  1.4779e-01,  1.6977e-01],
          [ 1.0759e-01,  1.5109e-01,  1.3400e-01],
          [ 1.4679e-01,  1.1283e-01,  7.9238e-02]],

         [[ 4.3010e-01,  4.1349e-01,  3.3435e-01],
          [ 3.3524e-01,  3.7894e-01,  3.6660e-01],
          [ 3.4610e-01,  3.0348e-01,  3.2541e-01]],

         ...,

         [[ 1.7422e-01,  1.2319e-01,  1.7807e-01],
          [ 1.3168e-01,  1.4664e-01,  7.5703e-02],
          [ 8.7482e-02,  1.2710e-01,  1.0617e-01]],

         [[ 2.8918e-01,  2.1335e-01,  3.0835e-01],
          [ 2.9417e-01,  2.6610e-01,  3.8148e-01],
          [ 3.5822e-01,  1.8312e-01,  2.4300e-01]],

         [[ 6.2543e-01,  6.9266e-01,  6.6342e-01],
          [ 6.4601e-01,  6.5722e-01,  6.6194e-01],
          [ 7.1699e-01,  7.2908e-01,  6.5544e-01]]],


        ...,


        [[[-3.0835e-03, -5.4564e-03, -4.0023e-03],
          [-4.0692e-03, -5.8401e-03, -5.1373e-03],
          [-3.0648e-03, -2.8590e-03, -4.6756e-03]],

         [[-3.8954e-03, -4.8944e-03, -5.4124e-03],
          [-1.1260e-02, -8.1189e-03, -8.4610e-03],
          [-7.5158e-03, -1.0222e-02, -8.0836e-03]],

         [[-1.4891e-02, -1.4623e-02, -2.0755e-02],
          [-2.3570e-02, -1.8869e-02, -2.5201e-02],
          [-2.3054e-02, -2.1368e-02, -1.9387e-02]],

         ...,

         [[-7.3070e-03, -1.0875e-02, -7.4364e-03],
          [-6.0824e-03, -5.9057e-03, -9.7995e-03],
          [-5.6780e-03, -4.5554e-03, -5.1283e-03]],

         [[-6.7616e-03, -8.6668e-03, -1.2406e-02],
          [-1.7809e-02, -1.6932e-02, -1.4825e-02],
          [-1.3919e-02, -1.8692e-02, -1.7844e-02]],

         [[-1.1690e-02, -1.2990e-02, -9.4364e-03],
          [-3.4773e-02, -3.4121e-02, -3.0164e-02],
          [-3.9313e-02, -4.2817e-02, -4.0379e-02]]],


        [[[-1.1916e-02, -8.5963e-03, -1.0027e-02],
          [-9.8618e-03, -1.3041e-02, -9.8268e-03],
          [-1.3514e-02, -1.5581e-02, -1.3258e-02]],

         [[-4.4533e-03, -6.6127e-03, -5.6979e-03],
          [-4.0485e-03, -4.0086e-03, -5.0110e-03],
          [-4.2605e-03, -4.7118e-03, -7.7490e-03]],

         [[-2.5375e-02, -2.8867e-02, -3.2323e-02],
          [-1.9552e-02, -2.3627e-02, -2.7003e-02],
          [-1.9886e-02, -1.9896e-02, -2.6292e-02]],

         ...,

         [[-8.8458e-03, -8.3307e-03, -7.5917e-03],
          [-1.1403e-02, -1.1842e-02, -1.1067e-02],
          [-1.5496e-02, -1.6875e-02, -1.5704e-02]],

         [[-1.7235e-02, -2.2534e-02, -1.8845e-02],
          [-1.8398e-02, -1.8702e-02, -1.9821e-02],
          [-2.2294e-02, -1.8882e-02, -2.1458e-02]],

         [[-2.3913e-02, -3.0531e-02, -3.6398e-02],
          [-2.0194e-02, -2.3742e-02, -3.0163e-02],
          [-1.7456e-02, -1.2982e-02, -2.0532e-02]]],


        [[[-3.1058e-02,  1.6961e-02, -5.0719e-02],
          [-2.3574e-02,  2.1136e-02, -5.6134e-04],
          [-7.0931e-02, -4.7651e-02, -1.5537e-02]],

         [[ 4.7571e-02, -7.3380e-03,  3.1953e-02],
          [ 1.1158e-01,  5.7628e-02, -1.6490e-04],
          [ 1.5483e-03, -5.2596e-03, -5.0021e-03]],

         [[ 5.3417e-02,  2.0064e-01,  1.3220e-01],
          [-1.2124e-01, -1.6742e-01, -8.4608e-02],
          [-2.1417e-01, -2.5808e-01, -3.0919e-01]],

         ...,

         [[ 2.0335e-02,  1.1659e-01, -2.2835e-02],
          [ 1.9424e-01,  2.3623e-01,  1.9429e-01],
          [ 8.7267e-03,  4.6949e-02,  3.9763e-02]],

         [[-2.1546e-02,  4.8327e-02,  2.2329e-02],
          [ 1.4284e-01,  4.5181e-02, -4.6277e-02],
          [ 1.0123e-01,  2.4752e-01,  1.2154e-01]],

         [[-3.1303e-01, -2.8268e-01, -2.1845e-01],
          [-1.3687e-01, -1.7780e-01, -2.2222e-01],
          [-6.3106e-03,  3.5331e-02,  1.3386e-01]]]], device='cuda:0'), 'backend.2.bias': tensor([-9.5445e-02,  1.2118e-01, -7.2397e-03, -1.1388e-01, -1.4564e-01,
        -1.3560e-02,  3.4898e-03,  7.2919e-02,  7.2378e-02, -8.7557e-02,
        -2.1074e-01, -4.4167e-02, -1.4452e-04, -2.8609e-02, -7.1421e-02,
        -1.7638e-01,  7.6595e-02, -9.6582e-02, -3.9318e-02,  1.0934e-02,
        -9.4722e-03, -5.9582e-03, -1.8186e-01,  6.3051e-02, -9.9821e-02,
         6.5248e-02, -1.8788e-01, -2.5883e-02, -7.8021e-02, -1.6218e-01,
         2.9943e-02,  2.5169e-02, -1.4130e-01, -1.0984e-02,  1.9060e-01,
        -6.5444e-02,  2.4095e-01,  2.0355e-01,  5.0609e-02,  3.8263e-01,
         8.4443e-02,  5.4891e-04,  5.1957e-03, -5.1462e-03, -1.3074e-01,
        -9.0038e-02, -1.0444e-01, -7.5575e-02, -4.8598e-02, -1.1293e-01,
         1.2865e-02, -6.1113e-02,  3.9259e-02,  2.2154e-02, -1.2546e-01,
         5.5564e-02, -8.7546e-02, -4.8289e-01,  2.3833e-02,  2.4561e-04,
         1.9773e-02,  3.4710e-02, -1.0664e-01, -8.6273e-03, -3.3261e-02,
        -2.8559e-02,  1.6658e-02, -3.4660e-02, -2.5922e-01,  1.1552e-01,
         1.8185e-02, -1.5381e-01, -5.6098e-02, -5.9998e-02, -2.5072e-01,
        -1.1116e-01,  1.4272e-01, -2.8125e-02,  2.4978e-01,  1.3900e-01,
        -2.2722e-01,  1.6405e-02,  1.9513e-02, -1.4806e-02,  2.3785e-02,
        -2.5480e-02, -9.9124e-02,  5.5201e-03,  9.6780e-03,  9.0138e-04,
         1.0361e-01, -8.6632e-02,  8.5514e-02,  8.5149e-02,  4.3013e-01,
        -1.7292e-01,  2.5248e-01, -2.4305e-02, -1.4437e-01, -9.8616e-02,
        -2.0638e-02, -2.6136e-02, -3.1094e-01,  2.7443e-01,  1.5303e-02,
        -5.0389e-02, -7.4305e-02,  6.4034e-02,  1.5670e-02,  1.0776e-01,
         5.7240e-02, -6.2665e-02, -6.3629e-02, -1.7401e-01, -1.7384e-01,
        -2.9028e-02, -3.5188e-02, -1.0351e-01,  5.5872e-02, -3.7032e-02,
        -9.5961e-02, -8.1390e-02, -1.5220e-01,  1.9719e-01, -1.1948e-01,
        -1.6690e-01, -9.5103e-02,  1.5895e-01, -4.6991e-02,  8.7207e-03,
        -4.3617e-02,  1.1448e-01, -2.8034e-02,  1.1368e-01, -6.3128e-02,
         2.6905e-03,  2.8197e-02, -7.3619e-02, -1.2489e-01, -6.4813e-04,
         3.3710e-01, -2.7532e-02, -1.2788e-01, -1.1739e-01, -1.4322e-01,
        -6.4528e-02,  4.3953e-02,  4.8672e-02,  1.0128e-01, -5.3157e-02,
         1.9053e-02,  5.7649e-03, -2.0636e-01,  4.9393e-02,  1.0601e-01,
         2.6320e-01,  9.8343e-03, -4.2334e-02,  4.7639e-02,  4.1247e-02,
        -4.3124e-02,  4.6514e-02, -1.8738e-02, -1.7739e-01,  1.6252e-01,
         5.0900e-02,  5.9270e-02, -7.1250e-02, -1.3990e-01, -1.2607e-02,
         1.3636e-01, -1.9153e-02,  9.9167e-02,  9.7898e-03, -7.9707e-03,
         9.6061e-02, -1.1978e-02, -2.6987e-02,  5.5692e-02, -2.0705e-02,
        -7.5236e-03,  9.6907e-02, -2.6948e-02,  1.9295e-02, -1.2362e-01,
        -2.1191e-01,  2.5301e-02, -4.3556e-02,  5.8500e-02,  2.8259e-03,
         3.3449e-03, -2.0438e-01, -1.5361e-01, -7.2069e-02, -1.3362e-01,
        -6.9234e-02,  7.7568e-03, -2.2435e-01, -5.0221e-02, -6.3790e-02,
         1.4208e-01, -1.0317e-01, -4.3361e-02,  2.3451e-01, -1.0269e-02,
        -2.0785e-01, -1.0589e-01, -1.0867e-01,  7.9162e-02,  2.6166e-02,
        -3.6232e-02,  2.0472e-01, -4.7378e-02, -2.2673e-01,  8.8925e-02,
        -1.1418e-01, -3.3484e-02,  1.1014e-01,  5.6061e-02, -5.1889e-03,
         5.2242e-02,  4.1363e-01,  1.6679e-01, -2.8169e-02, -1.5872e-01,
         1.9176e-01, -2.1009e-03,  2.7883e-01,  1.0203e-01, -3.1559e-03,
        -1.3493e-01,  2.3951e-02,  6.8327e-03, -2.6368e-02, -1.9143e-03,
        -2.4798e-02, -9.5861e-02,  3.1373e-01,  1.0827e-01, -3.9025e-01,
         1.2347e-02,  1.6870e-01, -1.3238e-02,  9.2258e-02, -1.0211e-01,
        -2.7446e-01, -1.4298e-01,  4.5024e-03,  9.2050e-02, -9.7825e-03,
        -1.4301e-01, -5.0958e-02,  1.0820e-01,  7.1858e-02, -1.1097e-01,
        -2.3028e-02, -1.9033e-01, -3.1622e-01, -1.0966e-01,  2.0771e-02,
        -1.2985e-01,  7.2917e-02, -6.8903e-03,  2.2240e-02,  4.5559e-02,
         4.6629e-02,  1.0876e-01,  1.8415e-01,  2.5828e-02, -3.4740e-03,
        -3.4905e-02, -1.1110e-01, -7.5262e-05, -5.3387e-02, -2.1667e-01,
         2.3660e-01,  8.3036e-02,  1.6275e-01, -6.9704e-02, -2.4589e-03,
         3.3348e-01, -5.4760e-02,  2.8822e-02, -5.8684e-02,  3.8902e-02,
        -2.1664e-01,  2.5284e-03,  1.5021e-01, -1.5284e-02,  5.2181e-03,
         3.5757e-02,  9.5709e-02,  2.2947e-01, -8.4516e-03,  1.3986e-01,
         3.1626e-02,  2.7621e-01,  1.1267e-01,  7.1197e-03,  6.4725e-02,
         5.0483e-02, -1.1644e-01, -1.0756e-01,  7.3277e-02,  2.8580e-01,
        -1.7353e-01,  2.0274e-01, -5.0729e-01, -2.1406e-01, -1.3282e-01,
        -1.5440e-02, -9.0185e-02,  1.2485e-01,  7.0717e-03,  5.6439e-02,
        -2.2061e-02, -3.1489e-01,  7.7756e-02, -2.7833e-02, -3.0607e-02,
         6.8867e-02, -7.9891e-02, -2.6295e-02,  1.7896e-02,  1.6963e-01,
         8.7095e-02,  1.7397e-02, -2.1467e-01,  2.5737e-02,  1.3856e-02,
         8.3726e-03, -2.8858e-01,  1.6858e-03,  5.3386e-02,  9.3108e-02,
         6.1977e-03, -5.2589e-02,  1.9725e-01, -3.6482e-01, -1.1734e-01,
         2.1406e-01, -1.0737e-02, -3.6181e-01,  5.7253e-01, -5.5065e-02,
         3.8286e-02, -5.8543e-01,  2.0143e-01,  5.1481e-03,  1.5529e-01,
        -5.8388e-02,  9.6524e-02,  3.9119e-03,  1.5408e-01, -6.9690e-04,
         3.3011e-01,  8.9386e-02,  1.8885e-01, -1.6546e-02,  1.7813e-03,
        -6.3065e-02, -2.0381e-02, -7.3931e-02,  5.7187e-02, -2.2169e-01,
        -1.7594e-01,  7.2577e-02,  8.9698e-02,  1.4016e-01,  1.4531e-01,
        -4.8202e-02, -7.4429e-02, -1.2660e-01,  2.2440e-02, -1.7195e-01,
         5.1155e-02, -1.6276e-02, -8.0198e-02,  1.0578e-01, -3.3091e-02,
         1.2326e-01,  1.1280e-01,  1.3938e-02, -2.6170e-01, -4.8323e-02,
         1.8080e-01, -8.4014e-02,  4.3010e-02, -2.0495e-01, -4.6512e-02,
         2.2161e-01,  2.0267e-02, -2.6133e-01, -6.8644e-02,  1.0455e-02,
        -1.6854e-02, -4.4688e-01, -2.6738e-01, -5.5871e-02, -7.4338e-02,
        -4.4163e-01, -6.0502e-02, -4.2866e-02,  2.1001e-01, -3.5372e-02,
         1.9708e-01,  8.2742e-03, -6.6396e-03,  9.9982e-03, -1.5928e-01,
        -9.6029e-02, -8.3696e-02, -2.3542e-01, -3.2168e-02,  2.4577e-02,
        -4.3336e-01, -1.3247e-01,  3.6884e-02, -1.4186e-01,  5.9450e-03,
        -9.1733e-02, -1.2927e-01,  8.5177e-02, -1.1440e-03,  4.2597e-02,
         5.3823e-02, -1.4818e-01, -7.7130e-02, -2.5510e-02,  2.2265e-01,
        -6.6040e-02, -1.0947e-01, -4.1537e-01, -2.4051e-02,  2.0213e-01,
        -1.0381e-01,  3.8250e-02, -2.7224e-02, -4.7806e-02, -1.2562e-02,
        -1.4074e-02, -1.2187e-01,  1.6062e-01, -1.7874e-01, -1.2774e-03,
         1.0068e-01,  3.8112e-02, -1.4348e-01,  1.2197e-01,  1.3993e-03,
        -1.0440e-02,  6.5085e-02,  1.1839e-02, -7.3008e-02, -2.5583e-01,
         2.6130e-03,  1.5690e-01,  1.7598e-01,  6.9527e-02, -6.1461e-02,
        -9.7276e-02,  3.5660e-02,  4.7912e-02,  8.2740e-02,  1.4097e-02,
         4.9414e-02,  4.2054e-02,  1.4344e-01, -6.2793e-02,  4.0219e-04,
         1.5250e-01, -1.7522e-01, -5.9423e-02, -1.0787e-01, -2.6677e-03,
         4.5776e-02, -1.4194e-01,  3.6366e-01,  1.7674e-01,  3.2443e-01,
        -2.4558e-01,  1.8080e-02, -3.6560e-01,  2.6440e-03,  9.1669e-02,
         7.1586e-03, -9.6864e-02, -6.1576e-02, -3.0196e-01, -1.1254e-01,
        -5.5086e-02, -5.7570e-02,  1.0761e-01, -2.8561e-02, -4.1266e-01,
         4.0287e-02,  2.9999e-02, -6.0385e-02,  3.4558e-02, -2.6565e-01,
        -3.9133e-02, -5.7808e-02,  1.2102e-01,  5.8583e-02, -1.1469e-02,
         4.9079e-02, -1.0090e-01, -8.9322e-02, -9.7825e-02,  7.6055e-02,
        -2.5764e-01,  1.2565e-02], device='cuda:0'), 'backend.10.bias': tensor([-5.8029e+00, -5.3878e+01,  1.0696e+01,  2.2877e+01, -1.1115e+01,
         2.1028e-01, -3.5056e+00, -4.7255e+00, -1.8161e+00,  5.6121e-01,
        -4.5989e+00, -1.4484e+01, -2.5311e+01, -2.5464e-01, -1.0811e+01,
        -1.0108e+01,  2.4036e+00,  7.8466e-01, -1.4855e+01, -3.5416e+01,
         3.4983e+00, -1.6306e+01, -2.6800e-01, -1.6920e-02,  1.0981e+00,
         2.8397e+01,  8.6920e-01, -1.3417e+00, -4.1239e-01, -3.3987e+01,
        -1.3303e+01, -3.8404e+00, -7.8278e-01,  4.7887e-02, -2.9392e-01,
        -4.3888e+01,  3.2917e-01, -5.0268e+01, -4.0567e-01,  8.4493e-01,
         5.0143e+00, -5.7116e+01,  7.1828e-02,  1.0728e+00,  4.6707e-01,
        -3.4152e+01, -7.9422e+00,  4.3289e-01,  1.0090e+01, -6.5736e-01,
        -2.2008e+01,  1.0102e+00, -2.4218e-01, -1.8479e+01, -2.5554e-02,
         7.1699e+00,  1.1377e+00,  1.8071e+00,  4.5674e+00,  8.1736e+00,
         1.3086e+00,  2.5759e+00, -2.7065e+01, -2.6927e-01], device='cuda:0'), 'output_layer.bias': tensor([-2368.7083], device='cuda:0'), 'backend.2.weight': tensor([[[[-2.6743e-02, -3.9614e-02, -8.0122e-03],
          [-1.7407e-02, -5.3059e-02, -2.6566e-02],
          [-3.5895e-02, -4.0331e-02, -1.3288e-02]],

         [[-8.8569e-03, -7.8051e-03, -8.0927e-03],
          [-1.2177e-02, -8.5556e-03, -4.6050e-03],
          [-1.0736e-02, -2.2353e-03, -2.1007e-03]],

         [[-5.4202e-02, -2.8204e-02, -6.6149e-02],
          [-9.3613e-02, -8.7685e-02, -1.0216e-01],
          [-8.6319e-02, -6.5349e-02, -6.5383e-02]],

         ...,

         [[-6.8696e-02, -1.2343e-01, -6.7855e-02],
          [-5.2470e-02, -1.2090e-01, -9.2998e-02],
          [-1.5116e-01, -1.8670e-01, -1.7145e-01]],

         [[-3.5145e-02, -2.8826e-02, -2.5547e-02],
          [-4.4438e-02, -3.8223e-02, -3.8730e-02],
          [-2.2132e-02, -2.8051e-02, -2.6023e-02]],

         [[-2.7207e-02, -1.4603e-02, -2.6463e-02],
          [-1.3161e-02, -1.7328e-02, -2.3120e-02],
          [-3.2824e-02, -1.9330e-02, -3.9087e-02]]],


        [[[ 7.7710e-02,  3.7035e-02,  5.9199e-02],
          [ 6.9621e-02,  3.8969e-02,  3.4250e-02],
          [ 5.2235e-02,  4.0353e-02,  4.5524e-02]],

         [[ 8.7279e-03,  1.0780e-02,  1.1893e-02],
          [ 7.5953e-03,  7.7006e-03,  8.8360e-03],
          [ 1.1768e-02,  6.2627e-03,  1.1724e-02]],

         [[ 7.2415e-02,  8.9039e-02,  8.2410e-02],
          [ 8.0391e-02,  7.5213e-02,  6.3758e-02],
          [ 7.1168e-02,  1.0386e-01,  9.9016e-02]],

         ...,

         [[ 1.4388e-01,  1.0236e-01,  1.3851e-01],
          [ 1.2051e-01,  1.1337e-01,  1.7001e-01],
          [ 1.5284e-01,  1.2835e-01,  1.4203e-01]],

         [[ 6.6291e-02,  5.3915e-02,  5.6078e-02],
          [ 4.6756e-02,  4.0121e-02,  2.8891e-02],
          [ 3.1187e-02,  4.4870e-02,  4.0961e-02]],

         [[ 2.8076e-02,  3.7204e-02,  3.6337e-02],
          [ 1.5339e-02,  4.2386e-02,  3.7633e-02],
          [ 1.9188e-02,  3.1696e-02,  4.1697e-02]]],


        [[[-9.8590e-03, -5.9494e-04, -1.5903e-03],
          [-1.4475e-03,  7.3021e-03, -3.8610e-03],
          [-8.3023e-03, -4.2504e-05, -1.1306e-02]],

         [[-6.2725e-04, -3.3455e-04,  7.6462e-05],
          [ 4.1101e-03,  6.4964e-04, -1.6114e-03],
          [ 1.8856e-03,  1.6977e-03, -2.0552e-03]],

         [[-1.1348e-02, -4.0553e-03, -9.0501e-03],
          [-2.9625e-03, -7.6350e-03, -1.2747e-02],
          [-1.6145e-02, -2.2904e-02, -9.9338e-03]],

         ...,

         [[-1.6460e-02, -2.5880e-02, -7.2923e-03],
          [-3.2706e-02,  8.7725e-03, -2.2339e-02],
          [-3.5233e-03,  5.4272e-03, -9.8809e-03]],

         [[ 5.0234e-03, -4.1964e-03,  3.6696e-03],
          [ 7.6086e-03, -2.2838e-03,  6.1409e-03],
          [-9.2007e-03, -6.9912e-03, -5.7220e-03]],

         [[-4.1636e-03, -5.1102e-03,  1.0456e-03],
          [-7.3523e-03, -3.9130e-03,  8.5424e-03],
          [-5.4494e-03, -4.1669e-03, -1.1901e-02]]],


        ...,


        [[[-8.8274e-03,  4.3762e-03,  6.6472e-02],
          [-8.1395e-03,  2.4337e-02,  4.2203e-02],
          [-1.7271e-02,  3.1401e-02,  6.8162e-02]],

         [[-4.0401e-03,  5.5717e-03,  1.0041e-02],
          [ 2.1242e-03,  7.6131e-03,  1.1766e-03],
          [ 6.4582e-04,  9.1160e-03,  6.0503e-03]],

         [[-2.5099e-02,  1.5326e-02, -1.1102e-03],
          [ 1.4317e-03,  2.7358e-02, -5.7295e-03],
          [-1.0060e-02,  1.4976e-03, -1.9915e-03]],

         ...,

         [[ 2.0682e-01,  1.0093e-01,  1.4818e-01],
          [ 6.5353e-02,  1.9606e-01,  2.1523e-01],
          [ 1.7583e-01,  1.0937e-01,  1.1586e-01]],

         [[-1.5120e-02, -9.0391e-03,  1.3653e-03],
          [-2.0698e-02, -1.1765e-02, -4.5474e-03],
          [-1.5399e-02, -1.9579e-02, -1.5346e-02]],

         [[ 8.9641e-03,  4.3921e-02,  3.4449e-02],
          [ 3.6677e-02,  5.0559e-02,  1.8873e-02],
          [ 3.5363e-02,  5.3386e-02,  2.4553e-02]]],


        [[[-6.4073e-02, -7.1425e-02, -1.3557e-01],
          [-1.0439e-01, -1.0575e-01, -1.1695e-01],
          [-1.1025e-01, -1.1215e-01, -1.0477e-01]],

         [[-1.5107e-02, -2.1762e-02, -2.7486e-02],
          [-2.0305e-02, -1.2360e-02, -2.1811e-02],
          [-2.3954e-02, -1.2941e-02, -1.2730e-02]],

         [[-1.3945e-01, -1.1372e-01, -1.1283e-01],
          [-1.5474e-01, -1.2211e-01, -1.1001e-01],
          [-1.8234e-01, -1.5628e-01, -1.4351e-01]],

         ...,

         [[-4.4711e-01, -4.0074e-01, -4.7918e-01],
          [-3.8266e-01, -4.4923e-01, -4.4080e-01],
          [-4.6187e-01, -4.5300e-01, -4.6997e-01]],

         [[-2.4722e-02, -3.4569e-02, -2.5149e-02],
          [-3.2767e-02, -3.5458e-02, -3.5848e-02],
          [-2.8946e-02, -3.0528e-02, -3.7151e-02]],

         [[-6.7310e-02, -7.3472e-02, -8.8186e-02],
          [-9.3798e-02, -9.4707e-02, -9.7847e-02],
          [-9.2636e-02, -8.5534e-02, -7.9306e-02]]],


        [[[-3.6620e-02, -1.3962e-02, -1.0299e-02],
          [-8.8741e-02, -4.4200e-02, -1.8938e-02],
          [-7.0730e-02, -3.1265e-02,  2.7327e-02]],

         [[-9.3137e-03,  8.7427e-04, -9.4217e-03],
          [-5.9766e-03, -2.6659e-03, -8.2795e-03],
          [ 3.5144e-03,  4.4633e-03, -7.3970e-04]],

         [[ 7.3822e-02,  4.9792e-02,  1.5396e-02],
          [ 1.2660e-01,  1.1229e-01,  9.8424e-02],
          [ 4.8686e-02,  5.5704e-02,  1.0727e-01]],

         ...,

         [[-8.3061e-02, -1.9620e-02,  9.4110e-02],
          [-1.6087e-02,  5.3200e-02,  5.2265e-02],
          [ 5.3613e-02,  5.5292e-02,  4.2041e-02]],

         [[-3.1701e-02, -4.6874e-02, -5.6747e-02],
          [-1.4007e-02, -1.7434e-02,  8.5385e-03],
          [-3.1721e-03, -1.3171e-02, -6.2188e-03]],

         [[-1.9242e-03,  1.0770e-02,  9.0755e-03],
          [-1.2533e-02, -1.8881e-04, -3.9585e-03],
          [-4.5672e-03, -1.1593e-02,  7.9196e-03]]]], device='cuda:0'), 'backend.6.bias': tensor([-8.3898e-02, -1.6172e-02,  1.1420e+00, -5.7551e-02,  5.3863e-01,
        -8.3389e-01,  1.1408e-01,  3.1573e-02, -1.6201e-01, -2.2798e-01,
        -1.0613e+00,  1.7285e-02, -1.9214e+00, -1.1184e-01, -6.8129e-01,
         2.2950e-02, -1.4048e+00, -2.4419e-01,  9.4105e-01,  2.4619e-01,
         3.1539e-01, -3.4581e-01,  4.3028e-01,  2.8217e-03, -6.5242e-01,
         1.2156e+00, -1.1701e+00,  9.7105e-02,  1.8542e-01, -8.4765e-01,
        -8.2549e-02,  8.8012e-01,  1.3529e+00,  1.4453e-01, -1.8760e-01,
         2.3450e-01, -5.5987e-02,  4.2681e-01, -3.5006e-01,  5.4509e-01,
        -8.3722e-01,  6.0964e-02,  8.9376e-03, -6.9759e-03,  2.5819e-01,
        -8.1418e-01, -1.1959e+00,  7.2166e-01, -1.3467e-01, -9.9605e-01,
         2.0732e+00,  7.9013e-01,  1.2127e+00, -1.5427e-01,  2.0352e-01,
        -5.0857e-01, -2.5497e-01, -2.5927e-01, -5.9108e-03, -1.0637e-01,
        -7.7560e-01, -3.9563e-01, -5.0864e-01, -4.2363e-01, -1.1203e-01,
         1.5607e+00,  1.1222e+00, -2.8460e-01, -5.2958e-01,  4.4043e-01,
        -2.0771e+00,  1.1595e+00,  5.9845e-01,  6.1729e-02,  3.3175e-02,
        -4.1539e-01,  5.6374e-01, -1.5174e+00, -9.2519e-01, -7.4753e-01,
         2.4033e-03, -7.1819e-02, -3.7930e-01, -1.2810e+00,  1.7283e+00,
        -1.5666e-02, -1.0817e-01,  4.1597e-01, -5.1974e-01, -2.8065e-01,
         4.1467e-01, -2.6418e-01, -9.3957e-01,  1.0207e+00,  2.1993e-01,
         7.7892e-01, -1.2826e-02, -9.0745e-01,  5.0318e-01, -1.2849e+00,
        -1.3128e+00,  1.6148e-02,  1.0761e-01,  1.2552e-02, -7.9037e-01,
        -4.6911e-01, -1.1418e+00, -7.8196e-02,  2.5988e-03,  1.5219e-02,
         5.2964e-02, -5.6886e-01,  2.0896e-01, -2.1517e-02,  4.7351e-01,
        -1.4713e+00, -3.6948e-01,  2.1909e-02,  1.2982e+00,  1.3832e+00,
        -4.6231e-01, -2.0406e-02,  2.7873e-02, -1.9149e+00,  1.5788e+00,
        -8.4886e-01,  1.3790e+00,  3.3353e+00, -1.1661e+00, -4.0027e-01,
         1.9986e-01,  1.0772e+00,  9.1899e-01, -6.6467e-01,  4.5549e-01,
         1.8903e+00, -7.6614e-01,  2.3348e-02, -1.0125e+00, -2.0532e+00,
        -8.9911e-01,  1.2650e+00, -1.0543e+00,  8.2443e-01, -8.1073e-01,
        -4.6521e-02, -4.7350e-04, -3.0504e-01, -9.6906e-03, -5.8533e-01,
        -5.4517e-01, -6.6429e-01, -2.3237e-02,  2.0377e+00,  1.8188e+00,
        -7.2864e-01, -2.5926e-02,  4.8815e-02, -2.2780e-04, -5.5809e-01,
        -3.7023e-01, -1.1683e-01, -1.0920e+00, -8.0474e-03,  8.5100e-02,
         1.4044e+00, -1.8894e-02, -1.2077e-01, -2.6243e-01, -4.0546e-01,
         2.1496e-02,  9.4085e-02, -6.4142e-01, -1.6538e+00, -8.9192e-01,
        -4.8411e-01,  1.4858e-02,  5.2869e-01,  1.6901e-01, -2.0868e-01,
         1.7790e-02,  4.9152e-01,  4.9781e-01, -7.0547e-01,  1.7543e-01,
        -7.4892e-01, -5.0036e-01, -6.2178e-02,  3.3094e-02,  1.9181e+00,
         4.4188e-01,  2.4910e-01, -3.7713e-01,  1.5005e+00,  3.7024e-01,
        -1.5421e-01, -2.9336e-01, -2.8169e-01, -1.0113e-01, -1.9074e+00,
        -6.8935e-01, -6.8837e-01,  1.9108e-01, -6.8252e-01, -6.3966e-01,
         1.6775e-01,  8.4237e-01, -4.1269e-01,  1.0999e+00,  1.0861e+00,
         5.0101e-01,  2.0691e-02, -7.4591e-01, -4.0649e-01,  3.1674e-01,
         4.7350e-02, -1.3425e-02,  4.4528e-01, -1.0489e+00, -1.3415e+00,
         3.2184e-01,  8.5183e-01, -3.3267e-01, -2.9079e-01, -4.9677e-01,
        -1.3985e-01,  4.5514e-02,  6.9376e-01, -1.9076e+00,  1.0485e+00,
        -5.9901e-01,  1.0391e+00, -3.5584e-01, -1.5562e-01, -7.4192e-01,
         1.9428e+00, -1.1659e+00, -4.8475e-02, -9.1319e-02, -1.1107e+00,
        -7.8743e-01, -1.0142e+00,  1.9766e-02,  6.6773e-02, -1.4531e-01,
        -2.2162e-01,  3.6885e-01, -3.8783e-01,  3.8288e-01, -7.1044e-01,
        -2.3415e-01, -3.7066e-01,  5.3615e-01, -6.6176e-02, -6.9477e-02,
         9.0231e-04], device='cuda:0'), 'backend.0.weight': tensor([[[[-1.0965e-02, -1.7620e-02, -1.1160e-02],
          [-3.1534e-03, -5.4647e-03, -6.9491e-03],
          [ 4.9162e-03,  6.9467e-03,  1.3822e-03]],

         [[-9.4743e-02, -8.2674e-02, -6.6372e-02],
          [ 5.5764e-03, -1.3236e-02, -4.1413e-02],
          [ 9.9202e-02,  7.3027e-02, -2.9823e-03]],

         [[ 5.2260e-02,  5.8763e-02,  5.5729e-02],
          [ 6.1537e-02,  8.4551e-02,  3.7032e-02],
          [ 1.0334e-01,  9.4035e-02,  6.6055e-02]],

         ...,

         [[ 4.8527e-04,  4.6796e-04,  3.1704e-03],
          [ 1.0340e-04, -2.0709e-03, -2.6304e-03],
          [ 7.7471e-04, -3.3153e-03, -2.7112e-03]],

         [[ 2.9965e-03, -6.2056e-03,  2.7157e-02],
          [-5.4858e-03, -1.4378e-02,  8.3999e-04],
          [-1.3346e-03,  7.5232e-03, -1.0117e-02]],

         [[ 7.4049e-02,  9.7487e-02,  1.3282e-01],
          [ 8.5059e-02,  8.1244e-02,  8.0770e-02],
          [ 7.5956e-02,  9.3830e-02,  8.4562e-02]]],


        [[[ 3.3562e-03,  5.4455e-03,  3.4570e-03],
          [ 7.2755e-03,  8.1888e-03,  2.1705e-03],
          [ 5.1378e-04,  5.7353e-03,  8.8268e-03]],

         [[ 1.1156e-01,  1.0452e-01,  8.9039e-02],
          [ 9.8318e-02,  1.2030e-01,  8.4501e-02],
          [ 8.3781e-02,  8.3955e-02,  6.3718e-02]],

         [[ 1.8970e-02,  2.2375e-02,  1.1430e-02],
          [ 1.7493e-02,  1.1409e-02,  1.2682e-02],
          [ 4.9658e-04, -3.6679e-03, -6.4819e-03]],

         ...,

         [[ 4.9066e-03,  4.3095e-03,  2.7887e-04],
          [ 3.1390e-03,  2.7697e-03,  4.3246e-03],
          [-1.0944e-03,  2.5523e-03,  2.1073e-03]],

         [[ 1.2171e-02,  1.2222e-02,  7.5667e-03],
          [ 1.7480e-02,  2.1930e-02,  1.4792e-02],
          [ 1.9990e-02,  2.3993e-02,  2.8636e-02]],

         [[ 9.6590e-03, -4.9525e-03,  1.7026e-02],
          [ 5.5919e-03, -9.2172e-03,  2.0788e-02],
          [-8.4711e-03, -1.2834e-04,  8.8654e-03]]],


        [[[ 1.0118e-02,  1.2773e-02,  7.2161e-03],
          [ 1.0304e-02,  1.2340e-02,  4.9387e-03],
          [ 1.7318e-02,  2.1504e-02,  1.9964e-03]],

         [[ 2.1414e-01,  1.4136e-01,  1.1734e-01],
          [ 2.9939e-01,  2.4249e-01,  1.0766e-01],
          [ 2.0077e-01,  2.0029e-01,  4.3070e-02]],

         [[ 4.6797e-02,  5.1595e-02,  4.4769e-02],
          [ 3.4121e-02,  5.9094e-02,  4.1480e-02],
          [ 7.0838e-02,  7.7758e-02,  7.5427e-02]],

         ...,

         [[-6.3569e-04, -4.8501e-04, -4.7804e-03],
          [ 1.0010e-02,  5.5793e-03,  5.0050e-03],
          [ 8.7090e-03,  4.7928e-03,  6.8313e-03]],

         [[ 5.1332e-02,  2.5490e-02,  5.5949e-03],
          [ 4.4769e-02,  3.4321e-02,  7.7112e-03],
          [ 3.5575e-02,  4.2393e-02,  2.2568e-02]],

         [[ 5.0630e-02,  2.1959e-02,  8.0026e-02],
          [-2.6765e-02,  7.8556e-03,  5.7531e-02],
          [ 7.2559e-02,  8.3124e-02,  7.9691e-02]]],


        ...,


        [[[ 2.0044e-02,  6.3764e-03,  5.0200e-04],
          [ 2.1295e-02,  8.4860e-03, -6.0191e-03],
          [ 1.8922e-02,  1.4829e-02,  8.0012e-03]],

         [[ 2.1408e-01,  1.7944e-01,  2.6113e-02],
          [ 2.9567e-01,  2.6751e-01,  9.5503e-02],
          [ 2.9139e-01,  2.5382e-01,  8.2906e-02]],

         [[ 1.7746e-01,  1.9658e-01,  1.8618e-01],
          [ 7.2045e-02,  4.3124e-02,  1.0901e-01],
          [ 1.5234e-01,  1.9394e-01,  1.6790e-01]],

         ...,

         [[ 3.3877e-03, -5.1776e-04,  1.4072e-03],
          [ 3.2954e-03,  6.6862e-04, -3.8081e-03],
          [ 9.4259e-03,  8.2753e-03,  4.3093e-03]],

         [[ 6.2550e-02,  3.2154e-02, -9.1813e-03],
          [ 6.9782e-02,  1.9212e-02, -1.8663e-02],
          [ 7.1130e-02,  4.4201e-02,  1.8714e-03]],

         [[ 2.4898e-01,  2.3219e-01,  3.5021e-01],
          [ 3.2858e-02,  3.7564e-02,  1.8472e-01],
          [ 1.1136e-01,  1.3887e-01,  1.8594e-01]]],


        [[[ 4.4694e-02,  4.3510e-02,  3.1191e-02],
          [ 4.5765e-02,  4.5040e-02,  4.3091e-02],
          [ 5.0478e-02,  5.0647e-02,  4.6610e-02]],

         [[ 4.8131e-01,  4.9007e-01,  4.3751e-01],
          [ 4.3487e-01,  4.5149e-01,  4.4865e-01],
          [ 3.1297e-01,  3.5288e-01,  3.5299e-01]],

         [[ 4.8868e-02,  5.6781e-02,  6.4834e-02],
          [ 3.0821e-02,  3.8099e-02,  4.7188e-02],
          [ 6.1474e-02,  5.3461e-02,  4.0251e-02]],

         ...,

         [[ 1.1525e-02,  1.3003e-02,  1.0197e-02],
          [ 5.2146e-03,  1.3580e-03,  8.1857e-03],
          [ 6.3619e-03,  2.3230e-03,  4.0533e-03]],

         [[ 6.6032e-02,  5.6164e-02,  2.7974e-02],
          [ 5.5589e-02,  5.5609e-02,  3.7570e-02],
          [ 2.7231e-02,  1.7299e-02, -1.6126e-03]],

         [[ 4.3124e-02,  2.8378e-02,  3.5877e-02],
          [ 1.2766e-02,  2.6667e-02,  2.7423e-02],
          [ 5.3279e-02,  7.6968e-02,  1.1785e-02]]],


        [[[ 9.0563e-03,  9.5053e-03,  1.0586e-02],
          [ 1.3179e-02,  1.0427e-02,  1.5776e-02],
          [ 1.5143e-02,  1.6777e-02,  1.7506e-02]],

         [[ 1.0941e-01,  1.0080e-01,  1.7831e-01],
          [ 1.3935e-01,  1.4261e-01,  2.3914e-01],
          [ 1.8721e-01,  1.9382e-01,  2.4268e-01]],

         [[ 5.9847e-02,  6.3961e-02,  5.8497e-02],
          [ 9.4831e-02,  1.2498e-01,  1.2457e-01],
          [ 9.6726e-02,  1.0555e-01,  9.4719e-02]],

         ...,

         [[ 4.8407e-04,  2.5725e-03,  1.3074e-03],
          [ 3.2864e-03,  2.4150e-03,  3.0782e-03],
          [ 3.2824e-03,  2.0314e-03,  1.3950e-03]],

         [[ 1.3698e-02,  7.8328e-03,  2.1782e-02],
          [ 1.6425e-02,  1.2317e-02,  2.7761e-02],
          [ 1.4945e-02,  1.5759e-02,  1.8320e-02]],

         [[ 8.6319e-02,  1.5244e-01,  1.0609e-01],
          [ 1.5536e-01,  1.3365e-01,  1.5492e-01],
          [ 1.0859e-01,  8.9653e-02,  6.4164e-02]]]], device='cuda:0'), 'output_layer.weight': tensor([[[[-1.6358e+00]],

         [[-2.5940e+01]],

         [[-2.2885e+01]],

         [[-4.2481e+01]],

         [[-8.9195e+00]],

         [[-4.3450e-01]],

         [[-4.4648e+00]],

         [[-8.7988e+00]],

         [[-9.7922e+00]],

         [[-6.4884e+00]],

         [[-1.6077e+00]],

         [[-9.1065e+00]],

         [[-9.2577e+00]],

         [[-8.4950e+00]],

         [[-3.1119e+00]],

         [[-4.4014e+00]],

         [[-1.1049e+00]],

         [[-9.0646e+00]],

         [[-1.0693e+01]],

         [[-1.3028e+01]],

         [[-1.9226e+01]],

         [[-5.4063e+00]],

         [[-1.7429e+00]],

         [[-4.2664e-01]],

         [[-1.4460e+00]],

         [[-6.2714e+01]],

         [[-1.6194e+00]],

         [[-1.6695e+00]],

         [[-1.2076e+00]],

         [[-1.8779e+01]],

         [[-4.6703e+00]],

         [[-1.2733e+01]],

         [[-1.3408e+00]],

         [[ 4.5206e-02]],

         [[-4.8045e+00]],

         [[-1.6932e+01]],

         [[-6.8475e-01]],

         [[-2.4269e+01]],

         [[-4.6628e-01]],

         [[-6.4551e+00]],

         [[-3.5551e+00]],

         [[-2.7895e+01]],

         [[-2.5402e-01]],

         [[-4.7532e-01]],

         [[-1.3100e-01]],

         [[-1.7155e+01]],

         [[-2.8089e+00]],

         [[-2.4248e-01]],

         [[-1.8241e+01]],

         [[-4.4687e-01]],

         [[-5.6391e+00]],

         [[-2.1812e+00]],

         [[-1.2111e-01]],

         [[-4.8903e+00]],

         [[-4.5772e-03]],

         [[-2.9828e+01]],

         [[-1.2588e+00]],

         [[-2.7432e+00]],

         [[-3.9311e+00]],

         [[-2.8007e+01]],

         [[-3.5534e+00]],

         [[-2.1570e+00]],

         [[-1.0613e+01]],

         [[-2.9810e-01]]]], device='cuda:0'), 'backend.4.weight': tensor([[[[-1.2049e-02, -6.0804e-02, -5.4470e-02],
          [-8.9146e-03, -8.2508e-02, -6.2419e-02],
          [-1.1260e-02, -5.8707e-02, -4.9905e-04]],

         [[-3.8529e-02, -2.3250e-02,  2.3059e-02],
          [-6.0005e-02,  3.9833e-02,  4.6436e-02],
          [-1.0442e-01, -3.2645e-02, -1.4298e-04]],

         [[-1.3504e-02, -2.6101e-02, -1.9275e-02],
          [-1.5315e-02, -2.7579e-02, -7.4564e-03],
          [-3.1707e-02, -1.0187e-02, -1.2930e-02]],

         ...,

         [[ 4.6738e-03, -5.3108e-02, -8.8509e-02],
          [ 4.9762e-02, -9.0174e-02, -3.2584e-02],
          [-4.8893e-02,  1.3480e-02,  3.9005e-02]],

         [[-5.9419e-02, -1.0136e-01, -1.1546e-01],
          [-7.5363e-02, -4.8470e-02, -2.4965e-02],
          [-4.4913e-02, -1.8796e-02, -1.4597e-02]],

         [[-8.9496e-02, -3.5858e-02, -1.2368e-02],
          [-2.1256e-02, -2.2860e-02, -6.7884e-02],
          [-1.1565e-01, -7.2963e-02, -5.9713e-02]]],


        [[[-6.1421e-02, -7.4409e-02, -5.5027e-02],
          [-8.4431e-02, -5.0343e-02, -1.7650e-02],
          [-4.9212e-02, -2.8633e-02, -3.9525e-02]],

         [[-1.1809e-01, -1.2985e-01, -1.3566e-01],
          [-1.5668e-01, -1.1772e-01, -1.3297e-01],
          [-1.5706e-01, -1.5218e-01, -1.7541e-01]],

         [[-3.7270e-02, -3.6366e-02, -3.9533e-02],
          [-3.3907e-02, -2.5396e-02, -3.3014e-02],
          [-2.8684e-02, -1.9192e-02, -1.9853e-02]],

         ...,

         [[-1.4428e-01, -1.3440e-01, -4.8936e-02],
          [-8.5696e-02, -9.6212e-02, -5.4566e-02],
          [-1.2662e-01, -7.0622e-02, -9.3470e-02]],

         [[-1.1058e-01, -7.2285e-02, -7.5916e-02],
          [-9.1712e-02, -5.9536e-02, -8.4217e-02],
          [-6.3677e-02, -6.2909e-02, -1.0002e-01]],

         [[-2.0823e-01, -2.0906e-01, -2.1805e-01],
          [-1.7231e-01, -2.0222e-01, -2.3789e-01],
          [-2.6540e-01, -2.6746e-01, -2.9672e-01]]],


        [[[ 2.7772e-03,  2.2999e-03, -5.3761e-02],
          [-2.6934e-02,  4.3403e-02, -7.2006e-02],
          [ 1.5621e-03,  1.1806e-02, -7.6259e-02]],

         [[-1.1999e-02,  1.6805e-02,  6.0268e-02],
          [ 7.1735e-02, -4.5542e-03,  5.1573e-02],
          [ 8.9457e-02,  8.7168e-02,  1.6582e-01]],

         [[-3.9869e-03,  9.4175e-03,  2.3183e-02],
          [ 3.4039e-02, -1.6632e-03,  2.0193e-02],
          [ 1.2939e-02, -1.6655e-03,  1.1720e-02]],

         ...,

         [[-5.3541e-02,  1.3020e-01, -1.4320e-01],
          [-8.9344e-02,  8.4100e-02, -1.5566e-01],
          [ 6.7427e-02, -2.3242e-02, -2.0595e-01]],

         [[ 3.7305e-02, -9.8501e-03,  4.2859e-02],
          [ 6.3234e-02, -4.5390e-02, -6.4480e-02],
          [ 6.6965e-03, -1.4844e-01, -1.3271e-02]],

         [[ 6.5942e-02,  8.0933e-04,  5.4286e-02],
          [ 7.0927e-03, -9.7528e-02,  9.8901e-02],
          [ 1.2406e-01,  7.0388e-02,  1.2213e-01]]],


        ...,


        [[[-9.2292e-02, -3.1216e-02, -7.2767e-02],
          [-9.2674e-02, -9.8752e-02, -1.3588e-01],
          [-1.0899e-01, -1.5503e-01, -7.5264e-02]],

         [[-1.1606e-01, -1.4396e-01, -5.8015e-02],
          [-3.7692e-02, -6.5500e-02, -8.3959e-02],
          [-6.8774e-02, -8.4262e-02, -5.5587e-02]],

         [[-3.3651e-02, -2.5016e-02, -3.0571e-02],
          [-2.4607e-02, -3.8932e-02, -3.2553e-02],
          [-2.4548e-02, -2.5013e-02, -2.2983e-02]],

         ...,

         [[-1.4992e-01, -1.0191e-01, -1.7541e-01],
          [-2.3860e-01, -2.6577e-01, -1.5842e-01],
          [-1.5260e-01, -1.9920e-01, -1.9439e-01]],

         [[-2.2625e-01, -2.1584e-01, -1.7163e-01],
          [-1.7381e-01, -1.5323e-01, -1.7070e-01],
          [-1.4792e-01, -1.9673e-01, -1.1021e-01]],

         [[-1.4642e-01, -8.4646e-02, -1.1512e-01],
          [-2.1538e-01, -2.6934e-01, -2.4112e-01],
          [-1.4448e-01, -8.2779e-02, -1.1832e-01]]],


        [[[-1.5638e-01, -1.4835e-01, -1.9036e-01],
          [-1.7547e-01, -8.7568e-02, -1.1182e-01],
          [-8.2418e-02,  2.9827e-02,  2.9444e-02]],

         [[-3.5351e-03,  7.8475e-02,  3.5789e-02],
          [ 2.8736e-02, -8.3442e-02, -3.0318e-02],
          [-1.1562e-01, -1.6252e-01, -1.9590e-01]],

         [[-5.9863e-02, -6.6110e-02, -3.8213e-02],
          [-5.4671e-02, -3.5383e-02, -2.5554e-02],
          [ 9.8641e-03, -6.5177e-03, -9.3011e-03]],

         ...,

         [[-3.2161e-01, -2.8489e-01, -2.5918e-01],
          [-3.2716e-01, -4.6101e-02, -1.2386e-01],
          [-6.2740e-02, -1.9311e-01, -9.9467e-02]],

         [[-2.3160e-01, -2.2290e-01, -1.7311e-01],
          [-1.2877e-01, -1.0607e-01, -1.8933e-01],
          [-1.3856e-01, -1.7023e-01, -8.4564e-02]],

         [[-9.7379e-02, -1.5025e-01, -2.1385e-01],
          [-1.5372e-01, -1.2470e-01, -9.2415e-02],
          [-1.2050e-01, -2.0160e-01, -1.7870e-01]]],


        [[[ 1.4705e-01,  2.1214e-01,  1.3027e-01],
          [ 1.5705e-01,  2.3031e-01,  1.4932e-01],
          [ 2.4698e-01,  3.2268e-01,  2.5551e-01]],

         [[ 4.3678e-01,  4.6324e-01,  4.4894e-01],
          [ 4.4244e-01,  3.3969e-01,  4.9461e-01],
          [ 3.9638e-01,  3.2134e-01,  2.9273e-01]],

         [[ 8.4497e-02,  7.1967e-02,  5.6404e-02],
          [ 5.4277e-02,  3.5380e-02,  4.2072e-02],
          [ 1.0959e-01,  7.9675e-02,  6.8024e-02]],

         ...,

         [[ 2.5636e-01,  3.1694e-01,  2.9748e-01],
          [ 3.4446e-01,  5.3526e-01,  3.9326e-01],
          [ 4.9409e-01,  4.1774e-01,  5.3854e-01]],

         [[ 4.0206e-01,  3.6071e-01,  3.3972e-01],
          [ 4.3792e-01,  3.8572e-01,  3.7576e-01],
          [ 4.6685e-01,  4.0983e-01,  4.3655e-01]],

         [[ 5.7194e-01,  5.3079e-01,  4.8957e-01],
          [ 6.5429e-01,  7.0739e-01,  6.6911e-01],
          [ 6.2929e-01,  4.8608e-01,  4.9187e-01]]]], device='cuda:0'), 'backend.4.bias': tensor([-1.0812e-01, -3.6618e-01,  1.2842e-01, -4.9060e-02, -2.9246e-01,
        -3.0940e-02, -2.1622e-01,  5.0669e-02,  7.6932e-02, -3.7847e-01,
         3.8316e-01,  6.9392e-02,  3.7674e-01,  3.4865e-02, -2.4371e-01,
        -6.7996e-02, -1.8840e-01,  9.8036e-02,  2.0499e-02,  1.9597e-03,
        -1.7969e-01,  3.6393e-01, -1.7573e-01, -4.2377e-01, -7.6806e-02,
        -5.1208e-01,  1.6246e-01,  1.3582e-01, -1.0089e-01, -6.3033e-01,
         2.1797e-01, -3.1502e-02,  2.5708e-02, -1.9572e-01,  4.0423e-02,
        -1.9214e-01, -1.6726e-01,  7.8278e-03,  1.1864e-01, -1.0253e-02,
        -5.1379e-05,  1.6473e-01,  4.8805e-02, -2.7859e-01, -2.8268e-01,
        -2.4050e-02, -1.5400e-03,  5.9487e-02, -3.5743e-01,  8.5501e-02,
        -3.2695e-01, -2.1991e-01, -4.9916e-01, -4.0063e-02, -2.6688e-02,
         3.2183e-01, -3.9357e-01, -1.2466e-02, -5.5511e-01, -3.7874e-01,
        -1.0882e-01, -8.0761e-03, -4.0334e-02, -2.3989e-01,  4.2835e-01,
         1.1270e-01,  5.2403e-03, -4.4078e-02, -1.1977e-01, -5.8302e-01,
        -4.5837e-01, -3.2117e-02, -4.3981e-01, -1.7271e-01, -1.0471e-01,
        -9.2244e-02, -2.5923e-01, -4.8508e-02, -1.3433e-01,  4.9865e-01,
         4.0564e-03,  4.7469e-01,  1.2650e-01,  2.1825e-01,  4.0002e-01,
         5.3300e-02, -4.8195e-02, -7.7327e-03,  3.1430e-02, -2.9858e-01,
         9.6678e-02,  5.9243e-03, -3.5871e-01, -1.8527e-01, -2.1072e-01,
        -2.4775e-02, -4.3054e-03, -4.8010e-01, -2.3097e-02, -4.8733e-01,
        -2.3378e-01,  1.2448e-02,  1.9692e-01,  6.4458e-01, -3.0372e-02,
        -7.6163e-02, -1.2317e-01,  1.7330e-01, -1.0179e-01,  4.4206e-02,
        -1.2982e-01, -1.8453e-01,  2.1300e-01, -5.0385e-02, -2.0802e-01,
         2.6361e-02, -5.6353e-01,  5.0608e-01,  1.8496e-01,  8.3391e-03,
        -3.2191e-02,  5.1195e-01, -1.3433e-02, -5.2053e-02,  1.4464e-01,
         3.7586e-02,  3.4294e-01,  6.9648e-03,  2.2646e-01,  5.1073e-01,
         3.4326e-02, -7.9605e-03,  3.3117e-01, -1.0774e-01, -4.2534e-02,
         3.0071e-02,  6.7353e-03, -7.9038e-01,  4.9791e-02, -4.3896e-01,
        -3.2473e-01, -2.9875e-01, -3.1350e-03, -4.8676e-03,  4.0755e-02,
        -7.9778e-03,  2.4404e-01, -5.4112e-02, -1.1398e-01,  1.1370e-03,
         3.8763e-02,  9.8145e-03, -3.7269e-01, -1.4726e-02,  5.2646e-01,
        -4.4866e-01,  2.7330e-01, -1.6092e-01, -1.5819e-01, -2.0994e-01,
         1.9684e-02, -2.4199e-02, -8.2345e-02, -3.9722e-01, -1.6619e-02,
         4.0969e-02,  3.9075e-01, -5.4413e-01, -1.2593e-01, -1.4784e-01,
        -3.4171e-01, -6.1623e-03, -2.4370e-01, -2.2418e-01,  3.0559e-04,
        -2.3541e-01, -6.4280e-02,  1.3203e-02, -1.1394e-01, -4.1009e-02,
        -8.9198e-02, -5.1333e-02, -3.2771e-01,  5.0280e-03,  2.6738e-01,
         6.9735e-02,  6.9241e-01,  4.3881e-01, -2.2326e-01,  2.3691e-02,
        -3.1278e-01, -9.1259e-02, -2.7652e-01,  1.0137e-01,  1.0067e+00,
        -3.0610e-02, -3.0768e-02, -1.6984e-01,  6.5684e-01,  8.3777e-02,
         4.4153e-01,  2.3669e-01, -1.1397e-01,  3.7615e-03, -2.0286e-02,
        -2.9738e-01,  5.2122e-02, -1.5838e-01, -1.8250e-01,  8.7092e-02,
        -9.9946e-03, -4.6142e-02, -4.2110e-01, -9.8055e-02, -1.8508e-01,
        -6.2269e-03,  1.6869e-02, -1.9718e-01, -2.3422e-01, -3.4677e-01,
         1.6644e-01,  1.2507e-01,  3.9420e-01,  7.4627e-02, -3.1263e-02,
        -3.1774e-01,  8.2826e-02,  1.5916e-02,  9.8656e-02,  1.1932e-02,
        -3.0593e-01, -3.5126e-02,  2.9627e-01,  2.0167e-01,  1.0441e-01,
        -1.0012e-01,  5.5526e-01, -1.0112e-01,  1.1197e-01, -5.4776e-02,
         5.3432e-01,  1.8932e-01,  1.2888e-01, -9.9682e-01, -3.9092e-02,
        -1.6113e-01,  1.7402e-02,  1.7736e-02,  1.6028e-01, -3.4079e-01,
         3.0156e-01,  7.4540e-02, -2.5540e-01, -3.4748e-01,  2.8851e-01,
        -2.7768e-01, -7.4829e-02,  1.7404e-01, -6.9480e-02, -2.7810e-01,
        -1.2865e-01,  2.2681e-01, -2.0875e-01, -4.3857e-01, -1.3635e-01,
        -3.7374e-01, -6.9183e-04,  2.8005e-01,  1.3251e-04, -1.2098e-01,
        -3.6943e-01, -1.2100e-01,  3.8067e-02, -3.8953e-01, -3.6714e-01,
        -4.5712e-02, -3.1230e-02, -1.0634e-01,  1.4169e-01,  2.3006e-01,
        -1.8546e-01, -2.0267e-01, -6.4678e-02, -2.3959e-01,  3.1085e-01,
         3.6061e-01,  1.6338e-02, -2.4541e-01, -8.0524e-02, -2.3345e-01,
        -1.0109e-02, -2.5681e-02,  9.0185e-01,  2.6805e-01,  3.4583e-01,
        -1.8347e-02, -1.3388e-01, -2.4006e-01,  1.4225e-02, -4.0938e-02,
        -1.7018e-01, -1.4158e-01, -2.0831e-01, -1.6937e-01, -8.4634e-02,
        -3.2971e-01, -2.7501e-01,  1.6289e-02, -4.0977e-02, -1.1737e-01,
         1.2762e-02, -1.3446e-01, -1.0033e-01, -1.4785e-01,  1.6940e-01,
        -6.3066e-02, -1.2878e-01,  6.4633e-01, -5.3337e-01,  1.4793e-02,
        -9.2402e-02, -4.7321e-01,  4.4709e-02, -3.0021e-01,  1.7768e-01,
        -4.5306e-01, -1.2879e-01, -3.4056e-02, -1.7092e-01, -3.2663e-01,
        -4.7844e-02, -3.4171e-01,  3.4814e-01, -1.8827e-01, -1.6557e-01,
        -5.7711e-01, -1.1870e-01,  2.7405e-01,  2.3554e-01, -2.6390e-01,
         2.1475e-01, -3.4903e-01,  1.3482e-01, -1.8987e-01, -2.4476e-02,
        -3.1930e-01,  9.0382e-02,  6.3579e-01, -1.4432e-01, -2.4493e-01,
         2.1646e-01,  4.9190e-01,  1.1630e-02,  7.9976e-02,  2.4348e-01,
         1.2597e-02, -1.4821e-01, -7.4587e-02,  1.5592e-01,  1.3076e-01,
         3.0585e-01, -3.6773e-01,  1.8266e-02,  9.1949e-02,  3.1869e-01,
        -2.1595e-01,  3.7490e-01, -2.6143e-02, -3.6379e-01,  8.8123e-03,
         2.6170e-02,  2.5108e-02,  2.6421e-02, -9.9199e-02,  3.0538e-01,
        -1.0716e-02, -1.9231e-01, -2.7256e-01,  1.1161e+00,  1.0306e-02,
        -9.5664e-02, -7.0538e-04, -3.1032e-01, -7.5437e-02,  2.4541e-01,
        -9.1378e-02, -5.9279e-01,  3.0517e-03,  1.4869e-02, -4.7875e-01,
         6.7284e-02, -1.8228e-01,  4.9475e-02,  3.0890e-02,  1.5925e-01,
         1.5410e-02,  3.8060e-02, -2.0830e-01, -1.9951e-01, -4.6217e-02,
        -5.7944e-01, -4.0634e-02,  1.8278e-01, -1.0761e-01, -5.3346e-01,
        -9.1331e-03, -3.6206e-01, -5.0548e-02,  2.9751e-01, -2.0689e-02,
         6.0334e-01,  2.5752e-01,  9.7460e-03,  6.7222e-03, -1.2128e-01,
        -8.0106e-02, -4.5752e-02,  6.7042e-02, -1.8903e-02, -2.1782e-01,
        -3.6457e-01, -2.6534e-02,  6.3350e-01, -3.4595e-01, -3.7133e-02,
        -9.5446e-02, -3.0462e-01, -3.0521e-01, -6.8317e-02, -5.2826e-01,
         1.4542e-01, -1.9183e-01,  1.9123e-03, -5.3527e-03, -1.5697e-01,
         2.8602e-02,  2.2384e-01, -4.2827e-02,  3.7193e-01, -1.0113e-01,
        -7.1846e-02, -1.7502e-01,  3.7556e-02, -6.9689e-01, -3.6151e-01,
        -3.2398e-02, -2.4084e-02, -3.1030e-01,  9.2290e-02, -4.0314e-01,
        -1.1534e-01,  1.2941e-01,  3.9191e-01,  6.1185e-02, -1.3613e-01,
        -2.1757e-02,  9.9645e-02,  2.4690e-01, -1.5003e-03,  1.3126e-01,
        -4.5444e-01,  3.8564e-01, -4.4021e-01,  4.3855e-01, -1.5638e-01,
         2.3229e-01,  4.4087e-02, -5.8860e-02, -1.5677e-03, -1.2277e-01,
        -8.8027e-02, -1.9164e-01, -6.1247e-02,  4.0479e-01, -3.7728e-01,
        -1.1528e-01,  1.1578e-01,  7.6796e-01, -7.4226e-02,  2.1551e-01,
         1.1526e-01, -2.0986e-03,  1.7941e-01, -7.2154e-01,  3.0800e-01,
        -3.7801e-02, -1.0173e-01,  2.5063e-01, -9.7411e-03, -1.2966e-01,
        -9.2895e-03,  5.0410e-02, -1.3581e-01,  2.7527e-01, -1.5140e-01,
         3.9171e-02,  5.3646e-02,  7.7754e-02,  2.6265e-02,  3.7059e-02,
         4.2296e-01, -4.2494e-02, -4.7810e-01, -2.3012e-01,  1.5902e-01,
         1.3807e-01, -1.8588e-01, -2.5382e-01,  1.1852e-02, -2.7152e-01,
        -2.3341e-01,  9.9333e-01], device='cuda:0')}
INFO:root:==> Evaluating the model at: 1
INFO:root:==> Evaluation results: MAE: 36.4862969404, MSE: 50.600121552
INFO:root:Saving checkpoint at: ../models/101//1.pt
INFO:root:Summary name (meta-train): train loss is illegal; using _meta-train___train_loss instead.
INFO:root:Summary name (meta-train): train MAE is illegal; using _meta-train___train_MAE instead.
INFO:root:Summary name (meta-train): train MSE is illegal; using _meta-train___train_MSE instead.
INFO:root:Summary name (meta-train): test MAE is illegal; using _meta-train___test_MAE instead.
INFO:root:Summary name (meta-train): test MSE is illegal; using _meta-train___test_MSE instead.
INFO:root:Summary name (meta-test) train loss is illegal; using _meta-test__train_loss instead.
INFO:root:Summary name (meta-test) train MAE is illegal; using _meta-test__train_MAE instead.
INFO:root:Summary name (meta-test) train MSE is illegal; using _meta-test__train_MSE instead.
INFO:root:Summary name (meta-test) test MAE is illegal; using _meta-test__test_MAE instead.
INFO:root:Summary name (meta-test) test MSE is illegal; using _meta-test__test_MSE instead.
INFO:root:===> Training epoch: 2/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:516.254337716, MAE: 1228.89445572, MSE: 1228.89444988
INFO:root:(Meta-testing) test MAE: 1211.59068375, MSE: 1211.59068454
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 3.96910071373, MAE: 5.78920888901, MSE: 5.78920878484
INFO:root:(Meta-training) post train loss: 2.55021190643, MAE: 3.69273805618, MSE: 3.69273806167
INFO:root:(Meta-training) pre-training test MAE: 2.81821250916, MSE: 2.81821251458
INFO:root:(Meta-training) post-training test MAE: 14.8133773804, MSE: 14.8133771291
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-72.3535, device='cuda:0'), 'backend.0.bias': tensor(-0.0175, device='cuda:0'), 'backend.10.weight': tensor(-146.6196, device='cuda:0'), 'backend.8.bias': tensor(-0.0953, device='cuda:0'), 'backend.6.weight': tensor(-101.1419, device='cuda:0'), 'backend.2.bias': tensor(-0.0419, device='cuda:0'), 'backend.10.bias': tensor(-0.2738, device='cuda:0'), 'output_layer.bias': tensor(13.7383, device='cuda:0'), 'backend.2.weight': tensor(-87.7092, device='cuda:0'), 'backend.6.bias': tensor(-0.0673, device='cuda:0'), 'backend.0.weight': tensor(-45.9411, device='cuda:0'), 'output_layer.weight': tensor(17.7771, device='cuda:0'), 'backend.4.weight': tensor(-38.0022, device='cuda:0'), 'backend.4.bias': tensor(-0.0194, device='cuda:0')}
INFO:root:==> Training scene: 2
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.1092300415, MAE: 13.7843608856, MSE: 13.7843609194
INFO:root:(Meta-training) post train loss: 24.7597560883, MAE: 319.908050537, MSE: 319.908055639
INFO:root:(Meta-training) pre-training test MAE: 16.1991672516, MSE: 16.1991674139
INFO:root:(Meta-training) post-training test MAE: 321.063598633, MSE: 321.063601079
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(3071.7388, device='cuda:0'), 'backend.0.bias': tensor(1.0439, device='cuda:0'), 'backend.10.weight': tensor(5227.1079, device='cuda:0'), 'backend.8.bias': tensor(3.4101, device='cuda:0'), 'backend.6.weight': tensor(4269.0088, device='cuda:0'), 'backend.2.bias': tensor(1.3926, device='cuda:0'), 'backend.10.bias': tensor(21.2511, device='cuda:0'), 'output_layer.bias': tensor(-352.2822, device='cuda:0'), 'backend.2.weight': tensor(3795.5933, device='cuda:0'), 'backend.6.bias': tensor(2.2225, device='cuda:0'), 'backend.0.weight': tensor(2667.0806, device='cuda:0'), 'output_layer.weight': tensor(-433.9278, device='cuda:0'), 'backend.4.weight': tensor(2385.2236, device='cuda:0'), 'backend.4.bias': tensor(1.0120, device='cuda:0')}
INFO:root:==> Training scene: 3
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 23.6817531586, MAE: 49.8900146484, MSE: 49.8900157534
INFO:root:(Meta-training) post train loss: 354.428466797, MAE: 1437.99291992, MSE: 1437.99291549
INFO:root:(Meta-training) pre-training test MAE: 16.4610977173, MSE: 16.461097865
INFO:root:(Meta-training) post-training test MAE: 1262.35803223, MSE: 1262.35801182
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(37342.2656, device='cuda:0'), 'backend.0.bias': tensor(14.3120, device='cuda:0'), 'backend.10.weight': tensor(40712.1133, device='cuda:0'), 'backend.8.bias': tensor(26.6770, device='cuda:0'), 'backend.6.weight': tensor(51950.1406, device='cuda:0'), 'backend.2.bias': tensor(15.4098, device='cuda:0'), 'backend.10.bias': tensor(164.4870, device='cuda:0'), 'output_layer.bias': tensor(-1631.0953, device='cuda:0'), 'backend.2.weight': tensor(50694.3047, device='cuda:0'), 'backend.6.bias': tensor(19.7638, device='cuda:0'), 'backend.0.weight': tensor(40206.5820, device='cuda:0'), 'output_layer.weight': tensor(-1673.1479, device='cuda:0'), 'backend.4.weight': tensor(40128.3047, device='cuda:0'), 'backend.4.bias': tensor(15.1422, device='cuda:0')}
INFO:root:==> Training scene: 4
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 10.4615850449, MAE: 20.6085929871, MSE: 20.6085931429
INFO:root:(Meta-training) post train loss: 40.9029922485, MAE: 445.036773682, MSE: 445.036778677
INFO:root:(Meta-training) pre-training test MAE: 5.16550350189, MSE: 5.16550350427
INFO:root:(Meta-training) post-training test MAE: 416.225341797, MSE: 416.225337107
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(4165.6128, device='cuda:0'), 'backend.0.bias': tensor(1.2552, device='cuda:0'), 'backend.10.weight': tensor(6280.8594, device='cuda:0'), 'backend.8.bias': tensor(4.6585, device='cuda:0'), 'backend.6.weight': tensor(5465.5029, device='cuda:0'), 'backend.2.bias': tensor(1.7907, device='cuda:0'), 'backend.10.bias': tensor(20.7245, device='cuda:0'), 'output_layer.bias': tensor(-399.2972, device='cuda:0'), 'backend.2.weight': tensor(4626.5371, device='cuda:0'), 'backend.6.bias': tensor(2.8286, device='cuda:0'), 'backend.0.weight': tensor(3231.8604, device='cuda:0'), 'output_layer.weight': tensor(-509.0814, device='cuda:0'), 'backend.4.weight': tensor(3166.0222, device='cuda:0'), 'backend.4.bias': tensor(1.3925, device='cuda:0')}
INFO:root:==> Training scene: 5
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.99841880798, MAE: 0.284796714783, MSE: 0.284796710208
INFO:root:(Meta-training) post train loss: 5.72084760666, MAE: 27.796705246, MSE: 27.7967048284
INFO:root:(Meta-training) pre-training test MAE: 1.51249980927, MSE: 1.51249978247
INFO:root:(Meta-training) post-training test MAE: 36.4604644775, MSE: 36.4604645954
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(193.4903, device='cuda:0'), 'backend.0.bias': tensor(0.0475, device='cuda:0'), 'backend.10.weight': tensor(358.9178, device='cuda:0'), 'backend.8.bias': tensor(0.3138, device='cuda:0'), 'backend.6.weight': tensor(274.9058, device='cuda:0'), 'backend.2.bias': tensor(0.1141, device='cuda:0'), 'backend.10.bias': tensor(0.9936, device='cuda:0'), 'output_layer.bias': tensor(-40.2124, device='cuda:0'), 'backend.2.weight': tensor(234.8077, device='cuda:0'), 'backend.6.bias': tensor(0.1891, device='cuda:0'), 'backend.0.weight': tensor(113.9289, device='cuda:0'), 'output_layer.weight': tensor(-42.4100, device='cuda:0'), 'backend.4.weight': tensor(104.0326, device='cuda:0'), 'backend.4.bias': tensor(0.0485, device='cuda:0')}
INFO:root:==> Training scene: 6
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 23.9756088257, MAE: 51.1383857727, MSE: 51.1383859883
INFO:root:(Meta-training) post train loss: 379.123382568, MAE: 1486.74609375, MSE: 1486.74611148
INFO:root:(Meta-training) pre-training test MAE: 50.7359733582, MSE: 50.7359726034
INFO:root:(Meta-training) post-training test MAE: 1449.84960938, MSE: 1449.84964738
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(51739.0781, device='cuda:0'), 'backend.0.bias': tensor(17.5430, device='cuda:0'), 'backend.10.weight': tensor(53416.9609, device='cuda:0'), 'backend.8.bias': tensor(34.5273, device='cuda:0'), 'backend.6.weight': tensor(71763.5469, device='cuda:0'), 'backend.2.bias': tensor(18.8600, device='cuda:0'), 'backend.10.bias': tensor(210.3823, device='cuda:0'), 'output_layer.bias': tensor(-2045.6981, device='cuda:0'), 'backend.2.weight': tensor(69992.4766, device='cuda:0'), 'backend.6.bias': tensor(25.1155, device='cuda:0'), 'backend.0.weight': tensor(55486.7305, device='cuda:0'), 'output_layer.weight': tensor(-1768.9493, device='cuda:0'), 'backend.4.weight': tensor(56900.8594, device='cuda:0'), 'backend.4.bias': tensor(18.8458, device='cuda:0')}
INFO:root:==> Training scene: 7
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 12.607966423, MAE: 19.3152103424, MSE: 19.3152106398
INFO:root:(Meta-training) post train loss: 54.5980606079, MAE: 520.249572754, MSE: 520.249579529
INFO:root:(Meta-training) pre-training test MAE: 38.8709602356, MSE: 38.870960087
INFO:root:(Meta-training) post-training test MAE: 533.328613281, MSE: 533.328610005
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(8189.1133, device='cuda:0'), 'backend.0.bias': tensor(2.8491, device='cuda:0'), 'backend.10.weight': tensor(10965.9258, device='cuda:0'), 'backend.8.bias': tensor(6.8243, device='cuda:0'), 'backend.6.weight': tensor(11341.8145, device='cuda:0'), 'backend.2.bias': tensor(3.4834, device='cuda:0'), 'backend.10.bias': tensor(40.1264, device='cuda:0'), 'output_layer.bias': tensor(-607.5929, device='cuda:0'), 'backend.2.weight': tensor(10623.4385, device='cuda:0'), 'backend.6.bias': tensor(4.9186, device='cuda:0'), 'backend.0.weight': tensor(7960.4189, device='cuda:0'), 'output_layer.weight': tensor(-733.5715, device='cuda:0'), 'backend.4.weight': tensor(7729.2549, device='cuda:0'), 'backend.4.bias': tensor(3.0016, device='cuda:0')}
INFO:root:==> Training scene: 8
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 22.1039981842, MAE: 46.7137908936, MSE: 46.7137904976
INFO:root:(Meta-training) post train loss: 157.35345459, MAE: 939.541931152, MSE: 939.541942917
INFO:root:(Meta-training) pre-training test MAE: 47.0304412842, MSE: 47.0304401924
INFO:root:(Meta-training) post-training test MAE: 964.933166504, MSE: 964.933158307
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(16193.8545, device='cuda:0'), 'backend.0.bias': tensor(6.1072, device='cuda:0'), 'backend.10.weight': tensor(19499.6211, device='cuda:0'), 'backend.8.bias': tensor(15.0193, device='cuda:0'), 'backend.6.weight': tensor(22362.1055, device='cuda:0'), 'backend.2.bias': tensor(7.1132, device='cuda:0'), 'backend.10.bias': tensor(88.7707, device='cuda:0'), 'output_layer.bias': tensor(-1049.5310, device='cuda:0'), 'backend.2.weight': tensor(21376.6562, device='cuda:0'), 'backend.6.bias': tensor(10.1490, device='cuda:0'), 'backend.0.weight': tensor(16263.0713, device='cuda:0'), 'output_layer.weight': tensor(-964.3151, device='cuda:0'), 'backend.4.weight': tensor(17059.3652, device='cuda:0'), 'backend.4.bias': tensor(6.7647, device='cuda:0')}
INFO:root:==> Training scene: 9
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 15.5649280548, MAE: 30.1861057281, MSE: 30.1861058895
INFO:root:(Meta-training) post train loss: 226.211776733, MAE: 1130.4642334, MSE: 1130.46422986
INFO:root:(Meta-training) pre-training test MAE: 10.4716529846, MSE: 10.471653049
INFO:root:(Meta-training) post-training test MAE: 919.627624512, MSE: 919.627608057
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(25303.9023, device='cuda:0'), 'backend.0.bias': tensor(8.5189, device='cuda:0'), 'backend.10.weight': tensor(31586.6250, device='cuda:0'), 'backend.8.bias': tensor(16.6408, device='cuda:0'), 'backend.6.weight': tensor(34904.6172, device='cuda:0'), 'backend.2.bias': tensor(9.2295, device='cuda:0'), 'backend.10.bias': tensor(114.2298, device='cuda:0'), 'output_layer.bias': tensor(-1216.5680, device='cuda:0'), 'backend.2.weight': tensor(33509.9375, device='cuda:0'), 'backend.6.bias': tensor(12.0250, device='cuda:0'), 'backend.0.weight': tensor(27330.4414, device='cuda:0'), 'output_layer.weight': tensor(-1779.3740, device='cuda:0'), 'backend.4.weight': tensor(25463.3906, device='cuda:0'), 'backend.4.bias': tensor(8.5939, device='cuda:0')}
INFO:root:==> Training scene: 10
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 41.4564476013, MAE: 94.2858657837, MSE: 94.2858643634
INFO:root:(Meta-training) post train loss: 2592.21582031, MAE: 3867.38378906, MSE: 3867.38374098
INFO:root:(Meta-training) pre-training test MAE: 4.53874778748, MSE: 4.53874775358
INFO:root:(Meta-training) post-training test MAE: 3629.98120117, MSE: 3629.98126717
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(365702.0312, device='cuda:0'), 'backend.0.bias': tensor(111.7294, device='cuda:0'), 'backend.10.weight': tensor(267977.7812, device='cuda:0'), 'backend.8.bias': tensor(206.6201, device='cuda:0'), 'backend.6.weight': tensor(540737.5000, device='cuda:0'), 'backend.2.bias': tensor(116.9884, device='cuda:0'), 'backend.10.bias': tensor(1117.5323, device='cuda:0'), 'output_layer.bias': tensor(-8538.7578, device='cuda:0'), 'backend.2.weight': tensor(549863.6250, device='cuda:0'), 'backend.6.bias': tensor(150.4595, device='cuda:0'), 'backend.0.weight': tensor(462079.9688, device='cuda:0'), 'output_layer.weight': tensor(-2080.1440, device='cuda:0'), 'backend.4.weight': tensor(473462.3750, device='cuda:0'), 'backend.4.bias': tensor(121.2143, device='cuda:0')}
INFO:root:==> Training scene: 11
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 23.6817531586, MAE: 49.8900146484, MSE: 49.8900157534
INFO:root:(Meta-training) post train loss: 367.792053223, MAE: 1464.24902344, MSE: 1464.24903961
INFO:root:(Meta-training) pre-training test MAE: 19.3152103424, MSE: 19.3152106398
INFO:root:(Meta-training) post-training test MAE: 1291.15930176, MSE: 1291.15931434
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(38954.3203, device='cuda:0'), 'backend.0.bias': tensor(14.1696, device='cuda:0'), 'backend.10.weight': tensor(43181.7031, device='cuda:0'), 'backend.8.bias': tensor(27.4757, device='cuda:0'), 'backend.6.weight': tensor(54572.2969, device='cuda:0'), 'backend.2.bias': tensor(15.4943, device='cuda:0'), 'backend.10.bias': tensor(166.6530, device='cuda:0'), 'output_layer.bias': tensor(-1702.8486, device='cuda:0'), 'backend.2.weight': tensor(52224.4609, device='cuda:0'), 'backend.6.bias': tensor(20.6135, device='cuda:0'), 'backend.0.weight': tensor(41051.6016, device='cuda:0'), 'output_layer.weight': tensor(-1818.5570, device='cuda:0'), 'backend.4.weight': tensor(41562.6484, device='cuda:0'), 'backend.4.bias': tensor(15.2926, device='cuda:0')}
INFO:root:==> Training scene: 12
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 54.6767272949, MAE: 119.720100403, MSE: 119.720099999
INFO:root:(Meta-training) post train loss: 3004.41699219, MAE: 4263.96777344, MSE: 4263.96787042
INFO:root:(Meta-training) pre-training test MAE: 58.4968757629, MSE: 58.4968761686
INFO:root:(Meta-training) post-training test MAE: 3870.51733398, MSE: 3870.51727809
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(340635.6250, device='cuda:0'), 'backend.0.bias': tensor(112.4788, device='cuda:0'), 'backend.10.weight': tensor(223132.6875, device='cuda:0'), 'backend.8.bias': tensor(227.8603, device='cuda:0'), 'backend.6.weight': tensor(500826.1875, device='cuda:0'), 'backend.2.bias': tensor(124.1805, device='cuda:0'), 'backend.10.bias': tensor(985.3832, device='cuda:0'), 'output_layer.bias': tensor(-8259.3818, device='cuda:0'), 'backend.2.weight': tensor(522881.8750, device='cuda:0'), 'backend.6.bias': tensor(158.9786, device='cuda:0'), 'backend.0.weight': tensor(431307.0625, device='cuda:0'), 'output_layer.weight': tensor(2424.0151, device='cuda:0'), 'backend.4.weight': tensor(458211.6250, device='cuda:0'), 'backend.4.bias': tensor(128.8817, device='cuda:0')}
INFO:root:==> Training scene: 13
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.85727882385, MAE: 3.33391475677, MSE: 3.33391472197
INFO:root:(Meta-training) post train loss: 10.2388830185, MAE: 174.71723938, MSE: 174.717238077
INFO:root:(Meta-training) pre-training test MAE: 4.4991440773, MSE: 4.49914415486
INFO:root:(Meta-training) post-training test MAE: 163.563751221, MSE: 163.563753816
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(1334.3936, device='cuda:0'), 'backend.0.bias': tensor(0.4264, device='cuda:0'), 'backend.10.weight': tensor(2294.5713, device='cuda:0'), 'backend.8.bias': tensor(1.4921, device='cuda:0'), 'backend.6.weight': tensor(1933.6404, device='cuda:0'), 'backend.2.bias': tensor(0.6541, device='cuda:0'), 'backend.10.bias': tensor(7.9537, device='cuda:0'), 'output_layer.bias': tensor(-177.6615, device='cuda:0'), 'backend.2.weight': tensor(1757.7644, device='cuda:0'), 'backend.6.bias': tensor(1.0409, device='cuda:0'), 'backend.0.weight': tensor(1115.8706, device='cuda:0'), 'output_layer.weight': tensor(-226.2311, device='cuda:0'), 'backend.4.weight': tensor(978.0040, device='cuda:0'), 'backend.4.bias': tensor(0.4060, device='cuda:0')}
INFO:root:==> Training scene: 14
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 12.4593448639, MAE: 19.0548706055, MSE: 19.0548708799
INFO:root:(Meta-training) post train loss: 63.053440094, MAE: 567.744750977, MSE: 567.744743481
INFO:root:(Meta-training) pre-training test MAE: 59.0543708801, MSE: 59.0543707203
INFO:root:(Meta-training) post-training test MAE: 595.035705566, MSE: 595.035713214
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(11374.3320, device='cuda:0'), 'backend.0.bias': tensor(3.8856, device='cuda:0'), 'backend.10.weight': tensor(14959.2969, device='cuda:0'), 'backend.8.bias': tensor(8.4382, device='cuda:0'), 'backend.6.weight': tensor(15694.9551, device='cuda:0'), 'backend.2.bias': tensor(4.6319, device='cuda:0'), 'backend.10.bias': tensor(52.4979, device='cuda:0'), 'output_layer.bias': tensor(-728.5649, device='cuda:0'), 'backend.2.weight': tensor(14668.6074, device='cuda:0'), 'backend.6.bias': tensor(6.3248, device='cuda:0'), 'backend.0.weight': tensor(10973.6992, device='cuda:0'), 'output_layer.weight': tensor(-916.5612, device='cuda:0'), 'backend.4.weight': tensor(11136.8936, device='cuda:0'), 'backend.4.bias': tensor(4.2230, device='cuda:0')}
INFO:root:==> Training scene: 15
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 5.44101047516, MAE: 0.198208808899, MSE: 0.198208810787
INFO:root:(Meta-training) post train loss: 5.13750505447, MAE: 70.5032653809, MSE: 70.5032655217
INFO:root:(Meta-training) pre-training test MAE: 40.5978088379, MSE: 40.5978094102
INFO:root:(Meta-training) post-training test MAE: 64.0235443115, MSE: 64.0235437957
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(418.6175, device='cuda:0'), 'backend.0.bias': tensor(0.1131, device='cuda:0'), 'backend.10.weight': tensor(711.2427, device='cuda:0'), 'backend.8.bias': tensor(0.5573, device='cuda:0'), 'backend.6.weight': tensor(580.2598, device='cuda:0'), 'backend.2.bias': tensor(0.2140, device='cuda:0'), 'backend.10.bias': tensor(1.9403, device='cuda:0'), 'output_layer.bias': tensor(-64.0678, device='cuda:0'), 'backend.2.weight': tensor(501.4886, device='cuda:0'), 'backend.6.bias': tensor(0.3432, device='cuda:0'), 'backend.0.weight': tensor(310.1732, device='cuda:0'), 'output_layer.weight': tensor(-70.5035, device='cuda:0'), 'backend.4.weight': tensor(295.2353, device='cuda:0'), 'backend.4.bias': tensor(0.1257, device='cuda:0')}
INFO:root:==> Training scene: 16
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 11.8369188309, MAE: 24.182220459, MSE: 24.1822204348
INFO:root:(Meta-training) post train loss: 47.3434638977, MAE: 484.744415283, MSE: 484.744407523
INFO:root:(Meta-training) pre-training test MAE: 27.6003780365, MSE: 27.6003783269
INFO:root:(Meta-training) post-training test MAE: 486.81918335, MSE: 486.819188072
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(5169.1807, device='cuda:0'), 'backend.0.bias': tensor(1.5650, device='cuda:0'), 'backend.10.weight': tensor(7900.3633, device='cuda:0'), 'backend.8.bias': tensor(5.4398, device='cuda:0'), 'backend.6.weight': tensor(6849.8169, device='cuda:0'), 'backend.2.bias': tensor(2.0992, device='cuda:0'), 'backend.10.bias': tensor(32.5798, device='cuda:0'), 'output_layer.bias': tensor(-486.1100, device='cuda:0'), 'backend.2.weight': tensor(5969.8828, device='cuda:0'), 'backend.6.bias': tensor(3.3522, device='cuda:0'), 'backend.0.weight': tensor(4244.0166, device='cuda:0'), 'output_layer.weight': tensor(-584.4918, device='cuda:0'), 'backend.4.weight': tensor(4160.0649, device='cuda:0'), 'backend.4.bias': tensor(1.6589, device='cuda:0')}
INFO:root:==> Training scene: 17
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 13.9336986542, MAE: 33.2850914001, MSE: 33.2850918411
INFO:root:(Meta-training) post train loss: 97.2933883667, MAE: 735.107543945, MSE: 735.107560157
INFO:root:(Meta-training) pre-training test MAE: 59.3954086304, MSE: 59.3954076771
INFO:root:(Meta-training) post-training test MAE: 690.414489746, MSE: 690.414481489
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(11168.6113, device='cuda:0'), 'backend.0.bias': tensor(3.1218, device='cuda:0'), 'backend.10.weight': tensor(15507.0342, device='cuda:0'), 'backend.8.bias': tensor(9.8320, device='cuda:0'), 'backend.6.weight': tensor(14654.5488, device='cuda:0'), 'backend.2.bias': tensor(3.9066, device='cuda:0'), 'backend.10.bias': tensor(57.8945, device='cuda:0'), 'output_layer.bias': tensor(-763.3457, device='cuda:0'), 'backend.2.weight': tensor(12478.5273, device='cuda:0'), 'backend.6.bias': tensor(6.1280, device='cuda:0'), 'backend.0.weight': tensor(9138.7227, device='cuda:0'), 'output_layer.weight': tensor(-1022.5334, device='cuda:0'), 'backend.4.weight': tensor(9214.9580, device='cuda:0'), 'backend.4.bias': tensor(3.3125, device='cuda:0')}
INFO:root:==> Training scene: 18
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 12.7663898468, MAE: 18.4024581909, MSE: 18.4024585906
INFO:root:(Meta-training) post train loss: 67.5466918945, MAE: 594.85559082, MSE: 594.855602226
INFO:root:(Meta-training) pre-training test MAE: 165.643920898, MSE: 165.64391991
INFO:root:(Meta-training) post-training test MAE: 619.783874512, MSE: 619.783883705
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(14195.2734, device='cuda:0'), 'backend.0.bias': tensor(4.8794, device='cuda:0'), 'backend.10.weight': tensor(17805.0039, device='cuda:0'), 'backend.8.bias': tensor(9.9376, device='cuda:0'), 'backend.6.weight': tensor(19944.2207, device='cuda:0'), 'backend.2.bias': tensor(5.3883, device='cuda:0'), 'backend.10.bias': tensor(70.1650, device='cuda:0'), 'output_layer.bias': tensor(-847.2023, device='cuda:0'), 'backend.2.weight': tensor(19382.6133, device='cuda:0'), 'backend.6.bias': tensor(7.3599, device='cuda:0'), 'backend.0.weight': tensor(15342.4316, device='cuda:0'), 'output_layer.weight': tensor(-991.5171, device='cuda:0'), 'backend.4.weight': tensor(15231.0420, device='cuda:0'), 'backend.4.bias': tensor(5.0187, device='cuda:0')}
INFO:root:==> Training scene: 19
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 4.40766191483, MAE: 1.5726556778, MSE: 1.57265567088
INFO:root:(Meta-training) post train loss: 9.15603256226, MAE: 188.275405884, MSE: 188.275407067
INFO:root:(Meta-training) pre-training test MAE: 7.04752397537, MSE: 7.0475240269
INFO:root:(Meta-training) post-training test MAE: 174.167694092, MSE: 174.167691509
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(2147.2251, device='cuda:0'), 'backend.0.bias': tensor(0.5245, device='cuda:0'), 'backend.10.weight': tensor(3423.9233, device='cuda:0'), 'backend.8.bias': tensor(1.8441, device='cuda:0'), 'backend.6.weight': tensor(2868.2793, device='cuda:0'), 'backend.2.bias': tensor(0.7333, device='cuda:0'), 'backend.10.bias': tensor(10.5090, device='cuda:0'), 'output_layer.bias': tensor(-211.1699, device='cuda:0'), 'backend.2.weight': tensor(2417.0735, device='cuda:0'), 'backend.6.bias': tensor(1.2213, device='cuda:0'), 'backend.0.weight': tensor(1714.4058, device='cuda:0'), 'output_layer.weight': tensor(-323.2026, device='cuda:0'), 'backend.4.weight': tensor(1420.3599, device='cuda:0'), 'backend.4.bias': tensor(0.4655, device='cuda:0')}
INFO:root:==> Training scene: 20
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 32.9993171692, MAE: 65.7394866943, MSE: 65.7394871883
INFO:root:(Meta-training) post train loss: 642.740600586, MAE: 1945.13098145, MSE: 1945.13097245
INFO:root:(Meta-training) pre-training test MAE: 76.9858169556, MSE: 76.9858163428
INFO:root:(Meta-training) post-training test MAE: 2007.33996582, MSE: 2007.33996871
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(93556.0938, device='cuda:0'), 'backend.0.bias': tensor(36.6302, device='cuda:0'), 'backend.10.weight': tensor(85291.9297, device='cuda:0'), 'backend.8.bias': tensor(59.5760, device='cuda:0'), 'backend.6.weight': tensor(139359.4375, device='cuda:0'), 'backend.2.bias': tensor(37.7628, device='cuda:0'), 'backend.10.bias': tensor(398.5801, device='cuda:0'), 'output_layer.bias': tensor(-3151.9961, device='cuda:0'), 'backend.2.weight': tensor(142560.4219, device='cuda:0'), 'backend.6.bias': tensor(47.4405, device='cuda:0'), 'backend.0.weight': tensor(117572.0312, device='cuda:0'), 'output_layer.weight': tensor(-892.1809, device='cuda:0'), 'backend.4.weight': tensor(121368.4062, device='cuda:0'), 'backend.4.bias': tensor(39.3064, device='cuda:0')}
INFO:root:==> Training scene: 21
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 2.53758049011, MAE: 1.30648040771, MSE: 1.3064804093
INFO:root:(Meta-training) post train loss: 2.26166057587, MAE: 14.1889877319, MSE: 14.1889878892
INFO:root:(Meta-training) pre-training test MAE: 4.25481557846, MSE: 4.2548156831
INFO:root:(Meta-training) post-training test MAE: 15.8492927551, MSE: 15.8492925155
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-60.9040, device='cuda:0'), 'backend.0.bias': tensor(-0.0146, device='cuda:0'), 'backend.10.weight': tensor(-115.0355, device='cuda:0'), 'backend.8.bias': tensor(-0.1589, device='cuda:0'), 'backend.6.weight': tensor(-82.8565, device='cuda:0'), 'backend.2.bias': tensor(-0.0369, device='cuda:0'), 'backend.10.bias': tensor(-0.2999, device='cuda:0'), 'output_layer.bias': tensor(16.4678, device='cuda:0'), 'backend.2.weight': tensor(-61.1397, device='cuda:0'), 'backend.6.bias': tensor(-0.0726, device='cuda:0'), 'backend.0.weight': tensor(-32.0693, device='cuda:0'), 'output_layer.weight': tensor(13.9953, device='cuda:0'), 'backend.4.weight': tensor(-31.8344, device='cuda:0'), 'backend.4.bias': tensor(-0.0193, device='cuda:0')}
INFO:root:==> Training scene: 22
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 37.5173072815, MAE: 91.3200531006, MSE: 91.3200555139
INFO:root:(Meta-training) post train loss: 865.788818359, MAE: 2282.07836914, MSE: 2282.07832907
INFO:root:(Meta-training) pre-training test MAE: 2.1544675827, MSE: 2.15446763386
INFO:root:(Meta-training) post-training test MAE: 1969.01965332, MSE: 1969.01967994
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(64608.1758, device='cuda:0'), 'backend.0.bias': tensor(23.5247, device='cuda:0'), 'backend.10.weight': tensor(60647.4609, device='cuda:0'), 'backend.8.bias': tensor(55.6110, device='cuda:0'), 'backend.6.weight': tensor(91600.0781, device='cuda:0'), 'backend.2.bias': tensor(27.0319, device='cuda:0'), 'backend.10.bias': tensor(258.1020, device='cuda:0'), 'output_layer.bias': tensor(-2564.7014, device='cuda:0'), 'backend.2.weight': tensor(88370.8125, device='cuda:0'), 'backend.6.bias': tensor(37.1903, device='cuda:0'), 'backend.0.weight': tensor(69070.1172, device='cuda:0'), 'output_layer.weight': tensor(-1933.6075, device='cuda:0'), 'backend.4.weight': tensor(74261.2031, device='cuda:0'), 'backend.4.bias': tensor(27.0150, device='cuda:0')}
INFO:root:==> Training scene: 23
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 24.0725383759, MAE: 54.6133651733, MSE: 54.6133649293
INFO:root:(Meta-training) post train loss: 272.815063477, MAE: 1259.02624512, MSE: 1259.02626065
INFO:root:(Meta-training) pre-training test MAE: 72.5470123291, MSE: 72.5470112938
INFO:root:(Meta-training) post-training test MAE: 1283.29638672, MSE: 1283.29639016
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(34347.8945, device='cuda:0'), 'backend.0.bias': tensor(11.1870, device='cuda:0'), 'backend.10.weight': tensor(38855.1250, device='cuda:0'), 'backend.8.bias': tensor(26.7474, device='cuda:0'), 'backend.6.weight': tensor(48143.6992, device='cuda:0'), 'backend.2.bias': tensor(12.5812, device='cuda:0'), 'backend.10.bias': tensor(163.7812, device='cuda:0'), 'output_layer.bias': tensor(-1613.8973, device='cuda:0'), 'backend.2.weight': tensor(44979.8984, device='cuda:0'), 'backend.6.bias': tensor(18.0100, device='cuda:0'), 'backend.0.weight': tensor(35654.7734, device='cuda:0'), 'output_layer.weight': tensor(-1496.9540, device='cuda:0'), 'backend.4.weight': tensor(37819.8164, device='cuda:0'), 'backend.4.bias': tensor(12.2604, device='cuda:0')}
INFO:root:==> Training scene: 24
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 19.9913425446, MAE: 39.0471534729, MSE: 39.0471532353
INFO:root:(Meta-training) post train loss: 104.422203064, MAE: 743.303527832, MSE: 743.30352145
INFO:root:(Meta-training) pre-training test MAE: 2.81179046631, MSE: 2.81179046158
INFO:root:(Meta-training) post-training test MAE: 669.234375, MSE: 669.234380654
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(5732.4121, device='cuda:0'), 'backend.0.bias': tensor(2.4548, device='cuda:0'), 'backend.10.weight': tensor(7614.5630, device='cuda:0'), 'backend.8.bias': tensor(7.7508, device='cuda:0'), 'backend.6.weight': tensor(7602.7134, device='cuda:0'), 'backend.2.bias': tensor(3.4238, device='cuda:0'), 'backend.10.bias': tensor(33.8490, device='cuda:0'), 'output_layer.bias': tensor(-585.1854, device='cuda:0'), 'backend.2.weight': tensor(7362.0850, device='cuda:0'), 'backend.6.bias': tensor(4.9562, device='cuda:0'), 'backend.0.weight': tensor(4986.9438, device='cuda:0'), 'output_layer.weight': tensor(-593.6747, device='cuda:0'), 'backend.4.weight': tensor(5247.8203, device='cuda:0'), 'backend.4.bias': tensor(3.0415, device='cuda:0')}
INFO:root:==> Training scene: 25
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.84738302231, MAE: 10.5608234406, MSE: 10.5608233865
INFO:root:(Meta-training) post train loss: 24.8375225067, MAE: 337.751403809, MSE: 337.751399423
INFO:root:(Meta-training) pre-training test MAE: 19.6562194824, MSE: 19.656219725
INFO:root:(Meta-training) post-training test MAE: 258.711700439, MSE: 258.711697044
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(2740.4409, device='cuda:0'), 'backend.0.bias': tensor(0.7267, device='cuda:0'), 'backend.10.weight': tensor(4818.3574, device='cuda:0'), 'backend.8.bias': tensor(2.6405, device='cuda:0'), 'backend.6.weight': tensor(3690.8647, device='cuda:0'), 'backend.2.bias': tensor(1.0188, device='cuda:0'), 'backend.10.bias': tensor(15.6160, device='cuda:0'), 'output_layer.bias': tensor(-281.1853, device='cuda:0'), 'backend.2.weight': tensor(3048.2998, device='cuda:0'), 'backend.6.bias': tensor(1.6787, device='cuda:0'), 'backend.0.weight': tensor(2041.1024, device='cuda:0'), 'output_layer.weight': tensor(-443.5167, device='cuda:0'), 'backend.4.weight': tensor(1750.4377, device='cuda:0'), 'backend.4.bias': tensor(0.7101, device='cuda:0')}
INFO:root:==> Training scene: 26
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 31.1438217163, MAE: 70.8855133057, MSE: 70.8855123377
INFO:root:(Meta-training) post train loss: 808.403320312, MAE: 2171.90991211, MSE: 2171.90987382
INFO:root:(Meta-training) pre-training test MAE: 88.7268447876, MSE: 88.7268455711
INFO:root:(Meta-training) post-training test MAE: 2165.09692383, MSE: 2165.09688005
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(115034.4062, device='cuda:0'), 'backend.0.bias': tensor(40.4682, device='cuda:0'), 'backend.10.weight': tensor(98838.8438, device='cuda:0'), 'backend.8.bias': tensor(76.1180, device='cuda:0'), 'backend.6.weight': tensor(165632.0312, device='cuda:0'), 'backend.2.bias': tensor(43.7439, device='cuda:0'), 'backend.10.bias': tensor(420.9445, device='cuda:0'), 'output_layer.bias': tensor(-3664.4104, device='cuda:0'), 'backend.2.weight': tensor(165466.1250, device='cuda:0'), 'backend.6.bias': tensor(54.0147, device='cuda:0'), 'backend.0.weight': tensor(133868.6875, device='cuda:0'), 'output_layer.weight': tensor(-1713.2833, device='cuda:0'), 'backend.4.weight': tensor(139707.5000, device='cuda:0'), 'backend.4.bias': tensor(43.7576, device='cuda:0')}
INFO:root:==> Training scene: 27
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 6.71693325043, MAE: 8.17980194092, MSE: 8.17980175795
INFO:root:(Meta-training) post train loss: 15.776017189, MAE: 252.175552368, MSE: 252.175549593
INFO:root:(Meta-training) pre-training test MAE: 1.43523073196, MSE: 1.43523070299
INFO:root:(Meta-training) post-training test MAE: 244.610778809, MSE: 244.610779799
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(2204.0884, device='cuda:0'), 'backend.0.bias': tensor(0.6460, device='cuda:0'), 'backend.10.weight': tensor(3614.0723, device='cuda:0'), 'backend.8.bias': tensor(2.3640, device='cuda:0'), 'backend.6.weight': tensor(3009.6987, device='cuda:0'), 'backend.2.bias': tensor(0.9771, device='cuda:0'), 'backend.10.bias': tensor(12.0789, device='cuda:0'), 'output_layer.bias': tensor(-249.3039, device='cuda:0'), 'backend.2.weight': tensor(2667.6492, device='cuda:0'), 'backend.6.bias': tensor(1.5338, device='cuda:0'), 'backend.0.weight': tensor(1768.9373, device='cuda:0'), 'output_layer.weight': tensor(-320.3657, device='cuda:0'), 'backend.4.weight': tensor(1684.0806, device='cuda:0'), 'backend.4.bias': tensor(0.6947, device='cuda:0')}
INFO:root:==> Training scene: 28
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 30.0274562836, MAE: 59.1998558044, MSE: 59.1998568146
INFO:root:(Meta-training) post train loss: 642.15246582, MAE: 1892.29101562, MSE: 1892.29100563
INFO:root:(Meta-training) pre-training test MAE: 59.0739479065, MSE: 59.0739468901
INFO:root:(Meta-training) post-training test MAE: 2027.73693848, MSE: 2027.73691587
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(104199.6328, device='cuda:0'), 'backend.0.bias': tensor(43.7927, device='cuda:0'), 'backend.10.weight': tensor(96442.7734, device='cuda:0'), 'backend.8.bias': tensor(61.3705, device='cuda:0'), 'backend.6.weight': tensor(152905., device='cuda:0'), 'backend.2.bias': tensor(43.6031, device='cuda:0'), 'backend.10.bias': tensor(430.3372, device='cuda:0'), 'output_layer.bias': tensor(-3337.6992, device='cuda:0'), 'backend.2.weight': tensor(154043.0938, device='cuda:0'), 'backend.6.bias': tensor(53.2600, device='cuda:0'), 'backend.0.weight': tensor(126083.8828, device='cuda:0'), 'output_layer.weight': tensor(-1421.4049, device='cuda:0'), 'backend.4.weight': tensor(131036.0469, device='cuda:0'), 'backend.4.bias': tensor(46.5922, device='cuda:0')}
INFO:root:==> Training scene: 29
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 2.21015429497, MAE: 10.8288135529, MSE: 10.8288137154
INFO:root:(Meta-training) post train loss: 5.46314096451, MAE: 169.880157471, MSE: 169.880156517
INFO:root:(Meta-training) pre-training test MAE: 6.42081975937, MSE: 6.42081964365
INFO:root:(Meta-training) post-training test MAE: 174.371505737, MSE: 174.371505341
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(-622.3689, device='cuda:0'), 'backend.0.bias': tensor(0.0154, device='cuda:0'), 'backend.10.weight': tensor(-1552.8418, device='cuda:0'), 'backend.8.bias': tensor(-1.1788, device='cuda:0'), 'backend.6.weight': tensor(-890.2266, device='cuda:0'), 'backend.2.bias': tensor(-0.2776, device='cuda:0'), 'backend.10.bias': tensor(-3.8755, device='cuda:0'), 'output_layer.bias': tensor(197.0610, device='cuda:0'), 'backend.2.weight': tensor(-509.2680, device='cuda:0'), 'backend.6.bias': tensor(-0.6979, device='cuda:0'), 'backend.0.weight': tensor(-70.9814, device='cuda:0'), 'output_layer.weight': tensor(201.2121, device='cuda:0'), 'backend.4.weight': tensor(67.0265, device='cuda:0'), 'backend.4.bias': tensor(0.0757, device='cuda:0')}
INFO:root:==> Training scene: 30
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 21.5030250549, MAE: 52.0463600159, MSE: 52.0463590113
INFO:root:(Meta-training) post train loss: 242.376815796, MAE: 1190.22241211, MSE: 1190.22240569
INFO:root:(Meta-training) pre-training test MAE: 2.59256792068, MSE: 2.59256790984
INFO:root:(Meta-training) post-training test MAE: 1095.93286133, MSE: 1095.93287888
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(21771.0938, device='cuda:0'), 'backend.0.bias': tensor(6.8379, device='cuda:0'), 'backend.10.weight': tensor(26454.5898, device='cuda:0'), 'backend.8.bias': tensor(19.2168, device='cuda:0'), 'backend.6.weight': tensor(28992.4805, device='cuda:0'), 'backend.2.bias': tensor(8.1289, device='cuda:0'), 'backend.10.bias': tensor(106.7569, device='cuda:0'), 'output_layer.bias': tensor(-1208.2202, device='cuda:0'), 'backend.2.weight': tensor(26217.1113, device='cuda:0'), 'backend.6.bias': tensor(12.0502, device='cuda:0'), 'backend.0.weight': tensor(19857.1602, device='cuda:0'), 'output_layer.weight': tensor(-1426.1820, device='cuda:0'), 'backend.4.weight': tensor(20855.8516, device='cuda:0'), 'backend.4.bias': tensor(7.6349, device='cuda:0')}
INFO:root:==> Training scene: 31
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 26.8884830475, MAE: 61.083984375, MSE: 61.0839845936
INFO:root:(Meta-training) post train loss: 515.405517578, MAE: 1748.68225098, MSE: 1748.68221813
INFO:root:(Meta-training) pre-training test MAE: 55.2232933044, MSE: 55.2232927355
INFO:root:(Meta-training) post-training test MAE: 1756.92041016, MSE: 1756.92038807
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(72824.4609, device='cuda:0'), 'backend.0.bias': tensor(26.4823, device='cuda:0'), 'backend.10.weight': tensor(71276.9922, device='cuda:0'), 'backend.8.bias': tensor(48.9381, device='cuda:0'), 'backend.6.weight': tensor(103292.2969, device='cuda:0'), 'backend.2.bias': tensor(27.7872, device='cuda:0'), 'backend.10.bias': tensor(311.8706, device='cuda:0'), 'output_layer.bias': tensor(-2594.7224, device='cuda:0'), 'backend.2.weight': tensor(103767.7188, device='cuda:0'), 'backend.6.bias': tensor(35.1333, device='cuda:0'), 'backend.0.weight': tensor(84226.1094, device='cuda:0'), 'output_layer.weight': tensor(-1533.5354, device='cuda:0'), 'backend.4.weight': tensor(87093.4844, device='cuda:0'), 'backend.4.bias': tensor(28.4178, device='cuda:0')}
INFO:root:==> Training scene: 32
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.63859272003, MAE: 19.9379844666, MSE: 19.9379844487
INFO:root:(Meta-training) post train loss: 33.7201347351, MAE: 400.201507568, MSE: 400.201511741
INFO:root:(Meta-training) pre-training test MAE: 38.3273239136, MSE: 38.3273239954
INFO:root:(Meta-training) post-training test MAE: 392.16619873, MSE: 392.166199621
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'17.weight': -1969.82275390625, '19.bias': 18.589231491088867, '17.bias': 2.331319808959961, '14.bias': 5.621622085571289, '12.weight': -818.099365234375, '10.weight': -369.82293701171875, '21.bias': 25.516963958740234, '5.weight': -132.8113555908203, '7.weight': -335.9803161621094, '2.weight': -63.11039352416992, '21.weight': -5152.9697265625, '0.bias': -4.0798115730285645, '14.weight': -1434.037109375, '7.bias': 3.75457763671875, '12.bias': 10.963644027709961, '5.bias': 7.090723037719727, '2.bias': 0.6074678897857666, '10.bias': 5.739318370819092, '19.weight': -3809.52099609375, '0.weight': -4.493677616119385}
INFO:root:Sum of gradients in backend: {'4.weight': -128.11431884765625, '6.bias': 0.2947346866130829, '10.weight': -22.762094497680664, '8.bias': 0.6360629796981812, '4.bias': 0.15327203273773193, '2.weight': -216.27066040039062, '0.bias': 0.012057916261255741, '6.weight': -82.45710754394531, '8.weight': -35.56964111328125, '2.bias': 0.029186423867940903, '10.bias': 0.3597584664821625, '0.weight': -108.17755126953125}
INFO:root:Sum of gradients in output layer: {'bias': tensor(0.0010, device='cuda:0', grad_fn=<SumBackward0>), 'weight': tensor(1.9183, device='cuda:0', grad_fn=<SumBackward0>)}
INFO:root:Sum of the total gradients: {'backend.8.weight': tensor(3950.3174, device='cuda:0'), 'backend.0.bias': tensor(1.0615, device='cuda:0'), 'backend.10.weight': tensor(6384.5479, device='cuda:0'), 'backend.8.bias': tensor(4.1714, device='cuda:0'), 'backend.6.weight': tensor(5202.0488, device='cuda:0'), 'backend.2.bias': tensor(1.4361, device='cuda:0'), 'backend.10.bias': tensor(26.5609, device='cuda:0'), 'output_layer.bias': tensor(-400.8296, device='cuda:0'), 'backend.2.weight': tensor(4327.9829, device='cuda:0'), 'backend.6.bias': tensor(2.4914, device='cuda:0'), 'backend.0.weight': tensor(3009.3633, device='cuda:0'), 'output_layer.weight': tensor(-513.0622, device='cuda:0'), 'backend.4.weight': tensor(2804.5176, device='cuda:0'), 'backend.4.bias': tensor(1.0501, device='cuda:0')}
INFO:root:===> Updating meta network
INFO:root:===> Gradients updated: {'backend.8.weight': tensor([[[[ 6.8500e+01,  6.9200e+01,  6.7374e+01],
          [ 8.1130e+01,  8.1142e+01,  7.8354e+01],
          [ 9.4654e+01,  9.4325e+01,  9.1033e+01]],

         [[ 1.9763e+01,  1.9535e+01,  1.8906e+01],
          [ 2.1434e+01,  2.0888e+01,  2.0205e+01],
          [ 2.1452e+01,  2.1028e+01,  2.0076e+01]],

         [[ 7.7526e-06,  7.6173e-06,  0.0000e+00],
          [ 1.9090e-07,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[ 7.8931e-03,  8.1940e-03,  8.1091e-03],
          [ 3.1910e-03,  3.2515e-03,  3.2079e-03],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-3.2931e-03, -3.9763e-03, -2.9480e-03],
          [-1.1305e-02, -8.9637e-03, -8.5531e-03]],

         [[ 5.7254e+01,  5.7467e+01,  5.6364e+01],
          [ 6.8570e+01,  6.8853e+01,  6.6636e+01],
          [ 7.8385e+01,  7.9085e+01,  7.6987e+01]]],


        [[[ 2.8843e-01,  6.4178e-01,  9.5157e-01],
          [ 1.3226e+00,  1.5301e+00,  1.6468e+00],
          [ 1.1369e+00,  1.2021e+00,  1.3162e+00]],

         [[-1.0336e-01, -3.3567e-02, -1.4014e-01],
          [-2.5926e-01, -2.1523e-01, -2.2595e-01],
          [-2.2854e-02, -1.7836e-02, -2.1987e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-2.5613e-03, -3.0998e-03, -3.2580e-03],
          [ 0.0000e+00, -1.5548e-07,  6.9376e-04]],

         [[-1.6809e-01,  6.9399e-02,  2.9576e-01],
          [ 1.3164e+00,  1.4056e+00,  1.5404e+00],
          [-2.5030e-01, -1.1763e-01, -3.8301e-02]]],


        [[[ 0.0000e+00,  1.4072e-03,  1.4685e-03],
          [ 3.5044e-03,  5.2437e-04,  5.3021e-04],
          [ 6.6553e-03,  1.5594e-04, -2.2808e-04]],

         [[ 0.0000e+00,  2.3793e-04,  9.4860e-05],
          [ 4.7451e-04,  4.3108e-04, -4.0159e-05],
          [ 9.6809e-04,  2.5551e-05, -9.4570e-05]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-3.5207e-06, -6.4305e-06, -5.2579e-06],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  8.3115e-04,  1.2171e-03],
          [ 3.1346e-03,  1.0932e-03,  5.1675e-04],
          [ 5.4035e-03,  1.7091e-03, -1.0483e-04]]],


        ...,


        [[[ 9.3893e+01,  9.2043e+01,  8.9429e+01],
          [ 9.2311e+01,  9.0183e+01,  8.7585e+01],
          [ 9.0090e+01,  8.7643e+01,  8.5036e+01]],

         [[ 1.6430e+01,  1.5787e+01,  1.5368e+01],
          [ 1.6741e+01,  1.6258e+01,  1.5828e+01],
          [ 1.6684e+01,  1.5974e+01,  1.5725e+01]],

         [[ 1.6539e-05,  0.0000e+00,  0.0000e+00],
          [ 1.2255e-09,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[ 3.8507e-03,  3.9865e-03,  3.8679e-03],
          [ 2.8962e-05,  3.3330e-05,  2.7877e-05],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 3.0503e-03,  4.0195e-03,  3.4909e-03],
          [-1.5857e-03,  3.5204e-04,  4.9988e-04]],

         [[ 7.1040e+01,  7.0000e+01,  6.8323e+01],
          [ 6.9262e+01,  6.7512e+01,  6.6256e+01],
          [ 6.9469e+01,  6.7352e+01,  6.5551e+01]]],


        [[[-9.0769e+01, -9.0545e+01, -8.9180e+01],
          [-7.9957e+01, -7.9844e+01, -7.8940e+01],
          [-7.3845e+01, -7.3057e+01, -7.2031e+01]],

         [[-1.3499e+01, -1.3748e+01, -1.3627e+01],
          [-1.4127e+01, -1.3996e+01, -1.3951e+01],
          [-1.3604e+01, -1.3279e+01, -1.3523e+01]],

         [[-3.3400e-06, -3.0406e-06,  0.0000e+00],
          [ 3.3190e-06,  4.4092e-06,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[-3.0481e-04, -2.0102e-04, -2.5596e-04],
          [-2.3381e-04, -2.2438e-04, -1.8193e-04],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-1.8962e-02, -1.2664e-02, -1.3681e-02],
          [ 7.3057e-03,  5.1468e-03,  5.4616e-03]],

         [[-6.7507e+01, -6.7884e+01, -6.7718e+01],
          [-5.4158e+01, -5.3947e+01, -5.4677e+01],
          [-5.7777e+01, -5.6918e+01, -5.6603e+01]]],


        [[[ 2.4307e+00,  2.4897e+00,  2.4586e+00],
          [ 1.0305e+00,  1.0753e+00,  1.1052e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-3.7559e-01, -3.4134e-01, -3.2943e-01],
          [-1.3573e-02, -1.7182e-02, -2.7581e-02],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 4.7860e-06,  1.3043e-09,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.4169e+00,  1.4055e+00,  1.3782e+00],
          [-2.7571e-01, -2.0677e-01, -1.4862e-01],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0'), 'backend.0.bias': tensor([ 6.4271e-01,  1.3261e-01,  8.2166e-01,  4.2967e+00,  5.0122e-01,
        -8.3578e-01,  3.7251e-01,  1.4915e+00,  1.7532e-01,  2.6076e+00,
         1.4997e+00,  3.9092e-01, -1.9909e-01,  4.7695e-01,  4.8510e+00,
         1.4758e+00,  5.3167e-01,  3.5239e+00,  5.4224e-01,  1.5415e-03,
         5.6892e-01,  3.5807e+00,  2.6208e+00, -3.4324e-02,  2.1962e-01,
         3.3762e-01,  4.1431e+00,  1.0288e+00,  8.3521e-02,  6.5991e-01,
         1.1452e+00,  6.4780e-02, -1.2198e-01,  9.1423e-02,  1.5951e-01,
         1.8433e+00,  2.9237e+00,  2.1886e-01,  9.9433e-01, -3.4839e-02,
         3.4251e-01,  1.4570e-01,  1.5638e+00,  3.7945e-01,  1.2993e+00,
         2.2617e-02,  7.6648e-01,  3.0719e-01,  5.6754e-01,  3.0084e+00,
         3.3616e-01,  3.5002e+00, -3.7949e-01,  1.4813e-01, -3.3914e-01,
         1.7151e+00,  1.8896e+00,  1.4140e-01,  1.1469e+00,  2.0810e+00,
         1.2499e+00,  1.1800e+00,  2.1905e-01,  2.3051e+00,  6.7310e-01,
        -1.1373e-01,  4.4346e+00, -1.5158e-01, -3.7229e-01,  7.1302e-01,
         3.0471e-01,  2.8109e+00, -1.3121e-01,  1.3297e+00,  7.5940e-01,
         2.4411e+00,  9.8452e-01,  1.4628e-01,  3.4914e+00,  1.2726e+00,
         2.8390e+00, -6.0333e-02, -2.3539e-01,  1.0620e-01,  5.0446e-01,
         8.5431e-01,  2.5197e-01,  1.2242e-01,  1.5815e+00,  8.7677e-01,
         8.5616e-01,  6.6076e-01,  6.3817e-01,  1.2388e+00, -5.7934e-03,
         1.1589e+00,  2.3248e-02, -1.0946e-01,  4.0853e-01,  2.9797e+00,
        -5.8518e-01,  1.7830e+00,  9.9414e-01,  1.6469e+00,  1.7347e-01,
         4.5891e-01,  3.2640e-02,  9.0782e-01,  1.1807e-01, -8.4953e-01,
         1.5499e-01,  3.3527e+00,  2.2968e-01,  1.9359e+00,  2.4061e+00,
         1.7776e+00,  1.6620e+00,  1.7696e+00, -9.8654e-02,  1.8688e+00,
        -4.3494e-01,  3.3414e-01,  8.9912e-02,  1.5696e+00,  1.1966e+00,
         4.0790e+00, -8.6799e-01, -1.1612e-01,  7.5688e-01, -2.2407e-01,
         5.5922e-01,  8.7837e-01, -7.9187e-03, -1.4875e-01,  3.4532e+00,
         4.3639e-01,  3.0173e+00, -6.4358e-02,  8.7933e-01,  1.2605e+00,
         1.7415e+00, -2.5821e-01,  1.3603e+00,  9.9639e-01,  4.6357e-01,
        -2.1552e-02,  3.9772e+00,  3.4227e+00,  8.8869e-02,  1.7308e+00,
         1.1939e+00,  5.1332e+00,  8.7641e-02,  6.7914e-01,  2.2366e+00,
         6.6786e-01,  4.4972e-01,  6.0310e-02,  9.9084e-01,  7.4625e-01,
         4.5270e+00, -1.3017e-01,  3.2770e+00, -1.1578e-01,  3.0323e-01,
         7.0736e-01,  2.2057e-02,  2.5557e+00, -1.7888e-01,  4.1382e-01,
         1.0603e+00,  8.9831e-03,  2.5401e-01,  9.3751e-01,  7.1370e-01,
         1.6564e-01,  5.4068e-01,  6.2232e-01,  7.9692e-01, -1.7852e-02,
         6.0777e-01, -3.7686e-01,  2.9666e-01,  4.6270e-02,  1.2990e+00,
         7.7713e-01,  1.4731e+00,  4.1503e-02,  7.2984e-02, -3.1105e-02,
        -7.6931e-01,  1.6267e-01,  1.1288e-02,  7.4117e-02,  9.1816e-01,
         2.0811e+00,  1.7281e+00,  1.6348e+00,  1.5756e+00,  1.2242e+00,
         9.2486e-01,  6.6997e+00,  8.6022e-01,  2.9728e+00,  7.5885e-01,
         1.7498e+00,  1.1076e+00,  1.4345e+00,  8.7017e-01,  6.2046e-01,
         3.0346e+00, -1.2637e-01,  4.9811e+00,  2.5048e+00,  2.1106e+00,
         4.4227e+00,  6.9140e-02,  3.3826e-01, -1.8427e-01,  1.2880e-03,
         8.1392e-01,  1.7322e-01, -6.2890e-03,  1.1744e+00,  1.1569e-01,
         1.0035e+00,  6.2787e-01,  2.6026e+00, -3.8903e-03,  1.6685e-03,
        -3.0907e-02,  9.8595e-01,  3.0786e+00,  1.9567e-02, -1.4842e-01,
         7.4401e-01,  7.3241e+00, -3.8962e-03,  4.9383e-01,  6.1911e-01,
         3.1449e-01,  3.9926e-01,  7.9356e-01, -9.8481e-02,  1.7990e+00,
         9.3995e-01,  1.6819e+00,  1.4116e+00,  1.8357e+00,  5.7664e-01,
         4.8116e-01,  2.8776e+00,  3.8745e+00,  3.3522e-01,  3.0938e-01,
         9.2291e-02,  5.0319e+00,  2.4399e-01,  4.3109e+00,  1.3893e+00,
         1.4411e+00,  9.5304e-02,  7.5806e-01, -1.9089e-02,  2.5814e+00,
         3.1530e-01,  1.1150e+00,  6.8442e-01,  1.8677e-02,  1.4183e-01,
        -8.1807e-02,  5.2571e-01, -3.7518e-01,  2.3405e+00,  1.7003e-01,
         2.4549e-02,  7.9121e-01,  1.8767e+00,  2.1471e-01,  4.7575e+00,
         1.8657e-02,  1.6125e+00,  2.3700e-01, -7.3080e-02,  2.4870e-02,
         7.4441e-01, -7.0439e-02,  7.3638e+00,  9.5889e-01, -2.5531e-02,
        -1.5977e+00,  2.3012e+00,  1.5501e-01, -3.0920e-02,  2.9780e+00,
        -7.6570e-01,  8.2372e-01, -2.4439e-01,  4.1070e+00,  3.0894e-03,
         2.1850e-03, -3.2068e-01,  2.2580e-01,  1.2940e+00,  1.9111e+00,
         6.2438e-01,  7.5012e-01, -4.9982e-01, -3.9261e-01,  3.3380e+00,
         2.3855e-02,  3.6120e+00,  5.1358e-01, -4.3873e-01, -2.7996e-02,
        -4.2173e-02,  2.3419e+00,  1.5971e+00,  5.2640e+00, -9.3731e-02,
         1.1678e-01,  1.3438e-01,  1.9983e-01,  4.9056e-01,  1.2791e+00,
         7.0784e-01,  4.0181e+00,  2.4782e+00,  1.0689e+00,  9.8158e-01,
         7.7982e-02,  2.9987e-02,  2.1565e-01,  3.0042e+00,  3.1258e-01,
        -8.6232e-02,  1.7156e+00,  1.5910e-01,  5.1526e-01,  2.0646e-01,
         5.3652e-01,  3.2112e+00, -3.1282e-01,  8.9140e-01,  2.3140e-01,
         8.0413e-01,  9.9446e-02, -7.7763e-03, -2.0943e-01,  1.6569e-01,
         7.5450e-01, -4.6509e-01,  4.6669e+00,  4.0239e+00,  2.8097e+00,
         4.7964e-01,  2.8385e+00,  5.0704e-01,  9.0181e-01,  6.7700e-02,
         2.0396e-01,  5.0428e-01,  3.1503e-02,  1.2841e+00,  4.1241e-02,
         3.7317e-01,  4.1834e-01,  8.8156e-01,  1.4978e+00,  1.1263e+00,
         2.6972e-01, -1.0922e+00, -7.1059e-02,  2.7146e-01, -9.7098e-01,
         9.0675e-01,  4.2842e+00,  2.6852e+00, -8.3088e-01,  1.7268e-01,
         3.2853e-03,  2.9246e+00,  3.8014e-01,  8.4477e-01,  5.1009e-01,
         1.9738e+00, -1.6720e-01,  1.0181e+00,  8.3210e-01,  1.1168e+00,
         2.5157e+00,  3.7572e-01,  5.7398e-02,  2.3714e+00,  7.9954e-01,
         3.0775e+00,  1.1407e-01,  2.5103e+00,  4.6323e+00,  2.5810e+00,
        -6.8535e-02,  2.4595e-01, -1.2318e-01, -4.6649e-01, -3.1908e-02,
         8.0268e-01,  1.2577e-01,  4.8753e-01,  7.0244e-01,  9.3064e-01,
         2.5241e+00,  1.6174e+00,  6.2297e-01, -2.1993e-01, -1.7251e-01,
         4.6536e-01,  3.0492e+00,  2.0547e+00,  2.3434e+00,  6.8572e-02,
         5.1362e-01,  8.4474e-02,  2.8808e-01,  6.1582e-01,  2.7755e-01,
         1.5805e-01,  1.3196e+00,  1.3266e-01,  4.4693e-01, -7.0953e-02,
        -2.7826e-01,  3.7890e+00,  1.0883e-02,  2.9552e-01,  1.0050e+00,
         5.7585e-02, -2.3738e-01,  1.5350e+00,  2.6040e-02,  9.9044e-01,
         1.4908e+00, -4.9155e-01,  1.0059e-02,  4.1496e-01,  1.1689e+00,
         3.5590e+00,  1.2488e-01,  3.8637e-01,  1.0355e-01,  3.5056e+00,
         4.9846e-01,  2.7022e+00, -3.6909e-02,  1.2214e+00,  7.2328e-01,
         4.2330e-01, -2.4330e-01, -3.4804e-02,  2.2473e+00, -1.1106e-01,
        -7.7259e-03,  3.7284e-01, -5.8856e-01,  7.3105e-02,  4.1265e-01,
         1.9225e-01,  3.3702e-01,  7.0249e-01,  7.6456e-01, -2.7365e-01,
         7.0650e-01,  2.8296e+00, -8.7829e-01,  6.5102e-01,  2.8472e+00,
         2.2696e-02,  5.3415e-02,  2.2943e-01,  1.6925e+00,  1.7857e+00,
        -7.0371e-02,  2.7338e-01,  5.7260e-01,  1.4354e+00,  1.1153e+00,
         6.2066e-01,  1.5705e-01, -2.0586e+00,  2.8887e+00,  1.7734e+00,
         2.2531e+00,  1.3805e-01,  1.9816e+00,  3.3315e-01,  1.4846e+00,
        -1.1967e+00,  1.0851e+00,  5.2559e-01,  1.1842e-01,  1.1387e+00,
         3.4040e+00, -6.6462e-01,  2.2816e+00, -7.4652e-02,  8.0078e-01,
         5.8143e-01,  5.8023e+00, -1.2434e-01,  1.7131e-01,  2.7057e+00,
         1.2577e+00,  1.0417e+00], device='cuda:0'), 'backend.10.weight': tensor([[[[-1.2612e+01, -1.2562e+01, -1.2553e+01],
          [-8.3070e+00, -8.3334e+00, -8.2571e+00],
          [-2.0314e+00, -2.0283e+00, -2.0546e+00]],

         [[ 4.4591e-01,  4.5845e-01,  4.6405e-01],
          [ 8.1380e-03, -2.7469e-02, -5.7380e-02],
          [-3.9093e-01, -3.8914e-01, -4.2115e-01]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 8.2265e-05,  3.9828e-05,  0.0000e+00],
          [ 0.0000e+00, -4.3305e-05,  0.0000e+00]],

         ...,

         [[ 1.5720e+00,  1.6284e+00,  1.5207e+00],
          [-1.1046e+00, -1.0609e+00, -1.1432e+00],
          [-1.3098e+00, -1.2895e+00, -1.2940e+00]],

         [[-6.4362e+00, -7.1974e+00, -7.8269e+00],
          [-9.3797e+00, -9.8452e+00, -1.0131e+01],
          [-4.1560e+00, -4.2097e+00, -4.3229e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 1.0644e+00,  1.0941e+00,  1.0912e+00],
          [-2.9814e-02, -2.9684e-02, -3.3513e-02]]],


        [[[-1.4033e+01, -1.4262e+01, -1.4741e+01],
          [-8.0257e+00, -8.3624e+00, -8.8416e+00],
          [ 9.6370e-02, -3.0107e-01, -9.3002e-01]],

         [[ 6.3540e-01,  6.5345e-01,  6.5959e-01],
          [ 5.4614e-02,  1.3855e-02, -6.1282e-02],
          [-1.5031e-01, -1.3804e-01, -1.4302e-01]],

         [[ 5.0790e-07,  1.9153e-04,  0.0000e+00],
          [ 3.6771e-04,  8.1510e-04,  3.3513e-04],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[ 4.7734e+00,  4.8846e+00,  4.7326e+00],
          [ 7.1525e-01,  8.3194e-01,  7.5235e-01],
          [-5.8457e-01, -5.2805e-01, -4.9554e-01]],

         [[ 2.5937e+00,  1.1430e+00, -3.8175e-01],
          [-3.4967e+00, -4.6246e+00, -5.7129e+00],
          [ 1.3669e-01, -7.2536e-01, -1.7000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 1.5169e+00,  1.5552e+00,  1.5510e+00],
          [-2.7869e-02, -3.0197e-02, -3.6158e-02]]],


        [[[ 5.8914e+01,  6.2199e+01,  6.5511e+01],
          [ 5.9161e+01,  6.2137e+01,  6.5469e+01],
          [ 5.7948e+01,  6.0846e+01,  6.4082e+01]],

         [[-5.7986e-03, -2.9371e-03, -3.8019e-03],
          [ 1.4439e-02,  1.0951e-02,  1.2828e-02],
          [ 2.2551e-02,  4.8087e-02,  7.7320e-02]],

         [[-5.2074e-06, -7.0968e-06,  1.1915e-03],
          [-3.1981e-05, -8.5479e-06,  1.6836e-03],
          [ 1.1094e-05,  9.9990e-06,  0.0000e+00]],

         ...,

         [[ 1.6504e+01,  1.7477e+01,  1.9058e+01],
          [ 1.8213e+01,  1.9265e+01,  2.1073e+01],
          [ 1.9944e+01,  2.0956e+01,  2.3011e+01]],

         [[ 2.2636e+02,  2.3524e+02,  2.3966e+02],
          [ 2.3509e+02,  2.4415e+02,  2.4848e+02],
          [ 2.3965e+02,  2.4826e+02,  2.5223e+02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-1.6512e-02, -8.7453e-03, -5.5487e-03],
          [ 2.9715e-04,  1.7849e-04,  9.0453e-05]]],


        ...,


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[-1.7149e-02, -1.6709e-02, -1.6057e-02],
          [-9.7922e-03, -9.6512e-03, -9.3100e-03],
          [ 2.6059e-04,  1.5242e-04,  0.0000e+00]],

         [[ 2.0062e-03,  2.2498e-03,  2.0511e-03],
          [-2.5462e-05, -8.6375e-05,  1.2793e-04],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 3.6251e-06,  1.6284e-05,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[-3.1740e-03, -3.2398e-03, -2.6343e-03],
          [-2.0167e-03, -1.9596e-03, -1.5382e-03],
          [ 0.0000e+00,  5.2911e-06,  0.0000e+00]],

         [[-1.9298e-02, -1.8135e-02, -1.7196e-02],
          [-9.9122e-03, -9.8434e-03, -9.4209e-03],
          [ 1.8908e-04,  9.3038e-05,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 3.1376e-03,  3.1477e-03,  3.1841e-03],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 2.1635e-06,  1.2625e-06,  0.0000e+00],
          [ 3.6652e-03,  3.2767e-03,  2.6815e-03],
          [ 7.4822e-03,  6.6623e-03,  5.4791e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 7.1539e-08,  1.9016e-07,  0.0000e+00],
          [ 3.5365e-05,  8.0855e-05,  4.7459e-05],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  6.2527e-08,  0.0000e+00],
          [ 3.3469e-09,  5.7561e-06,  1.3150e-06],
          [ 2.9115e-08,  1.2720e-05,  6.3555e-06]],

         [[ 1.4386e-06,  5.5948e-07,  0.0000e+00],
          [ 2.9595e-03,  2.3148e-03,  1.9175e-03],
          [ 6.8847e-03,  5.7763e-03,  4.6091e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0'), 'backend.8.bias': tensor([ 1.4900e+01,  1.1793e+00,  7.8554e-03,  4.2273e-02,  1.4412e+01,
         5.4867e-01,  0.0000e+00, -1.4625e-01,  7.0670e+01, -4.6320e+00,
         2.7468e+01,  3.8238e+00, -7.9432e+00,  2.6212e-05,  0.0000e+00,
         0.0000e+00,  7.1838e+00,  0.0000e+00, -1.8379e+01,  0.0000e+00,
        -3.2559e+01, -6.1111e+01, -4.6996e+00,  1.4722e+01,  2.5635e+00,
        -2.7382e+01, -5.1338e+00, -9.2904e+01, -5.1541e-03,  8.0127e-04,
         6.9246e+01,  3.5244e+01,  3.9595e-06,  1.0642e+01,  8.3957e-01,
         6.3825e-02,  3.6023e+01,  6.7901e+00,  0.0000e+00,  4.0217e+01,
         0.0000e+00,  7.3426e-03,  0.0000e+00, -7.1300e+00, -3.9687e-03,
         1.4089e+02,  0.0000e+00, -3.2603e+01,  3.9132e+00, -4.0415e-03,
        -1.0443e-02,  6.7618e+00, -3.5729e-01, -4.9631e-01,  5.4558e+01,
         2.2062e+00, -8.3038e+00,  1.3409e+02,  0.0000e+00, -8.3627e+00,
         3.3265e+01,  5.7399e-06,  5.3816e+00, -2.2330e+01, -9.8914e+00,
         0.0000e+00,  2.7474e+00, -2.4188e-05,  1.6068e+00, -3.9457e+00,
         5.4099e+01, -1.7963e-02,  2.4349e-01,  0.0000e+00,  4.3936e+01,
         2.6940e+00,  2.5708e+01, -2.8179e+01,  1.5051e-03,  5.1832e+01,
         1.1959e+01,  6.5187e+00,  7.3258e+01,  1.3515e+00,  3.4250e-05,
         1.9595e+01,  3.4089e+00, -1.1202e-02, -1.2762e+00, -1.4675e+01,
        -3.1319e+01,  1.1112e+00,  5.8287e+01,  1.0371e+01, -5.8673e+01,
         2.2653e+01,  6.2716e-02, -2.0294e-03, -1.0331e+01,  0.0000e+00,
         0.0000e+00,  4.2853e+01,  1.4115e-02,  4.6496e+01,  5.3462e+01,
         1.6574e+00,  3.9950e-04,  6.1944e+01, -5.8317e-05, -1.0698e-02,
         6.2029e+01,  1.8066e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
        -1.9388e-02, -2.6974e+01,  0.0000e+00,  3.9523e+01,  1.7301e-02,
        -1.6163e-03,  0.0000e+00, -4.6901e+01,  8.8061e+01,  1.7062e+01,
         5.9168e+01, -7.1661e+01,  5.8212e+00], device='cuda:0'), 'backend.6.weight': tensor([[[[-3.0959e-03, -2.8103e-04, -8.3711e-05],
          [ 3.3141e-02,  3.8535e-02,  4.6474e-02],
          [ 6.8820e-02,  7.5453e-02,  7.9961e-02]],

         [[-5.9407e+00, -6.0243e+00, -6.0883e+00],
          [-6.6667e+00, -6.6700e+00, -6.7499e+00],
          [-7.5121e+00, -7.6552e+00, -7.5059e+00]],

         [[-3.1498e+00, -3.2820e+00, -3.4029e+00],
          [-3.7263e+00, -3.8588e+00, -3.8657e+00],
          [-4.6700e+00, -4.7504e+00, -4.6096e+00]],

         ...,

         [[ 2.8293e-05,  4.6358e-05,  1.3187e-05],
          [ 3.5210e-02,  3.7269e-02,  3.9281e-02],
          [ 7.0661e-02,  7.4598e-02,  7.7476e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-1.0922e+01, -1.0903e+01, -1.1021e+01],
          [-1.1942e+01, -1.2010e+01, -1.2035e+01],
          [-1.2901e+01, -1.2966e+01, -1.2916e+01]]],


        [[[-2.6518e-03,  2.6899e-04, -2.3348e-05],
          [-1.1996e-02, -7.4832e-03, -3.8975e-03],
          [-1.3334e-02, -1.4357e-02, -1.3441e-02]],

         [[ 1.0005e+01,  9.7713e+00,  9.2823e+00],
          [ 9.9798e+00,  9.8455e+00,  9.4776e+00],
          [ 9.6503e+00,  9.3656e+00,  8.8951e+00]],

         [[ 1.6524e+00,  1.6512e+00,  1.5655e+00],
          [ 1.8201e+00,  1.7461e+00,  1.5407e+00],
          [ 2.0217e+00,  1.9295e+00,  1.8430e+00]],

         ...,

         [[ 1.3300e-05,  8.5628e-06,  6.7208e-06],
          [-2.7549e-03, -3.1112e-03, -3.3972e-03],
          [-6.8011e-03, -9.6609e-03, -1.2465e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.5838e+01,  1.6094e+01,  1.5825e+01],
          [ 1.6716e+01,  1.6868e+01,  1.6567e+01],
          [ 1.7136e+01,  1.7150e+01,  1.6776e+01]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -5.3163e-05, -8.8013e-05],
          [ 0.0000e+00, -8.1474e-05, -1.3013e-04]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -4.1535e-05, -9.9369e-05],
          [ 0.0000e+00, -5.2821e-05, -1.0034e-04]],

         ...,

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -1.5883e-05, -8.2952e-05],
          [ 0.0000e+00, -6.4567e-05, -1.4453e-04]]],


        ...,


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 7.4569e-03,  7.1923e-03,  7.1301e-03],
          [ 1.1933e-02,  1.2143e-02,  1.1733e-02]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 4.4204e-03,  4.8004e-03,  4.3294e-03],
          [ 4.1551e-03,  4.2882e-03,  3.9450e-03]],

         ...,

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 8.2077e-03,  8.3739e-03,  7.8580e-03],
          [ 1.6033e-02,  1.5777e-02,  1.5420e-02]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [-3.3916e-05, -1.9361e-05,  6.8994e-05],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.5967e-04,  1.0195e-04, -1.0280e-04],
          [ 3.5556e-05, -3.8273e-05, -7.0353e-05],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.8671e-04, -3.3776e-05, -3.1321e-06],
          [ 5.4746e-05,  6.5817e-05,  5.9611e-07],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -2.2477e-05,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 6.6550e-05, -8.5660e-05, -1.4462e-04],
          [ 2.0438e-05, -7.1270e-05, -1.7524e-04],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[-2.0632e-03, -1.3356e-03, -3.5285e-04],
          [-1.7837e-01, -1.8546e-01, -1.8792e-01],
          [ 1.4503e-01,  1.5847e-01,  1.7224e-01]],

         [[-3.1996e+00, -3.6964e+00, -3.8916e+00],
          [-5.4944e+00, -5.9084e+00, -6.0684e+00],
          [-4.7797e+00, -5.3009e+00, -5.5426e+00]],

         [[-4.0959e+00, -4.2408e+00, -4.2423e+00],
          [-2.2779e+00, -2.5759e+00, -2.5605e+00],
          [-2.6814e+00, -2.8280e+00, -2.7318e+00]],

         ...,

         [[-1.0097e-04,  5.5968e-06,  1.2102e-05],
          [-1.2892e-01, -1.3094e-01, -1.3589e-01],
          [ 1.1469e-01,  1.2218e-01,  1.3109e-01]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[-6.3231e+00, -6.9414e+00, -7.3390e+00],
          [-8.0046e+00, -8.6754e+00, -9.0920e+00],
          [-9.4203e+00, -1.0137e+01, -1.0669e+01]]]], device='cuda:0'), 'backend.2.bias': tensor([ 3.1759e-01,  1.4086e+00,  3.1543e+00,  2.9897e+00,  0.0000e+00,
         7.7057e-01,  1.5910e-03,  4.2160e+00,  3.9014e-04,  4.8472e-05,
         9.7005e-01,  4.1282e+00, -3.1421e+00,  3.8997e-01,  5.9891e-01,
         1.1300e-04,  1.6883e+00,  1.8117e-01, -3.9039e-01,  9.7340e-01,
         1.0122e-01, -6.0194e-01,  5.1096e-06,  5.9548e+00,  2.0020e+00,
        -6.4562e-01, -1.4057e-01, -7.3293e-03,  1.3886e-04,  4.9294e-01,
         1.4707e-05, -1.0774e+00,  5.1305e+00,  1.8997e-01,  4.1591e+00,
         2.4571e+00,  1.0821e+00,  2.1206e-01,  3.8619e-04,  9.0416e-01,
         4.4066e+00,  1.5097e-01,  2.0984e-02,  2.9289e-01,  2.6504e-01,
         0.0000e+00,  3.0146e-01,  1.3533e+00, -2.8968e-03,  6.8772e-01,
        -1.9301e-05,  1.4487e+00,  1.1689e+00,  3.7213e+00,  1.1437e+00,
        -3.5713e-01,  4.2306e+00, -7.0367e-01, -1.9475e-01,  9.4728e-03,
        -5.1310e-01,  2.8665e-05,  2.5709e+00,  1.4588e-02,  2.4111e+00,
         2.2937e+00,  1.5393e-01, -2.8528e-05,  3.0347e-01,  2.3542e+00,
         1.5046e+00,  0.0000e+00, -7.8712e-01,  9.7224e-01,  2.9846e-02,
         0.0000e+00,  4.8287e+00,  5.3363e+00,  2.2314e+00,  1.8215e+00,
         2.6047e-01, -1.0819e+00, -4.3602e-03, -8.4029e-02,  4.4260e-04,
         2.8626e-04,  4.6005e-02,  9.3593e-01,  2.2757e+00,  1.0398e-01,
         1.7199e+00,  5.2796e-01, -2.3848e-02,  3.0909e+00,  6.4145e+00,
         3.0311e-04,  3.9614e+00,  8.9145e-03,  6.1509e-01,  2.1072e-01,
         6.8099e-01,  7.5360e-02, -6.5995e-03,  3.3152e+00,  1.1633e+00,
        -7.2330e-04,  2.2896e+00,  7.0256e-01,  6.2285e-01,  1.3425e+00,
         2.6416e+00,  3.4716e-01, -3.0948e-03,  9.1225e-03, -6.7279e-02,
         1.7995e+00,  6.4338e-02, -8.9913e-08, -1.8917e-02, -1.0790e-01,
         1.3889e+00,  1.3142e-01, -1.8146e-01,  3.3965e+00,  1.4980e+00,
         1.0755e-02,  5.2972e-01,  2.4389e+00,  9.8167e-01,  1.5433e+00,
         7.6076e-01,  3.5792e+00,  4.3908e-01,  2.6553e+00,  0.0000e+00,
         9.4712e-01,  1.8605e-03,  1.4400e+00, -1.4796e-03, -3.7362e-01,
         3.9270e+00,  1.0669e-02,  1.5842e+00,  3.1491e+00, -8.2889e-01,
         5.5453e-01,  3.5501e-04,  1.8082e+00,  4.4588e+00,  2.1416e-02,
         1.9860e+00, -2.4149e-06, -2.0494e-03, -2.2290e-03,  7.9375e-07,
         6.7708e+00,  1.3298e-01, -3.1829e-01, -1.4826e-04, -2.4105e+00,
         1.9802e-02,  3.2940e+00,  1.8658e+00,  8.8795e-06,  3.2170e+00,
         6.5870e-05,  9.7198e-03,  2.9354e+00,  1.7643e+00, -1.1610e-03,
         4.2522e+00,  4.5224e-05, -4.5873e-01,  8.3187e-01,  3.2185e+00,
         5.7432e-06,  2.2308e-02,  3.3325e+00,  5.3301e-01,  3.7201e+00,
         1.5439e-01,  6.3617e+00,  6.7849e-01, -6.8947e-02, -3.2804e-01,
         2.7357e-03, -1.5576e-03,  3.7193e-02,  2.6818e-01,  4.1099e+00,
         0.0000e+00, -3.4623e-02,  1.9220e+00,  6.7028e-05, -9.8528e-02,
         0.0000e+00,  2.0563e+00,  0.0000e+00,  9.6651e-01, -1.6028e-01,
         1.4347e+00, -7.2519e-04,  1.3713e+00,  3.7820e+00, -5.6414e-03,
         5.9066e-02, -3.7222e-01,  2.9894e-03,  3.5630e+00,  1.0515e+00,
        -8.7256e-03,  8.9780e-01, -2.9871e-01, -4.3234e-01,  2.0856e+00,
         0.0000e+00,  5.7814e-03, -3.9721e-01, -2.4469e-05,  3.6084e-04,
         3.4556e+00,  1.5607e-01,  7.4292e-01,  1.8675e-01,  1.0763e+00,
         4.3792e+00,  1.6129e+00,  5.3151e+00,  3.4003e-03, -1.1778e-02,
         3.2911e-03,  2.6880e+00,  2.1243e-03,  2.7532e-01,  1.3251e+00,
         9.0994e-01,  3.1771e-02,  3.2735e+00, -8.6505e-01,  6.6013e-01,
         4.3597e-03,  4.2709e-06, -3.7368e-02, -1.0150e-01,  7.4874e-07,
         4.5904e-01,  9.9265e-01,  1.3909e+00,  4.9059e-02,  6.1070e-01,
        -8.6107e-02,  7.3762e-01,  6.1741e+00,  3.7277e+00, -6.5529e-04,
         1.5371e+00, -1.3887e-05,  5.5599e-05, -4.2974e-04, -2.0841e+00,
         3.0643e+00,  1.9570e+00, -1.4779e+00,  3.8049e+00,  3.4563e+00,
         8.3906e-01,  5.1832e+00,  3.5935e-01, -6.1161e-01,  4.4531e-01,
        -6.3986e-06,  1.5613e-02, -3.3874e-01,  1.2613e-03,  1.2891e-04,
         5.1271e+00,  1.7760e+00,  7.9638e-01, -3.4976e-03,  5.2213e-01,
         5.0328e-02,  1.2591e+00,  2.5101e-02,  2.2227e-01,  1.2391e-01,
         5.4473e-01,  2.7703e-01,  2.9236e+00,  2.4901e+00,  1.9044e-05,
         2.1020e-01,  1.3084e-01,  1.5520e-02, -1.9446e-01,  4.7373e-02,
         9.8694e-01,  6.1832e+00,  4.0437e+00,  2.2702e+00,  6.2566e+00,
         4.5034e+00,  3.7963e-01,  5.0667e-02, -1.5453e-01,  5.6949e+00,
        -2.8978e-01,  1.5766e+00, -2.9317e-03,  2.2982e-05,  1.3710e-02,
         3.6047e-02, -9.1101e-05,  6.1409e+00,  2.0102e-01,  1.9897e+00,
         1.4315e+00,  0.0000e+00,  6.7258e+00, -1.7134e-01,  4.5582e+00,
        -5.7037e-02,  1.1788e-01,  3.2204e-01, -2.6164e-02,  6.8241e-01,
        -5.4375e-03,  3.3593e+00, -5.8896e-02, -3.2130e-03,  5.6187e-02,
        -4.6467e-01, -1.0860e-01,  5.4050e+00, -4.8753e-02,  5.0633e-05,
        -5.0136e-02,  2.1390e-02,  8.2393e-01,  3.3290e-07,  2.8176e-01,
         2.9590e+00,  0.0000e+00,  4.0353e-02,  8.2758e+00,  1.3135e+00,
         1.1648e+00, -5.8794e-03,  2.8252e+00,  2.6835e+00,  2.2790e+00,
         1.2764e-03,  3.8830e-02,  5.9775e-03,  2.1132e+00,  1.0549e+00,
         6.7684e+00, -8.8376e-01,  1.0189e+00, -2.0481e-05,  3.6895e-05,
         3.4517e+00,  9.0359e-01,  6.6038e-01,  4.9663e-01,  0.0000e+00,
         9.4809e-01,  3.6926e+00,  3.8660e-01,  3.1523e+00,  2.7561e-04,
        -9.3906e-07,  3.4080e-03,  2.6797e+00,  8.9340e-01,  1.0343e+00,
         5.6106e+00,  2.6574e-02,  3.3058e-01,  4.2061e+00, -6.0101e-02,
         7.3344e-03,  2.6659e+00,  4.3140e-01,  2.9748e-01,  2.1571e-01,
         5.6885e+00, -1.5672e-03,  1.1221e+00,  2.0652e+00, -3.8493e-01,
         6.8977e+00,  6.8502e-01, -2.1986e-05,  5.2788e+00,  3.8200e+00,
         5.3481e-02,  4.4051e-02, -2.3139e-03, -1.3108e-02,  5.0132e-04,
         1.4826e-01, -1.9925e-02, -1.8252e-02,  4.3136e-01,  1.8586e+00,
         5.0791e+00,  1.3056e-04,  1.4005e+00,  7.8747e-01,  3.7154e-02,
        -1.0581e+00,  0.0000e+00, -2.8137e-03,  5.4615e-03,  1.6574e+00,
         1.1270e+00,  1.2449e-01,  6.1318e-01, -3.6335e-02,  7.0385e-02,
         2.3280e+00,  1.7856e-02,  8.7494e-02,  0.0000e+00, -2.0865e+00,
         4.7533e+00,  4.2463e-01,  6.6003e-03,  1.4132e-01,  4.4473e+00,
        -3.8706e-04, -3.3000e-02, -3.7318e-03, -1.9362e-03,  1.3151e+00,
         2.0727e+00,  2.5712e-02,  3.2640e-01, -1.2388e-07,  3.7761e-02,
         2.8580e-03,  1.0974e+00,  3.1836e+00,  2.5696e+00, -2.2254e-01,
         4.7016e+00,  3.5000e-01, -2.1413e-04,  1.1664e-01, -6.8504e-03,
         1.1382e+00,  2.0336e+00,  8.4871e-01,  2.7186e+00,  1.6621e-02,
         1.2375e-02,  5.7867e+00, -1.6136e-01,  1.6339e-04,  0.0000e+00,
         6.8297e-03,  3.1415e+00,  1.4376e+00,  4.0787e+00, -4.8453e-01,
         3.0216e-02, -6.6747e-01,  6.4819e+00,  3.2801e-03, -1.1741e-01,
        -1.4049e-02,  0.0000e+00,  1.0498e+00,  1.2665e+00,  5.6819e+00,
         4.1810e-01,  1.5865e-01,  1.2948e+00,  1.9029e+00,  1.4274e-01,
        -2.1341e-01, -1.0794e-01,  1.2486e-02, -7.5067e-01,  2.2898e-01,
         0.0000e+00,  2.3821e-05, -1.9514e-01,  1.8774e-03,  1.5081e+00,
        -7.5928e-03,  3.6748e-03, -2.8771e+00,  1.4140e-01,  0.0000e+00,
         1.7112e+00,  1.0050e-03,  3.4578e+00,  3.9243e+00,  2.1866e+00,
         6.9149e-01,  2.1775e+00,  3.0018e+00, -1.2441e-01,  1.6134e+00,
         2.4229e+00,  1.5608e+00,  1.6936e+00,  2.7727e-02,  3.5284e+00,
        -1.0632e+00,  1.2312e-03], device='cuda:0'), 'backend.10.bias': tensor([ 1.8783e+01,  4.3733e+01,  2.5684e+02, -3.2561e-03, -1.2359e+01,
         1.1547e+02, -3.1198e+00,  8.3059e+01,  1.4000e+02, -7.3681e-01,
        -5.0591e+01, -1.5468e-01,  1.0281e+02,  1.2756e+00,  1.6010e+02,
         1.1045e+01,  1.2830e+03,  6.7232e+01, -1.5623e+01,  1.0352e+02,
         1.9360e+01,  9.5123e+01, -8.2065e-04,  1.0450e+02,  2.8057e+02,
         4.3277e+02,  2.4633e+02,  2.9370e-03, -1.4829e+02,  6.9665e-02,
         7.1711e+00, -1.9232e+00,  1.9986e+02,  5.9815e+02,  7.1439e+01,
         9.0712e+01,  2.4118e-02,  9.0101e+01, -4.7573e-03, -3.0624e-07,
         1.8101e+00,  4.8774e+01,  2.0609e-01, -1.0513e-02,  2.5788e+00,
         1.5999e+01,  6.4506e+00, -8.8568e-02,  1.3948e+00,  5.6513e+00,
         4.0536e+01, -3.4019e-02,  0.0000e+00,  2.8110e-01, -4.8581e+00,
         2.4915e+02,  0.0000e+00,  1.1508e-01,  5.7998e+02,  2.6994e-01,
        -3.5060e-01,  0.0000e+00, -3.4694e-02,  7.8421e-03], device='cuda:0'), 'output_layer.bias': tensor([-48546.2656], device='cuda:0'), 'backend.2.weight': tensor([[[[-6.4635e-02, -9.6916e-02, -6.7550e-02],
          [ 1.6841e-01,  1.4668e-01,  1.6919e-01],
          [ 2.0291e-01,  1.8141e-01,  1.6464e-01]],

         [[ 1.5663e-02,  7.4929e-03, -9.4513e-03],
          [ 1.6636e-01,  1.6025e-01,  1.5642e-01],
          [ 1.1273e-02,  1.3815e-03, -4.0456e-03]],

         [[-7.5925e-01, -6.2591e-01, -5.8945e-01],
          [-3.9378e-01, -3.7516e-01, -4.0318e-01],
          [ 4.4954e-01,  3.0107e-01,  3.1709e-01]],

         ...,

         [[-9.3454e-01, -9.0982e-01, -7.9814e-01],
          [ 1.6759e-01,  2.0778e-01,  3.3853e-01],
          [-1.8147e-03, -1.1693e-02, -3.9303e-02]],

         [[ 3.5014e-01,  2.9868e-01,  3.4211e-01],
          [-8.5595e-01, -8.4063e-01, -8.1313e-01],
          [-6.0886e-01, -6.0176e-01, -5.5870e-01]],

         [[ 2.9380e-01,  3.2268e-01,  2.5209e-01],
          [-2.5400e-01, -2.7295e-01, -2.2365e-01],
          [-7.1756e-01, -6.7351e-01, -6.4528e-01]]],


        [[[ 5.6435e-01,  5.8203e-01,  5.8303e-01],
          [ 4.7701e-01,  5.0131e-01,  5.1548e-01],
          [ 4.0729e-01,  4.2508e-01,  4.3733e-01]],

         [[ 7.2442e-02,  6.5861e-02,  7.9195e-02],
          [ 4.8784e-02,  4.3863e-02,  4.4741e-02],
          [ 6.1212e-02,  5.1065e-02,  5.3166e-02]],

         [[ 1.1560e+00,  1.1450e+00,  1.0935e+00],
          [ 1.0533e+00,  1.0883e+00,  1.0024e+00],
          [ 6.1067e-01,  6.3459e-01,  5.7783e-01]],

         ...,

         [[ 1.9252e+00,  2.0255e+00,  2.0408e+00],
          [ 1.6723e+00,  1.7008e+00,  1.6763e+00],
          [ 1.3849e+00,  1.3863e+00,  1.3342e+00]],

         [[ 9.5660e-01,  9.5319e-01,  1.0441e+00],
          [ 1.5580e+00,  1.6244e+00,  1.7149e+00],
          [ 1.0933e+00,  1.0929e+00,  1.1703e+00]],

         [[ 8.9927e-01,  8.6494e-01,  8.1821e-01],
          [ 1.0213e+00,  9.8577e-01,  9.3177e-01],
          [ 1.2662e+00,  1.2589e+00,  1.2431e+00]]],


        [[[ 2.2816e+00,  2.2710e+00,  2.2500e+00],
          [ 2.4083e+00,  2.4084e+00,  2.3927e+00],
          [ 2.4195e+00,  2.5289e+00,  2.5152e+00]],

         [[ 5.7919e-02,  4.7188e-02,  2.9559e-02],
          [-2.6466e-03, -8.1487e-03, -3.3949e-02],
          [ 6.4341e-02,  5.2665e-02,  4.6937e-02]],

         [[ 3.8155e+00,  3.8069e+00,  3.7308e+00],
          [ 4.2054e+00,  4.2784e+00,  4.2427e+00],
          [ 5.1261e+00,  5.1267e+00,  5.0676e+00]],

         ...,

         [[ 1.0047e+01,  1.0056e+01,  9.7152e+00],
          [ 9.9996e+00,  1.0215e+01,  9.9554e+00],
          [ 1.1597e+01,  1.1787e+01,  1.1646e+01]],

         [[ 1.9054e+00,  1.7789e+00,  1.8063e+00],
          [ 1.9441e+00,  1.7815e+00,  1.7328e+00],
          [ 3.0551e+00,  2.8992e+00,  2.6791e+00]],

         [[ 2.4428e+00,  2.4877e+00,  2.4139e+00],
          [ 2.7092e+00,  2.6199e+00,  2.5976e+00],
          [ 2.7081e+00,  2.6781e+00,  2.6690e+00]]],


        ...,


        [[[ 2.6391e+00,  2.6735e+00,  2.6910e+00],
          [ 2.6792e+00,  2.7079e+00,  2.7183e+00],
          [ 2.5579e+00,  2.5441e+00,  2.5652e+00]],

         [[ 1.5859e-01,  1.5324e-01,  1.5137e-01],
          [-1.1303e-02, -2.0908e-02, -6.3581e-02],
          [-3.5575e-01, -3.6873e-01, -3.8632e-01]],

         [[ 4.3654e+00,  4.4132e+00,  4.4109e+00],
          [ 5.8398e+00,  5.9330e+00,  5.8919e+00],
          [ 5.6541e+00,  5.8352e+00,  5.8085e+00]],

         ...,

         [[ 1.1088e+01,  1.1240e+01,  1.1107e+01],
          [ 1.1846e+01,  1.1954e+01,  1.1736e+01],
          [ 1.0283e+01,  1.0434e+01,  1.0272e+01]],

         [[ 1.2082e+00,  1.1517e+00,  1.1570e+00],
          [ 3.0666e+00,  2.9958e+00,  2.9935e+00],
          [ 4.6782e+00,  4.5943e+00,  4.5047e+00]],

         [[ 2.5522e+00,  2.6313e+00,  2.5385e+00],
          [ 2.7222e+00,  2.7399e+00,  2.6340e+00],
          [ 4.1209e+00,  4.1448e+00,  4.1245e+00]]],


        [[[-2.9237e-01, -3.1518e-01, -4.3780e-01],
          [-1.4256e-01, -1.2583e-01, -1.4116e-01],
          [-2.0814e-01, -2.2180e-01, -2.6059e-01]],

         [[-2.3134e-02, -2.9565e-02, -4.5126e-02],
          [ 3.5314e-02,  8.0137e-03,  9.6990e-03],
          [-2.1341e-01, -2.4901e-01, -2.7805e-01]],

         [[-1.1031e+00, -1.0078e+00, -1.0715e+00],
          [-3.9696e-01, -3.9531e-01, -4.6979e-01],
          [ 1.5442e-01,  1.2222e-01,  8.2694e-02]],

         ...,

         [[-1.7260e+00, -1.7605e+00, -1.9208e+00],
          [-8.1266e-01, -8.1995e-01, -8.7254e-01],
          [-1.9390e+00, -1.8983e+00, -1.9462e+00]],

         [[-1.4837e+00, -1.4456e+00, -1.4959e+00],
          [-1.7014e+00, -1.6847e+00, -1.6857e+00],
          [-1.3769e-01, -1.2459e-01, -2.2250e-01]],

         [[-7.2500e-01, -8.0629e-01, -8.5326e-01],
          [-1.4034e+00, -1.3734e+00, -1.3315e+00],
          [-1.0960e+00, -1.0423e+00, -1.0655e+00]]],


        [[[ 4.0790e-04,  7.6467e-05, -4.1249e-05],
          [ 2.9510e-06, -7.1753e-05, -6.6087e-06],
          [ 0.0000e+00,  1.7812e-06,  6.8927e-06]],

         [[ 0.0000e+00, -1.2479e-05,  2.5424e-05],
          [ 7.9855e-05, -1.5036e-06,  2.3006e-04],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 4.2182e-04,  5.2418e-04,  1.8035e-04],
          [ 4.4104e-04,  3.9912e-04,  2.8819e-04],
          [ 0.0000e+00,  2.7090e-05,  2.8828e-05]],

         ...,

         [[ 1.9153e-03,  2.1777e-03,  2.2459e-03],
          [ 1.3172e-03,  1.8804e-03,  1.8020e-03],
          [ 0.0000e+00,  3.2030e-05,  2.6647e-05]],

         [[ 2.9604e-04,  1.6309e-03,  2.4449e-03],
          [-2.2246e-05,  1.4616e-05,  2.7714e-05],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 1.1392e-03,  8.2970e-04,  2.4315e-03],
          [ 1.0622e-03,  5.2571e-04,  4.8625e-04],
          [ 0.0000e+00,  1.9191e-05,  3.2881e-05]]]], device='cuda:0'), 'backend.6.bias': tensor([-4.7424e+00,  2.8371e+00, -1.1093e-04,  0.0000e+00, -7.1933e-03,
         5.8636e+00, -4.3196e+00,  1.7178e+01,  1.0411e+01,  5.3236e+00,
         0.0000e+00,  2.0427e-04,  4.5264e+00,  3.4525e-09,  0.0000e+00,
         0.0000e+00,  1.2646e+01, -6.4829e+00,  8.6104e-02,  1.2444e+01,
         8.8204e+00, -4.8732e-01,  2.4030e+00, -1.0875e+01, -1.1334e-04,
         4.4894e+00,  1.0301e+01, -1.6590e+00,  6.8200e-06,  5.3025e+00,
         1.8914e+01,  1.2593e+01,  1.7661e+01,  2.1312e-01,  0.0000e+00,
         1.0664e+01,  4.2428e+00,  2.3247e+01,  8.7352e+00,  1.1318e-01,
         0.0000e+00,  7.1652e+00,  2.0780e+01,  5.3354e+00,  2.4413e+01,
         3.2562e+00,  0.0000e+00, -4.3515e+00, -1.1215e+00,  7.2224e-01,
         1.1861e+01,  2.5620e+01, -1.1056e+01,  5.4389e-05,  7.8719e+00,
         5.3380e+00,  4.2133e-05,  6.9973e+00,  0.0000e+00, -3.6629e-04,
         4.6993e-01,  8.2353e+00,  7.9508e+00,  3.7874e+00, -1.5590e+00,
         1.3816e+01,  5.3887e+00,  2.3110e+01,  3.7486e-03,  2.5057e+01,
        -2.8888e-03, -9.4660e+00,  0.0000e+00,  9.6963e+00,  0.0000e+00,
         2.5613e-06,  3.6216e-01, -3.3510e-01,  1.7862e+01,  1.2049e-03,
         3.6279e+00,  4.1113e-09,  1.4798e+01,  1.7092e+00,  2.2949e+01,
         0.0000e+00,  0.0000e+00, -4.7342e-01, -7.4938e+00,  0.0000e+00,
        -5.8682e-01,  1.7924e-01, -1.2313e+00, -9.2993e-05,  0.0000e+00,
         7.2247e-01,  3.8225e-03,  1.4272e-01, -2.7709e+00,  1.2774e+01,
         1.0936e+01, -2.1908e+00, -6.0240e-02,  2.7487e-01,  6.7056e+00,
        -3.6223e+00,  2.1529e-01,  6.8885e-02, -5.9394e+00,  7.2934e+00,
         2.4185e+00,  7.4665e+00,  1.0580e+01,  3.5195e-02,  1.8874e+01,
         0.0000e+00, -4.1436e+00,  4.0931e-05, -1.5103e+01, -1.1535e+00,
         4.2263e-03,  0.0000e+00,  6.8313e+00,  0.0000e+00, -6.4916e+00,
         8.2672e+00,  3.8516e+00,  7.0871e+00,  0.0000e+00,  5.7353e-06,
        -1.2034e-02,  1.0471e+01, -5.8923e+00,  1.5868e+01,  1.8059e+01,
         1.2286e+01,  1.8802e+01,  3.9179e+00,  0.0000e+00,  9.1303e+00,
         1.9378e+00, -3.1775e-02, -1.5044e-01,  2.1646e+00,  4.0531e-01,
        -6.2095e-03,  6.9837e+00,  2.4876e+00, -1.3063e-03,  6.8749e-03,
         8.5002e+00,  6.3251e+00,  4.8507e+00, -3.5260e+00,  2.7991e+00,
         0.0000e+00,  7.5252e-01,  3.0547e+00, -2.6545e+00,  0.0000e+00,
         0.0000e+00,  5.4700e+00,  0.0000e+00,  6.8519e-01, -1.5069e+01,
        -3.1230e+00,  0.0000e+00,  1.6224e+01,  2.4189e-01,  6.4461e+00,
         2.8143e+00, -2.5554e+00,  3.3562e+00,  3.8189e-05,  0.0000e+00,
         1.4483e+00, -5.2096e+00,  0.0000e+00,  1.4254e-01,  2.9253e-03,
         1.2901e+01,  7.3338e-05,  1.4665e+00,  2.2203e+00,  6.6298e+00,
         0.0000e+00, -2.4047e-02,  5.3652e-06,  8.1594e+00,  9.5197e+00,
        -5.3161e+00,  0.0000e+00, -4.4988e+00, -1.5217e-01,  2.7951e-01,
         0.0000e+00, -5.9410e-06, -1.4558e-03, -4.2140e+00, -4.5029e-04,
         2.4792e+00,  5.6879e-03, -5.1523e-05,  1.7605e+00,  0.0000e+00,
         9.6501e+00,  5.7578e+00,  4.3424e-01,  6.5823e+00, -1.2652e-01,
         8.7528e-02,  1.7094e+00,  0.0000e+00,  9.7064e+00, -2.3884e+00,
        -8.2629e-01, -1.0886e-01, -1.5436e+00,  4.2201e-03,  5.7538e-01,
        -2.1543e+00, -2.0459e+01,  1.6133e+01,  1.6280e+01,  2.4100e+00,
         1.6985e-01,  0.0000e+00, -3.0288e-01,  0.0000e+00,  2.1300e+00,
        -4.2212e-03,  1.5700e+00, -6.1610e+00, -5.0504e-03, -5.2108e+00,
         1.4943e+01,  2.2445e+01,  6.7315e+00,  6.6501e-01, -2.1890e+00,
        -1.1722e+00,  0.0000e+00,  1.7833e-01, -2.2184e+00, -7.4701e-02,
         3.2784e+00, -1.8447e+00,  1.2767e+00,  0.0000e+00,  0.0000e+00,
        -9.1118e-01,  1.3425e-02, -3.6709e+00,  9.9506e-03,  1.8800e-04,
        -4.2387e+00], device='cuda:0'), 'backend.0.weight': tensor([[[[ 1.1970e-02,  1.0134e-02,  1.2053e-02],
          [ 9.5027e-03,  5.7649e-03,  1.0011e-02],
          [ 9.2760e-03,  9.2519e-03,  1.1832e-02]],

         [[ 1.6554e-04,  1.0335e-02,  4.4328e-03],
          [-3.1035e-04,  8.5070e-03,  2.5382e-03],
          [ 1.4636e-04,  1.7584e-02,  2.5071e-03]],

         [[ 2.3240e-02,  3.0842e-02,  3.4578e-02],
          [ 7.9075e-03,  1.4747e-02,  1.8316e-02],
          [ 1.4045e-02,  1.6731e-02,  1.4828e-02]],

         ...,

         [[ 6.1130e-04,  1.3405e-04,  4.8253e-04],
          [ 6.0507e-04,  2.4863e-04,  4.8805e-04],
          [ 6.7985e-04,  9.2357e-04,  3.0847e-04]],

         [[ 5.6171e-02,  6.2819e-02,  9.5627e-02],
          [ 6.6935e-02,  8.2085e-02,  6.2142e-02],
          [ 7.7412e-02,  9.7235e-02,  3.1741e-02]],

         [[ 2.0892e-03,  3.4027e-03,  2.5698e-03],
          [ 3.2569e-03,  3.7289e-03,  2.4643e-03],
          [ 4.5145e-03,  2.9994e-03,  2.6633e-03]]],


        [[[-6.6603e-05,  1.0019e-03,  5.9941e-04],
          [ 4.3024e-04,  1.0475e-03,  1.4983e-03],
          [-1.9741e-04,  8.6789e-04,  7.9717e-04]],

         [[ 1.4535e-05, -3.1910e-05, -1.8621e-03],
          [ 1.4547e-06, -7.0951e-05, -7.9001e-04],
          [-2.8302e-06, -2.4631e-05, -3.4344e-05]],

         [[-2.8526e-04,  5.1939e-03,  1.2529e-02],
          [ 4.5492e-03,  2.9291e-03,  3.4762e-03],
          [ 3.6286e-03,  2.3911e-03,  2.0525e-03]],

         ...,

         [[-1.1580e-05,  1.8515e-04, -4.7741e-05],
          [ 2.4836e-04,  3.6157e-05,  4.8729e-06],
          [ 1.7798e-04, -6.8946e-05, -1.1960e-05]],

         [[ 1.1069e-02,  7.2073e-03,  4.2297e-03],
          [ 3.2651e-03,  8.5884e-04,  5.3282e-03],
          [ 3.2897e-03,  7.0419e-03,  2.8352e-03]],

         [[-8.0650e-05, -6.2284e-07,  3.8482e-04],
          [ 1.5251e-04,  5.2457e-04,  2.9893e-04],
          [ 4.9389e-05,  6.6547e-05,  1.1632e-04]]],


        [[[ 1.2677e-03,  1.1538e-02,  1.4866e-02],
          [ 1.7445e-02,  1.4753e-02,  2.2650e-02],
          [ 2.7385e-02,  2.4357e-02,  2.5168e-02]],

         [[-7.1365e-05,  2.7773e-03,  3.0401e-03],
          [ 1.1647e-04,  3.4831e-03,  5.3199e-03],
          [ 3.5750e-04,  4.4020e-03, -4.2063e-04]],

         [[ 6.2750e-02,  7.8612e-02,  8.3874e-02],
          [ 1.0671e-01,  1.2440e-01,  1.1918e-01],
          [ 3.5656e-02,  3.8072e-02,  4.0045e-02]],

         ...,

         [[ 3.1575e-04,  4.3219e-04,  2.4527e-04],
          [ 7.2556e-04,  4.5349e-04,  7.7056e-04],
          [ 4.7401e-04, -1.5976e-04,  7.7391e-04]],

         [[ 1.2171e-01,  1.3261e-01,  1.3563e-01],
          [ 1.1739e-01,  1.0491e-01,  1.1888e-01],
          [ 9.3471e-02,  1.0192e-01,  5.8208e-02]],

         [[ 3.3480e-03,  4.1552e-03,  8.1009e-03],
          [ 1.2421e-02,  1.0166e-02,  1.1361e-02],
          [ 4.7980e-03,  4.9524e-03,  5.1972e-03]]],


        ...,


        [[[ 5.2432e-02,  4.5853e-02,  5.3963e-02],
          [ 6.0085e-02,  5.9533e-02,  7.0752e-02],
          [ 5.8690e-02,  5.8423e-02,  6.4951e-02]],

         [[ 1.8375e-04,  3.1231e-03,  2.6784e-02],
          [ 1.3956e-03,  3.9800e-03,  2.8016e-02],
          [ 8.2276e-04,  2.9971e-03,  2.7396e-02]],

         [[ 8.4757e-02,  1.0114e-01,  1.1666e-01],
          [ 5.8666e-02,  5.4254e-02,  6.0549e-02],
          [ 7.1683e-02,  7.1174e-02,  7.3581e-02]],

         ...,

         [[ 3.9224e-03,  4.2642e-03,  4.4249e-03],
          [ 3.4636e-03,  4.1124e-03,  5.9496e-03],
          [ 4.4180e-03,  4.2039e-03,  5.4832e-03]],

         [[ 2.9173e-01,  3.1419e-01,  3.2728e-01],
          [ 2.9000e-01,  2.8632e-01,  3.0029e-01],
          [ 3.1038e-01,  3.2944e-01,  3.0515e-01]],

         [[ 9.9086e-03,  1.1940e-02,  1.6751e-02],
          [ 1.4013e-02,  1.2566e-02,  1.3863e-02],
          [ 1.4555e-02,  1.2064e-02,  1.3017e-02]]],


        [[[ 1.5196e-02,  1.1808e-02,  1.2671e-02],
          [ 3.4857e-03,  2.2245e-03,  7.1625e-03],
          [ 3.7623e-03, -3.1583e-03, -7.8041e-04]],

         [[ 4.3100e-04,  8.1462e-03,  1.4815e-02],
          [ 2.8360e-04,  1.3852e-02,  2.5328e-02],
          [-4.8780e-05,  2.4618e-02,  3.5685e-02]],

         [[ 9.2165e-02,  7.5893e-02,  8.2687e-02],
          [ 4.7648e-02,  3.5945e-02,  4.5284e-02],
          [ 2.5113e-02,  2.0966e-02,  2.0324e-02]],

         ...,

         [[-1.6176e-04,  1.0178e-03,  9.8204e-04],
          [-1.2820e-05,  2.5615e-04, -8.2869e-05],
          [ 3.4207e-05, -6.5481e-04, -1.1628e-03]],

         [[ 1.0081e-01,  8.6448e-02,  7.0306e-02],
          [ 2.0325e-01,  1.6923e-01,  2.0938e-01],
          [ 3.1042e-02,  3.2243e-02,  5.4905e-02]],

         [[ 6.6962e-03,  1.8774e-03,  6.9654e-03],
          [ 2.0471e-03,  5.4860e-03,  2.4812e-03],
          [ 2.2668e-03,  1.9502e-03,  3.8067e-03]]],


        [[[ 1.8624e-02,  2.2312e-02,  1.8920e-02],
          [ 7.5841e-03,  1.3199e-02,  1.3875e-02],
          [ 2.2029e-02,  2.5610e-02,  1.3293e-02]],

         [[ 1.9185e-04,  8.1733e-03,  1.0261e-02],
          [ 1.3473e-04,  1.5847e-02,  2.3613e-02],
          [ 2.9654e-04,  1.4703e-02,  2.7129e-02]],

         [[ 6.8438e-03, -1.8660e-04,  9.3251e-04],
          [ 9.5374e-03,  2.4663e-02,  5.3067e-03],
          [ 1.9108e-02,  2.4059e-02,  2.1151e-02]],

         ...,

         [[ 1.8764e-03,  2.1689e-03,  2.3976e-03],
          [ 1.6033e-03,  1.6116e-03,  9.8976e-04],
          [ 1.4481e-03,  1.8442e-03,  1.8812e-03]],

         [[ 1.1025e-01,  1.2266e-01,  1.5979e-01],
          [ 1.9392e-01,  1.7399e-01,  1.7459e-01],
          [ 5.6993e-02,  6.4720e-02,  4.5355e-02]],

         [[ 5.3725e-03,  2.0433e-03,  3.7284e-04],
          [ 4.9176e-03,  7.0496e-03,  2.4922e-03],
          [ 4.9517e-03,  6.2583e-03,  3.1222e-03]]]], device='cuda:0'), 'output_layer.weight': tensor([[[[ 7.4855e+01]],

         [[ 4.0001e+01]],

         [[-9.7836e+02]],

         [[ 4.4185e-03]],

         [[-2.2189e+01]],

         [[-6.0617e+01]],

         [[-1.2658e+01]],

         [[ 4.6479e+03]],

         [[ 1.4089e+03]],

         [[ 5.8337e+01]],

         [[-2.4453e+01]],

         [[ 3.2582e-02]],

         [[ 2.2780e+02]],

         [[-1.6849e+01]],

         [[ 2.4993e+02]],

         [[ 2.6226e+01]],

         [[-5.3672e+03]],

         [[-8.7495e+02]],

         [[-1.8005e+01]],

         [[ 1.2377e+02]],

         [[-3.4219e+02]],

         [[ 1.0222e+02]],

         [[ 3.8673e-01]],

         [[-4.2101e+03]],

         [[-3.3007e+03]],

         [[-1.8900e+03]],

         [[-5.9217e+03]],

         [[ 4.4314e-03]],

         [[-8.7811e+02]],

         [[ 2.3058e-01]],

         [[ 8.2964e+00]],

         [[-8.5374e+00]],

         [[ 2.9007e+03]],

         [[-2.5294e+03]],

         [[-4.4914e+02]],

         [[ 9.3687e+01]],

         [[-9.9870e-02]],

         [[ 1.8103e+02]],

         [[ 5.9501e+01]],

         [[ 5.7171e-06]],

         [[-6.8429e-01]],

         [[ 4.3085e+01]],

         [[-3.6502e+00]],

         [[ 1.7581e-02]],

         [[ 1.1991e+01]],

         [[ 1.9148e+01]],

         [[ 2.8344e+00]],

         [[ 3.7866e-01]],

         [[-1.2852e+00]],

         [[ 1.9348e+01]],

         [[ 3.3910e+01]],

         [[-9.4291e-02]],

         [[ 0.0000e+00]],

         [[ 2.9373e-01]],

         [[-2.9611e+00]],

         [[-6.6187e+03]],

         [[ 0.0000e+00]],

         [[-1.4576e+00]],

         [[-2.3819e+03]],

         [[ 1.1930e-01]],

         [[ 1.1611e+01]],

         [[ 0.0000e+00]],

         [[ 2.5092e-02]],

         [[ 1.1296e-02]]]], device='cuda:0'), 'backend.4.weight': tensor([[[[-4.4179e-02, -5.9377e-02, -6.6701e-02],
          [-9.8369e-02, -1.0910e-01, -1.2085e-01],
          [-1.9603e-04,  7.7769e-04, -5.2878e-05]],

         [[-3.3188e-02, -3.5058e-02, -3.6053e-02],
          [-2.9494e-02, -2.6537e-02, -2.8477e-02],
          [-2.6413e-05,  3.9913e-05, -7.3896e-05]],

         [[-8.5401e-02, -8.0561e-02, -8.1290e-02],
          [-1.3630e-01, -1.5167e-01, -1.6078e-01],
          [-1.8877e-04, -1.3825e-03,  7.6332e-05]],

         ...,

         [[-5.5605e-02, -8.6483e-02, -1.2123e-01],
          [-2.2798e-02, -3.9803e-02, -6.3527e-02],
          [-5.8735e-05,  1.5407e-03,  1.8206e-03]],

         [[-5.6061e-02, -6.0885e-02, -8.6836e-02],
          [-6.4764e-02, -6.3279e-02, -6.8632e-02],
          [-4.3024e-06,  1.5629e-03,  1.8741e-03]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  3.2303e-07],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 2.3908e+00,  2.5381e+00,  2.5584e+00],
          [ 2.6739e+00,  2.8398e+00,  2.9221e+00],
          [ 2.3337e+00,  2.5085e+00,  2.6994e+00]],

         [[ 6.3602e-02,  5.9310e-02,  4.4193e-02],
          [ 9.9780e-02,  9.6031e-02,  9.9930e-02],
          [ 3.3650e-01,  3.5910e-01,  3.3152e-01]],

         [[ 1.8329e+00,  1.9817e+00,  2.1330e+00],
          [ 1.7119e+00,  1.7507e+00,  1.8875e+00],
          [ 1.6848e+00,  1.7121e+00,  1.7635e+00]],

         ...,

         [[ 2.6765e+00,  2.8856e+00,  2.9223e+00],
          [ 3.2281e+00,  3.5218e+00,  3.6464e+00],
          [ 3.6565e+00,  3.8046e+00,  3.8169e+00]],

         [[ 3.1254e-01,  3.7181e-01,  3.8598e-01],
          [ 2.5671e-01,  3.4244e-01,  2.7876e-01],
          [-2.1134e-02,  7.0643e-02,  2.6290e-02]],

         [[ 2.1798e-07,  1.4887e-07,  0.0000e+00],
          [-1.9705e-05, -2.0931e-05, -3.1806e-05],
          [-1.2410e-04, -7.3903e-05,  3.7588e-05]]],


        [[[ 5.6427e+00,  5.5062e+00,  5.3483e+00],
          [ 5.4162e+00,  5.4135e+00,  5.2775e+00],
          [ 6.6560e+00,  6.6933e+00,  6.5599e+00]],

         [[ 1.1674e+00,  1.2203e+00,  1.2011e+00],
          [ 8.2228e-01,  8.2413e-01,  8.0575e-01],
          [ 9.3082e-01,  9.1014e-01,  8.5485e-01]],

         [[ 4.3760e+00,  4.3119e+00,  4.1928e+00],
          [ 4.9830e+00,  5.0748e+00,  5.0743e+00],
          [ 5.6955e+00,  5.8322e+00,  5.8518e+00]],

         ...,

         [[ 8.6059e+00,  8.4499e+00,  8.2457e+00],
          [ 7.5964e+00,  7.4218e+00,  7.3400e+00],
          [ 6.9273e+00,  6.8217e+00,  6.8411e+00]],

         [[ 1.6415e+00,  1.5389e+00,  1.4872e+00],
          [ 2.0367e+00,  1.9440e+00,  1.9120e+00],
          [ 2.0443e+00,  2.0207e+00,  2.0052e+00]],

         [[ 2.2428e-06,  2.8132e-08,  0.0000e+00],
          [ 1.2730e-04,  1.0258e-04,  7.1943e-05],
          [ 5.4599e-04,  4.6088e-04,  2.9288e-04]]],


        ...,


        [[[ 5.0465e-02,  6.4598e-02,  6.8248e-02],
          [ 1.4693e-01,  1.6275e-01,  1.7260e-01],
          [ 2.9200e-05,  7.7410e-05,  5.6753e-05]],

         [[ 5.1595e-03,  6.2951e-03,  5.2357e-03],
          [ 4.8619e-02,  4.3360e-02,  3.5462e-02],
          [-6.2577e-08,  3.6611e-05, -3.2880e-08]],

         [[ 1.4114e-01,  1.4783e-01,  1.4731e-01],
          [ 1.3983e-01,  1.5863e-01,  1.6437e-01],
          [ 2.9035e-05,  4.0650e-05,  2.3867e-05]],

         ...,

         [[ 6.1174e-02,  9.0042e-02,  9.8078e-02],
          [ 4.8675e-02,  6.9025e-02,  7.1592e-02],
          [ 1.8738e-06,  9.0123e-05,  8.7945e-06]],

         [[ 5.3747e-02,  5.1414e-02,  6.8334e-02],
          [ 1.4592e-01,  1.5495e-01,  1.5642e-01],
          [-3.4198e-07,  4.3474e-05,  2.8187e-05]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -3.7870e-08, -1.6299e-07],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],


        [[[ 3.4214e+00,  3.5128e+00,  3.4257e+00],
          [ 3.2902e+00,  3.4361e+00,  3.1967e+00],
          [ 3.0894e+00,  3.2558e+00,  2.9887e+00]],

         [[-2.7116e-01, -2.7706e-01, -2.3759e-01],
          [ 7.8529e-02,  7.4545e-02,  1.1246e-01],
          [-1.8028e-01, -1.6976e-01, -1.5349e-01]],

         [[ 2.8669e+00,  2.9341e+00,  2.7644e+00],
          [ 2.5417e+00,  2.6249e+00,  2.4960e+00],
          [ 2.4562e+00,  2.5381e+00,  2.4885e+00]],

         ...,

         [[ 5.0563e+00,  5.2285e+00,  4.9127e+00],
          [ 5.6640e+00,  5.7337e+00,  5.4940e+00],
          [ 5.4356e+00,  5.5666e+00,  5.4099e+00]],

         [[ 2.4171e-01,  2.0907e-01,  1.5144e-01],
          [ 1.5094e-01,  7.6182e-02, -4.0121e-02],
          [ 6.0601e-01,  5.6058e-01,  3.5845e-01]],

         [[ 3.1707e-06,  2.0444e-06,  0.0000e+00],
          [-1.4304e-04, -1.3625e-04, -5.7287e-05],
          [-2.2072e-04, -2.3010e-04, -1.7277e-04]]]], device='cuda:0'), 'backend.4.bias': tensor([-2.3515e-01,  2.0505e+00,  6.8647e+00,  1.6647e-02,  1.7110e+00,
         7.7802e-02,  0.0000e+00,  0.0000e+00,  1.0193e-01, -3.9482e-01,
         6.2354e+00, -1.2014e-03,  5.1309e+00,  2.1746e-02,  0.0000e+00,
        -1.8265e-02,  2.0409e+00,  4.6842e+00,  7.0525e-01, -2.1545e+00,
         1.3455e+00,  2.1836e+00,  9.0947e-02,  6.8881e+00,  6.6829e-01,
         1.0641e+00,  0.0000e+00, -4.1451e-04, -5.2381e-01,  1.5220e-01,
         2.6974e+00, -2.5714e-02,  9.8410e+00,  2.6666e+00,  3.0849e-01,
        -3.3128e-01,  1.2544e+00, -1.1770e+00,  2.5229e+00,  0.0000e+00,
         0.0000e+00, -8.8232e-01,  6.7338e+00, -4.3693e-02,  0.0000e+00,
         2.2183e-03,  0.0000e+00,  4.2435e+00,  2.9965e+00,  4.1035e+00,
        -1.4814e+00, -8.0547e-01, -4.3715e+00, -1.7401e-01, -3.1953e+00,
         1.8639e+00,  0.0000e+00, -1.7265e-03,  6.5476e+00, -1.5685e+00,
        -1.7417e+00,  5.0467e-05,  3.9864e-01, -7.8891e-06,  1.5776e+00,
         5.9208e+00, -3.9309e+00, -1.2162e-01,  2.7867e-04, -1.2163e+00,
        -3.2614e-04,  0.0000e+00, -3.2340e-01,  8.5553e-02, -5.6640e-05,
         0.0000e+00, -6.1330e-06,  0.0000e+00,  1.8266e+00,  7.1331e+00,
         3.6393e-04,  3.1094e+00,  2.1099e-01,  5.5999e+00,  6.7801e+00,
        -6.3408e-03,  0.0000e+00,  1.9459e-04,  1.1064e-01, -8.8315e-02,
         2.1558e+00,  0.0000e+00,  2.7544e+00,  1.2407e-01,  2.9092e-02,
         7.7958e-03,  2.0071e+00,  4.4247e-02, -1.1706e-03,  3.2001e+00,
         1.3188e+00,  5.7862e+00,  8.5751e+00,  9.3184e+00,  6.3964e-01,
         1.1903e+00,  0.0000e+00,  1.1568e+01,  0.0000e+00, -7.4448e-03,
         1.9758e-03, -1.6382e-03,  1.4050e-01, -4.0811e-02, -6.7495e-06,
         9.2908e-02,  2.8180e-03, -3.2892e+00, -1.9695e+00,  0.0000e+00,
         1.7107e+00,  4.8321e+00, -7.6096e-01, -1.3250e-01,  8.9577e+00,
         1.1205e+00,  1.6200e+01,  2.2193e+00, -1.6502e-01, -8.9891e-01,
         5.2659e-04,  0.0000e+00,  1.3546e+00,  0.0000e+00, -8.4388e-01,
        -3.3364e+00,  8.3779e-02, -3.9248e-03,  9.0705e-02,  3.5860e+00,
        -4.0187e-01,  9.4908e-03,  0.0000e+00,  6.7616e-06,  0.0000e+00,
         1.7617e-01,  7.1250e+00,  1.4892e+00,  7.2822e-04, -1.7583e+00,
         3.4351e-01,  3.7636e-02, -1.3714e+00,  7.2323e-02, -7.1723e+00,
        -2.6279e-05, -2.5626e-02, -4.4798e+00,  2.8957e+00,  2.8120e+00,
        -2.0257e+00,  1.0656e-03, -1.6250e+00, -1.6012e-01,  1.2714e+00,
         5.1511e+00,  0.0000e+00,  8.9933e-01,  1.3359e+00, -2.3501e-02,
         5.7606e+00, -2.6841e-02,  1.2148e-02,  1.0277e+00,  1.0389e-02,
        -2.1452e-03,  6.1902e+00,  8.6685e+00,  0.0000e+00,  1.3814e+00,
         0.0000e+00, -7.7265e-03, -5.6773e-01,  9.8685e-01, -1.1261e+00,
         2.1534e+00,  1.1618e+01,  3.2448e+00,  1.9123e-02, -2.6640e+00,
        -5.9022e-01,  2.5654e+00, -9.0370e-04,  1.7416e-02, -1.0217e+00,
         2.4085e+00,  0.0000e+00,  2.3184e-03, -1.4057e+00, -4.2769e-01,
        -1.2497e-02, -9.9764e-03, -6.6860e-01,  2.0957e+00,  7.4978e-01,
        -1.7883e+00,  5.2934e-02, -7.9075e-05, -4.6763e+00,  0.0000e+00,
         3.5171e-01,  1.8633e-01,  0.0000e+00, -2.6141e-04,  9.7021e-01,
         3.6932e+00,  2.0814e+00,  4.5582e-04, -1.8675e+00, -3.1270e+00,
        -7.2005e-01,  3.1757e+00,  5.5897e+00, -5.9889e+00,  0.0000e+00,
        -1.7882e+00,  3.8564e+00,  1.3146e-04, -2.9168e-02,  3.2582e+00,
         4.0228e-01,  4.6612e+00,  2.3708e+00,  3.2317e+00, -2.7082e-02,
        -1.9168e-02,  2.7708e+00,  1.6282e-03,  3.2035e-03,  4.2521e+00,
         2.5678e+00,  3.8319e+00,  2.3794e-01,  4.7109e-01,  2.9944e+00,
        -2.3913e-01,  7.6791e+00,  3.1082e+00,  6.5183e-01, -5.8784e-05,
         1.3500e-01, -4.6756e-02, -8.9902e-04,  9.4656e-01, -1.8415e+00,
        -9.8212e-01, -7.3975e+00,  5.9560e+00, -4.0072e+00, -2.2061e-04,
         6.6339e+00,  1.7482e+00,  5.1286e-02,  4.4700e-01, -2.2806e-07,
         8.0038e-03,  3.8992e+00,  5.3103e+00, -3.7672e-04,  9.7402e-01,
         0.0000e+00, -6.3297e-01,  1.3567e+00, -4.4587e-04,  3.7667e-01,
         1.5289e-04,  8.3802e+00, -9.8891e-04,  5.1373e+00,  1.8841e+00,
         6.8057e-04, -9.3682e-01,  5.5651e+00,  0.0000e+00,  8.2702e+00,
         5.4742e+00,  4.3780e-01, -1.4370e+00,  3.6820e+00,  2.0460e+00,
         1.0500e+00,  2.1929e+00,  1.0286e+01, -4.3970e+00,  6.1014e-04,
         3.5860e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.8225e-01,
         0.0000e+00,  5.8881e+00,  0.0000e+00,  1.0962e+01, -1.3392e-05,
        -6.6541e-02,  0.0000e+00,  2.8881e+00,  0.0000e+00,  1.3898e-04,
         4.1562e+00,  4.3014e+00,  3.0509e+00,  4.0441e+00, -3.6217e+00,
         1.4108e+00, -1.8959e-02, -3.6033e+00, -2.6952e-01,  1.0037e+01,
         2.3116e-01,  5.2684e-04,  0.0000e+00,  2.6322e-03, -4.2778e-03,
        -1.2418e-02,  4.1272e+00,  1.1838e-03,  5.9814e-02,  9.9647e+00,
        -2.8229e+00,  6.8752e-01,  5.5480e-01, -6.1919e-01,  8.1435e+00,
        -3.2161e+00,  7.5289e+00,  7.8528e-04,  9.0537e-01,  3.2925e-01,
         1.9776e+00,  4.1305e-02,  2.6290e-05,  7.7962e-01,  0.0000e+00,
        -1.4290e-02,  2.6721e+00, -8.1051e-02,  1.8392e-04, -2.6649e+00,
         4.0596e-01,  6.6747e+00,  0.0000e+00,  4.8177e-01, -5.2572e-06,
         4.8524e-02, -1.0296e-04,  0.0000e+00, -1.1060e-05,  2.9489e+00,
         4.3262e+00,  5.6895e+00, -8.5009e+00, -3.4374e+00,  1.3741e+00,
         8.2418e-02,  1.0058e-01,  0.0000e+00,  1.2909e+00, -8.5877e-01,
         9.9255e-02,  5.0161e+00,  2.0721e-01, -4.3960e-04,  4.8840e+00,
        -8.6477e-01,  4.2617e+00, -4.6234e-02,  5.4315e+00,  5.4770e-01,
         1.6369e-01,  4.0959e+00,  4.4012e+00, -3.0826e+00,  6.1912e+00,
        -1.7204e+00,  6.6239e-02,  0.0000e+00, -8.1564e-01, -6.6517e+00,
         2.7532e-03,  1.9330e+00, -7.1793e-01, -9.3122e-01, -3.0196e+00,
         6.8962e+00,  3.1005e+00,  5.1246e-02,  2.8447e-02,  1.4275e-01,
         1.1492e-03,  3.6621e+00, -1.4869e+00, -6.8430e-02,  1.9337e-01,
         2.2659e+00,  1.2856e-02,  4.0591e-01, -2.0437e-02, -1.9693e-01,
         8.8117e+00,  4.9775e+00, -2.3276e+00,  3.1452e+00,  0.0000e+00,
         0.0000e+00, -1.4685e+00,  2.8370e+00, -2.2097e-03,  2.6450e-03,
        -1.9936e+00,  1.9682e+00, -1.6799e+00, -1.2972e-02, -1.0841e+00,
        -1.6173e+00,  0.0000e+00,  1.1212e-03,  1.9521e-01,  8.1820e-01,
         6.9064e+00, -2.3394e-03,  2.9313e+00, -1.2684e+00,  7.4562e-01,
        -3.3443e-02, -5.3799e-01,  2.6303e+00,  2.4185e+00,  2.7394e+00,
        -2.2062e+00,  0.0000e+00,  6.9463e+00,  0.0000e+00, -6.0074e-04,
        -1.9425e-01,  2.8577e+00, -5.7676e-01,  5.7014e-04,  7.6974e-01,
         3.0279e+00,  0.0000e+00,  7.7451e+00,  3.0988e-01, -1.0100e+00,
         2.5401e+00,  5.8313e+00, -5.2318e+00,  6.4500e-01,  6.8251e+00,
         2.8867e+00,  7.0603e-01,  0.0000e+00, -2.7568e-01,  3.1978e+00,
         5.5409e+00, -2.8294e+00,  3.7307e+00, -3.3000e-01,  2.1742e+00,
         5.8310e-01, -4.5780e-02,  1.5876e-01,  6.2007e+00,  9.6875e-01,
         3.6345e-02,  5.3320e+00,  2.2668e+00, -1.4184e-08,  1.8185e+00,
         2.6132e+00,  0.0000e+00,  1.0965e+00, -1.0681e+00,  0.0000e+00,
         7.0170e+00, -5.6846e-04, -6.0596e-01,  0.0000e+00, -1.5861e-05,
        -3.2595e-01,  0.0000e+00,  0.0000e+00,  1.3309e+00, -2.4052e+00,
         8.9213e-01,  1.3782e+00,  6.3894e+00, -9.2214e-01, -7.5296e-06,
        -7.1503e-01,  0.0000e+00, -1.5677e-01, -1.3363e-03,  6.4800e+00,
         4.8249e-01,  2.2711e-07,  2.3774e-01, -9.4475e-01,  2.2505e-01,
         0.0000e+00,  1.1141e+00], device='cuda:0')}
INFO:root:==> Evaluating the model at: 2
INFO:root:Started MAML Skip training
INFO:root:Started MAML Skip training
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.20041767332e-05, MAE: 181.33829422, MSE: 181.338294539
INFO:root:(Meta-testing) test MAE: 230.546960449, MSE: 230.54695963
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.20041768241e-05, MAE: 181.338288116, MSE: 181.338287771
INFO:root:(Meta-testing) test MAE: 230.546948242, MSE: 230.546948661
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.14827143079e-05, MAE: 174.916371918, MSE: 174.916371477
INFO:root:(Meta-testing) test MAE: 230.545959473, MSE: 230.545959638
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:Started MAML Skip training
INFO:root:Started MAML Skip training
INFO:root:Started MAML Skip training
INFO:root:Started MAML Skip training
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280519124e-05, MAE: 183.482511139, MSE: 183.482511308
INFO:root:(Meta-testing) test MAE: 230.546611023, MSE: 230.546610166
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280513667e-05, MAE: 183.482501984, MSE: 183.482501391
INFO:root:(Meta-testing) test MAE: 230.546607971, MSE: 230.546606439
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280520034e-05, MAE: 183.482514191, MSE: 183.482514882
INFO:root:(Meta-testing) test MAE: 230.54659729, MSE: 230.546596329
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280517305e-05, MAE: 183.482505035, MSE: 183.482504366
INFO:root:(Meta-testing) test MAE: 230.546604919, MSE: 230.546603983
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280511848e-05, MAE: 183.482501984, MSE: 183.482501092
INFO:root:(Meta-testing) test MAE: 230.546601868, MSE: 230.546600705
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280510939e-05, MAE: 183.482498932, MSE: 183.482498636
INFO:root:(Meta-testing) test MAE: 230.546609497, MSE: 230.546608839
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280515486e-05, MAE: 183.482501984, MSE: 183.482501092
INFO:root:(Meta-testing) test MAE: 230.546598816, MSE: 230.546597919
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280521853e-05, MAE: 183.482511139, MSE: 183.482510915
INFO:root:(Meta-testing) test MAE: 230.546589661, MSE: 230.546589217
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280516396e-05, MAE: 183.48249588, MSE: 183.482495661
INFO:root:(Meta-testing) test MAE: 230.546603394, MSE: 230.546601943
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280513667e-05, MAE: 183.482505035, MSE: 183.482504366
INFO:root:(Meta-testing) test MAE: 230.546607971, MSE: 230.546606769
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280513667e-05, MAE: 183.482505035, MSE: 183.482504366
INFO:root:(Meta-testing) test MAE: 230.546607971, MSE: 230.546606769
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280521853e-05, MAE: 183.482511139, MSE: 183.482510915
INFO:root:(Meta-testing) test MAE: 230.546592712, MSE: 230.546591855
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280514577e-05, MAE: 183.482505035, MSE: 183.482504366
INFO:root:(Meta-testing) test MAE: 230.546606445, MSE: 230.546606053
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280516396e-05, MAE: 183.482508087, MSE: 183.48250794
INFO:root:(Meta-testing) test MAE: 230.54659729, MSE: 230.546596351
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280510029e-05, MAE: 183.482498932, MSE: 183.482498416
INFO:root:(Meta-testing) test MAE: 230.546592712, MSE: 230.546591033
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280518215e-05, MAE: 183.482508087, MSE: 183.48250764
INFO:root:(Meta-testing) test MAE: 230.546592712, MSE: 230.546592216
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280512758e-05, MAE: 183.482501984, MSE: 183.482501092
INFO:root:(Meta-testing) test MAE: 230.546603394, MSE: 230.546602414
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280519124e-05, MAE: 183.482501984, MSE: 183.482501092
INFO:root:(Meta-testing) test MAE: 230.546601868, MSE: 230.546601558
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280518215e-05, MAE: 183.482511139, MSE: 183.482510915
INFO:root:(Meta-testing) test MAE: 230.546595764, MSE: 230.546594641
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280510939e-05, MAE: 183.482501984, MSE: 183.482501391
INFO:root:(Meta-testing) test MAE: 230.546606445, MSE: 230.546605644
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) post train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) pre-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:(Meta-training) post-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:==========================
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280518215e-05, MAE: 183.482501984, MSE: 183.482501691
INFO:root:(Meta-testing) test MAE: 230.546588135, MSE: 230.54658739
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) post train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) pre-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:(Meta-training) post-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:==========================
INFO:root:Started MAML Skip training
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280513667e-05, MAE: 183.482505035, MSE: 183.482504366
INFO:root:(Meta-testing) test MAE: 230.546607971, MSE: 230.546606769
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.2128050912e-05, MAE: 183.482498932, MSE: 183.482498244
INFO:root:(Meta-testing) test MAE: 230.546607971, MSE: 230.546606769
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280515486e-05, MAE: 183.482505035, MSE: 183.482504366
INFO:root:(Meta-testing) test MAE: 230.546598816, MSE: 230.546597919
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280517305e-05, MAE: 183.482498932, MSE: 183.482498636
INFO:root:(Meta-testing) test MAE: 230.546601868, MSE: 230.546601558
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280515486e-05, MAE: 183.482501984, MSE: 183.482501691
INFO:root:(Meta-testing) test MAE: 230.546592712, MSE: 230.546591885
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280511848e-05, MAE: 183.482505035, MSE: 183.482504366
INFO:root:(Meta-testing) test MAE: 230.546601868, MSE: 230.546600705
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280517305e-05, MAE: 183.482505035, MSE: 183.482504366
INFO:root:(Meta-testing) test MAE: 230.546604919, MSE: 230.546603983
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280517305e-05, MAE: 183.482505035, MSE: 183.482504366
INFO:root:(Meta-testing) test MAE: 230.546604919, MSE: 230.546603983
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) post train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) pre-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:(Meta-training) post-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:==========================
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280521853e-05, MAE: 183.482511139, MSE: 183.482510915
INFO:root:(Meta-testing) test MAE: 230.546592712, MSE: 230.546591855
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) post train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) pre-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:(Meta-training) post-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:==========================
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280517305e-05, MAE: 183.482505035, MSE: 183.482504366
INFO:root:(Meta-testing) test MAE: 230.546604919, MSE: 230.546603983
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) post train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) pre-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:(Meta-training) post-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.2128050821e-05, MAE: 183.482498932, MSE: 183.482498416
INFO:root:(Meta-testing) test MAE: 230.546600342, MSE: 230.546598665
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) post train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) pre-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:(Meta-training) post-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 2
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.58111922955e-06, MAE: 122.985221863, MSE: 122.985223642
INFO:root:(Meta-training) post train loss: 1.57703998411e-05, MAE: 196.61920166, MSE: 196.619198897
INFO:root:(Meta-training) pre-training test MAE: 192.034912109, MSE: 192.034908936
INFO:root:(Meta-training) post-training test MAE: 192.034912109, MSE: 192.034908936
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 3
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.21140556075e-05, MAE: 169.018478394, MSE: 169.018478557
INFO:root:(Meta-training) post train loss: 1.21140556075e-05, MAE: 169.018478394, MSE: 169.018478557
INFO:root:(Meta-training) pre-training test MAE: 244.432281494, MSE: 244.432282289
INFO:root:(Meta-training) post-training test MAE: 244.432281494, MSE: 244.432282289
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 4
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.4796989793e-06, MAE: 165.983947754, MSE: 165.983950655
INFO:root:(Meta-training) post train loss: 7.4796989793e-06, MAE: 165.983947754, MSE: 165.983950655
INFO:root:(Meta-training) pre-training test MAE: 153.916519165, MSE: 153.916519327
INFO:root:(Meta-training) post-training test MAE: 153.916519165, MSE: 153.916519327
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 5
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.75201624492e-06, MAE: 126.965133667, MSE: 126.965135009
INFO:root:(Meta-training) post train loss: 7.75201624492e-06, MAE: 126.965133667, MSE: 126.965135009
INFO:root:(Meta-training) pre-training test MAE: 215.986160278, MSE: 215.986155879
INFO:root:(Meta-training) post-training test MAE: 215.986160278, MSE: 215.986155879
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 6
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 2.06456570595e-05, MAE: 310.239227295, MSE: 310.239222214
INFO:root:(Meta-training) post train loss: 2.17983542825e-05, MAE: 306.193054199, MSE: 306.19305593
INFO:root:(Meta-training) pre-training test MAE: 232.036911011, MSE: 232.03691281
INFO:root:(Meta-training) post-training test MAE: 232.036911011, MSE: 232.03691281
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 7
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.55319521582e-05, MAE: 203.084976196, MSE: 203.084976826
INFO:root:(Meta-training) post train loss: 1.55319521582e-05, MAE: 203.084976196, MSE: 203.084976826
INFO:root:(Meta-training) pre-training test MAE: 202.922012329, MSE: 202.922013961
INFO:root:(Meta-training) post-training test MAE: 202.922012329, MSE: 202.922013961
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 8
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.63726435858e-05, MAE: 252.518875122, MSE: 252.518873057
INFO:root:(Meta-training) post train loss: 1.63726435858e-05, MAE: 252.518875122, MSE: 252.518873057
INFO:root:(Meta-training) pre-training test MAE: 257.311828613, MSE: 257.311824447
INFO:root:(Meta-training) post-training test MAE: 257.311828613, MSE: 257.311824447
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 9
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.03365937321e-05, MAE: 199.187133789, MSE: 199.187137198
INFO:root:(Meta-training) post train loss: 1.03365937321e-05, MAE: 199.187133789, MSE: 199.187137198
INFO:root:(Meta-training) pre-training test MAE: 251.235961914, MSE: 251.235960429
INFO:root:(Meta-training) post-training test MAE: 251.235961914, MSE: 251.235960429
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 10
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.26448176161e-05, MAE: 212.021102905, MSE: 212.021105597
INFO:root:(Meta-training) post train loss: 1.26448176161e-05, MAE: 212.021102905, MSE: 212.021105597
INFO:root:(Meta-training) pre-training test MAE: 184.242462158, MSE: 184.242462956
INFO:root:(Meta-training) post-training test MAE: 184.242462158, MSE: 184.242462956
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 11
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.22297915368e-05, MAE: 143.381866455, MSE: 143.381865572
INFO:root:(Meta-training) post train loss: 7.79699803388e-06, MAE: 92.6095352173, MSE: 92.6095371287
INFO:root:(Meta-training) pre-training test MAE: 275.897705078, MSE: 275.897710891
INFO:root:(Meta-training) post-training test MAE: 275.897705078, MSE: 275.897710891
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 12
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.74013403011e-05, MAE: 274.921478271, MSE: 274.921480268
INFO:root:(Meta-training) post train loss: 1.09869179141e-05, MAE: 200.568145752, MSE: 200.568148097
INFO:root:(Meta-training) pre-training test MAE: 330.328674316, MSE: 330.328671553
INFO:root:(Meta-training) post-training test MAE: 330.328674316, MSE: 330.328671553
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 13
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.05357403299e-05, MAE: 175.497940063, MSE: 175.497941138
INFO:root:(Meta-training) post train loss: 8.88438717084e-06, MAE: 169.003707886, MSE: 169.003709741
INFO:root:(Meta-training) pre-training test MAE: 225.097900391, MSE: 225.097904047
INFO:root:(Meta-training) post-training test MAE: 225.097900391, MSE: 225.097904047
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 14
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.87998373603e-06, MAE: 141.779785156, MSE: 141.779786333
INFO:root:(Meta-training) post train loss: 9.87998373603e-06, MAE: 141.779785156, MSE: 141.779786333
INFO:root:(Meta-training) pre-training test MAE: 160.713027954, MSE: 160.713029137
INFO:root:(Meta-training) post-training test MAE: 160.713027954, MSE: 160.713029137
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 15
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.86622580967e-06, MAE: 196.780349731, MSE: 196.780354234
INFO:root:(Meta-training) post train loss: 9.31688555283e-06, MAE: 185.546524048, MSE: 185.54652171
INFO:root:(Meta-training) pre-training test MAE: 227.639068604, MSE: 227.639071504
INFO:root:(Meta-training) post-training test MAE: 227.639068604, MSE: 227.639071504
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 16
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.20611121019e-05, MAE: 142.660888672, MSE: 142.660887794
INFO:root:(Meta-training) post train loss: 1.20611121019e-05, MAE: 142.660888672, MSE: 142.660887794
INFO:root:(Meta-training) pre-training test MAE: 121.886199951, MSE: 121.886201408
INFO:root:(Meta-training) post-training test MAE: 121.886199951, MSE: 121.886201408
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 17
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.21527937154e-05, MAE: 103.114608765, MSE: 103.114606484
INFO:root:(Meta-training) post train loss: 1.26900886244e-05, MAE: 99.6990509033, MSE: 99.6990490959
INFO:root:(Meta-training) pre-training test MAE: 61.5766296387, MSE: 61.5766302787
INFO:root:(Meta-training) post-training test MAE: 61.5766296387, MSE: 61.5766302787
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 18
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.15019065561e-05, MAE: 184.536254883, MSE: 184.536253637
INFO:root:(Meta-training) post train loss: 1.49415736814e-05, MAE: 221.861801147, MSE: 221.861804185
INFO:root:(Meta-training) pre-training test MAE: 185.890289307, MSE: 185.890288124
INFO:root:(Meta-training) post-training test MAE: 185.890289307, MSE: 185.890288124
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 19
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.70141374838e-05, MAE: 267.874084473, MSE: 267.87408131
INFO:root:(Meta-training) post train loss: 1.70141374838e-05, MAE: 267.874084473, MSE: 267.87408131
INFO:root:(Meta-training) pre-training test MAE: 227.446350098, MSE: 227.446353565
INFO:root:(Meta-training) post-training test MAE: 227.446350098, MSE: 227.446353565
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 20
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.50177127379e-06, MAE: 159.559509277, MSE: 159.559507169
INFO:root:(Meta-training) post train loss: 9.50177127379e-06, MAE: 159.559509277, MSE: 159.559507169
INFO:root:(Meta-training) pre-training test MAE: 141.779785156, MSE: 141.779786333
INFO:root:(Meta-training) post-training test MAE: 141.779785156, MSE: 141.779786333
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 21
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.48162232817e-06, MAE: 185.365005493, MSE: 185.365000995
INFO:root:(Meta-training) post train loss: 1.06054894786e-05, MAE: 190.862670898, MSE: 190.862669461
INFO:root:(Meta-training) pre-training test MAE: 149.066055298, MSE: 149.066057347
INFO:root:(Meta-training) post-training test MAE: 149.066055298, MSE: 149.066057347
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 22
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.18889010992e-05, MAE: 166.920501709, MSE: 166.920499415
INFO:root:(Meta-training) post train loss: 1.18889010992e-05, MAE: 166.920501709, MSE: 166.920499415
INFO:root:(Meta-training) pre-training test MAE: 168.540100098, MSE: 168.54010094
INFO:root:(Meta-training) post-training test MAE: 168.540100098, MSE: 168.54010094
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 23
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.23596028061e-05, MAE: 125.771629333, MSE: 125.771630067
INFO:root:(Meta-training) post train loss: 1.18414536701e-05, MAE: 125.980690002, MSE: 125.980688159
INFO:root:(Meta-training) pre-training test MAE: 200.518432617, MSE: 200.518429639
INFO:root:(Meta-training) post-training test MAE: 200.518432617, MSE: 200.518429639
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 24
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.20231388792e-05, MAE: 242.816467285, MSE: 242.81646554
INFO:root:(Meta-training) post train loss: 1.23136906041e-05, MAE: 237.218399048, MSE: 237.218402137
INFO:root:(Meta-training) pre-training test MAE: 189.820632935, MSE: 189.820628736
INFO:root:(Meta-training) post-training test MAE: 189.820632935, MSE: 189.820628736
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 25
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.92604600469e-06, MAE: 207.09942627, MSE: 207.099425096
INFO:root:(Meta-training) post train loss: 9.92604600469e-06, MAE: 207.09942627, MSE: 207.099425096
INFO:root:(Meta-training) pre-training test MAE: 203.48147583, MSE: 203.481475662
INFO:root:(Meta-training) post-training test MAE: 203.48147583, MSE: 203.481475662
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 26
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.16682052371e-06, MAE: 128.811950684, MSE: 128.811954147
INFO:root:(Meta-training) post train loss: 7.16682052371e-06, MAE: 128.811950684, MSE: 128.811954147
INFO:root:(Meta-training) pre-training test MAE: 178.735366821, MSE: 178.735368719
INFO:root:(Meta-training) post-training test MAE: 178.735366821, MSE: 178.735368719
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 27
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.52163305151e-06, MAE: 170.673568726, MSE: 170.67356795
INFO:root:(Meta-training) post train loss: 1.23920990518e-05, MAE: 219.518951416, MSE: 219.518952058
INFO:root:(Meta-training) pre-training test MAE: 197.131942749, MSE: 197.131945423
INFO:root:(Meta-training) post-training test MAE: 197.131942749, MSE: 197.131945423
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 28
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.29396503832e-06, MAE: 143.693710327, MSE: 143.693711806
INFO:root:(Meta-training) post train loss: 8.29396503832e-06, MAE: 143.693710327, MSE: 143.693711806
INFO:root:(Meta-training) pre-training test MAE: 263.803619385, MSE: 263.803623103
INFO:root:(Meta-training) post-training test MAE: 263.803619385, MSE: 263.803623103
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 29
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.4535613496e-06, MAE: 137.884384155, MSE: 137.884384597
INFO:root:(Meta-training) post train loss: 8.4535613496e-06, MAE: 137.884384155, MSE: 137.884384597
INFO:root:(Meta-training) pre-training test MAE: 178.631118774, MSE: 178.631117591
INFO:root:(Meta-training) post-training test MAE: 178.631118774, MSE: 178.631117591
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 30
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.78916944203e-06, MAE: 142.5365448, MSE: 142.536542738
INFO:root:(Meta-training) post train loss: 8.78916944203e-06, MAE: 142.5365448, MSE: 142.536542738
INFO:root:(Meta-training) pre-training test MAE: 146.194458008, MSE: 146.194460608
INFO:root:(Meta-training) post-training test MAE: 146.194458008, MSE: 146.194460608
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 31
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.30455910039e-05, MAE: 213.753082275, MSE: 213.753079291
INFO:root:(Meta-training) post train loss: 1.30455910039e-05, MAE: 213.753082275, MSE: 213.753079291
INFO:root:(Meta-training) pre-training test MAE: 277.622283936, MSE: 277.622284431
INFO:root:(Meta-training) post-training test MAE: 277.622283936, MSE: 277.622284431
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 32
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.29761147036e-05, MAE: 213.236984253, MSE: 213.236984875
INFO:root:(Meta-training) post train loss: 1.29761147036e-05, MAE: 213.236984253, MSE: 213.236984875
INFO:root:(Meta-training) pre-training test MAE: 131.863006592, MSE: 131.863003009
INFO:root:(Meta-training) post-training test MAE: 131.863006592, MSE: 131.863003009
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:===> Updating meta network
INFO:root:Started MAML Skip training
INFO:root:===> Training epoch: 1/15000
INFO:root:** Testing meta network for 10 iterations
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:** Evaluated test and train steps
INFO:root:==========================
INFO:root:(Meta-testing) train loss:1.21280515486e-05, MAE: 183.482508087, MSE: 183.48250764
INFO:root:(Meta-testing) test MAE: 230.54659729, MSE: 230.546596711
INFO:root:==========================
INFO:root:==> Training scene: 1
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) post train loss: 9.60693705565e-06, MAE: 185.980178833, MSE: 185.980173675
INFO:root:(Meta-training) pre-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:(Meta-training) post-training test MAE: 162.749679565, MSE: 162.749681979
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 2
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.58111922955e-06, MAE: 122.985221863, MSE: 122.985223642
INFO:root:(Meta-training) post train loss: 1.57703998411e-05, MAE: 196.61920166, MSE: 196.619198897
INFO:root:(Meta-training) pre-training test MAE: 192.034912109, MSE: 192.034908936
INFO:root:(Meta-training) post-training test MAE: 192.034912109, MSE: 192.034908936
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 3
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.21140556075e-05, MAE: 169.018478394, MSE: 169.018478557
INFO:root:(Meta-training) post train loss: 1.21140556075e-05, MAE: 169.018478394, MSE: 169.018478557
INFO:root:(Meta-training) pre-training test MAE: 244.432281494, MSE: 244.432282289
INFO:root:(Meta-training) post-training test MAE: 244.432281494, MSE: 244.432282289
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 4
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.4796989793e-06, MAE: 165.983947754, MSE: 165.983950655
INFO:root:(Meta-training) post train loss: 7.4796989793e-06, MAE: 165.983947754, MSE: 165.983950655
INFO:root:(Meta-training) pre-training test MAE: 153.916519165, MSE: 153.916519327
INFO:root:(Meta-training) post-training test MAE: 153.916519165, MSE: 153.916519327
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 5
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.75201624492e-06, MAE: 126.965133667, MSE: 126.965135009
INFO:root:(Meta-training) post train loss: 7.75201624492e-06, MAE: 126.965133667, MSE: 126.965135009
INFO:root:(Meta-training) pre-training test MAE: 215.986160278, MSE: 215.986155879
INFO:root:(Meta-training) post-training test MAE: 215.986160278, MSE: 215.986155879
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 6
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 2.06456570595e-05, MAE: 310.239227295, MSE: 310.239222214
INFO:root:(Meta-training) post train loss: 2.17983542825e-05, MAE: 306.193054199, MSE: 306.19305593
INFO:root:(Meta-training) pre-training test MAE: 232.036911011, MSE: 232.03691281
INFO:root:(Meta-training) post-training test MAE: 232.036911011, MSE: 232.03691281
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 7
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.55319521582e-05, MAE: 203.084976196, MSE: 203.084976826
INFO:root:(Meta-training) post train loss: 1.55319521582e-05, MAE: 203.084976196, MSE: 203.084976826
INFO:root:(Meta-training) pre-training test MAE: 202.922012329, MSE: 202.922013961
INFO:root:(Meta-training) post-training test MAE: 202.922012329, MSE: 202.922013961
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 8
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.63726435858e-05, MAE: 252.518875122, MSE: 252.518873057
INFO:root:(Meta-training) post train loss: 1.63726435858e-05, MAE: 252.518875122, MSE: 252.518873057
INFO:root:(Meta-training) pre-training test MAE: 257.311828613, MSE: 257.311824447
INFO:root:(Meta-training) post-training test MAE: 257.311828613, MSE: 257.311824447
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 9
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.03365937321e-05, MAE: 199.187133789, MSE: 199.187137198
INFO:root:(Meta-training) post train loss: 1.03365937321e-05, MAE: 199.187133789, MSE: 199.187137198
INFO:root:(Meta-training) pre-training test MAE: 251.235961914, MSE: 251.235960429
INFO:root:(Meta-training) post-training test MAE: 251.235961914, MSE: 251.235960429
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 10
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.26448176161e-05, MAE: 212.021102905, MSE: 212.021105597
INFO:root:(Meta-training) post train loss: 1.26448176161e-05, MAE: 212.021102905, MSE: 212.021105597
INFO:root:(Meta-training) pre-training test MAE: 184.242462158, MSE: 184.242462956
INFO:root:(Meta-training) post-training test MAE: 184.242462158, MSE: 184.242462956
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 11
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.22297915368e-05, MAE: 143.381866455, MSE: 143.381865572
INFO:root:(Meta-training) post train loss: 7.79699803388e-06, MAE: 92.6095352173, MSE: 92.6095371287
INFO:root:(Meta-training) pre-training test MAE: 275.897705078, MSE: 275.897710891
INFO:root:(Meta-training) post-training test MAE: 275.897705078, MSE: 275.897710891
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 12
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.74013403011e-05, MAE: 274.921478271, MSE: 274.921480268
INFO:root:(Meta-training) post train loss: 1.09869179141e-05, MAE: 200.568145752, MSE: 200.568148097
INFO:root:(Meta-training) pre-training test MAE: 330.328674316, MSE: 330.328671553
INFO:root:(Meta-training) post-training test MAE: 330.328674316, MSE: 330.328671553
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 13
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.05357403299e-05, MAE: 175.497940063, MSE: 175.497941138
INFO:root:(Meta-training) post train loss: 8.88438717084e-06, MAE: 169.003707886, MSE: 169.003709741
INFO:root:(Meta-training) pre-training test MAE: 225.097900391, MSE: 225.097904047
INFO:root:(Meta-training) post-training test MAE: 225.097900391, MSE: 225.097904047
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 14
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.87998373603e-06, MAE: 141.779785156, MSE: 141.779786333
INFO:root:(Meta-training) post train loss: 9.87998373603e-06, MAE: 141.779785156, MSE: 141.779786333
INFO:root:(Meta-training) pre-training test MAE: 160.713027954, MSE: 160.713029137
INFO:root:(Meta-training) post-training test MAE: 160.713027954, MSE: 160.713029137
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 15
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.86622580967e-06, MAE: 196.780349731, MSE: 196.780354234
INFO:root:(Meta-training) post train loss: 9.31688555283e-06, MAE: 185.546524048, MSE: 185.54652171
INFO:root:(Meta-training) pre-training test MAE: 227.639068604, MSE: 227.639071504
INFO:root:(Meta-training) post-training test MAE: 227.639068604, MSE: 227.639071504
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 16
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.20611121019e-05, MAE: 142.660888672, MSE: 142.660887794
INFO:root:(Meta-training) post train loss: 1.20611121019e-05, MAE: 142.660888672, MSE: 142.660887794
INFO:root:(Meta-training) pre-training test MAE: 121.886199951, MSE: 121.886201408
INFO:root:(Meta-training) post-training test MAE: 121.886199951, MSE: 121.886201408
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 17
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.21527937154e-05, MAE: 103.114608765, MSE: 103.114606484
INFO:root:(Meta-training) post train loss: 1.26900886244e-05, MAE: 99.6990509033, MSE: 99.6990490959
INFO:root:(Meta-training) pre-training test MAE: 61.5766296387, MSE: 61.5766302787
INFO:root:(Meta-training) post-training test MAE: 61.5766296387, MSE: 61.5766302787
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 18
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.15019065561e-05, MAE: 184.536254883, MSE: 184.536253637
INFO:root:(Meta-training) post train loss: 1.49415736814e-05, MAE: 221.861801147, MSE: 221.861804185
INFO:root:(Meta-training) pre-training test MAE: 185.890289307, MSE: 185.890288124
INFO:root:(Meta-training) post-training test MAE: 185.890289307, MSE: 185.890288124
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 19
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.70141374838e-05, MAE: 267.874084473, MSE: 267.87408131
INFO:root:(Meta-training) post train loss: 1.70141374838e-05, MAE: 267.874084473, MSE: 267.87408131
INFO:root:(Meta-training) pre-training test MAE: 227.446350098, MSE: 227.446353565
INFO:root:(Meta-training) post-training test MAE: 227.446350098, MSE: 227.446353565
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 20
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.50177127379e-06, MAE: 159.559509277, MSE: 159.559507169
INFO:root:(Meta-training) post train loss: 9.50177127379e-06, MAE: 159.559509277, MSE: 159.559507169
INFO:root:(Meta-training) pre-training test MAE: 141.779785156, MSE: 141.779786333
INFO:root:(Meta-training) post-training test MAE: 141.779785156, MSE: 141.779786333
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 21
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.48162232817e-06, MAE: 185.365005493, MSE: 185.365000995
INFO:root:(Meta-training) post train loss: 1.06054894786e-05, MAE: 190.862670898, MSE: 190.862669461
INFO:root:(Meta-training) pre-training test MAE: 149.066055298, MSE: 149.066057347
INFO:root:(Meta-training) post-training test MAE: 149.066055298, MSE: 149.066057347
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 22
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.18889010992e-05, MAE: 166.920501709, MSE: 166.920499415
INFO:root:(Meta-training) post train loss: 1.18889010992e-05, MAE: 166.920501709, MSE: 166.920499415
INFO:root:(Meta-training) pre-training test MAE: 168.540100098, MSE: 168.54010094
INFO:root:(Meta-training) post-training test MAE: 168.540100098, MSE: 168.54010094
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 23
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.23596028061e-05, MAE: 125.771629333, MSE: 125.771630067
INFO:root:(Meta-training) post train loss: 1.18414536701e-05, MAE: 125.980690002, MSE: 125.980688159
INFO:root:(Meta-training) pre-training test MAE: 200.518432617, MSE: 200.518429639
INFO:root:(Meta-training) post-training test MAE: 200.518432617, MSE: 200.518429639
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 24
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.20231388792e-05, MAE: 242.816467285, MSE: 242.81646554
INFO:root:(Meta-training) post train loss: 1.23136906041e-05, MAE: 237.218399048, MSE: 237.218402137
INFO:root:(Meta-training) pre-training test MAE: 189.820632935, MSE: 189.820628736
INFO:root:(Meta-training) post-training test MAE: 189.820632935, MSE: 189.820628736
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 25
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 9.92604600469e-06, MAE: 207.09942627, MSE: 207.099425096
INFO:root:(Meta-training) post train loss: 9.92604600469e-06, MAE: 207.09942627, MSE: 207.099425096
INFO:root:(Meta-training) pre-training test MAE: 203.48147583, MSE: 203.481475662
INFO:root:(Meta-training) post-training test MAE: 203.48147583, MSE: 203.481475662
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 26
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.16682052371e-06, MAE: 128.811950684, MSE: 128.811954147
INFO:root:(Meta-training) post train loss: 7.16682052371e-06, MAE: 128.811950684, MSE: 128.811954147
INFO:root:(Meta-training) pre-training test MAE: 178.735366821, MSE: 178.735368719
INFO:root:(Meta-training) post-training test MAE: 178.735366821, MSE: 178.735368719
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 27
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 7.52163305151e-06, MAE: 170.673568726, MSE: 170.67356795
INFO:root:(Meta-training) post train loss: 1.23920990518e-05, MAE: 219.518951416, MSE: 219.518952058
INFO:root:(Meta-training) pre-training test MAE: 197.131942749, MSE: 197.131945423
INFO:root:(Meta-training) post-training test MAE: 197.131942749, MSE: 197.131945423
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 28
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.29396503832e-06, MAE: 143.693710327, MSE: 143.693711806
INFO:root:(Meta-training) post train loss: 8.29396503832e-06, MAE: 143.693710327, MSE: 143.693711806
INFO:root:(Meta-training) pre-training test MAE: 263.803619385, MSE: 263.803623103
INFO:root:(Meta-training) post-training test MAE: 263.803619385, MSE: 263.803623103
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 29
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.4535613496e-06, MAE: 137.884384155, MSE: 137.884384597
INFO:root:(Meta-training) post train loss: 8.4535613496e-06, MAE: 137.884384155, MSE: 137.884384597
INFO:root:(Meta-training) pre-training test MAE: 178.631118774, MSE: 178.631117591
INFO:root:(Meta-training) post-training test MAE: 178.631118774, MSE: 178.631117591
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 30
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 8.78916944203e-06, MAE: 142.5365448, MSE: 142.536542738
INFO:root:(Meta-training) post train loss: 8.78916944203e-06, MAE: 142.5365448, MSE: 142.536542738
INFO:root:(Meta-training) pre-training test MAE: 146.194458008, MSE: 146.194460608
INFO:root:(Meta-training) post-training test MAE: 146.194458008, MSE: 146.194460608
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 31
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.30455910039e-05, MAE: 213.753082275, MSE: 213.753079291
INFO:root:(Meta-training) post train loss: 1.30455910039e-05, MAE: 213.753082275, MSE: 213.753079291
INFO:root:(Meta-training) pre-training test MAE: 277.622283936, MSE: 277.622284431
INFO:root:(Meta-training) post-training test MAE: 277.622283936, MSE: 277.622284431
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:==> Training scene: 32
INFO:root:==========================
INFO:root:(Meta-training) pre train loss: 1.29761147036e-05, MAE: 213.236984253, MSE: 213.236984875
INFO:root:(Meta-training) post train loss: 1.29761147036e-05, MAE: 213.236984253, MSE: 213.236984875
INFO:root:(Meta-training) pre-training test MAE: 131.863006592, MSE: 131.863003009
INFO:root:(Meta-training) post-training test MAE: 131.863006592, MSE: 131.863003009
INFO:root:==========================
INFO:root:Sum of gradients in VGG: {'CCN.net.series_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.series_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.series_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.parallel_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.conv2.weight': -183.43357849121094, 'CCN.net.series_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.parallel_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.series_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.parallel_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.parallel_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.series_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.series_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.series_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.series_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.series_blocks.0.2.conv3.weight': -41.76806640625, 'CCN.net.parallel_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.parallel_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.0.0.bn2.weight': 10.20899772644043, 'CCN.net.series_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.1.1.conv3.weight': -79.61557006835938, 'CCN.net.parallel_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.series_blocks.2.4.bn1.bias': -22.490863800048828, 'CCN.net.series_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.series_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.parallel_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.parallel_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.2.5.conv1.weight': -252.38800048828125, 'CCN.net.parallel_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.series_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.parallel_blocks.0.0.downsample.0.weight': -55.957618713378906, 'CCN.net.parallel_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.0.0.conv1.weight': -17.98272132873535, 'CCN.net.parallel_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.1.0.bn1.bias': -8.773087501525879, 'CCN.net.series_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.series_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.parallel_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.series_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.1.0.bn3.bias': 8.21412467956543, 'CCN.net.series_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.parallel_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.parallel_blocks.2.4.bn1.weight': 42.67822265625, 'CCN.net.series_blocks.1.0.bn1.weight': 26.33399200439453, 'CCN.net.parallel_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.series_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.series_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.de_pred.0.conv.weight': 3.327059268951416, 'CCN.net.series_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.2.5.bn1.bias': -27.54751205444336, 'CCN.net.parallel_blocks.1.0.conv3.weight': -8.427694320678711, 'CCN.net.series_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.series_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.series_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.1.conv2.weight': -5.469148635864258, 'CCN.net.parallel_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.series_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.0.0.bn1.bias': 1.9774373769760132, 'CCN.net.parallel_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.parallel_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.parallel_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.2.5.bn2.bias': -22.80148696899414, 'CCN.net.parallel_blocks.2.3.bn3.weight': 90.16149139404297, 'CCN.net.series_blocks.1.1.bn2.bias': 0.5834231376647949, 'CCN.net.series_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.series_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.parallel_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.series_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.parallel_blocks.1.2.bn2.bias': -0.7210344076156616, 'CCN.net.series_blocks.1.0.bn2.weight': 25.785093307495117, 'CCN.net.parallel_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.2.bn3.bias': -59.28116989135742, 'CCN.net.series_blocks.2.0.conv3.weight': -109.8289794921875, 'CCN.net.series_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.parallel_blocks.2.3.bn1.bias': -20.045610427856445, 'CCN.net.series_blocks.2.4.bn3.bias': -85.25318908691406, 'CCN.net.parallel_blocks.0.0.bn1.weight': 12.027508735656738, 'CCN.net.series_blocks.2.3.conv1.weight': -203.07943725585938, 'CCN.net.parallel_blocks.1.3.bn3.bias': -27.47713279724121, 'CCN.net.series_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.0.2.bn3.bias': -2.9477639198303223, 'CCN.net.parallel_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.de_pred.1.conv.bias': -0.04382781311869621, 'CCN.net.parallel_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.series_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.series_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.series_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.parallel_blocks.1.2.bn1.bias': 0.4168529808521271, 'CCN.net.parallel_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.parallel_blocks.2.0.downsample.1.weight': 112.02447509765625, 'CCN.net.series_blocks.1.1.bn3.weight': 39.089019775390625, 'CCN.net.parallel_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.series_blocks.2.0.bn2.bias': 8.506669998168945, 'CCN.net.parallel_blocks.2.3.bn1.weight': 42.1528434753418, 'CCN.net.series_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.parallel_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.2.4.conv3.weight': -420.01580810546875, 'CCN.net.parallel_blocks.1.3.bn1.bias': -3.475039005279541, 'CCN.net.series_blocks.0.1.conv2.weight': 1.8179049491882324, 'CCN.net.parallel_blocks.0.0.downsample.1.weight': 53.793853759765625, 'CCN.net.parallel_blocks.1.0.bn3.weight': 53.60310363769531, 'CCN.net.parallel_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.parallel_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.series_blocks.2.1.conv1.weight': -144.06649780273438, 'CCN.net.parallel_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.series_blocks.2.0.conv2.weight': -241.29165649414062, 'CCN.net.parallel_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.2.4.bn2.bias': -22.6175594329834, 'CCN.net.parallel_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.series_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.series_blocks.0.2.bn2.weight': 14.192859649658203, 'CCN.net.series_blocks.1.2.bn2.weight': 23.364215850830078, 'CCN.net.parallel_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.series_blocks.0.0.bn2.bias': 6.8025102615356445, 'CCN.net.parallel_blocks.0.1.bn2.weight': 11.800176620483398, 'CCN.net.series_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.parallel_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.series_blocks.1.0.bn2.bias': 2.378915309906006, 'CCN.net.parallel_blocks.2.5.conv2.weight': -530.3341064453125, 'CCN.net.series_blocks.1.2.conv3.weight': -31.11838150024414, 'CCN.net.parallel_blocks.2.2.bn2.bias': -17.67669677734375, 'CCN.net.parallel_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.conv3.weight': -286.15338134765625, 'CCN.net.parallel_blocks.2.3.bn3.bias': -64.311279296875, 'CCN.net.series_blocks.0.1.bn3.bias': 0.20338959991931915, 'CCN.net.series_blocks.2.2.bn3.weight': 91.83480834960938, 'CCN.net.series_blocks.2.2.conv3.weight': -202.6392822265625, 'CCN.net.series_blocks.0.2.bn1.bias': -1.2411961555480957, 'CCN.net.de_pred.0.conv.bias': -0.032479528337717056, 'CCN.net.parallel_blocks.2.0.downsample.0.weight': 19.907575607299805, 'CCN.net.parallel_blocks.1.2.bn3.bias': -28.344253540039062, 'CCN.net.parallel_blocks.2.2.bn2.weight': 47.07444763183594, 'CCN.net.parallel_blocks.1.1.bn3.bias': -9.741931915283203, 'CCN.net.series_blocks.2.5.bn2.weight': 49.45762634277344, 'CCN.net.parallel_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.series_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.series_blocks.0.2.bn1.weight': 11.683123588562012, 'CCN.net.parallel_blocks.0.1.bn2.bias': -0.16875439882278442, 'CCN.net.parallel_blocks.1.0.downsample.1.bias': 8.21412467956543, 'CCN.net.parallel_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.bn1.bias': 13.48707103729248, 'CCN.net.parallel_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.3.bn2.bias': -7.958684921264648, 'CCN.net.parallel_blocks.0.1.bn3.weight': 19.72805404663086, 'CCN.net.series_blocks.2.2.bn1.weight': 39.77424621582031, 'CCN.net.series_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.parallel_blocks.1.3.conv3.weight': -78.49781799316406, 'CCN.net.parallel_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.parallel_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.parallel_blocks.0.1.bn1.weight': 11.681779861450195, 'CCN.net.de_pred.1.conv.weight': -0.495599627494812, 'CCN.net.parallel_blocks.1.1.bn1.bias': 5.442982196807861, 'CCN.net.parallel_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.parallel_blocks.0.0.bn3.weight': 32.464805603027344, 'CCN.net.series_blocks.1.3.bn2.weight': 25.961750030517578, 'CCN.net.series_blocks.1.3.bn3.weight': 43.87541198730469, 'CCN.net.series_blocks.2.0.conv1.weight': -166.15890502929688, 'CCN.net.parallel_blocks.0.0.conv3.weight': 6.833502769470215, 'CCN.net.parallel_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.2.4.bn3.weight': 93.33111572265625, 'CCN.net.series_blocks.0.0.bn3.bias': 7.647769927978516, 'CCN.net.parallel_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.series_blocks.1.1.conv1.weight': -4.899997711181641, 'CCN.net.series_blocks.2.1.bn2.bias': -13.965373039245605, 'CCN.net.series_blocks.2.0.bn2.weight': 46.515899658203125, 'CCN.net.parallel_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.3.conv1.weight': -64.35025787353516, 'CCN.net.series_blocks.1.0.downsample.1.weight': 64.53800964355469, 'CCN.net.parallel_blocks.2.4.bn2.weight': 45.47444534301758, 'CCN.net.series_blocks.0.0.conv2.weight': 29.282196044921875, 'CCN.net.series_blocks.2.3.conv2.weight': -452.53466796875, 'CCN.net.series_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.3.bn2.weight': 44.13803482055664, 'CCN.net.series_blocks.1.2.bn3.weight': 51.87647247314453, 'CCN.net.parallel_blocks.2.0.downsample.1.bias': -10.244501113891602, 'CCN.net.series_blocks.2.5.bn1.weight': 47.10686492919922, 'CCN.net.parallel_blocks.1.2.conv1.weight': -51.32628631591797, 'CCN.net.series_blocks.2.2.conv2.weight': -419.3601379394531, 'CCN.net.parallel_blocks.0.2.bn2.bias': -3.1067214012145996, 'CCN.net.series_blocks.2.5.bn3.weight': 108.74171447753906, 'CCN.net.parallel_blocks.2.1.bn2.weight': 47.70252990722656, 'CCN.net.parallel_blocks.1.1.bn2.weight': 20.93747329711914, 'CCN.net.series_blocks.2.1.bn1.weight': 40.19976043701172, 'CCN.net.series_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.1.3.bn1.weight': 21.7882137298584, 'CCN.net.parallel_blocks.2.5.conv3.weight': -606.1807861328125, 'CCN.net.series_blocks.1.2.conv2.weight': -49.043304443359375, 'CCN.net.parallel_blocks.1.0.downsample.0.weight': -46.38568115234375, 'CCN.net.parallel_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.series_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.0.bn1.bias': -32.74672317504883, 'CCN.net.parallel_blocks.2.2.conv1.weight': -136.44851684570312, 'CCN.net.parallel_blocks.2.0.bn3.weight': 141.13339233398438, 'CCN.net.parallel_blocks.1.0.conv1.weight': -49.65019989013672, 'CCN.net.parallel_blocks.2.2.bn1.bias': -11.770919799804688, 'CCN.net.series_blocks.0.1.bn1.bias': -1.295539379119873, 'CCN.net.series_blocks.2.1.bn3.weight': 104.63200378417969, 'CCN.net.series_blocks.1.0.conv2.weight': -79.73009490966797, 'CCN.net.parallel_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.parallel_blocks.2.1.bn3.bias': -54.8338508605957, 'CCN.net.parallel_blocks.0.1.conv1.weight': 22.047794342041016, 'CCN.net.conv1.weight': -4.65757942199707, 'CCN.net.parallel_blocks.0.2.conv1.weight': 1.987381935119629, 'CCN.net.series_blocks.0.2.conv2.weight': -31.46959686279297, 'CCN.net.series_blocks.2.0.bn3.bias': -10.244501113891602, 'CCN.net.parallel_blocks.1.1.bn1.weight': 14.939726829528809, 'CCN.net.parallel_blocks.2.3.conv3.weight': -305.9095458984375, 'CCN.net.series_blocks.2.4.conv1.weight': -264.8551330566406, 'CCN.net.series_blocks.2.1.bn1.bias': -3.477635383605957, 'CCN.net.parallel_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.bn1.weight': 16.472471237182617, 'CCN.net.series_blocks.0.1.conv3.weight': -3.0874505043029785, 'CCN.net.series_blocks.2.5.bn3.bias': -113.74501037597656, 'CCN.net.parallel_blocks.0.0.downsample.1.bias': 7.647769927978516, 'CCN.net.series_blocks.2.4.conv2.weight': -555.3164672851562, 'CCN.net.parallel_blocks.1.3.conv2.weight': -109.66592407226562, 'CCN.net.series_blocks.2.3.bn2.bias': -17.018157958984375, 'CCN.net.parallel_blocks.0.2.bn3.weight': 19.02667999267578, 'CCN.net.series_blocks.1.2.bn1.weight': 21.876338958740234, 'CCN.net.series_blocks.2.0.bn1.weight': 59.77009963989258, 'CCN.net.series_blocks.1.1.bn1.bias': 5.442982196807861}
INFO:root:===> Updating meta network
